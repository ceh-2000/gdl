{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232f433-696e-4b0b-a987-5cec2fc06a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender GPS\n",
    "%run main.py --cfg configs/GPS/neural-GPS+RWSE+small.yaml  wandb.use False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "842ff2b8-271d-49fb-bf9d-bbf5c4d95b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-21 11:39:59.645531\n",
      "[*] Loaded dataset 'HCPGender' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1078000, 1000], edge_index=[2, 49133748], y=[1078])\n",
      "  undirected: True\n",
      "  num graphs: 1078\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 2\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [06:23<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:06:40.62\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [03:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:03:47.60\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPGender\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: CustomGatedGCN+Exphormer\n",
      "  layers: 3\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 27\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Gender\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Gender\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 2\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 233028\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 714.43064, 'eta': 18575.19658, 'eta_hours': 5.15978, 'loss': 0.69485321, 'lr': 0.0, 'params': 233028, 'time_iter': 13.2302, 'accuracy': 0.47448, 'precision': 0.41944, 'recall': 0.38228, 'f1': 0.4, 'auc': 0.45734}\n",
      "...computing epoch stats took: 0.32s\n",
      "val: {'epoch': 0, 'time_epoch': 7.88273, 'loss': 0.69522598, 'lr': 0, 'params': 233028, 'time_iter': 1.1261, 'accuracy': 0.43519, 'precision': 0.33333, 'recall': 0.2449, 'f1': 0.28235, 'auc': 0.41577}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 0, 'time_epoch': 7.89998, 'loss': 0.69651492, 'lr': 0, 'params': 233028, 'time_iter': 1.12857, 'accuracy': 0.46296, 'precision': 0.32, 'recall': 0.16327, 'f1': 0.21622, 'auc': 0.37945}\n",
      "...computing epoch stats took: 0.03s\n",
      "> Epoch 0: took 730.6s (avg 730.6s) | Best so far: epoch 0\ttrain_loss: 0.6949 train_accuracy: 0.4745\tval_loss: 0.6952 val_accuracy: 0.4352\ttest_loss: 0.6965 test_accuracy: 0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gender Exphormer\n",
    "%run main.py --cfg configs/Exphormer/neural-Gender.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846350fa-d6ad-4cbe-9c1a-4480fef49865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-20 11:38:36.724242\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 7\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [06:01<00:00, 20.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:06:09.38\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [01:48<00:00, 68.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:52.96\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=400, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 5\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 10\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act\n",
      "params: 233028\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 197319\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 43.63662, 'eta': 392.7296, 'eta_hours': 0.10909, 'loss': 1.95121648, 'lr': 0.0, 'params': 197319, 'time_iter': 0.11699, 'accuracy': 0.14125, 'f1': 0.06135, 'auc': 0.48182}\n",
      "...computing epoch stats took: 0.40s\n",
      "val: {'epoch': 0, 'time_epoch': 2.85975, 'loss': 1.95126557, 'lr': 0, 'params': 197319, 'time_iter': 0.06085, 'accuracy': 0.15591, 'f1': 0.07634, 'auc': 0.48324}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 0, 'time_epoch': 2.81073, 'loss': 1.959684, 'lr': 0, 'params': 197319, 'time_iter': 0.0598, 'accuracy': 0.10738, 'f1': 0.05241, 'auc': 0.48665}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 49.8s (avg 49.8s) | Best so far: epoch 0\ttrain_loss: 1.9512 train_accuracy: 0.1412\tval_loss: 1.9513 val_accuracy: 0.1559\ttest_loss: 1.9597 test_accuracy: 0.1074\n",
      "train: {'epoch': 1, 'time_epoch': 40.25741, 'eta': 335.57612, 'eta_hours': 0.09322, 'loss': 1.71560727, 'lr': 0.0002, 'params': 197319, 'time_iter': 0.10793, 'accuracy': 0.60531, 'f1': 0.61, 'auc': 0.88591}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 1, 'time_epoch': 2.57601, 'loss': 1.53831209, 'lr': 0, 'params': 197319, 'time_iter': 0.05481, 'accuracy': 0.80108, 'f1': 0.8008, 'auc': 0.96399}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 2.76981, 'loss': 1.53521613, 'lr': 0, 'params': 197319, 'time_iter': 0.05893, 'accuracy': 0.79732, 'f1': 0.79694, 'auc': 0.96741}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 1: took 45.7s (avg 47.7s) | Best so far: epoch 1\ttrain_loss: 1.7156 train_accuracy: 0.6053\tval_loss: 1.5383 val_accuracy: 0.8011\ttest_loss: 1.5352 test_accuracy: 0.7973\n",
      "train: {'epoch': 2, 'time_epoch': 40.11333, 'eta': 289.35051, 'eta_hours': 0.08038, 'loss': 1.32076193, 'lr': 0.0004, 'params': 197319, 'time_iter': 0.10754, 'accuracy': 0.85556, 'f1': 0.85417, 'auc': 0.97328}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 2, 'time_epoch': 2.60456, 'loss': 1.12566705, 'lr': 0, 'params': 197319, 'time_iter': 0.05542, 'accuracy': 0.91398, 'f1': 0.91706, 'auc': 0.98692}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 2, 'time_epoch': 2.60508, 'loss': 1.1397886, 'lr': 0, 'params': 197319, 'time_iter': 0.05543, 'accuracy': 0.88322, 'f1': 0.88182, 'auc': 0.98465}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 2: took 45.4s (avg 47.0s) | Best so far: epoch 2\ttrain_loss: 1.3208 train_accuracy: 0.8556\tval_loss: 1.1257 val_accuracy: 0.9140\ttest_loss: 1.1398 test_accuracy: 0.8832\n",
      "train: {'epoch': 3, 'time_epoch': 42.16109, 'eta': 249.25267, 'eta_hours': 0.06924, 'loss': 0.92047738, 'lr': 0.0006, 'params': 197319, 'time_iter': 0.11303, 'accuracy': 0.91468, 'f1': 0.9144, 'auc': 0.9858}\n",
      "val: {'epoch': 3, 'time_epoch': 3.08572, 'loss': 0.78992649, 'lr': 0, 'params': 197319, 'time_iter': 0.06565, 'accuracy': 0.88978, 'f1': 0.89179, 'auc': 0.98835}\n",
      "test: {'epoch': 3, 'time_epoch': 3.17326, 'loss': 0.80055277, 'lr': 0, 'params': 197319, 'time_iter': 0.06752, 'accuracy': 0.87651, 'f1': 0.88051, 'auc': 0.9874}\n",
      "> Epoch 3: took 48.5s (avg 47.3s) | Best so far: epoch 2\ttrain_loss: 1.3208 train_accuracy: 0.8556\tval_loss: 1.1257 val_accuracy: 0.9140\ttest_loss: 1.1398 test_accuracy: 0.8832\n",
      "train: {'epoch': 4, 'time_epoch': 44.26339, 'eta': 210.43183, 'eta_hours': 0.05845, 'loss': 0.63259634, 'lr': 0.0008, 'params': 197319, 'time_iter': 0.11867, 'accuracy': 0.91821, 'f1': 0.91789, 'auc': 0.98659}\n",
      "val: {'epoch': 4, 'time_epoch': 2.82808, 'loss': 0.50946026, 'lr': 0, 'params': 197319, 'time_iter': 0.06017, 'accuracy': 0.92876, 'f1': 0.92988, 'auc': 0.99304}\n",
      "test: {'epoch': 4, 'time_epoch': 3.17647, 'loss': 0.51768905, 'lr': 0, 'params': 197319, 'time_iter': 0.06758, 'accuracy': 0.92752, 'f1': 0.92728, 'auc': 0.991}\n",
      "> Epoch 4: took 50.4s (avg 47.9s) | Best so far: epoch 4\ttrain_loss: 0.6326 train_accuracy: 0.9182\tval_loss: 0.5095 val_accuracy: 0.9288\ttest_loss: 0.5177 test_accuracy: 0.9275\n",
      "train: {'epoch': 5, 'time_epoch': 44.21792, 'eta': 169.7665, 'eta_hours': 0.04716, 'loss': 0.45073063, 'lr': 0.001, 'params': 197319, 'time_iter': 0.11855, 'accuracy': 0.92291, 'f1': 0.9226, 'auc': 0.98965}\n",
      "val: {'epoch': 5, 'time_epoch': 2.85407, 'loss': 0.46997651, 'lr': 0, 'params': 197319, 'time_iter': 0.06072, 'accuracy': 0.89785, 'f1': 0.89636, 'auc': 0.98876}\n",
      "test: {'epoch': 5, 'time_epoch': 3.38891, 'loss': 0.41943259, 'lr': 0, 'params': 197319, 'time_iter': 0.0721, 'accuracy': 0.91544, 'f1': 0.91204, 'auc': 0.98847}\n",
      "> Epoch 5: took 50.6s (avg 48.4s) | Best so far: epoch 4\ttrain_loss: 0.6326 train_accuracy: 0.9182\tval_loss: 0.5095 val_accuracy: 0.9288\ttest_loss: 0.5177 test_accuracy: 0.9275\n",
      "train: {'epoch': 6, 'time_epoch': 44.31002, 'eta': 128.12562, 'eta_hours': 0.03559, 'loss': 0.30322027, 'lr': 0.00090451, 'params': 197319, 'time_iter': 0.11879, 'accuracy': 0.94793, 'f1': 0.94786, 'auc': 0.99365}\n",
      "val: {'epoch': 6, 'time_epoch': 2.90828, 'loss': 0.30798846, 'lr': 0, 'params': 197319, 'time_iter': 0.06188, 'accuracy': 0.93414, 'f1': 0.93575, 'auc': 0.99407}\n",
      "test: {'epoch': 6, 'time_epoch': 3.63265, 'loss': 0.27919137, 'lr': 0, 'params': 197319, 'time_iter': 0.07729, 'accuracy': 0.94631, 'f1': 0.94366, 'auc': 0.99402}\n",
      "> Epoch 6: took 50.9s (avg 48.7s) | Best so far: epoch 6\ttrain_loss: 0.3032 train_accuracy: 0.9479\tval_loss: 0.3080 val_accuracy: 0.9341\ttest_loss: 0.2792 test_accuracy: 0.9463\n",
      "train: {'epoch': 7, 'time_epoch': 43.99584, 'eta': 85.7389, 'eta_hours': 0.02382, 'loss': 0.21025146, 'lr': 0.00065451, 'params': 197319, 'time_iter': 0.11795, 'accuracy': 0.96523, 'f1': 0.96521, 'auc': 0.9957}\n",
      "val: {'epoch': 7, 'time_epoch': 2.73069, 'loss': 0.23649922, 'lr': 0, 'params': 197319, 'time_iter': 0.0581, 'accuracy': 0.95027, 'f1': 0.95115, 'auc': 0.99708}\n",
      "test: {'epoch': 7, 'time_epoch': 2.70064, 'loss': 0.22056685, 'lr': 0, 'params': 197319, 'time_iter': 0.05746, 'accuracy': 0.95973, 'f1': 0.95925, 'auc': 0.99588}\n",
      "> Epoch 7: took 49.5s (avg 48.8s) | Best so far: epoch 7\ttrain_loss: 0.2103 train_accuracy: 0.9652\tval_loss: 0.2365 val_accuracy: 0.9503\ttest_loss: 0.2206 test_accuracy: 0.9597\n",
      "train: {'epoch': 8, 'time_epoch': 41.84234, 'eta': 42.75533, 'eta_hours': 0.01188, 'loss': 0.1481795, 'lr': 0.00034549, 'params': 197319, 'time_iter': 0.11218, 'accuracy': 0.97968, 'f1': 0.97965, 'auc': 0.99812}\n",
      "val: {'epoch': 8, 'time_epoch': 2.72323, 'loss': 0.19328197, 'lr': 0, 'params': 197319, 'time_iter': 0.05794, 'accuracy': 0.96237, 'f1': 0.9634, 'auc': 0.99549}\n",
      "test: {'epoch': 8, 'time_epoch': 2.66356, 'loss': 0.197799, 'lr': 0, 'params': 197319, 'time_iter': 0.05667, 'accuracy': 0.96107, 'f1': 0.9614, 'auc': 0.99597}\n",
      "> Epoch 8: took 47.3s (avg 48.7s) | Best so far: epoch 8\ttrain_loss: 0.1482 train_accuracy: 0.9797\tval_loss: 0.1933 val_accuracy: 0.9624\ttest_loss: 0.1978 test_accuracy: 0.9611\n",
      "train: {'epoch': 9, 'time_epoch': 41.00265, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.10765356, 'lr': 9.549e-05, 'params': 197319, 'time_iter': 0.10993, 'accuracy': 0.99026, 'f1': 0.99024, 'auc': 0.99946}\n",
      "val: {'epoch': 9, 'time_epoch': 2.58388, 'loss': 0.17106122, 'lr': 0, 'params': 197319, 'time_iter': 0.05498, 'accuracy': 0.97177, 'f1': 0.97262, 'auc': 0.99701}\n",
      "test: {'epoch': 9, 'time_epoch': 2.61222, 'loss': 0.18624892, 'lr': 0, 'params': 197319, 'time_iter': 0.05558, 'accuracy': 0.9651, 'f1': 0.96418, 'auc': 0.9955}\n",
      "> Epoch 9: took 46.3s (avg 48.4s) | Best so far: epoch 9\ttrain_loss: 0.1077 train_accuracy: 0.9903\tval_loss: 0.1711 val_accuracy: 0.9718\ttest_loss: 0.1862 test_accuracy: 0.9651\n",
      "Avg time per epoch: 48.43s\n",
      "Total train loop time: 0.13h\n",
      "Task done, results saved in results\\neural-Act\\0\n",
      "9\n",
      "{'epoch': 9, 'time_epoch': 2.61222, 'loss': 0.18624892, 'lr': 0, 'params': 197319, 'time_iter': 0.05558, 'accuracy': 0.9651, 'f1': 0.96418, 'auc': 0.9955}\n",
      "{'epoch': 9, 'time_epoch': 41.00265, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.10765356, 'lr': 9.549e-05, 'params': 197319, 'time_iter': 0.10993, 'accuracy': 0.99026, 'f1': 0.99024, 'auc': 0.99946}\n",
      "{'epoch': 9, 'time_epoch': 2.58388, 'loss': 0.17106122, 'lr': 0, 'params': 197319, 'time_iter': 0.05498, 'accuracy': 0.97177, 'f1': 0.97262, 'auc': 0.99701}\n",
      "Results aggregated across runs saved in results\\neural-Act\\agg\n",
      "[*] All done: 2024-02-20 11:55:03.684028\n"
     ]
    }
   ],
   "source": [
    "#Activity\n",
    "%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892e84f-a7ee-409f-85c9-3bfdf360be5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-20 13:40:07.651888\n",
      "[*] Loaded dataset 'HCPAge' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1065000, 1000], edge_index=[2, 48551656], y=[1065])\n",
      "  undirected: True\n",
      "  num graphs: 1065\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 3\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [04:38<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:04:48.49\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [01:19<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:21.70\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 3, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPAge\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: CustomGatedGCN+Exphormer\n",
      "  layers: 3\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 10\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 3\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Age\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Age\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 3\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 233158\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 1363.54533, 'eta': 12271.90801, 'eta_hours': 3.40886, 'loss': 1.11467545, 'lr': 0.0, 'params': 233158, 'time_iter': 25.25084, 'accuracy': 0.22418, 'f1': 0.20771, 'auc': 0.46414}\n",
      "...computing epoch stats took: 0.26s\n",
      "val: {'epoch': 0, 'time_epoch': 91.5703, 'loss': 1.11029489, 'lr': 0, 'params': 233158, 'time_iter': 13.08147, 'accuracy': 0.27358, 'f1': 0.23307, 'auc': 0.40984}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 0, 'time_epoch': 110.75387, 'loss': 1.10129182, 'lr': 0, 'params': 233158, 'time_iter': 15.82198, 'accuracy': 0.31776, 'f1': 0.28284, 'auc': 0.51385}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 1566.2s (avg 1566.2s) | Best so far: epoch 0\ttrain_loss: 1.1147 train_accuracy: 0.2242\tval_loss: 1.1103 val_accuracy: 0.2736\ttest_loss: 1.1013 test_accuracy: 0.3178\n",
      "train: {'epoch': 1, 'time_epoch': 2199.92035, 'eta': 14253.86272, 'eta_hours': 3.95941, 'loss': 1.07860017, 'lr': 0.00033333, 'params': 233158, 'time_iter': 40.73927, 'accuracy': 0.40141, 'f1': 0.35093, 'auc': 0.54923}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 1, 'time_epoch': 91.46539, 'loss': 1.05762855, 'lr': 0, 'params': 233158, 'time_iter': 13.06648, 'accuracy': 0.43396, 'f1': 0.31467, 'auc': 0.62942}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 110.66893, 'loss': 1.08493008, 'lr': 0, 'params': 233158, 'time_iter': 15.80985, 'accuracy': 0.45794, 'f1': 0.39594, 'auc': 0.52786}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 2402.1s (avg 1984.1s) | Best so far: epoch 1\ttrain_loss: 1.0786 train_accuracy: 0.4014\tval_loss: 1.0576 val_accuracy: 0.4340\ttest_loss: 1.0849 test_accuracy: 0.4579\n",
      "train: {'epoch': 2, 'time_epoch': 2214.88254, 'eta': 13482.81251, 'eta_hours': 3.74523, 'loss': 1.04535089, 'lr': 0.00066667, 'params': 233158, 'time_iter': 41.01634, 'accuracy': 0.46714, 'f1': 0.33579, 'auc': 0.59888}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 2, 'time_epoch': 91.43079, 'loss': 1.08953633, 'lr': 0, 'params': 233158, 'time_iter': 13.06154, 'accuracy': 0.26415, 'f1': 0.1393, 'auc': 0.59721}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 2, 'time_epoch': 110.7228, 'loss': 1.10921701, 'lr': 0, 'params': 233158, 'time_iter': 15.81754, 'accuracy': 0.3271, 'f1': 0.16432, 'auc': 0.47547}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 2417.1s (avg 2128.5s) | Best so far: epoch 1\ttrain_loss: 1.0786 train_accuracy: 0.4014\tval_loss: 1.0576 val_accuracy: 0.4340\ttest_loss: 1.0849 test_accuracy: 0.4579\n",
      "train: {'epoch': 3, 'time_epoch': 2216.74517, 'eta': 11992.64008, 'eta_hours': 3.33129, 'loss': 0.99738129, 'lr': 0.001, 'params': 233158, 'time_iter': 41.05084, 'accuracy': 0.53521, 'f1': 0.44481, 'auc': 0.68102}\n",
      "val: {'epoch': 3, 'time_epoch': 91.43098, 'loss': 1.02285994, 'lr': 0, 'params': 233158, 'time_iter': 13.06157, 'accuracy': 0.50943, 'f1': 0.26667, 'auc': 0.60059}\n",
      "test: {'epoch': 3, 'time_epoch': 110.67339, 'loss': 1.08958989, 'lr': 0, 'params': 233158, 'time_iter': 15.81048, 'accuracy': 0.41121, 'f1': 0.21091, 'auc': 0.54696}\n",
      "> Epoch 3: took 2418.9s (avg 2201.1s) | Best so far: epoch 3\ttrain_loss: 0.9974 train_accuracy: 0.5352\tval_loss: 1.0229 val_accuracy: 0.5094\ttest_loss: 1.0896 test_accuracy: 0.4112\n",
      "train: {'epoch': 4, 'time_epoch': 2171.91142, 'eta': 10167.00481, 'eta_hours': 2.82417, 'loss': 0.92529952, 'lr': 0.00095048, 'params': 233158, 'time_iter': 40.22058, 'accuracy': 0.60211, 'f1': 0.52936, 'auc': 0.76089}\n",
      "val: {'epoch': 4, 'time_epoch': 91.42724, 'loss': 1.06716274, 'lr': 0, 'params': 233158, 'time_iter': 13.06103, 'accuracy': 0.46226, 'f1': 0.2922, 'auc': 0.58248}\n",
      "test: {'epoch': 4, 'time_epoch': 110.66832, 'loss': 1.10031086, 'lr': 0, 'params': 233158, 'time_iter': 15.80976, 'accuracy': 0.47664, 'f1': 0.3384, 'auc': 0.57124}\n",
      "> Epoch 4: took 2374.1s (avg 2235.7s) | Best so far: epoch 3\ttrain_loss: 0.9974 train_accuracy: 0.5352\tval_loss: 1.0229 val_accuracy: 0.5094\ttest_loss: 1.0896 test_accuracy: 0.4112\n",
      "train: {'epoch': 5, 'time_epoch': 2192.6559, 'eta': 8239.77381, 'eta_hours': 2.28883, 'loss': 0.84553316, 'lr': 0.00081174, 'params': 233158, 'time_iter': 40.60474, 'accuracy': 0.68545, 'f1': 0.65177, 'auc': 0.82802}\n",
      "val: {'epoch': 5, 'time_epoch': 91.43619, 'loss': 1.04599548, 'lr': 0, 'params': 233158, 'time_iter': 13.06231, 'accuracy': 0.43396, 'f1': 0.39069, 'auc': 0.64656}\n",
      "test: {'epoch': 5, 'time_epoch': 110.66505, 'loss': 1.10720728, 'lr': 0, 'params': 233158, 'time_iter': 15.80929, 'accuracy': 0.36449, 'f1': 0.33056, 'auc': 0.56535}\n",
      "> Epoch 5: took 2394.8s (avg 2262.2s) | Best so far: epoch 3\ttrain_loss: 0.9974 train_accuracy: 0.5352\tval_loss: 1.0229 val_accuracy: 0.5094\ttest_loss: 1.0896 test_accuracy: 0.4112\n"
     ]
    }
   ],
   "source": [
    "#Age\n",
    "%run main.py --cfg configs/Exphormer/neural-Age.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3620e-cb63-486c-bea3-3c685b4a4178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
