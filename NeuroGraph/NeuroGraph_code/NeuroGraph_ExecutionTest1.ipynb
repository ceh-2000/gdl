{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32937f6d-42c8-4157-affb-751b2faaa68c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NeuroGraph.datasets import NeuroGraphDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3dbb7a-0e14-4d81-95d5-b7cbd2c68bb6",
   "metadata": {},
   "source": [
    "## Loading Benchmark Dataset\n",
    "\n",
    "NeuroGraph provides two classes for loading static and dynamic benchmark datastes. For this project we have decided to analyze the static ones, specifically we are targeting to improve scores obtained for the HPC-age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2ab628-4210-4090-af97-29cfa418ec81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_gender = NeuroGraphDataset(root=\"data/\", name= \"HCPGender\")\n",
    "#dataset_task = NeuroGraphDataset(root=\"data/\", name= \"HCPActivity\")\n",
    "#dataset_age = NeuroGraphDataset(root=\"data/\", name= \"HCPAge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d741e0d5-07f4-485e-b906-b8e6501319ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c0abe-de4b-491c-acb8-686ede900975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab474f4-1045-4185-8cb4-c3490a3a12dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "#2.0.4\n",
    "print(torch_geometric.__version__)\n",
    "#!pip install torch-geometric==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9ec6a7-b1bd-4308-83ae-014050fc9a70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "2\n",
      "1000\n",
      "Activity\n",
      "7\n",
      "400\n",
      "Age\n",
      "3\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Gender\")\n",
    "print(dataset_gender.num_classes)\n",
    "print(dataset_gender.num_features)\n",
    "\n",
    "print(\"Activity\")\n",
    "print(dataset_task.num_classes)\n",
    "print(dataset_task.num_features)\n",
    "\n",
    "print(\"Age\")\n",
    "print(dataset_age.num_classes)\n",
    "print(dataset_age.num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd87947-51b4-48f7-8eec-dadd580018ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dynamic datasets we can use \n",
    "#data_obj = NeuroGraphDynamic(root=\"data/\", name= \"DynHCPGender\")\n",
    "#dataset = data_obj.dataset\n",
    "#labels = data_obj.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60bc482b-6c98-44d8-adcc-7742f3f5b17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "2\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Gender\")\n",
    "print(dataset_gender.num_classes)\n",
    "print(dataset_gender.num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df176523-f94e-40a5-b022-a6d971c3c582",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "Here we follow NeuroGraph to preprocess the data to construct functional connectomes and generate corresponding graphs-based representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca722984-b918-4950-b9f4-6219415739d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuroGraph import utils\n",
    "\n",
    "# fmri and regs could be numpy arrays\n",
    "fc = utils.preprocess(fmri, regs, n_rois= 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142c11b-c33d-499f-b7f9-f2e910f3a900",
   "metadata": {},
   "source": [
    "The corresponding Adjacency matrix and PyG data objects can be created from the functional_connectome as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe36b93-83e6-4a71-90fe-9fe134c0b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuroGraph import utils\n",
    "\n",
    "adj = utils.construct_adj(fc, threshold= 5) # construct the adjacency matrix\n",
    "data = utils.construct_data(fc, label= 1,threshold = 5) # construct PyG data object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bf794e-c62d-428f-aeca-a5976f99e2fd",
   "metadata": {},
   "source": [
    "NG use correlation as node features while constructing data object from functional connectome.\n",
    "\n",
    "The following is the source code for processing one fMRI scan with corresponding regressor using NG preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a5356b-63a7-4dcc-946c-5c451160d724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuroGraph import utils\n",
    "import numpy as np\n",
    "from nilearn.image import load_img\n",
    "\n",
    "img = load_img(\"data/raw/1.nii.gz\") # 1.nii.gz is fMRI scan\n",
    "regs = np.loadtxt(\"data/raw/1.txt\") # 1.txt is the movement regressor\n",
    "\n",
    "fmri = img.get_fdata()\n",
    "fc = utils.preprocess(fmri, regs, n_rois= 100)\n",
    "adj = utils.construct_adj(fc, threshold= 5) # construct the adjacency matrix\n",
    "data = utils.construct_data(fc, label = 1,threshold = 5) # construct torch Data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225c019-95bf-4faa-81c3-378da50c5d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2afb108-5618-462b-881c-e5cafc26b662",
   "metadata": {},
   "source": [
    "## NG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e43431d-008f-461e-a21f-06648d3baeb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch import nn\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.nn import aggr\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import APPNP, MLP, GCNConv, GINConv, SAGEConv, GraphConv, TransformerConv, ChebConv, GATConv, SGConv, GeneralConv\n",
    "from torch.nn import Conv1d, MaxPool1d, ModuleList\n",
    "import random\n",
    "import math\n",
    "softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "class ResidualGNNs(torch.nn.Module):\n",
    "    def __init__(self,args, train_dataset, hidden_channels,hidden, num_layers, GNN, k=0.6):\n",
    "        super().__init__()\n",
    "        self.convs = ModuleList()\n",
    "        self.aggr = aggr.MeanAggregation()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        num_features = train_dataset.num_features\n",
    "        if args['model']==\"ChebConv\":\n",
    "            if num_layers>0:\n",
    "                self.convs.append(GNN(num_features, hidden_channels,K=5))\n",
    "                for i in range(0, num_layers - 1):\n",
    "                    self.convs.append(GNN(hidden_channels, hidden_channels,K=5))\n",
    "        else:\n",
    "            if num_layers>0:\n",
    "                self.convs.append(GNN(num_features, hidden_channels))\n",
    "                for i in range(0, num_layers - 1):\n",
    "                    self.convs.append(GNN(hidden_channels, hidden_channels))\n",
    "        \n",
    "        input_dim1 = int(((num_features * num_features)/2)- (num_features/2)+(hidden_channels*num_layers))\n",
    "        input_dim = int(((num_features * num_features)/2)- (num_features/2))\n",
    "        self.bn = nn.BatchNorm1d(input_dim)\n",
    "        self.bnh = nn.BatchNorm1d(hidden_channels*num_layers)\n",
    "        # self.attention = Attention(input_dim1, hidden_channels)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim1, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden, hidden//2),\n",
    "            nn.BatchNorm1d(hidden//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden//2, hidden//2),\n",
    "            nn.BatchNorm1d(hidden//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear((hidden//2), args['num_classes']),\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # for conv in self.convs:\n",
    "        #     x = conv(x, edge_index).relu()\n",
    "        \n",
    "        xs = [x]        \n",
    "        for conv in self.convs:\n",
    "            xs += [conv(xs[-1], edge_index).tanh()]\n",
    "        h = []\n",
    "        for i, xx in enumerate(xs):\n",
    "            if i== 0:\n",
    "                xx = xx.reshape(data.num_graphs, x.shape[1],-1)\n",
    "                x = torch.stack([t.triu().flatten()[t.triu().flatten().nonzero(as_tuple=True)] for t in xx])\n",
    "                x = self.bn(x)\n",
    "            else:\n",
    "                # xx = xx.reshape(data.num_graphs, x.shape[1],-1)\n",
    "                xx = self.aggr(xx,batch)\n",
    "                # h.append(torch.stack([t.flatten() for t in xx]))\n",
    "                h.append(xx)\n",
    "        \n",
    "        h = torch.cat(h,dim=1)\n",
    "        h = self.bnh(h)\n",
    "        # x = torch.stack(h, dim=0)\n",
    "        x = torch.cat((x,h),dim=1)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ce635-8994-446d-83b1-f359814528cb",
   "metadata": {},
   "source": [
    "## Applying NG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb94307c-0d38-46db-b34b-6921199989db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NeuroGraph.datasets import NeuroGraphDataset\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "import os,random\n",
    "import os.path as osp\n",
    "import sys\n",
    "import time\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37aa9bc9-7cd0-4fd1-9f1d-dc034f08829a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args={'dataset':'HCPGender',\n",
    "      'runs':1,\n",
    "      'device':'cuda',\n",
    "      'seed':123,\n",
    "      'model':\"GCNConv\",\n",
    "      'hidden':32,\n",
    "      'hidden_mlp':64,\n",
    "      'num_layers':3,\n",
    "      'epochs':100,\n",
    "      'echo_epoch':50,\n",
    "      'batch_size':16,\n",
    "      'early_stopping':50,\n",
    "      'lr':1e-5,\n",
    "      'weight_decay':0.0005,\n",
    "      'dropout':0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "565dee6c-162c-4f99-81d6-719f68363f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"base_params/\"\n",
    "res_path = \"results/\"\n",
    "root = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbb22e05-e89e-4a5b-a9df-ba4829dba5b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "if not os.path.isdir(res_path):\n",
    "    os.mkdir(res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924973eb-f300-46f6-98c8-96fc581a61fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logger(info):\n",
    "    f = open(os.path.join(res_path, 'results_new.csv'), 'a')\n",
    "    print(info, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "242401c7-7a9f-4f50-968d-86ed080b5e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fix seed\n",
    "torch.manual_seed(args['seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args['seed'])\n",
    "random.seed(args['seed'])\n",
    "np.random.seed(args['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ac27498-c7e1-429f-a941-97dcf5a02523",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1078\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "dataset=dataset_gender\n",
    "#dataset = NeuroGraphDataset(root=root, name= args.dataset)\n",
    "print(dataset.num_classes)\n",
    "print(len(dataset))\n",
    "print(dataset.num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62c2725b-761e-497e-a4c6-f263aac9a6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [d.y.item() for d in dataset]\n",
    "train_tmp, test_indices = train_test_split(list(range(len(labels))),\n",
    "                        test_size=0.2, stratify=labels,random_state=123,shuffle= True)\n",
    "tmp = dataset[train_tmp]\n",
    "train_labels = [d.y.item() for d in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f4e6fc7-2f32-4647-aa6e-3a0026d57135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_indices, val_indices = train_test_split(list(range(len(train_labels))),\n",
    " test_size=0.125, stratify=train_labels,random_state=123,shuffle = True)\n",
    "train_dataset = tmp[train_indices]\n",
    "val_dataset = tmp[val_indices]\n",
    "test_dataset = dataset[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed38b4bb-3db0-4b5c-b3c1-c71ad97197f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset HCPGender loaded with train 754 val 108 test 216 splits\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset {} loaded with train {} val {} test {} splits\".format(args['dataset'],len(train_dataset), len(val_dataset), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "982c6f4f-eae6-446f-b530-5d19a505d002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, args['batch_size'], shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, args['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, args['batch_size'], shuffle=False)\n",
    "args['num_features'],args['num_classes']= dataset.num_features,dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04d204aa-cf94-447b-b99c-fbf46db122bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(train_loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:  \n",
    "        data = data.to(args['device'])\n",
    "        out = model(data)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y) \n",
    "        total_loss +=loss\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad()\n",
    "    return total_loss/len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bd3a4c8-489b-4047-8a0e-ef4f4152bdfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:  \n",
    "        data = data.to(args['device'])\n",
    "        out = model(data)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a77faaf0-1c18-4ad4-9053-d0f0282a0383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_acc_history, test_acc_history, test_loss_history = [],[],[]\n",
    "seeds = [123,124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39809964-350e-4ce1-abc7-6f4070bb13c6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualGNNs(\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConv(1000, 32)\n",
      "    (1-2): 2 x GCNConv(32, 32)\n",
      "  )\n",
      "  (aggr): MeanAggregation()\n",
      "  (bn): BatchNorm1d(499500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bnh): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=499596, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Linear(in_features=32, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters is: 33011002\n",
      "epoch: 0, loss: 0.046233, val_acc:0.47, test_acc:0.48\n",
      "epoch: 1, loss: 0.044995, val_acc:0.49, test_acc:0.61\n",
      "epoch: 2, loss: 0.045478, val_acc:0.51, test_acc:0.62\n",
      "epoch: 3, loss: 0.044936, val_acc:0.59, test_acc:0.69\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m best_val_acc,best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m---> 20\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m test(val_loader)\n\u001b[0;32m     22\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test(test_loader)\n",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      5\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:  \n\u001b[0;32m      7\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      8\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(data)  \u001b[38;5;66;03m# Perform a single forward pass.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuro1\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuro1\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuro1\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuro1\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py:27\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     25\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuro1\\lib\\site-packages\\torch_geometric\\data\\batch.py:97\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[1;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuro1\\lib\\site-packages\\torch_geometric\\data\\collate.py:109\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m value, slices, incs \u001b[38;5;241m=\u001b[39m \u001b[43m_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# If parts of the data are already on GPU, make sure that auxiliary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# data like `batch` or `ptr` are also created on GPU:\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_cuda:\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuro1\\lib\\site-packages\\torch_geometric\\data\\collate.py:204\u001b[0m, in \u001b[0;36m_collate\u001b[1;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[0;32m    201\u001b[0m         shape[cat_dim] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(slices[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    202\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;241m*\u001b[39mshape)\n\u001b[1;32m--> 204\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m increment \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, EdgeIndex) \u001b[38;5;129;01mand\u001b[39;00m values[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mis_sorted:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Check whether the whole `EdgeIndex` is sorted by row:\u001b[39;00m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m values[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mis_sorted_by_row \u001b[38;5;129;01mand\u001b[39;00m (value[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdiff() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index in range(args['runs']):\n",
    "    start = time.time()\n",
    "    torch.manual_seed(seeds[index])\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seeds[index])\n",
    "    random.seed(seeds[index])\n",
    "    np.random.seed(seeds[index])\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    gnn = eval(args['model'])\n",
    "    model = ResidualGNNs(args,train_dataset,args['hidden'],args['hidden_mlp'],args['num_layers'],gnn).to(args['device']) ## apply GNN*\n",
    "    print(model)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total number of parameters is: {total_params}\")\n",
    "    # model.reset_parameters()\n",
    "    optimizer = Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "    loss, test_acc = [],[]\n",
    "    best_val_acc,best_val_loss = 0.0,0.0\n",
    "    for epoch in range(args['epochs']):\n",
    "        loss = train(train_loader)\n",
    "        val_acc = test(val_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        # if epoch%10==0:\n",
    "        print(\"epoch: {}, loss: {}, val_acc:{}, test_acc:{}\".format(epoch, np.round(loss.item(),6), np.round(val_acc,2),np.round(test_acc,2)))\n",
    "        val_acc_history.append(val_acc)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            if epoch> int(args['epochs']/2):\n",
    "                torch.save(model.state_dict(), path + args['dataset']+args['model']+'task-checkpoint-best-acc.pkl')\n",
    "    \n",
    "    #test the model   \n",
    "    model.load_state_dict(torch.load(path + args['dataset']+args['model']+'task-checkpoint-best-acc.pkl'))\n",
    "    model.eval()\n",
    "    test_acc = test(test_loader)\n",
    "    test_loss = train(test_loader).item()\n",
    "    test_acc_history.append(test_acc)\n",
    "    test_loss_history.append(test_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7391dfb-387c-4c41-9276-946ba5a5ae5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "099ddca8-08e8-445d-93b1-db00de128167",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8796296296296297] [0.03500416502356529]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#test the model   \n",
    "model.load_state_dict(torch.load(path + args['dataset']+args['model']+'task-checkpoint-best-acc.pkl'))\n",
    "model.eval()\n",
    "test_acc = test(test_loader)\n",
    "test_loss = train(test_loader).item()\n",
    "test_acc_history.append(test_acc)\n",
    "test_loss_history.append(test_loss)\n",
    "print(test_acc_history, test_loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bfdd7f-e56c-487c-b8f4-05264615b2a7",
   "metadata": {},
   "source": [
    "Metrics obtained:\n",
    "- Age: 0.5\n",
    "- Gender 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1430a216-c570-4f30-bb86-3ed37826d643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90843272-0417-42e4-99ce-af62d7db93c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e0a3ab-c15a-4ae7-bb40-9ad0f113f83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3821e4d0-6994-41ff-8b90-bbe184d28c1c",
   "metadata": {},
   "source": [
    "# EXPHORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c78bd-c0ec-4caa-b162-64c7030fc60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Exphormer for LRGB Datasets\n",
    "%run main_exphormer.py --cfg configs/Exphormer_LRGB/peptides-struct-EX.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6185243f-f7a0-4f04-8b5e-99c684ddd05c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running Exphormer for Cifar10\n",
    "%run main_exphormer.py --cfg configs/Exphormer/cifar10.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "056efe44-e214-4e12-8008-368d3dc1a7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric as tg\n",
    "\n",
    "print(torch.__version__)\n",
    "#2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a49587a4-39af-4464-94ed-a1e384e46421",
   "metadata": {},
   "outputs": [],
   "source": [
    "xform_args={\n",
    "    'node_encoder':True,\n",
    "    'node_encoder_name': 'LinearNode+EquivStableLapPE',\n",
    "    'dim_inner':40,\n",
    "    'node_encoder_bn':False,\n",
    "    'edge_encoder':True,\n",
    "    'dim_edge':16,\n",
    "    'layer_type':'CustomGatedGCN+Exphormer',\n",
    "    'edge_encoder_name':'LinearEdge',\n",
    "    'dim_pe':cfg.posenc_ERE.dim_pe,\n",
    "'layers_pre_mp':0,\n",
    "'dim_hidden':40,\n",
    "'layers':5,\n",
    "'n_heads':4,\n",
    "'pna_degrees':cfg.gt.pna_degrees,\n",
    "'enable':True,\n",
    "'dropout':0.1,\n",
    "'attn_dropout':0.1,\n",
    "'layer_norm':False,\n",
    "'batch_norm':True,\n",
    "'bigbird':cfg.gt.bigbird,\n",
    "'head':'default'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18f127e1-2b0c-4b6a-99cd-159d955bb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_optimizer_config(cfg):\n",
    "    return OptimizerConfig(optimizer=cfg.optim.optimizer,\n",
    "                           base_lr=cfg.optim.base_lr,\n",
    "                           weight_decay=cfg.optim.weight_decay,\n",
    "                           momentum=cfg.optim.momentum)\n",
    "\n",
    "\n",
    "def new_scheduler_config(cfg):\n",
    "    return ExtendedSchedulerConfig(\n",
    "        scheduler=cfg.optim.scheduler,\n",
    "        steps=cfg.optim.steps, lr_decay=cfg.optim.lr_decay,\n",
    "        max_epoch=cfg.optim.max_epoch, reduce_factor=cfg.optim.reduce_factor,\n",
    "        schedule_patience=cfg.optim.schedule_patience, min_lr=cfg.optim.min_lr,\n",
    "        num_warmup_epochs=cfg.optim.num_warmup_epochs,\n",
    "        train_mode=cfg.train.mode, eval_period=cfg.train.eval_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "843cdd6e-23bd-4506-8ca4-a829f1069712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\exphormer\\lib\\site-packages\\torchaudio\\backend\\utils.py:67: UserWarning: No audio backend is available.\n",
      "  warnings.warn('No audio backend is available.')\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "import graphgps  # noqa, register custom modules\n",
    "from graphgps.optimizer.extra_optimizers import ExtendedSchedulerConfig\n",
    "\n",
    "from torch_geometric.graphgym.cmd_args import parse_args\n",
    "#from torch_geometric.graphgym.config import (cfg, dump_cfg,\n",
    "#                                             set_agg_dir, set_cfg, load_cfg,\n",
    "#                                             makedirs_rm_exist)\n",
    "from torch_geometric.graphgym.config import (cfg, dump_cfg,\n",
    "                                             set_cfg, load_cfg,\n",
    "                                             makedirs_rm_exist)\n",
    "from torch_geometric.graphgym.loader import create_loader\n",
    "from torch_geometric.graphgym.logger import set_printing\n",
    "from torch_geometric.graphgym.optim import create_optimizer, \\\n",
    "    create_scheduler, OptimizerConfig\n",
    "from torch_geometric.graphgym.model_builder import create_model\n",
    "from torch_geometric.graphgym.train import train\n",
    "from torch_geometric.graphgym.utils.agg_runs import agg_runs\n",
    "from torch_geometric.graphgym.utils.comp_budget import params_count\n",
    "from torch_geometric.graphgym.utils.device import auto_select_device\n",
    "from torch_geometric.graphgym.register import train_dict\n",
    "from torch_geometric import seed_everything\n",
    "\n",
    "from graphgps.finetuning import load_pretrained_model_cfg, \\\n",
    "    init_model_from_pretrained\n",
    "from graphgps.logger import create_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e866de70-2e46-4738-9af1-b7e0f1cf4c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric.graphgym.register as register\n",
    "from torch_geometric.graphgym.config import cfg\n",
    "from torch_geometric.graphgym.models.gnn import GNNPreMP\n",
    "from torch_geometric.graphgym.models.layer import (new_layer_config,\n",
    "                                                   BatchNorm1dNode)\n",
    "from torch_geometric.graphgym.register import register_network\n",
    "from graphgps.encoder.ER_edge_encoder import EREdgeEncoder\n",
    "\n",
    "from graphgps.layer.gps_layer import GPSLayer\n",
    "\n",
    "\n",
    "class FeatureEncoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Encoding node and edge features\n",
    "\n",
    "    Args:\n",
    "        dim_in (int): Input feature dimension\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_in):\n",
    "        super(FeatureEncoder, self).__init__()\n",
    "        self.dim_in = dim_in\n",
    "        if cfg.dataset.node_encoder:\n",
    "            # Encode integer node features via nn.Embeddings\n",
    "            NodeEncoder = register.node_encoder_dict[\n",
    "                cfg.dataset.node_encoder_name]\n",
    "            self.node_encoder = NodeEncoder(cfg.gnn.dim_inner)\n",
    "            if cfg.dataset.node_encoder_bn:\n",
    "                self.node_encoder_bn = BatchNorm1dNode(\n",
    "                    new_layer_config(cfg.gnn.dim_inner, -1, -1, has_act=False,\n",
    "                                     has_bias=False, cfg=cfg))\n",
    "            # Update dim_in to reflect the new dimension fo the node features\n",
    "            self.dim_in = cfg.gnn.dim_inner\n",
    "        if cfg.dataset.edge_encoder:\n",
    "            # Hard-set edge dim for PNA.\n",
    "            cfg.gnn.dim_edge = 16 if 'PNA' in cfg.gt.layer_type else cfg.gnn.dim_inner\n",
    "            if cfg.dataset.edge_encoder_name == 'ER':\n",
    "                self.edge_encoder = EREdgeEncoder(cfg.gnn.dim_edge)\n",
    "            elif cfg.dataset.edge_encoder_name.endswith('+ER'):\n",
    "                EdgeEncoder = register.edge_encoder_dict[\n",
    "                    cfg.dataset.edge_encoder_name[:-3]]\n",
    "                self.edge_encoder = EdgeEncoder(cfg.gnn.dim_edge - cfg.posenc_ERE.dim_pe)\n",
    "                self.edge_encoder_er = EREdgeEncoder(cfg.posenc_ERE.dim_pe, use_edge_attr=True)\n",
    "            else:\n",
    "                EdgeEncoder = register.edge_encoder_dict[\n",
    "                    cfg.dataset.edge_encoder_name]\n",
    "                self.edge_encoder = EdgeEncoder(cfg.gnn.dim_edge)\n",
    "\n",
    "            if cfg.dataset.edge_encoder_bn:\n",
    "                self.edge_encoder_bn = BatchNorm1dNode(\n",
    "                    new_layer_config(cfg.gnn.dim_edge, -1, -1, has_act=False,\n",
    "                                    has_bias=False, cfg=cfg))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        for module in self.children():\n",
    "            batch = module(batch)\n",
    "        return batch\n",
    "\n",
    "\n",
    "@register_network('GPSModel')\n",
    "class GPSModel(torch.nn.Module):\n",
    "    \"\"\"Multi-scale graph x-former.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.encoder = FeatureEncoder(dim_in)\n",
    "        dim_in = self.encoder.dim_in\n",
    "\n",
    "        if cfg.gnn.layers_pre_mp > 0:\n",
    "            self.pre_mp = GNNPreMP(\n",
    "                dim_in, cfg.gnn.dim_inner, cfg.gnn.layers_pre_mp)\n",
    "            dim_in = cfg.gnn.dim_inner\n",
    "\n",
    "        assert cfg.gt.dim_hidden == cfg.gnn.dim_inner == dim_in, \\\n",
    "            \"The inner and hidden dims must match.\"\n",
    "\n",
    "        try:\n",
    "            local_gnn_type, global_model_type = cfg.gt.layer_type.split('+')\n",
    "        except:\n",
    "            raise ValueError(f\"Unexpected layer type: {cfg.gt.layer_type}\")\n",
    "        layers = []\n",
    "        for _ in range(cfg.gt.layers):\n",
    "            layers.append(GPSLayer(\n",
    "                dim_h=cfg.gt.dim_hidden,\n",
    "                local_gnn_type=local_gnn_type,\n",
    "                global_model_type=global_model_type,\n",
    "                num_heads=cfg.gt.n_heads,\n",
    "                pna_degrees=cfg.gt.pna_degrees,\n",
    "                equivstable_pe=cfg.posenc_EquivStableLapPE.enable,\n",
    "                dropout=cfg.gt.dropout,\n",
    "                attn_dropout=cfg.gt.attn_dropout,\n",
    "                layer_norm=cfg.gt.layer_norm,\n",
    "                batch_norm=cfg.gt.batch_norm,\n",
    "                bigbird_cfg=cfg.gt.bigbird,\n",
    "            ))\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "\n",
    "        GNNHead = register.head_dict[cfg.gnn.head]\n",
    "        self.post_mp = GNNHead(dim_in=cfg.gnn.dim_inner, dim_out=dim_out)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        for module in self.children():\n",
    "            batch = module(batch)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98275d71-2b43-4500-b43f-b89455b78fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW \n",
    "class FeatureEncoder(torch.nn.Module):\n",
    "    def __init__(self, dim_in):\n",
    "        super(FeatureEncoder, self).__init__()\n",
    "        self.dim_in = dim_in\n",
    "        if xform_args['node_encoder']:\n",
    "            # Encode integer node features via nn.Embeddings\n",
    "            NodeEncoder = register.node_encoder_dict[\n",
    "                xform_args['node_encoder_name']]\n",
    "            self.node_encoder = NodeEncoder(xform_args['dim_inner'])\n",
    "            if xform_args['node_encoder_bn']:\n",
    "                self.node_encoder_bn = BatchNorm1dNode(\n",
    "                    new_layer_config(xform_args['dim_inner'], -1, -1, has_act=False,\n",
    "                                     has_bias=False, cfg=cfg))\n",
    "            # Update dim_in to reflect the new dimension fo the node features\n",
    "            self.dim_in = xform_args['dim_inner']\n",
    "        if xform_args['edge_encoder']:\n",
    "            # Hard-set edge dim for PNA.\n",
    "            xform_args['dim_edge'] = 16 if 'PNA' in xform_args['layer_type'] else xform_args['dim_inner']\n",
    "            if xform_args['edge_encoder_name'] == 'ER':\n",
    "                self.edge_encoder = EREdgeEncoder(xform_args['dim_edge'])\n",
    "            elif xform_args['edge_encoder_name'].endswith('+ER'):\n",
    "                EdgeEncoder = register.edge_encoder_dict[\n",
    "                    xform_args['edge_encoder_name'][:-3]]\n",
    "                self.edge_encoder = EdgeEncoder(xform_args['dim_edge'] - xform_args['dim_pe'])\n",
    "                self.edge_encoder_er = EREdgeEncoder(xform_args['dim_pe'], use_edge_attr=True)\n",
    "            else:\n",
    "                EdgeEncoder = register.edge_encoder_dict[\n",
    "                    xform_args['edge_encoder_name']]\n",
    "                self.edge_encoder = EdgeEncoder(xform_args['dim_edge'])\n",
    "\n",
    "            if xform_args['edge_encoder_bn']:\n",
    "                self.edge_encoder_bn = BatchNorm1dNode(\n",
    "                    new_layer_config(xform_args['dim_edge'], -1, -1, has_act=False,\n",
    "                                    has_bias=False, cfg=cfg))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        for module in self.children():\n",
    "            batch = module(batch)\n",
    "        return batch\n",
    "\n",
    "\n",
    "class GPSModel(torch.nn.Module):\n",
    "    \"\"\"Multi-scale graph x-former.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.encoder = FeatureEncoder(dim_in)\n",
    "        dim_in = self.encoder.dim_in\n",
    "\n",
    "        if cfg.gnn.layers_pre_mp > 0:\n",
    "            self.pre_mp = GNNPreMP(\n",
    "                dim_in, xform_args['dim_inner'], xform_args['layers_pre_mp'])\n",
    "            dim_in = xform_args['dim_inner']\n",
    "\n",
    "        assert xform_args['dim_hidden'] == xform_args['dim_inner'] == dim_in, \\\n",
    "            \"The inner and hidden dims must match.\"\n",
    "\n",
    "        try:\n",
    "            local_gnn_type, global_model_type = xform_args['layer_type'].split('+')\n",
    "        except:\n",
    "            raise ValueError(f\"Unexpected layer type: {xform_args['layer_type']}\")\n",
    "        layers = []\n",
    "        for _ in range(xform_args['layers']):\n",
    "            layers.append(GPSLayer(\n",
    "                dim_h=xform_args['dim_hidden'],\n",
    "                local_gnn_type=local_gnn_type,\n",
    "                global_model_type=global_model_type,\n",
    "                num_heads=xform_args['n_heads'],\n",
    "                pna_degrees=xform_args['pna_degrees'],\n",
    "                equivstable_pe=xform_args['enable'],\n",
    "                dropout=xform_args['dropout'],\n",
    "                attn_dropout=xform_args['attn_dropout'],\n",
    "                layer_norm=xform_args['layer_norm'],\n",
    "                batch_norm=xform_args['batch_norm'],\n",
    "                bigbird_cfg=xform_args['bigbird'],\n",
    "            ))\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "\n",
    "        GNNHead = register.head_dict[xform_args['head']]\n",
    "        self.post_mp = GNNHead(dim_in=xform_args['dim_inner'], dim_out=dim_out)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        for module in self.children():\n",
    "            batch = module(batch)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b5e105e-a4e7-49bc-aae7-d9e545a9177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_set_out_dir(cfg, cfg_fname, name_tag):\n",
    "    \"\"\"Set custom main output directory path to cfg.\n",
    "    Include the config filename and name_tag in the new :obj:`cfg.out_dir`.\n",
    "\n",
    "    Args:\n",
    "        cfg (CfgNode): Configuration node\n",
    "        cfg_fname (string): Filename for the yaml format configuration file\n",
    "        name_tag (string): Additional name tag to identify this execution of the\n",
    "            configuration file, specified in :obj:`cfg.name_tag`\n",
    "    \"\"\"\n",
    "    run_name = os.path.splitext(os.path.basename(cfg_fname))[0]\n",
    "    run_name += f\"-{name_tag}\" if name_tag else \"\"\n",
    "    cfg.out_dir = os.path.join(cfg.out_dir, run_name)\n",
    "\n",
    "\n",
    "def custom_set_run_dir(cfg, run_id):\n",
    "    \"\"\"Custom output directory naming for each experiment run.\n",
    "\n",
    "    Args:\n",
    "        cfg (CfgNode): Configuration node\n",
    "        run_id (int): Main for-loop iter id (the random seed or dataset split)\n",
    "    \"\"\"\n",
    "    cfg.run_dir = os.path.join(cfg.out_dir, str(run_id))\n",
    "    # Make output directory\n",
    "    if cfg.train.auto_resume:\n",
    "        os.makedirs(cfg.run_dir, exist_ok=True)\n",
    "    else:\n",
    "        makedirs_rm_exist(cfg.run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e3dd1-0c40-40af-94a0-46a875d8da73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5136a6d-8cb0-41e7-b3e4-035d688a4c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.nn.conv.gcn_conv.GCNConv"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(args['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d79f8e-f2b9-48d1-8298-18df9917f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(args['runs']):\n",
    "    start = time.time()\n",
    "    torch.manual_seed(seeds[index])\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seeds[index])\n",
    "    random.seed(seeds[index])\n",
    "    np.random.seed(seeds[index])\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    gnn = eval(args['model'])\n",
    "    \n",
    "    model = GPSModel(args,train_dataset,args['hidden'],args['hidden_mlp'],args['num_layers'],gnn).to(args['device']) ## apply GNN*\n",
    "    print(model)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total number of parameters is: {total_params}\")\n",
    "    # model.reset_parameters()\n",
    "    optimizer = Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "    loss, test_acc = [],[]\n",
    "    best_val_acc,best_val_loss = 0.0,0.0\n",
    "    for epoch in range(args['epochs']):\n",
    "        loss = train(train_loader)\n",
    "        val_acc = test(val_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        # if epoch%10==0:\n",
    "        print(\"epoch: {}, loss: {}, val_acc:{}, test_acc:{}\".format(epoch, np.round(loss.item(),6), np.round(val_acc,2),np.round(test_acc,2)))\n",
    "        val_acc_history.append(val_acc)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            if epoch> int(args['epochs']/2):\n",
    "                torch.save(model.state_dict(), path + args['dataset']+args['model']+'task-checkpoint-best-acc.pkl')\n",
    "    \n",
    "    #test the model   \n",
    "    model.load_state_dict(torch.load(path + args['dataset']+args['model']+'task-checkpoint-best-acc.pkl'))\n",
    "    model.eval()\n",
    "    test_acc = test(test_loader)\n",
    "    test_loss = train(test_loader).item()\n",
    "    test_acc_history.append(test_acc)\n",
    "    test_loss_history.append(test_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1a84e5-8b3f-4e5c-b5a4-1a3eeed7d7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd0deb-3917-4c3c-a7b0-f77b8ca192fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9607c-4d8d-49c4-9d55-2a3a5aa6bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cmd line args\n",
    "    args = parse_args()\n",
    "    # Load config file\n",
    "    set_cfg(cfg)\n",
    "    load_cfg(cfg, args)\n",
    "    custom_set_out_dir(cfg, args.cfg_file, cfg.name_tag)\n",
    "    dump_cfg(cfg)\n",
    "    # Set Pytorch environment\n",
    "    torch.set_num_threads(cfg.num_threads)\n",
    "    # Repeat for multiple experiment runs\n",
    "    for run_id, seed, split_index in zip(*run_loop_settings()):\n",
    "        # Set configurations for each run\n",
    "        custom_set_run_dir(cfg, run_id)\n",
    "        set_printing()\n",
    "        cfg.dataset.split_index = split_index\n",
    "        cfg.seed = seed\n",
    "        cfg.run_id = run_id\n",
    "        seed_everything(cfg.seed)\n",
    "        auto_select_device()\n",
    "        if cfg.pretrained.dir:\n",
    "            cfg = load_pretrained_model_cfg(cfg)\n",
    "        logging.info(f\"[*] Run ID {run_id}: seed={cfg.seed}, \"\n",
    "                     f\"split_index={cfg.dataset.split_index}\")\n",
    "        logging.info(f\"    Starting now: {datetime.datetime.now()}\")\n",
    "        # Set machine learning pipeline\n",
    "        loaders = create_loader()\n",
    "        loggers = create_logger()\n",
    "        # custom_train expects three loggers for 'train', 'valid' and 'test'.\n",
    "        # GraphGym code creates one logger/loader for each of the 'train_mask' etc.\n",
    "        # attributes in the dataset. As a work around it, we create one logger for each\n",
    "        # of the types.\n",
    "        # loaders are a const, so it is ok to just duplicate the loader. \n",
    "        if cfg.dataset.name == 'ogbn-arxiv' or cfg.dataset.name == 'ogbn-proteins':\n",
    "            loggers_2 = create_logger()\n",
    "            loggers_3 = create_logger()\n",
    "            loggers_2[0].name = \"val\"\n",
    "            loggers_3[0].name = \"test\"\n",
    "            loggers.extend(loggers_2)\n",
    "            loggers.extend(loggers_3)\n",
    "            loaders = loaders*3\n",
    "        model = create_model()\n",
    "        if cfg.pretrained.dir:\n",
    "            model = init_model_from_pretrained(\n",
    "                model, cfg.pretrained.dir, cfg.pretrained.freeze_main,\n",
    "                cfg.pretrained.reset_prediction_head\n",
    "            )\n",
    "        optimizer = create_optimizer(model.parameters(),\n",
    "                                     new_optimizer_config(cfg))\n",
    "        scheduler = create_scheduler(optimizer, new_scheduler_config(cfg))\n",
    "        # Print model info\n",
    "        logging.info(model)\n",
    "        logging.info(cfg)\n",
    "        cfg.params = params_count(model)\n",
    "        logging.info('Num parameters: %s', cfg.params)\n",
    "        # Start training\n",
    "        if cfg.train.mode == 'standard':\n",
    "            if cfg.wandb.use:\n",
    "                logging.warning(\"[W] WandB logging is not supported with the \"\n",
    "                                \"default train.mode, set it to `custom`\")\n",
    "            train(loggers, loaders, model, optimizer, scheduler)\n",
    "        else:\n",
    "            train_dict[cfg.train.mode](loggers, loaders, model, optimizer,\n",
    "                                       scheduler)\n",
    "    # Aggregate results from different seeds\n",
    "    try:\n",
    "        agg_runs(cfg.out_dir, cfg.metric_best)\n",
    "    except Exception as e:\n",
    "        logging.info(f\"Failed when trying to aggregate multiple runs: {e}\")\n",
    "    # When being launched in batch mode, mark a yaml as done\n",
    "    if args.mark_done:\n",
    "        os.rename(args.cfg_file, f'{args.cfg_file}_done')\n",
    "    logging.info(f\"[*] All done: {datetime.datetime.now()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407fb85-db67-4b53-b135-1278671160f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584a71a-cccb-4b92-9e57-0b6de93c943e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d8abe-f5b5-4e27-91cb-882d10d2e3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df755ee4-4011-42de-ae84-e2922354e712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a543b7c8-d4b0-4de1-86d5-62f906459611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d8a9e-713a-4e05-8825-64e817e56b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fa7501c-0360-4616-8bc9-467bd503a70d",
   "metadata": {},
   "source": [
    "# Other - BigBird"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3344ba-78dc-423d-8aa9-f787fcf9b337",
   "metadata": {},
   "source": [
    "## Load Data and SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d45a7014-b7fd-4c10-8ea8-65fb70d5371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "import os,random\n",
    "import os.path as osp\n",
    "import sys\n",
    "import time\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c15acc3-b302-4afa-8a6d-83e9919fa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torch_geometric==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc0e70e-bc00-47eb-91b2-ea862e3b9421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'DataEdgeAttr' on <module 'torch_geometric.data.data' from 'C:\\\\Users\\\\jmlr9\\\\.conda\\\\envs\\\\exphormer2\\\\lib\\\\site-packages\\\\torch_geometric\\\\data\\\\data.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mNeuroGraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeuroGraphDataset\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mNeuroGraphDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHCPGender\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive - University of Cambridge\\Courses Material\\U L65 Geometric Deep Learning\\Project\\NeuroGraph_code\\NeuroGraph\\datasets.py:78\u001b[0m, in \u001b[0;36mNeuroGraphDataset.__init__\u001b[1;34m(self, root, name, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilenames\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_filter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\.conda\\envs\\exphormer2\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:56\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, root: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     53\u001b[0m              transform: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     54\u001b[0m              pre_transform: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     55\u001b[0m              pre_filter: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_filter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\exphormer2\\lib\\site-packages\\torch_geometric\\data\\dataset.py:87\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download()\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\exphormer2\\lib\\site-packages\\torch_geometric\\data\\dataset.py:170\u001b[0m, in \u001b[0;36mDataset._process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m    169\u001b[0m makedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir)\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m path \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_transform.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    173\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(_repr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_transform), path)\n",
      "File \u001b[1;32m~\\OneDrive - University of Cambridge\\Courses Material\\U L65 Geometric Deep Learning\\Project\\NeuroGraph_code\\NeuroGraph\\datasets.py:108\u001b[0m, in \u001b[0;36mNeuroGraphDataset.process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 108\u001b[0m     data, slices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     num_samples \u001b[38;5;241m=\u001b[39m slices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    111\u001b[0m     data_list: List[Data] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\.conda\\envs\\exphormer2\\lib\\site-packages\\torch\\serialization.py:607\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    605\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[0;32m    606\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[1;32m--> 607\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32m~\\.conda\\envs\\exphormer2\\lib\\site-packages\\torch\\serialization.py:882\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m    880\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m    881\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m--> 882\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    884\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\.conda\\envs\\exphormer2\\lib\\site-packages\\torch\\serialization.py:875\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_class\u001b[39m(\u001b[38;5;28mself\u001b[39m, mod_name, name):\n\u001b[0;32m    874\u001b[0m     mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m--> 875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'DataEdgeAttr' on <module 'torch_geometric.data.data' from 'C:\\\\Users\\\\jmlr9\\\\.conda\\\\envs\\\\exphormer2\\\\lib\\\\site-packages\\\\torch_geometric\\\\data\\\\data.py'>"
     ]
    }
   ],
   "source": [
    "from NeuroGraph.datasets import NeuroGraphDataset\n",
    "dataset = NeuroGraphDataset(root=\"data/\", name= \"HCPGender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4949fe1-13a4-4ff8-9a7f-aed77b04b985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "2\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Gender\")\n",
    "print(dataset.num_classes)\n",
    "print(dataset.num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baeac2bb-6bd3-4291-bc4e-96eefac575ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"base_params/\"\n",
    "res_path = \"results/\"\n",
    "root = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b093f023-782d-4dc1-9744-142a6065d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "if not os.path.isdir(res_path):\n",
    "    os.mkdir(res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e5433b-f6a1-431e-b861-77794fec5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logger(info):\n",
    "    f = open(os.path.join(res_path, 'results_new.csv'), 'a')\n",
    "    print(info, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859fee99-4267-4f2b-aeb9-7be9dcad5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed\n",
    "seed_fixed=123\n",
    "torch.manual_seed(seed_fixed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_fixed)\n",
    "random.seed(seed_fixed)\n",
    "np.random.seed(seed_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8278653f-ed38-49ed-9e80-5935023144c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [d.y.item() for d in dataset]\n",
    "train_tmp, test_indices = train_test_split(list(range(len(labels))),\n",
    "                        test_size=0.2, stratify=labels,random_state=123,shuffle= True)\n",
    "tmp = dataset[train_tmp]\n",
    "train_labels = [d.y.item() for d in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "118f4e2a-73cf-40bb-98b4-d3f61820e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = train_test_split(list(range(len(train_labels))),\n",
    " test_size=0.125, stratify=train_labels,random_state=123,shuffle = True)\n",
    "train_dataset = tmp[train_indices]\n",
    "val_dataset = tmp[val_indices]\n",
    "test_dataset = dataset[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b304ecde-d095-47c3-9b85-86a478634b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'dataset': 'HCPGender',\n",
    "    'runs': 1,\n",
    "    'device': 'cuda',\n",
    "    'seed': seed_fixed,\n",
    "    'model': 'BigBird',  # Change from 'GCNConv' to 'BigBird'\n",
    "       'num_layers': 3,  # Number of layers in the model\n",
    "    'epochs': 15,  # Number of training epochs\n",
    "    'echo_epoch': 3,  # Print epoch every 50 epochs\n",
    "    'batch_size': 16,  # Batch size for training\n",
    "    'early_stopping': 5,  # Patience for early stopping\n",
    "    'lr': 1e-5,  # Learning rate\n",
    "    'weight_decay': 0.0005,  # Weight decay\n",
    "    'dropout': 0.5,  # Dropout probability\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e973a52-bc4a-41ba-a48c-c0d199accf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset HCPGender loaded with train 754 val 108 test 216 splits\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset {} loaded with train {} val {} test {} splits\".format(args['dataset'],len(train_dataset), len(val_dataset), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa05c283-a119-44c2-a4a1-eb4e57a93ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, args['batch_size'], shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, args['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, args['batch_size'], shuffle=False)\n",
    "args['num_features'],args['num_classes']= dataset.num_features,dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ea1f31f-6c75-4afa-bebd-7cf78674f190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa05de37-7929-4937-8360-63527e664761",
   "metadata": {},
   "source": [
    "## BigBird Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67041cb8-f302-4cb4-827e-cfec6208eaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\exphormer1\\lib\\site-packages\\torch_geometric\\graphgym\\imports.py:14: UserWarning: Please install 'pytorch_lightning' for using the GraphGym experiment manager via 'pip install pytorch_lightning'\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' for using the GraphGym \"\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\exphormer1\\lib\\site-packages\\torch_geometric\\graphgym\\logger.py:23: UserWarning: Please install 'pytorch_lightning' for using the GraphGym experiment manager via 'pip install pytorch_lightning'\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' for using the GraphGym \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric.graphgym.register as register\n",
    "from torch_geometric.graphgym.config import cfg\n",
    "from torch_geometric.graphgym.models.gnn import FeatureEncoder, GNNPreMP\n",
    "from torch_geometric.graphgym.register import register_network\n",
    "\n",
    "from graphgps.layer.bigbird_layer import BigBirdModel as BackboneBigBird\n",
    "\n",
    "class BigBird(torch.nn.Module):\n",
    "    \"\"\"BigBird without edge features.\n",
    "    This model disregards edge features and runs a linear transformer over a set of node features only.\n",
    "    BirBird applies random sparse attention to the input sequence - the longer the sequence the closer it is to O(N)\n",
    "    https://arxiv.org/abs/2007.14062\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.encoder = FeatureEncoder(dim_in)\n",
    "        dim_in = self.encoder.dim_in\n",
    "\n",
    "        if cfg.gnn.layers_pre_mp > 0:\n",
    "            self.pre_mp = GNNPreMP(\n",
    "                dim_in, cfg.gnn.dim_inner, cfg.gnn.layers_pre_mp)\n",
    "            dim_in = cfg.gnn.dim_inner\n",
    "\n",
    "        assert cfg.gt.dim_hidden == cfg.gnn.dim_inner == dim_in, \\\n",
    "            \"The inner and hidden dims must match.\"\n",
    "\n",
    "        # Copy main Transformer hyperparams to the BigBird config.\n",
    "        cfg.gt.bigbird.layers = cfg.gt.layers\n",
    "        cfg.gt.bigbird.n_heads = cfg.gt.n_heads\n",
    "        cfg.gt.bigbird.dim_hidden = cfg.gt.dim_hidden\n",
    "        cfg.gt.bigbird.dropout = cfg.gt.dropout\n",
    "        self.trf = BackboneBigBird(\n",
    "            config=cfg.gt.bigbird,\n",
    "        )\n",
    "\n",
    "        GNNHead = register.head_dict[cfg.gnn.head]\n",
    "        self.post_mp = GNNHead(dim_in=cfg.gnn.dim_inner, dim_out=dim_out)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        for module in self.children():\n",
    "            batch = module(batch)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe1fc6-399e-46c4-8399-d1162af96642",
   "metadata": {},
   "source": [
    "## Aplying Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3035fae-5041-4812-9abe-d166375cf4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_bigbird = {\n",
    "    'dataset': 'HCPGender',\n",
    "    'runs': 1,\n",
    "    'device': 'cuda',\n",
    "    'seed': seed_fixed,\n",
    "    'model': 'BigBird',  # Change from 'GCNConv' to 'BigBird'\n",
    "   # 'dim_in': ?,  # Define the appropriate input dimensionality of the features\n",
    "   # 'dim_out': ?,  # Define the appropriate output dimensionality\n",
    "    'num_layers': 3,  # Number of layers in the model\n",
    "    'epochs': 15,  # Number of training epochs\n",
    "    'echo_epoch': 3,  # Print epoch every 50 epochs\n",
    "    'batch_size': 16,  # Batch size for training\n",
    "    'early_stopping': 5,  # Patience for early stopping\n",
    "    'lr': 1e-5,  # Learning rate\n",
    "    'weight_decay': 0.0005,  # Weight decay\n",
    "    'dropout': 0.5,  # Dropout probability\n",
    "}\n",
    "\n",
    "num_features = dataset.num_features  # Number of input features in your dataset\n",
    "num_classes = dataset.num_classes  # Number of classes in your classification task\n",
    "dim_in = num_features  # Number of input features\n",
    "dim_out = num_classes \n",
    "\n",
    "args=args_bigbird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26e3a619-17f1-4ec3-98ff-050c6afff4b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Non-existent config key: train.mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Load the configurations from the YAML file\u001b[39;00m\n\u001b[0;32m     25\u001b[0m set_cfg(cfg)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mload_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m dump_cfg(cfg)\n",
      "File \u001b[1;32m~\\.conda\\envs\\exphormer1\\lib\\site-packages\\torch_geometric\\graphgym\\config.py:503\u001b[0m, in \u001b[0;36mload_cfg\u001b[1;34m(cfg, args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cfg\u001b[39m(cfg, args):\n\u001b[0;32m    495\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03m    Load configurations from file system and command line\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    501\u001b[0m \n\u001b[0;32m    502\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 503\u001b[0m     \u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m     cfg\u001b[38;5;241m.\u001b[39mmerge_from_list(args\u001b[38;5;241m.\u001b[39mopts)\n\u001b[0;32m    505\u001b[0m     assert_cfg(cfg)\n",
      "File \u001b[1;32m~\\.conda\\envs\\exphormer1\\lib\\site-packages\\yacs\\config.py:213\u001b[0m, in \u001b[0;36mCfgNode.merge_from_file\u001b[1;34m(self, cfg_filename)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cfg_filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    212\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_cfg(f)\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_from_other_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\exphormer1\\lib\\site-packages\\yacs\\config.py:217\u001b[0m, in \u001b[0;36mCfgNode.merge_from_other_cfg\u001b[1;34m(self, cfg_other)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_from_other_cfg\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg_other):\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Merge `cfg_other` into this CfgNode.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m     \u001b[43m_merge_a_into_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_other\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\exphormer1\\lib\\site-packages\\yacs\\config.py:478\u001b[0m, in \u001b[0;36m_merge_a_into_b\u001b[1;34m(a, b, root, key_list)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, CfgNode):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         \u001b[43m_merge_a_into_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\exphormer1\\lib\\site-packages\\yacs\\config.py:491\u001b[0m, in \u001b[0;36m_merge_a_into_b\u001b[1;34m(a, b, root, key_list)\u001b[0m\n\u001b[0;32m    489\u001b[0m     root\u001b[38;5;241m.\u001b[39mraise_key_rename_error(full_key)\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-existent config key: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(full_key))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Non-existent config key: train.mode'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from yacs.config import CfgNode\n",
    "from torch_geometric.graphgym.config import load_cfg, set_cfg, cfg\n",
    "import yaml \n",
    "\n",
    "# Define the path to your YAML file\n",
    "cfg_file = 'cifar10.yaml'\n",
    "\n",
    "# Create an empty argparse Namespace object\n",
    "class ArgsObject:\n",
    "    pass\n",
    "\n",
    "# Convert the YAML file to a dictionary\n",
    "with open(cfg_file, 'r') as file:\n",
    "    cfg_dict = yaml.safe_load(file)\n",
    "\n",
    "# Create a CfgNode object from the dictionary\n",
    "cfg = CfgNode(cfg_dict)\n",
    "\n",
    "# Create an ArgsObject instance with the cfg_file attribute\n",
    "args = ArgsObject()\n",
    "args.cfg_file = cfg_file\n",
    "\n",
    "# Load the configurations from the YAML file\n",
    "set_cfg(cfg)\n",
    "load_cfg(cfg, args)\n",
    "dump_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33a7212d-4470-45f0-9373-01fd5b84e5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3d81634-30d5-4179-a1d4-d1dd912dd5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'batch_size': 16, 'sampler': 'full_batch', 'sample_node': False, 'node_per_graph': 32, 'radius': 'extend', 'eval_period': 10, 'skip_train_eval': False, 'ckpt_period': 100, 'enable_ckpt': True, 'auto_resume': False, 'epoch_resume': -1, 'ckpt_clean': True, 'iter_per_epoch': 32, 'walk_length': 4, 'neighbor_sizes': [20, 15, 10, 5], 'ckpt_best': False})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d7d09-cd6e-454d-b4ba-11fd5812a342",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(train_loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:  \n",
    "        data = data.to(args['device'])\n",
    "        out = model(data)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y) \n",
    "        total_loss +=loss\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad()\n",
    "    return total_loss/len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:  \n",
    "        data = data.to(args['device'])\n",
    "        out = model(data)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd115527-4041-4d03-9302-216d1a2ca30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_history, test_acc_history, test_loss_history = [],[],[]\n",
    "seeds = [123,124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9736fee7-fba4-45b8-a8a7-5675328d5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(args['runs']):\n",
    "    start = time.time()\n",
    "    torch.manual_seed(seeds[index])\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seeds[index])\n",
    "    random.seed(seeds[index])\n",
    "    np.random.seed(seeds[index])\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    gnn = eval(args['model'])\n",
    "    model = ResidualGNNs(args,train_dataset,args['hidden'],args['hidden_mlp'],args['num_layers'],gnn).to(args['device']) ## apply GNN*\n",
    "    print(model)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total number of parameters is: {total_params}\")\n",
    "    # model.reset_parameters()\n",
    "    optimizer = Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "    loss, test_acc = [],[]\n",
    "    best_val_acc,best_val_loss = 0.0,0.0\n",
    "    for epoch in range(args['epochs']):\n",
    "        loss = train(train_loader)\n",
    "        val_acc = test(val_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        # if epoch%10==0:\n",
    "        print(\"epoch: {}, loss: {}, val_acc:{}, test_acc:{}\".format(epoch, np.round(loss.item(),6), np.round(val_acc,2),np.round(test_acc,2)))\n",
    "        val_acc_history.append(val_acc)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            if epoch> int(args['epochs']/2):\n",
    "                torch.save(model.state_dict(), path + args['dataset']+args['model']+'task-checkpoint-best-acc.pkl')\n",
    "    \n",
    "    #test the model   \n",
    "    model.load_state_dict(torch.load(path + args['dataset']+args['model']+'task-checkpoint-best-acc.pkl'))\n",
    "    model.eval()\n",
    "    test_acc = test(test_loader)\n",
    "    test_loss = train(test_loader).item()\n",
    "    test_acc_history.append(test_acc)\n",
    "    test_loss_history.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e73f1-49c3-453e-9035-41ef7949c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model   \n",
    "model.load_state_dict(torch.load(path + args['dataset']+args['model']+'task-checkpoint-best-acc.pkl'))\n",
    "model.eval()\n",
    "test_acc = test(test_loader)\n",
    "test_loss = train(test_loader).item()\n",
    "test_acc_history.append(test_acc)\n",
    "test_loss_history.append(test_loss)\n",
    "print(test_acc_history, test_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761a2f0-b1b1-43a8-8bef-cde83715eea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
