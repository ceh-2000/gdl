{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746b20cf-e617-4835-b55f-0f56a77dd7a4",
   "metadata": {},
   "source": [
    "##  Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232f433-696e-4b0b-a987-5cec2fc06a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-26 11:51:17.185700\n",
      "[*] Loaded dataset 'HCPGender' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1078000, 1000], edge_index=[2, 49133748], y=[1078])\n",
      "  undirected: True\n",
      "  num graphs: 1078\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 2\n",
      "Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [03:37<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:03:41.26\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): GPSModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): RWSENodeEncoder(\n",
      "        (linear_x): Linear(in_features=1000, out_features=48, bias=True)\n",
      "        (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (pe_encoder): Linear(in_features=16, out_features=16, bias=True)\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (1): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (2): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPGender\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: RWSE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_edge: 64\n",
      "  dim_inner: 64\n",
      "  dropout: 0.0\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.5\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: None\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.0\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: CustomGatedGCN+Transformer\n",
      "  layers: 3\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: GPSModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 30\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-GPS+RWSE+small\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: True\n",
      "  kernel:\n",
      "    times: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "    times_func: range(1,17)\n",
      "  layers: 3\n",
      "  model: Linear\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: BatchNorm\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: False\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 0\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-GPS+RWSE+small\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 2\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 216673\n",
      "Start from epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'epoch': 0, 'time_epoch': 64.07032, 'eta': 1858.03942, 'eta_hours': 0.51612, 'loss': 0.69307512, 'lr': 0.0, 'params': 216673, 'time_iter': 1.18649, 'accuracy': 0.48608, 'precision': 0.44495, 'recall': 0.49114, 'f1': 0.46691, 'auc': 0.50626}\n",
      "...computing epoch stats took: 0.07s\n",
      "val: {'epoch': 0, 'time_epoch': 6.80105, 'loss': 0.69427233, 'lr': 0, 'params': 216673, 'time_iter': 0.97158, 'accuracy': 0.47222, 'precision': 0.44118, 'recall': 0.61224, 'f1': 0.51282, 'auc': 0.46558}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 0, 'time_epoch': 9.37489, 'loss': 0.69229356, 'lr': 0, 'params': 216673, 'time_iter': 1.33927, 'accuracy': 0.48148, 'precision': 0.4507, 'recall': 0.65306, 'f1': 0.53333, 'auc': 0.52992}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 80.4s (avg 80.4s) | Best so far: epoch 0\ttrain_loss: 0.6931 train_accuracy: 0.4861\tval_loss: 0.6943 val_accuracy: 0.4722\ttest_loss: 0.6923 test_accuracy: 0.4815\n",
      "train: {'epoch': 1, 'time_epoch': 62.62505, 'eta': 1773.73525, 'eta_hours': 0.4927, 'loss': 0.67570423, 'lr': 0.0002, 'params': 216673, 'time_iter': 1.15972, 'accuracy': 0.60209, 'precision': 0.57065, 'recall': 0.53165, 'f1': 0.55046, 'auc': 0.63509}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 1, 'time_epoch': 6.32395, 'loss': 0.66346799, 'lr': 0, 'params': 216673, 'time_iter': 0.90342, 'accuracy': 0.62963, 'precision': 0.66667, 'recall': 0.36735, 'f1': 0.47368, 'auc': 0.70806}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 9.37852, 'loss': 0.65900842, 'lr': 0, 'params': 216673, 'time_iter': 1.33979, 'accuracy': 0.66667, 'precision': 0.68571, 'recall': 0.4898, 'f1': 0.57143, 'auc': 0.743}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 1: took 78.4s (avg 79.4s) | Best so far: epoch 1\ttrain_loss: 0.6757 train_accuracy: 0.6021\tval_loss: 0.6635 val_accuracy: 0.6296\ttest_loss: 0.6590 test_accuracy: 0.6667\n",
      "train: {'epoch': 2, 'time_epoch': 49.12676, 'eta': 1582.39924, 'eta_hours': 0.43956, 'loss': 0.64179115, 'lr': 0.0004, 'params': 216673, 'time_iter': 0.90975, 'accuracy': 0.7123, 'precision': 0.71429, 'recall': 0.62025, 'f1': 0.66396, 'auc': 0.76997}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 2, 'time_epoch': 6.51536, 'loss': 0.62196197, 'lr': 0, 'params': 216673, 'time_iter': 0.93077, 'accuracy': 0.75, 'precision': 0.89286, 'recall': 0.5102, 'f1': 0.64935, 'auc': 0.85265}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 2, 'time_epoch': 9.54835, 'loss': 0.61574861, 'lr': 0, 'params': 216673, 'time_iter': 1.36405, 'accuracy': 0.77778, 'precision': 0.87879, 'recall': 0.59184, 'f1': 0.70732, 'auc': 0.89242}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 2: took 65.3s (avg 74.7s) | Best so far: epoch 2\ttrain_loss: 0.6418 train_accuracy: 0.7123\tval_loss: 0.6220 val_accuracy: 0.7500\ttest_loss: 0.6157 test_accuracy: 0.7778\n",
      "train: {'epoch': 3, 'time_epoch': 78.87155, 'eta': 1655.50899, 'eta_hours': 0.45986, 'loss': 0.59014902, 'lr': 0.0006, 'params': 216673, 'time_iter': 1.46058, 'accuracy': 0.78422, 'precision': 0.79772, 'recall': 0.70886, 'f1': 0.75067, 'auc': 0.82059}\n",
      "val: {'epoch': 3, 'time_epoch': 6.32246, 'loss': 0.70168394, 'lr': 0, 'params': 216673, 'time_iter': 0.90321, 'accuracy': 0.51852, 'precision': 0.48485, 'recall': 0.97959, 'f1': 0.64865, 'auc': 0.83743}\n",
      "test: {'epoch': 3, 'time_epoch': 9.34035, 'loss': 0.69205891, 'lr': 0, 'params': 216673, 'time_iter': 1.33434, 'accuracy': 0.53704, 'precision': 0.49495, 'recall': 1.0, 'f1': 0.66216, 'auc': 0.79177}\n",
      "> Epoch 3: took 94.6s (avg 79.7s) | Best so far: epoch 2\ttrain_loss: 0.6418 train_accuracy: 0.7123\tval_loss: 0.6220 val_accuracy: 0.7500\ttest_loss: 0.6157 test_accuracy: 0.7778\n",
      "train: {'epoch': 4, 'time_epoch': 73.10833, 'eta': 1639.01009, 'eta_hours': 0.45528, 'loss': 0.54619702, 'lr': 0.0008, 'params': 216673, 'time_iter': 1.35386, 'accuracy': 0.80858, 'precision': 0.80749, 'recall': 0.76456, 'f1': 0.78544, 'auc': 0.86441}\n",
      "val: {'epoch': 4, 'time_epoch': 6.38496, 'loss': 0.64425968, 'lr': 0, 'params': 216673, 'time_iter': 0.91214, 'accuracy': 0.62963, 'precision': 0.55172, 'recall': 0.97959, 'f1': 0.70588, 'auc': 0.88032}\n",
      "test: {'epoch': 4, 'time_epoch': 9.64722, 'loss': 0.6543018, 'lr': 0, 'params': 216673, 'time_iter': 1.37817, 'accuracy': 0.62963, 'precision': 0.55056, 'recall': 1.0, 'f1': 0.71014, 'auc': 0.86752}\n",
      "> Epoch 4: took 89.2s (avg 81.6s) | Best so far: epoch 2\ttrain_loss: 0.6418 train_accuracy: 0.7123\tval_loss: 0.6220 val_accuracy: 0.7500\ttest_loss: 0.6157 test_accuracy: 0.7778\n",
      "train: {'epoch': 5, 'time_epoch': 59.14891, 'eta': 1547.8037, 'eta_hours': 0.42995, 'loss': 0.51266737, 'lr': 0.001, 'params': 216673, 'time_iter': 1.09535, 'accuracy': 0.81323, 'precision': 0.80155, 'recall': 0.78734, 'f1': 0.79438, 'auc': 0.86189}\n",
      "val: {'epoch': 5, 'time_epoch': 6.2995, 'loss': 0.50117662, 'lr': 0, 'params': 216673, 'time_iter': 0.89993, 'accuracy': 0.82407, 'precision': 0.84091, 'recall': 0.7551, 'f1': 0.7957, 'auc': 0.87098}\n",
      "test: {'epoch': 5, 'time_epoch': 9.3422, 'loss': 0.50891542, 'lr': 0, 'params': 216673, 'time_iter': 1.3346, 'accuracy': 0.82407, 'precision': 0.82609, 'recall': 0.77551, 'f1': 0.8, 'auc': 0.87098}\n",
      "> Epoch 5: took 74.9s (avg 80.4s) | Best so far: epoch 5\ttrain_loss: 0.5127 train_accuracy: 0.8132\tval_loss: 0.5012 val_accuracy: 0.8241\ttest_loss: 0.5089 test_accuracy: 0.8241\n",
      "train: {'epoch': 6, 'time_epoch': 89.96775, 'eta': 1567.01851, 'eta_hours': 0.43528, 'loss': 0.45885927, 'lr': 0.00099606, 'params': 216673, 'time_iter': 1.66607, 'accuracy': 0.84455, 'precision': 0.82707, 'recall': 0.83544, 'f1': 0.83123, 'auc': 0.89478}\n",
      "val: {'epoch': 6, 'time_epoch': 6.26864, 'loss': 0.50700348, 'lr': 0, 'params': 216673, 'time_iter': 0.89552, 'accuracy': 0.7963, 'precision': 0.84615, 'recall': 0.67347, 'f1': 0.75, 'auc': 0.85749}\n",
      "test: {'epoch': 6, 'time_epoch': 9.3931, 'loss': 0.52501959, 'lr': 0, 'params': 216673, 'time_iter': 1.34187, 'accuracy': 0.77778, 'precision': 0.85714, 'recall': 0.61224, 'f1': 0.71429, 'auc': 0.84365}\n",
      "> Epoch 6: took 105.7s (avg 84.1s) | Best so far: epoch 5\ttrain_loss: 0.5127 train_accuracy: 0.8132\tval_loss: 0.5012 val_accuracy: 0.8241\ttest_loss: 0.5089 test_accuracy: 0.8241\n",
      "train: {'epoch': 7, 'time_epoch': 51.1773, 'eta': 1452.26395, 'eta_hours': 0.40341, 'loss': 0.41231615, 'lr': 0.00098429, 'params': 216673, 'time_iter': 0.94773, 'accuracy': 0.87239, 'precision': 0.86445, 'recall': 0.8557, 'f1': 0.86005, 'auc': 0.92028}\n",
      "val: {'epoch': 7, 'time_epoch': 6.31625, 'loss': 0.49727282, 'lr': 0, 'params': 216673, 'time_iter': 0.90232, 'accuracy': 0.77778, 'precision': 0.68657, 'recall': 0.93878, 'f1': 0.7931, 'auc': 0.89139}\n",
      "test: {'epoch': 7, 'time_epoch': 9.42742, 'loss': 0.55061358, 'lr': 0, 'params': 216673, 'time_iter': 1.34677, 'accuracy': 0.75, 'precision': 0.65714, 'recall': 0.93878, 'f1': 0.77311, 'auc': 0.87928}\n",
      "> Epoch 7: took 67.0s (avg 81.9s) | Best so far: epoch 5\ttrain_loss: 0.5127 train_accuracy: 0.8132\tval_loss: 0.5012 val_accuracy: 0.8241\ttest_loss: 0.5089 test_accuracy: 0.8241\n",
      "train: {'epoch': 8, 'time_epoch': 74.01451, 'eta': 1404.92447, 'eta_hours': 0.39026, 'loss': 0.3924089, 'lr': 0.00096489, 'params': 216673, 'time_iter': 1.37064, 'accuracy': 0.87355, 'precision': 0.84541, 'recall': 0.88608, 'f1': 0.86527, 'auc': 0.9232}\n",
      "val: {'epoch': 8, 'time_epoch': 6.50611, 'loss': 0.41185461, 'lr': 0, 'params': 216673, 'time_iter': 0.92944, 'accuracy': 0.85185, 'precision': 0.82353, 'recall': 0.85714, 'f1': 0.84, 'auc': 0.91681}\n",
      "test: {'epoch': 8, 'time_epoch': 9.64736, 'loss': 0.45578411, 'lr': 0, 'params': 216673, 'time_iter': 1.37819, 'accuracy': 0.81481, 'precision': 0.79592, 'recall': 0.79592, 'f1': 0.79592, 'auc': 0.88827}\n",
      "> Epoch 8: took 90.2s (avg 82.8s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 9, 'time_epoch': 58.47464, 'eta': 1321.17026, 'eta_hours': 0.36699, 'loss': 0.33877121, 'lr': 0.00093815, 'params': 216673, 'time_iter': 1.08286, 'accuracy': 0.90487, 'precision': 0.8962, 'recall': 0.8962, 'f1': 0.8962, 'auc': 0.93465}\n",
      "val: {'epoch': 9, 'time_epoch': 6.59895, 'loss': 0.74798613, 'lr': 0, 'params': 216673, 'time_iter': 0.94271, 'accuracy': 0.65741, 'precision': 1.0, 'recall': 0.2449, 'f1': 0.39344, 'auc': 0.78969}\n",
      "test: {'epoch': 9, 'time_epoch': 9.65504, 'loss': 0.8325421, 'lr': 0, 'params': 216673, 'time_iter': 1.37929, 'accuracy': 0.58333, 'precision': 0.75, 'recall': 0.12245, 'f1': 0.21053, 'auc': 0.79453}\n",
      "> Epoch 9: took 74.8s (avg 82.0s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 10, 'time_epoch': 61.56912, 'eta': 1247.35734, 'eta_hours': 0.34649, 'loss': 0.34447115, 'lr': 0.00090451, 'params': 216673, 'time_iter': 1.14017, 'accuracy': 0.89443, 'precision': 0.89791, 'recall': 0.86835, 'f1': 0.88288, 'auc': 0.93775}\n",
      "val: {'epoch': 10, 'time_epoch': 6.48285, 'loss': 0.55832695, 'lr': 0, 'params': 216673, 'time_iter': 0.92612, 'accuracy': 0.76852, 'precision': 0.92857, 'recall': 0.53061, 'f1': 0.67532, 'auc': 0.87721}\n",
      "test: {'epoch': 10, 'time_epoch': 9.71795, 'loss': 0.58232828, 'lr': 0, 'params': 216673, 'time_iter': 1.38828, 'accuracy': 0.75, 'precision': 0.89286, 'recall': 0.5102, 'f1': 0.64935, 'auc': 0.88585}\n",
      "> Epoch 10: took 77.8s (avg 81.7s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 11, 'time_epoch': 62.10833, 'eta': 1176.39387, 'eta_hours': 0.32678, 'loss': 0.29353269, 'lr': 0.00086448, 'params': 216673, 'time_iter': 1.15015, 'accuracy': 0.91995, 'precision': 0.91371, 'recall': 0.91139, 'f1': 0.91255, 'auc': 0.95178}\n",
      "val: {'epoch': 11, 'time_epoch': 6.39743, 'loss': 0.43548011, 'lr': 0, 'params': 216673, 'time_iter': 0.91392, 'accuracy': 0.83333, 'precision': 0.82979, 'recall': 0.79592, 'f1': 0.8125, 'auc': 0.86717}\n",
      "test: {'epoch': 11, 'time_epoch': 9.22878, 'loss': 0.43969521, 'lr': 0, 'params': 216673, 'time_iter': 1.3184, 'accuracy': 0.7963, 'precision': 0.77551, 'recall': 0.77551, 'f1': 0.77551, 'auc': 0.899}\n",
      "> Epoch 11: took 77.8s (avg 81.3s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 12, 'time_epoch': 63.95702, 'eta': 1109.21024, 'eta_hours': 0.30811, 'loss': 0.27774553, 'lr': 0.00081871, 'params': 216673, 'time_iter': 1.18439, 'accuracy': 0.92459, 'precision': 0.91457, 'recall': 0.92152, 'f1': 0.91803, 'auc': 0.96434}\n",
      "val: {'epoch': 12, 'time_epoch': 6.53703, 'loss': 0.44406747, 'lr': 0, 'params': 216673, 'time_iter': 0.93386, 'accuracy': 0.83333, 'precision': 0.81633, 'recall': 0.81633, 'f1': 0.81633, 'auc': 0.88378}\n",
      "test: {'epoch': 12, 'time_epoch': 9.71306, 'loss': 0.44033204, 'lr': 0, 'params': 216673, 'time_iter': 1.38758, 'accuracy': 0.82407, 'precision': 0.82609, 'recall': 0.77551, 'f1': 0.8, 'auc': 0.90488}\n",
      "> Epoch 12: took 80.3s (avg 81.3s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 13, 'time_epoch': 81.89538, 'eta': 1062.98855, 'eta_hours': 0.29527, 'loss': 0.22880035, 'lr': 0.00076791, 'params': 216673, 'time_iter': 1.51658, 'accuracy': 0.9478, 'precision': 0.92476, 'recall': 0.96456, 'f1': 0.94424, 'auc': 0.9735}\n",
      "val: {'epoch': 13, 'time_epoch': 6.57451, 'loss': 0.93312893, 'lr': 0, 'params': 216673, 'time_iter': 0.93922, 'accuracy': 0.61111, 'precision': 1.0, 'recall': 0.14286, 'f1': 0.25, 'auc': 0.64338}\n",
      "test: {'epoch': 13, 'time_epoch': 9.75989, 'loss': 0.99500354, 'lr': 0, 'params': 216673, 'time_iter': 1.39427, 'accuracy': 0.57407, 'precision': 0.71429, 'recall': 0.10204, 'f1': 0.17857, 'auc': 0.58526}\n",
      "> Epoch 13: took 98.3s (avg 82.5s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 14, 'time_epoch': 82.47727, 'eta': 1012.59225, 'eta_hours': 0.28128, 'loss': 0.24114126, 'lr': 0.00071289, 'params': 216673, 'time_iter': 1.52736, 'accuracy': 0.93503, 'precision': 0.90843, 'recall': 0.95443, 'f1': 0.93086, 'auc': 0.97311}\n",
      "val: {'epoch': 14, 'time_epoch': 6.54786, 'loss': 0.5245276, 'lr': 0, 'params': 216673, 'time_iter': 0.93541, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.82982}\n",
      "test: {'epoch': 14, 'time_epoch': 9.65446, 'loss': 0.44685582, 'lr': 0, 'params': 216673, 'time_iter': 1.37921, 'accuracy': 0.81481, 'precision': 0.83721, 'recall': 0.73469, 'f1': 0.78261, 'auc': 0.88551}\n",
      "> Epoch 14: took 98.8s (avg 83.6s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 15, 'time_epoch': 74.60796, 'eta': 951.30018, 'eta_hours': 0.26425, 'loss': 0.22595019, 'lr': 0.00065451, 'params': 216673, 'time_iter': 1.38163, 'accuracy': 0.94432, 'precision': 0.94373, 'recall': 0.93418, 'f1': 0.93893, 'auc': 0.9791}\n",
      "val: {'epoch': 15, 'time_epoch': 6.60411, 'loss': 0.60561958, 'lr': 0, 'params': 216673, 'time_iter': 0.94344, 'accuracy': 0.73148, 'precision': 0.63514, 'recall': 0.95918, 'f1': 0.76423, 'auc': 0.83812}\n",
      "test: {'epoch': 15, 'time_epoch': 9.73936, 'loss': 0.59436017, 'lr': 0, 'params': 216673, 'time_iter': 1.39134, 'accuracy': 0.73148, 'precision': 0.63514, 'recall': 0.95918, 'f1': 0.76423, 'auc': 0.8689}\n",
      "> Epoch 15: took 91.0s (avg 84.0s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 16, 'time_epoch': 57.5449, 'eta': 875.39332, 'eta_hours': 0.24316, 'loss': 0.1957381, 'lr': 0.00059369, 'params': 216673, 'time_iter': 1.06565, 'accuracy': 0.95476, 'precision': 0.94724, 'recall': 0.95443, 'f1': 0.95082, 'auc': 0.98229}\n",
      "val: {'epoch': 16, 'time_epoch': 6.64314, 'loss': 0.49237362, 'lr': 0, 'params': 216673, 'time_iter': 0.94902, 'accuracy': 0.81481, 'precision': 0.85366, 'recall': 0.71429, 'f1': 0.77778, 'auc': 0.86614}\n",
      "test: {'epoch': 16, 'time_epoch': 9.74371, 'loss': 0.55252695, 'lr': 0, 'params': 216673, 'time_iter': 1.39196, 'accuracy': 0.78704, 'precision': 0.84211, 'recall': 0.65306, 'f1': 0.73563, 'auc': 0.87548}\n",
      "> Epoch 16: took 74.0s (avg 83.4s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 17, 'time_epoch': 69.79982, 'eta': 809.69662, 'eta_hours': 0.22492, 'loss': 0.18462183, 'lr': 0.0005314, 'params': 216673, 'time_iter': 1.29259, 'accuracy': 0.95708, 'precision': 0.94527, 'recall': 0.96203, 'f1': 0.95358, 'auc': 0.98311}\n",
      "val: {'epoch': 17, 'time_epoch': 6.52554, 'loss': 0.50552979, 'lr': 0, 'params': 216673, 'time_iter': 0.93222, 'accuracy': 0.81481, 'precision': 0.80851, 'recall': 0.77551, 'f1': 0.79167, 'auc': 0.88793}\n",
      "test: {'epoch': 17, 'time_epoch': 9.7506, 'loss': 0.46397377, 'lr': 0, 'params': 216673, 'time_iter': 1.39294, 'accuracy': 0.80556, 'precision': 0.78, 'recall': 0.79592, 'f1': 0.78788, 'auc': 0.90695}\n",
      "> Epoch 17: took 86.1s (avg 83.6s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 18, 'time_epoch': 81.18797, 'eta': 750.16115, 'eta_hours': 0.20838, 'loss': 0.15401666, 'lr': 0.0004686, 'params': 216673, 'time_iter': 1.50348, 'accuracy': 0.96984, 'precision': 0.95782, 'recall': 0.97722, 'f1': 0.96742, 'auc': 0.98631}\n",
      "val: {'epoch': 18, 'time_epoch': 6.62865, 'loss': 0.50609595, 'lr': 0, 'params': 216673, 'time_iter': 0.94695, 'accuracy': 0.82407, 'precision': 0.875, 'recall': 0.71429, 'f1': 0.78652, 'auc': 0.85057}\n",
      "test: {'epoch': 18, 'time_epoch': 9.30288, 'loss': 0.54476327, 'lr': 0, 'params': 216673, 'time_iter': 1.32898, 'accuracy': 0.7963, 'precision': 0.86486, 'recall': 0.65306, 'f1': 0.74419, 'auc': 0.86475}\n",
      "> Epoch 18: took 97.2s (avg 84.3s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 19, 'time_epoch': 81.8457, 'eta': 688.7893, 'eta_hours': 0.19133, 'loss': 0.1501764, 'lr': 0.00040631, 'params': 216673, 'time_iter': 1.51566, 'accuracy': 0.97332, 'precision': 0.96269, 'recall': 0.97975, 'f1': 0.97114, 'auc': 0.99045}\n",
      "val: {'epoch': 19, 'time_epoch': 6.55556, 'loss': 0.51218969, 'lr': 0, 'params': 216673, 'time_iter': 0.93651, 'accuracy': 0.81481, 'precision': 0.79592, 'recall': 0.79592, 'f1': 0.79592, 'auc': 0.8817}\n",
      "test: {'epoch': 19, 'time_epoch': 9.68599, 'loss': 0.47652489, 'lr': 0, 'params': 216673, 'time_iter': 1.38371, 'accuracy': 0.81481, 'precision': 0.74576, 'recall': 0.89796, 'f1': 0.81481, 'auc': 0.89934}\n",
      "> Epoch 19: took 98.1s (avg 85.0s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 20, 'time_epoch': 69.82145, 'eta': 620.31431, 'eta_hours': 0.17231, 'loss': 0.15940873, 'lr': 0.00034549, 'params': 216673, 'time_iter': 1.29299, 'accuracy': 0.96984, 'precision': 0.97187, 'recall': 0.96203, 'f1': 0.96692, 'auc': 0.98383}\n",
      "val: {'epoch': 20, 'time_epoch': 6.58041, 'loss': 0.49908549, 'lr': 0, 'params': 216673, 'time_iter': 0.94006, 'accuracy': 0.82407, 'precision': 0.875, 'recall': 0.71429, 'f1': 0.78652, 'auc': 0.85853}\n",
      "test: {'epoch': 20, 'time_epoch': 9.76064, 'loss': 0.51425894, 'lr': 0, 'params': 216673, 'time_iter': 1.39438, 'accuracy': 0.83333, 'precision': 0.89744, 'recall': 0.71429, 'f1': 0.79545, 'auc': 0.88827}\n",
      "> Epoch 20: took 86.2s (avg 85.1s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 21, 'time_epoch': 74.79113, 'eta': 553.52407, 'eta_hours': 0.15376, 'loss': 0.13203067, 'lr': 0.00028711, 'params': 216673, 'time_iter': 1.38502, 'accuracy': 0.9768, 'precision': 0.97229, 'recall': 0.97722, 'f1': 0.97475, 'auc': 0.98991}\n",
      "val: {'epoch': 21, 'time_epoch': 6.33224, 'loss': 0.50796908, 'lr': 0, 'params': 216673, 'time_iter': 0.90461, 'accuracy': 0.82407, 'precision': 0.85714, 'recall': 0.73469, 'f1': 0.79121, 'auc': 0.87444}\n",
      "test: {'epoch': 21, 'time_epoch': 9.25287, 'loss': 0.47269039, 'lr': 0, 'params': 216673, 'time_iter': 1.32184, 'accuracy': 0.83333, 'precision': 0.86047, 'recall': 0.7551, 'f1': 0.80435, 'auc': 0.90834}\n",
      "> Epoch 21: took 90.4s (avg 85.3s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 22, 'time_epoch': 68.46777, 'eta': 484.1136, 'eta_hours': 0.13448, 'loss': 0.13143863, 'lr': 0.00023209, 'params': 216673, 'time_iter': 1.26792, 'accuracy': 0.97564, 'precision': 0.9675, 'recall': 0.97975, 'f1': 0.97358, 'auc': 0.99216}\n",
      "val: {'epoch': 22, 'time_epoch': 7.32756, 'loss': 0.53657972, 'lr': 0, 'params': 216673, 'time_iter': 1.04679, 'accuracy': 0.80556, 'precision': 0.85, 'recall': 0.69388, 'f1': 0.76404, 'auc': 0.87202}\n",
      "test: {'epoch': 22, 'time_epoch': 10.77693, 'loss': 0.50639838, 'lr': 0, 'params': 216673, 'time_iter': 1.53956, 'accuracy': 0.83333, 'precision': 0.86047, 'recall': 0.7551, 'f1': 0.80435, 'auc': 0.89242}\n",
      "> Epoch 22: took 86.7s (avg 85.4s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 23, 'time_epoch': 82.66513, 'eta': 418.33102, 'eta_hours': 0.1162, 'loss': 0.12663357, 'lr': 0.00018129, 'params': 216673, 'time_iter': 1.53084, 'accuracy': 0.9768, 'precision': 0.96992, 'recall': 0.97975, 'f1': 0.97481, 'auc': 0.99378}\n",
      "val: {'epoch': 23, 'time_epoch': 7.14014, 'loss': 0.55709679, 'lr': 0, 'params': 216673, 'time_iter': 1.02002, 'accuracy': 0.81481, 'precision': 0.87179, 'recall': 0.69388, 'f1': 0.77273, 'auc': 0.86095}\n",
      "test: {'epoch': 23, 'time_epoch': 10.66994, 'loss': 0.53404711, 'lr': 0, 'params': 216673, 'time_iter': 1.52428, 'accuracy': 0.80556, 'precision': 0.86842, 'recall': 0.67347, 'f1': 0.75862, 'auc': 0.89346}\n",
      "> Epoch 23: took 100.6s (avg 86.0s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n",
      "train: {'epoch': 24, 'time_epoch': 59.17996, 'eta': 346.50081, 'eta_hours': 0.09625, 'loss': 0.10972624, 'lr': 0.00013552, 'params': 216673, 'time_iter': 1.09593, 'accuracy': 0.98492, 'precision': 0.98477, 'recall': 0.98228, 'f1': 0.98352, 'auc': 0.99129}\n",
      "val: {'epoch': 24, 'time_epoch': 7.16784, 'loss': 0.51218678, 'lr': 0, 'params': 216673, 'time_iter': 1.02398, 'accuracy': 0.82407, 'precision': 0.82609, 'recall': 0.77551, 'f1': 0.8, 'auc': 0.88291}\n",
      "test: {'epoch': 24, 'time_epoch': 10.63994, 'loss': 0.43345737, 'lr': 0, 'params': 216673, 'time_iter': 1.51999, 'accuracy': 0.83333, 'precision': 0.82979, 'recall': 0.79592, 'f1': 0.8125, 'auc': 0.91733}\n",
      "> Epoch 24: took 77.1s (avg 85.6s) | Best so far: epoch 8\ttrain_loss: 0.3924 train_accuracy: 0.8736\tval_loss: 0.4119 val_accuracy: 0.8518\ttest_loss: 0.4558 test_accuracy: 0.8148\n"
     ]
    }
   ],
   "source": [
    "#Gender GPS Using CustomGatedGCN+Transformer\n",
    "%run main.py --cfg configs/GPS/neural-GPS+RWSE+small.yaml  wandb.use False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842ff2b8-271d-49fb-bf9d-bbf5c4d95b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-26 00:41:17.663633\n",
      "[*] Loaded dataset 'HCPGender' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1078000, 1000], edge_index=[2, 49133748], y=[1078])\n",
      "  undirected: True\n",
      "  num graphs: 1078\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 2\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [04:19<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:04:21.90\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [01:21<00:00, 13.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:24.08\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPGender\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: CustomGatedGCN+Exphormer\n",
      "  layers: 3\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 50\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Gender\n",
      "params: 304204\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Gender\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 2\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 233028\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 504.25968, 'eta': 24708.72427, 'eta_hours': 6.86353, 'loss': 0.69485726, 'lr': 0.0, 'params': 233028, 'time_iter': 9.33814, 'accuracy': 0.47796, 'precision': 0.42424, 'recall': 0.38987, 'f1': 0.40633, 'auc': 0.45717}\n",
      "...computing epoch stats took: 0.15s\n",
      "val: {'epoch': 0, 'time_epoch': 12.73323, 'loss': 0.69520744, 'lr': 0, 'params': 233028, 'time_iter': 1.81903, 'accuracy': 0.43519, 'precision': 0.33333, 'recall': 0.2449, 'f1': 0.28235, 'auc': 0.41577}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 0, 'time_epoch': 12.38901, 'loss': 0.69651322, 'lr': 0, 'params': 233028, 'time_iter': 1.76986, 'accuracy': 0.47222, 'precision': 0.33333, 'recall': 0.16327, 'f1': 0.21918, 'auc': 0.37945}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 529.6s (avg 529.6s) | Best so far: epoch 0\ttrain_loss: 0.6949 train_accuracy: 0.4780\tval_loss: 0.6952 val_accuracy: 0.4352\ttest_loss: 0.6965 test_accuracy: 0.4722\n",
      "train: {'epoch': 1, 'time_epoch': 401.13983, 'eta': 21729.58821, 'eta_hours': 6.036, 'loss': 0.67113402, 'lr': 0.0002, 'params': 233028, 'time_iter': 7.42852, 'accuracy': 0.61369, 'precision': 0.59627, 'recall': 0.48608, 'f1': 0.53556, 'auc': 0.66477}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 1, 'time_epoch': 12.51014, 'loss': 0.65220799, 'lr': 0, 'params': 233028, 'time_iter': 1.78716, 'accuracy': 0.73148, 'precision': 0.70833, 'recall': 0.69388, 'f1': 0.70103, 'auc': 0.77655}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 12.2851, 'loss': 0.65073595, 'lr': 0, 'params': 233028, 'time_iter': 1.75501, 'accuracy': 0.68519, 'precision': 0.65306, 'recall': 0.65306, 'f1': 0.65306, 'auc': 0.77862}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 426.0s (avg 477.8s) | Best so far: epoch 1\ttrain_loss: 0.6711 train_accuracy: 0.6137\tval_loss: 0.6522 val_accuracy: 0.7315\ttest_loss: 0.6507 test_accuracy: 0.6852\n",
      "train: {'epoch': 2, 'time_epoch': 417.02562, 'eta': 20717.99361, 'eta_hours': 5.755, 'loss': 0.62131707, 'lr': 0.0004, 'params': 233028, 'time_iter': 7.7227, 'accuracy': 0.74826, 'precision': 0.76023, 'recall': 0.65823, 'f1': 0.70556, 'auc': 0.8102}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 2, 'time_epoch': 12.6021, 'loss': 0.5931476, 'lr': 0, 'params': 233028, 'time_iter': 1.8003, 'accuracy': 0.77778, 'precision': 0.80488, 'recall': 0.67347, 'f1': 0.73333, 'auc': 0.88862}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 12.26008, 'loss': 0.5990563, 'lr': 0, 'params': 233028, 'time_iter': 1.75144, 'accuracy': 0.7963, 'precision': 0.84615, 'recall': 0.67347, 'f1': 0.75, 'auc': 0.86371}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 442.0s (avg 465.8s) | Best so far: epoch 2\ttrain_loss: 0.6213 train_accuracy: 0.7483\tval_loss: 0.5931 val_accuracy: 0.7778\ttest_loss: 0.5991 test_accuracy: 0.7963\n",
      "train: {'epoch': 3, 'time_epoch': 558.31696, 'eta': 21628.53402, 'eta_hours': 6.00793, 'loss': 0.54349787, 'lr': 0.0006, 'params': 233028, 'time_iter': 10.3392, 'accuracy': 0.84687, 'precision': 0.84514, 'recall': 0.81519, 'f1': 0.8299, 'auc': 0.89164}\n",
      "val: {'epoch': 3, 'time_epoch': 18.22374, 'loss': 0.55448024, 'lr': 0, 'params': 233028, 'time_iter': 2.60339, 'accuracy': 0.7963, 'precision': 0.74545, 'recall': 0.83673, 'f1': 0.78846, 'auc': 0.86337}\n",
      "test: {'epoch': 3, 'time_epoch': 19.45654, 'loss': 0.54576684, 'lr': 0, 'params': 233028, 'time_iter': 2.77951, 'accuracy': 0.7963, 'precision': 0.76471, 'recall': 0.79592, 'f1': 0.78, 'auc': 0.87513}\n",
      "> Epoch 3: took 596.0s (avg 498.4s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n",
      "train: {'epoch': 4, 'time_epoch': 686.3867, 'eta': 23104.15906, 'eta_hours': 6.41782, 'loss': 0.51245939, 'lr': 0.0008, 'params': 233028, 'time_iter': 12.71086, 'accuracy': 0.83643, 'precision': 0.81281, 'recall': 0.83544, 'f1': 0.82397, 'auc': 0.8912}\n",
      "val: {'epoch': 4, 'time_epoch': 19.9432, 'loss': 0.58089428, 'lr': 0, 'params': 233028, 'time_iter': 2.84903, 'accuracy': 0.74074, 'precision': 0.64384, 'recall': 0.95918, 'f1': 0.77049, 'auc': 0.89139}\n",
      "test: {'epoch': 4, 'time_epoch': 19.32457, 'loss': 0.61210132, 'lr': 0, 'params': 233028, 'time_iter': 2.76065, 'accuracy': 0.66667, 'precision': 0.58025, 'recall': 0.95918, 'f1': 0.72308, 'auc': 0.88689}\n",
      "> Epoch 4: took 725.7s (avg 543.9s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n",
      "train: {'epoch': 5, 'time_epoch': 682.87121, 'eta': 23833.33327, 'eta_hours': 6.62037, 'loss': 0.5133551, 'lr': 0.001, 'params': 233028, 'time_iter': 12.64576, 'accuracy': 0.80394, 'precision': 0.79124, 'recall': 0.77722, 'f1': 0.78416, 'auc': 0.84606}\n",
      "val: {'epoch': 5, 'time_epoch': 19.16162, 'loss': 0.70294828, 'lr': 0, 'params': 233028, 'time_iter': 2.73737, 'accuracy': 0.61111, 'precision': 0.88889, 'recall': 0.16327, 'f1': 0.27586, 'auc': 0.72432}\n",
      "test: {'epoch': 5, 'time_epoch': 18.3582, 'loss': 0.74518831, 'lr': 0, 'params': 233028, 'time_iter': 2.6226, 'accuracy': 0.55556, 'precision': 0.6, 'recall': 0.06122, 'f1': 0.11111, 'auc': 0.66551}\n",
      "> Epoch 5: took 720.4s (avg 573.3s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n",
      "train: {'epoch': 6, 'time_epoch': 657.4398, 'eta': 24002.84445, 'eta_hours': 6.66746, 'loss': 0.43101851, 'lr': 0.00099878, 'params': 233028, 'time_iter': 12.17481, 'accuracy': 0.86311, 'precision': 0.84029, 'recall': 0.86582, 'f1': 0.85287, 'auc': 0.92032}\n",
      "val: {'epoch': 6, 'time_epoch': 12.07031, 'loss': 0.59987622, 'lr': 0, 'params': 233028, 'time_iter': 1.72433, 'accuracy': 0.68519, 'precision': 0.59494, 'recall': 0.95918, 'f1': 0.73438, 'auc': 0.73296}\n",
      "test: {'epoch': 6, 'time_epoch': 11.80973, 'loss': 0.61729868, 'lr': 0, 'params': 233028, 'time_iter': 1.6871, 'accuracy': 0.67593, 'precision': 0.58974, 'recall': 0.93878, 'f1': 0.72441, 'auc': 0.70564}\n",
      "> Epoch 6: took 681.3s (avg 588.7s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n",
      "train: {'epoch': 7, 'time_epoch': 415.78895, 'eta': 22696.95093, 'eta_hours': 6.30471, 'loss': 0.40361605, 'lr': 0.00099513, 'params': 233028, 'time_iter': 7.6998, 'accuracy': 0.87007, 'precision': 0.85287, 'recall': 0.86582, 'f1': 0.8593, 'auc': 0.92938}\n",
      "val: {'epoch': 7, 'time_epoch': 11.99645, 'loss': 0.7635301, 'lr': 0, 'params': 233028, 'time_iter': 1.71378, 'accuracy': 0.59259, 'precision': 1.0, 'recall': 0.10204, 'f1': 0.18519, 'auc': 0.78347}\n",
      "test: {'epoch': 7, 'time_epoch': 11.84437, 'loss': 0.81480106, 'lr': 0, 'params': 233028, 'time_iter': 1.69205, 'accuracy': 0.56481, 'precision': 0.75, 'recall': 0.06122, 'f1': 0.11321, 'auc': 0.69146}\n",
      "> Epoch 7: took 439.7s (avg 570.1s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n",
      "train: {'epoch': 8, 'time_epoch': 413.68112, 'eta': 21579.25607, 'eta_hours': 5.99424, 'loss': 0.36647144, 'lr': 0.00098907, 'params': 233028, 'time_iter': 7.66076, 'accuracy': 0.89095, 'precision': 0.87719, 'recall': 0.88608, 'f1': 0.88161, 'auc': 0.93867}\n",
      "val: {'epoch': 8, 'time_epoch': 12.11912, 'loss': 0.59167739, 'lr': 0, 'params': 233028, 'time_iter': 1.7313, 'accuracy': 0.72222, 'precision': 0.63014, 'recall': 0.93878, 'f1': 0.7541, 'auc': 0.88689}\n",
      "test: {'epoch': 8, 'time_epoch': 11.77849, 'loss': 0.63644475, 'lr': 0, 'params': 233028, 'time_iter': 1.68264, 'accuracy': 0.68519, 'precision': 0.59494, 'recall': 0.95918, 'f1': 0.73438, 'auc': 0.89969}\n",
      "> Epoch 8: took 437.6s (avg 555.4s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n",
      "train: {'epoch': 9, 'time_epoch': 414.38679, 'eta': 20605.18664, 'eta_hours': 5.72366, 'loss': 0.34015259, 'lr': 0.00098063, 'params': 233028, 'time_iter': 7.67383, 'accuracy': 0.89327, 'precision': 0.88354, 'recall': 0.88354, 'f1': 0.88354, 'auc': 0.94015}\n",
      "val: {'epoch': 9, 'time_epoch': 12.02661, 'loss': 0.81192482, 'lr': 0, 'params': 233028, 'time_iter': 1.71809, 'accuracy': 0.56481, 'precision': 0.51064, 'recall': 0.97959, 'f1': 0.67133, 'auc': 0.71429}\n",
      "test: {'epoch': 9, 'time_epoch': 11.84543, 'loss': 0.8528793, 'lr': 0, 'params': 233028, 'time_iter': 1.6922, 'accuracy': 0.53704, 'precision': 0.49495, 'recall': 1.0, 'f1': 0.66216, 'auc': 0.7385}\n",
      "> Epoch 9: took 438.3s (avg 543.7s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n",
      "train: {'epoch': 10, 'time_epoch': 415.23091, 'eta': 19735.87048, 'eta_hours': 5.48219, 'loss': 0.29406891, 'lr': 0.00096985, 'params': 233028, 'time_iter': 7.68946, 'accuracy': 0.92111, 'precision': 0.91816, 'recall': 0.90886, 'f1': 0.91349, 'auc': 0.95259}\n",
      "val: {'epoch': 10, 'time_epoch': 12.08083, 'loss': 0.50639908, 'lr': 0, 'params': 233028, 'time_iter': 1.72583, 'accuracy': 0.7963, 'precision': 0.72131, 'recall': 0.89796, 'f1': 0.8, 'auc': 0.89139}\n",
      "test: {'epoch': 10, 'time_epoch': 11.81111, 'loss': 0.47775048, 'lr': 0, 'params': 233028, 'time_iter': 1.6873, 'accuracy': 0.7963, 'precision': 0.70149, 'recall': 0.95918, 'f1': 0.81034, 'auc': 0.90315}\n",
      "> Epoch 10: took 439.1s (avg 534.2s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n",
      "train: {'epoch': 11, 'time_epoch': 420.21442, 'eta': 18958.01629, 'eta_hours': 5.26612, 'loss': 0.26442186, 'lr': 0.00095677, 'params': 233028, 'time_iter': 7.78175, 'accuracy': 0.93503, 'precision': 0.9313, 'recall': 0.92658, 'f1': 0.92893, 'auc': 0.96405}\n",
      "val: {'epoch': 11, 'time_epoch': 11.89475, 'loss': 0.62016202, 'lr': 0, 'params': 233028, 'time_iter': 1.69925, 'accuracy': 0.74074, 'precision': 0.81818, 'recall': 0.55102, 'f1': 0.65854, 'auc': 0.81702}\n",
      "test: {'epoch': 11, 'time_epoch': 11.89182, 'loss': 0.7157056, 'lr': 0, 'params': 233028, 'time_iter': 1.69883, 'accuracy': 0.66667, 'precision': 0.74074, 'recall': 0.40816, 'f1': 0.52632, 'auc': 0.8184}\n",
      "> Epoch 11: took 444.0s (avg 526.6s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n",
      "train: {'epoch': 12, 'time_epoch': 404.42086, 'eta': 18190.23272, 'eta_hours': 5.05284, 'loss': 0.23427757, 'lr': 0.00094147, 'params': 233028, 'time_iter': 7.48928, 'accuracy': 0.94432, 'precision': 0.94602, 'recall': 0.93165, 'f1': 0.93878, 'auc': 0.96375}\n",
      "val: {'epoch': 12, 'time_epoch': 11.91009, 'loss': 0.56700327, 'lr': 0, 'params': 233028, 'time_iter': 1.70144, 'accuracy': 0.75926, 'precision': 0.71698, 'recall': 0.77551, 'f1': 0.7451, 'auc': 0.82947}\n",
      "test: {'epoch': 12, 'time_epoch': 11.66777, 'loss': 0.51635704, 'lr': 0, 'params': 233028, 'time_iter': 1.66682, 'accuracy': 0.78704, 'precision': 0.75, 'recall': 0.79592, 'f1': 0.77228, 'auc': 0.88378}\n",
      "> Epoch 12: took 428.0s (avg 519.1s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n",
      "train: {'epoch': 13, 'time_epoch': 631.81487, 'eta': 18059.08556, 'eta_hours': 5.01641, 'loss': 0.23782986, 'lr': 0.00092402, 'params': 233028, 'time_iter': 11.70028, 'accuracy': 0.93503, 'precision': 0.9206, 'recall': 0.93924, 'f1': 0.92982, 'auc': 0.96858}\n",
      "val: {'epoch': 13, 'time_epoch': 42.47235, 'loss': 0.56361558, 'lr': 0, 'params': 233028, 'time_iter': 6.06748, 'accuracy': 0.75, 'precision': 0.69643, 'recall': 0.79592, 'f1': 0.74286, 'auc': 0.88101}\n",
      "test: {'epoch': 13, 'time_epoch': 40.57412, 'loss': 0.4069549, 'lr': 0, 'params': 233028, 'time_iter': 5.7963, 'accuracy': 0.85185, 'precision': 0.8, 'recall': 0.89796, 'f1': 0.84615, 'auc': 0.90384}\n",
      "> Epoch 13: took 714.9s (avg 533.0s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n",
      "train: {'epoch': 14, 'time_epoch': 725.24085, 'eta': 18079.17667, 'eta_hours': 5.02199, 'loss': 0.2051203, 'lr': 0.00090451, 'params': 233028, 'time_iter': 13.43039, 'accuracy': 0.94896, 'precision': 0.95116, 'recall': 0.93671, 'f1': 0.94388, 'auc': 0.96995}\n",
      "val: {'epoch': 14, 'time_epoch': 43.13234, 'loss': 0.76621887, 'lr': 0, 'params': 233028, 'time_iter': 6.16176, 'accuracy': 0.69444, 'precision': 0.6, 'recall': 0.97959, 'f1': 0.74419, 'auc': 0.76583}\n",
      "test: {'epoch': 14, 'time_epoch': 41.2208, 'loss': 0.83474948, 'lr': 0, 'params': 233028, 'time_iter': 5.88869, 'accuracy': 0.62963, 'precision': 0.55056, 'recall': 1.0, 'f1': 0.71014, 'auc': 0.81148}\n",
      "> Epoch 14: took 811.8s (avg 551.6s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n",
      "train: {'epoch': 15, 'time_epoch': 729.04814, 'eta': 18014.19177, 'eta_hours': 5.00394, 'loss': 0.19331826, 'lr': 0.00088302, 'params': 233028, 'time_iter': 13.50089, 'accuracy': 0.95244, 'precision': 0.95619, 'recall': 0.93924, 'f1': 0.94764, 'auc': 0.97867}\n",
      "val: {'epoch': 15, 'time_epoch': 43.10259, 'loss': 0.52358349, 'lr': 0, 'params': 233028, 'time_iter': 6.15751, 'accuracy': 0.77778, 'precision': 0.72727, 'recall': 0.81633, 'f1': 0.76923, 'auc': 0.84607}\n",
      "test: {'epoch': 15, 'time_epoch': 41.23196, 'loss': 0.48745612, 'lr': 0, 'params': 233028, 'time_iter': 5.89028, 'accuracy': 0.82407, 'precision': 0.75862, 'recall': 0.89796, 'f1': 0.82243, 'auc': 0.8696}\n",
      "> Epoch 15: took 813.4s (avg 568.0s) | Best so far: epoch 3\ttrain_loss: 0.5435 train_accuracy: 0.8469\tval_loss: 0.5545 val_accuracy: 0.7963\ttest_loss: 0.5458 test_accuracy: 0.7963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gender - Using CustomGCN +Exphormer\n",
    "%run main.py --cfg configs/Exphormer/neural-Gender.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ceb29f-c66c-44b8-82df-0d661e91d4bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-26 18:04:09.220758\n",
      "[*] Loaded dataset 'HCPGender' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1078000, 1000], edge_index=[2, 49133748], y=[1078])\n",
      "  undirected: True\n",
      "  num graphs: 1078\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 2\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [07:22<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:07:37.45\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [05:10<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:05:13.30\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPGender\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 3\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 50\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Gender\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Gender\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 2\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 168897\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 21.76908, 'eta': 1066.6849, 'eta_hours': 0.2963, 'loss': 0.70052447, 'lr': 0.0, 'params': 168897, 'time_iter': 0.40313, 'accuracy': 0.45476, 'precision': 0.45583, 'recall': 0.97975, 'f1': 0.62219, 'auc': 0.51131}\n",
      "...computing epoch stats took: 0.29s\n",
      "val: {'epoch': 0, 'time_epoch': 1.28529, 'loss': 0.7047557, 'lr': 0, 'params': 168897, 'time_iter': 0.18361, 'accuracy': 0.4537, 'precision': 0.45283, 'recall': 0.97959, 'f1': 0.61935, 'auc': 0.45036}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 0, 'time_epoch': 1.22352, 'loss': 0.70879127, 'lr': 0, 'params': 168897, 'time_iter': 0.17479, 'accuracy': 0.4537, 'precision': 0.45283, 'recall': 0.97959, 'f1': 0.61935, 'auc': 0.35974}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 24.6s (avg 24.6s) | Best so far: epoch 0\ttrain_loss: 0.7005 train_accuracy: 0.4548\tval_loss: 0.7048 val_accuracy: 0.4537\ttest_loss: 0.7088 test_accuracy: 0.4537\n",
      "train: {'epoch': 1, 'time_epoch': 21.32328, 'eta': 1034.21652, 'eta_hours': 0.28728, 'loss': 0.67138138, 'lr': 0.0002, 'params': 168897, 'time_iter': 0.39488, 'accuracy': 0.61369, 'precision': 0.56327, 'recall': 0.69873, 'f1': 0.62373, 'auc': 0.68282}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 1, 'time_epoch': 1.45465, 'loss': 0.66005258, 'lr': 0, 'params': 168897, 'time_iter': 0.20781, 'accuracy': 0.66667, 'precision': 0.76, 'recall': 0.38776, 'f1': 0.51351, 'auc': 0.74922}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 1, 'time_epoch': 1.45522, 'loss': 0.65609588, 'lr': 0, 'params': 168897, 'time_iter': 0.20789, 'accuracy': 0.7037, 'precision': 0.77419, 'recall': 0.4898, 'f1': 0.6, 'auc': 0.76271}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 1: took 24.3s (avg 24.5s) | Best so far: epoch 1\ttrain_loss: 0.6714 train_accuracy: 0.6137\tval_loss: 0.6601 val_accuracy: 0.6667\ttest_loss: 0.6561 test_accuracy: 0.7037\n",
      "train: {'epoch': 2, 'time_epoch': 22.67982, 'eta': 1030.43069, 'eta_hours': 0.28623, 'loss': 0.62607261, 'lr': 0.0004, 'params': 168897, 'time_iter': 0.42, 'accuracy': 0.73202, 'precision': 0.7, 'recall': 0.72658, 'f1': 0.71304, 'auc': 0.79093}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 2, 'time_epoch': 1.45373, 'loss': 0.60050054, 'lr': 0, 'params': 168897, 'time_iter': 0.20768, 'accuracy': 0.76852, 'precision': 0.8, 'recall': 0.65306, 'f1': 0.7191, 'auc': 0.86475}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 2, 'time_epoch': 1.44763, 'loss': 0.60355864, 'lr': 0, 'params': 168897, 'time_iter': 0.2068, 'accuracy': 0.76852, 'precision': 0.76087, 'recall': 0.71429, 'f1': 0.73684, 'auc': 0.8523}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 2: took 25.7s (avg 24.9s) | Best so far: epoch 2\ttrain_loss: 0.6261 train_accuracy: 0.7320\tval_loss: 0.6005 val_accuracy: 0.7685\ttest_loss: 0.6036 test_accuracy: 0.7685\n",
      "train: {'epoch': 3, 'time_epoch': 22.15628, 'eta': 1011.1772, 'eta_hours': 0.28088, 'loss': 0.56890407, 'lr': 0.0006, 'params': 168897, 'time_iter': 0.4103, 'accuracy': 0.8051, 'precision': 0.78734, 'recall': 0.78734, 'f1': 0.78734, 'auc': 0.84251}\n",
      "val: {'epoch': 3, 'time_epoch': 1.39107, 'loss': 0.56941091, 'lr': 0, 'params': 168897, 'time_iter': 0.19872, 'accuracy': 0.80556, 'precision': 0.83333, 'recall': 0.71429, 'f1': 0.76923, 'auc': 0.85022}\n",
      "test: {'epoch': 3, 'time_epoch': 1.48559, 'loss': 0.5737844, 'lr': 0, 'params': 168897, 'time_iter': 0.21223, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.86544}\n",
      "> Epoch 3: took 25.1s (avg 24.9s) | Best so far: epoch 3\ttrain_loss: 0.5689 train_accuracy: 0.8051\tval_loss: 0.5694 val_accuracy: 0.8056\ttest_loss: 0.5738 test_accuracy: 0.8056\n",
      "train: {'epoch': 4, 'time_epoch': 22.71642, 'eta': 995.80388, 'eta_hours': 0.27661, 'loss': 0.53615426, 'lr': 0.0008, 'params': 168897, 'time_iter': 0.42067, 'accuracy': 0.81787, 'precision': 0.82337, 'recall': 0.76709, 'f1': 0.79423, 'auc': 0.85467}\n",
      "val: {'epoch': 4, 'time_epoch': 1.43036, 'loss': 0.517682, 'lr': 0, 'params': 168897, 'time_iter': 0.20434, 'accuracy': 0.80556, 'precision': 0.75, 'recall': 0.85714, 'f1': 0.8, 'auc': 0.88724}\n",
      "test: {'epoch': 4, 'time_epoch': 1.45566, 'loss': 0.53523963, 'lr': 0, 'params': 168897, 'time_iter': 0.20795, 'accuracy': 0.78704, 'precision': 0.71667, 'recall': 0.87755, 'f1': 0.78899, 'auc': 0.8779}\n",
      "> Epoch 4: took 25.7s (avg 25.1s) | Best so far: epoch 3\ttrain_loss: 0.5689 train_accuracy: 0.8051\tval_loss: 0.5694 val_accuracy: 0.8056\ttest_loss: 0.5738 test_accuracy: 0.8056\n",
      "train: {'epoch': 5, 'time_epoch': 29.70933, 'eta': 1029.26417, 'eta_hours': 0.28591, 'loss': 0.49597389, 'lr': 0.001, 'params': 168897, 'time_iter': 0.55017, 'accuracy': 0.83295, 'precision': 0.82429, 'recall': 0.80759, 'f1': 0.81586, 'auc': 0.86372}\n",
      "val: {'epoch': 5, 'time_epoch': 1.28291, 'loss': 0.7519724, 'lr': 0, 'params': 168897, 'time_iter': 0.18327, 'accuracy': 0.53704, 'precision': 0.45455, 'recall': 0.10204, 'f1': 0.16667, 'auc': 0.52473}\n",
      "test: {'epoch': 5, 'time_epoch': 1.18112, 'loss': 0.755023, 'lr': 0, 'params': 168897, 'time_iter': 0.16873, 'accuracy': 0.52778, 'precision': 0.4, 'recall': 0.08163, 'f1': 0.13559, 'auc': 0.59149}\n",
      "> Epoch 5: took 32.3s (avg 26.3s) | Best so far: epoch 3\ttrain_loss: 0.5689 train_accuracy: 0.8051\tval_loss: 0.5694 val_accuracy: 0.8056\ttest_loss: 0.5738 test_accuracy: 0.8056\n",
      "train: {'epoch': 6, 'time_epoch': 21.18, 'eta': 992.28153, 'eta_hours': 0.27563, 'loss': 0.46580319, 'lr': 0.00099878, 'params': 168897, 'time_iter': 0.39222, 'accuracy': 0.84339, 'precision': 0.83854, 'recall': 0.81519, 'f1': 0.8267, 'auc': 0.88807}\n",
      "val: {'epoch': 6, 'time_epoch': 1.50493, 'loss': 0.48739285, 'lr': 0, 'params': 168897, 'time_iter': 0.21499, 'accuracy': 0.81481, 'precision': 0.78431, 'recall': 0.81633, 'f1': 0.8, 'auc': 0.88758}\n",
      "test: {'epoch': 6, 'time_epoch': 1.52685, 'loss': 0.49901677, 'lr': 0, 'params': 168897, 'time_iter': 0.21812, 'accuracy': 0.7963, 'precision': 0.77551, 'recall': 0.77551, 'f1': 0.77551, 'auc': 0.87478}\n",
      "> Epoch 6: took 24.3s (avg 26.0s) | Best so far: epoch 6\ttrain_loss: 0.4658 train_accuracy: 0.8434\tval_loss: 0.4874 val_accuracy: 0.8148\ttest_loss: 0.4990 test_accuracy: 0.7963\n",
      "train: {'epoch': 7, 'time_epoch': 22.17714, 'eta': 964.48456, 'eta_hours': 0.26791, 'loss': 0.41027839, 'lr': 0.00099513, 'params': 168897, 'time_iter': 0.41069, 'accuracy': 0.87239, 'precision': 0.86632, 'recall': 0.85316, 'f1': 0.85969, 'auc': 0.91552}\n",
      "val: {'epoch': 7, 'time_epoch': 1.42461, 'loss': 0.63476494, 'lr': 0, 'params': 168897, 'time_iter': 0.20352, 'accuracy': 0.69444, 'precision': 0.94444, 'recall': 0.34694, 'f1': 0.50746, 'auc': 0.83916}\n",
      "test: {'epoch': 7, 'time_epoch': 1.47676, 'loss': 0.6699913, 'lr': 0, 'params': 168897, 'time_iter': 0.21097, 'accuracy': 0.64815, 'precision': 0.92308, 'recall': 0.2449, 'f1': 0.3871, 'auc': 0.8101}\n",
      "> Epoch 7: took 25.2s (avg 25.9s) | Best so far: epoch 6\ttrain_loss: 0.4658 train_accuracy: 0.8434\tval_loss: 0.4874 val_accuracy: 0.8148\ttest_loss: 0.4990 test_accuracy: 0.7963\n",
      "train: {'epoch': 8, 'time_epoch': 22.74876, 'eta': 940.54047, 'eta_hours': 0.26126, 'loss': 0.37810729, 'lr': 0.00098907, 'params': 168897, 'time_iter': 0.42127, 'accuracy': 0.88399, 'precision': 0.85888, 'recall': 0.89367, 'f1': 0.87593, 'auc': 0.93353}\n",
      "val: {'epoch': 8, 'time_epoch': 1.44566, 'loss': 0.56820238, 'lr': 0, 'params': 168897, 'time_iter': 0.20652, 'accuracy': 0.71296, 'precision': 0.62162, 'recall': 0.93878, 'f1': 0.74797, 'auc': 0.88966}\n",
      "test: {'epoch': 8, 'time_epoch': 1.45559, 'loss': 0.55616413, 'lr': 0, 'params': 168897, 'time_iter': 0.20794, 'accuracy': 0.73148, 'precision': 0.62821, 'recall': 1.0, 'f1': 0.77165, 'auc': 0.90522}\n",
      "> Epoch 8: took 25.7s (avg 25.9s) | Best so far: epoch 6\ttrain_loss: 0.4658 train_accuracy: 0.8434\tval_loss: 0.4874 val_accuracy: 0.8148\ttest_loss: 0.4990 test_accuracy: 0.7963\n",
      "train: {'epoch': 9, 'time_epoch': 21.8079, 'eta': 913.072, 'eta_hours': 0.25363, 'loss': 0.36087258, 'lr': 0.00098063, 'params': 168897, 'time_iter': 0.40385, 'accuracy': 0.88979, 'precision': 0.875, 'recall': 0.88608, 'f1': 0.8805, 'auc': 0.93661}\n",
      "val: {'epoch': 9, 'time_epoch': 1.37678, 'loss': 0.50178584, 'lr': 0, 'params': 168897, 'time_iter': 0.19668, 'accuracy': 0.7963, 'precision': 0.78723, 'recall': 0.7551, 'f1': 0.77083, 'auc': 0.85265}\n",
      "test: {'epoch': 9, 'time_epoch': 1.18548, 'loss': 0.51743556, 'lr': 0, 'params': 168897, 'time_iter': 0.16935, 'accuracy': 0.77778, 'precision': 0.7451, 'recall': 0.77551, 'f1': 0.76, 'auc': 0.84573}\n",
      "> Epoch 9: took 24.5s (avg 25.7s) | Best so far: epoch 6\ttrain_loss: 0.4658 train_accuracy: 0.8434\tval_loss: 0.4874 val_accuracy: 0.8148\ttest_loss: 0.4990 test_accuracy: 0.7963\n",
      "train: {'epoch': 10, 'time_epoch': 50.32207, 'eta': 987.72843, 'eta_hours': 0.27437, 'loss': 0.30961184, 'lr': 0.00096985, 'params': 168897, 'time_iter': 0.93189, 'accuracy': 0.91647, 'precision': 0.91948, 'recall': 0.8962, 'f1': 0.90769, 'auc': 0.95227}\n",
      "val: {'epoch': 10, 'time_epoch': 4.74184, 'loss': 0.43203809, 'lr': 0, 'params': 168897, 'time_iter': 0.67741, 'accuracy': 0.84259, 'precision': 0.88095, 'recall': 0.7551, 'f1': 0.81319, 'auc': 0.86925}\n",
      "test: {'epoch': 10, 'time_epoch': 4.42309, 'loss': 0.51475258, 'lr': 0, 'params': 168897, 'time_iter': 0.63187, 'accuracy': 0.77778, 'precision': 0.82051, 'recall': 0.65306, 'f1': 0.72727, 'auc': 0.87963}\n",
      "> Epoch 10: took 59.6s (avg 28.8s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 11, 'time_epoch': 70.83712, 'eta': 1106.51942, 'eta_hours': 0.30737, 'loss': 0.33997994, 'lr': 0.00095677, 'params': 168897, 'time_iter': 1.3118, 'accuracy': 0.88283, 'precision': 0.88889, 'recall': 0.85063, 'f1': 0.86934, 'auc': 0.94263}\n",
      "val: {'epoch': 11, 'time_epoch': 4.07247, 'loss': 0.48572115, 'lr': 0, 'params': 168897, 'time_iter': 0.58178, 'accuracy': 0.7963, 'precision': 0.70149, 'recall': 0.95918, 'f1': 0.81034, 'auc': 0.87167}\n",
      "test: {'epoch': 11, 'time_epoch': 4.08026, 'loss': 0.4675704, 'lr': 0, 'params': 168897, 'time_iter': 0.58289, 'accuracy': 0.78704, 'precision': 0.69118, 'recall': 0.95918, 'f1': 0.80342, 'auc': 0.90107}\n",
      "> Epoch 11: took 79.1s (avg 33.0s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 12, 'time_epoch': 57.86385, 'eta': 1159.21296, 'eta_hours': 0.322, 'loss': 0.27333113, 'lr': 0.00094147, 'params': 168897, 'time_iter': 1.07155, 'accuracy': 0.92227, 'precision': 0.90594, 'recall': 0.92658, 'f1': 0.91615, 'auc': 0.96047}\n",
      "val: {'epoch': 12, 'time_epoch': 1.3244, 'loss': 1.04152377, 'lr': 0, 'params': 168897, 'time_iter': 0.1892, 'accuracy': 0.49074, 'precision': 0.47115, 'recall': 1.0, 'f1': 0.64052, 'auc': 0.55863}\n",
      "test: {'epoch': 12, 'time_epoch': 1.26148, 'loss': 1.00563061, 'lr': 0, 'params': 168897, 'time_iter': 0.18021, 'accuracy': 0.51852, 'precision': 0.48515, 'recall': 1.0, 'f1': 0.65333, 'auc': 0.56244}\n",
      "> Epoch 12: took 60.6s (avg 35.1s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 13, 'time_epoch': 20.28662, 'eta': 1099.48542, 'eta_hours': 0.30541, 'loss': 0.25168482, 'lr': 0.00092402, 'params': 168897, 'time_iter': 0.37568, 'accuracy': 0.92807, 'precision': 0.90709, 'recall': 0.93924, 'f1': 0.92289, 'auc': 0.97028}\n",
      "val: {'epoch': 13, 'time_epoch': 1.43722, 'loss': 0.69476861, 'lr': 0, 'params': 168897, 'time_iter': 0.20532, 'accuracy': 0.7037, 'precision': 0.61333, 'recall': 0.93878, 'f1': 0.74194, 'auc': 0.80249}\n",
      "test: {'epoch': 13, 'time_epoch': 1.46662, 'loss': 0.75562266, 'lr': 0, 'params': 168897, 'time_iter': 0.20952, 'accuracy': 0.65741, 'precision': 0.57143, 'recall': 0.97959, 'f1': 0.7218, 'auc': 0.84262}\n",
      "> Epoch 13: took 23.3s (avg 34.3s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 14, 'time_epoch': 22.91833, 'eta': 1051.15732, 'eta_hours': 0.29199, 'loss': 0.22664398, 'lr': 0.00090451, 'params': 168897, 'time_iter': 0.42441, 'accuracy': 0.93735, 'precision': 0.94057, 'recall': 0.92152, 'f1': 0.93095, 'auc': 0.97498}\n",
      "val: {'epoch': 14, 'time_epoch': 1.47796, 'loss': 0.66335973, 'lr': 0, 'params': 168897, 'time_iter': 0.21114, 'accuracy': 0.71296, 'precision': 0.625, 'recall': 0.91837, 'f1': 0.7438, 'auc': 0.84054}\n",
      "test: {'epoch': 14, 'time_epoch': 1.437, 'loss': 0.64786115, 'lr': 0, 'params': 168897, 'time_iter': 0.20529, 'accuracy': 0.72222, 'precision': 0.62025, 'recall': 1.0, 'f1': 0.76562, 'auc': 0.88724}\n",
      "> Epoch 14: took 25.9s (avg 33.7s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 15, 'time_epoch': 49.49691, 'eta': 1062.48493, 'eta_hours': 0.29513, 'loss': 0.20598599, 'lr': 0.00088302, 'params': 168897, 'time_iter': 0.91661, 'accuracy': 0.94896, 'precision': 0.93766, 'recall': 0.9519, 'f1': 0.94472, 'auc': 0.97398}\n",
      "val: {'epoch': 15, 'time_epoch': 4.65441, 'loss': 0.52215601, 'lr': 0, 'params': 168897, 'time_iter': 0.66492, 'accuracy': 0.7963, 'precision': 0.72881, 'recall': 0.87755, 'f1': 0.7963, 'auc': 0.85022}\n",
      "test: {'epoch': 15, 'time_epoch': 4.45946, 'loss': 0.52297403, 'lr': 0, 'params': 168897, 'time_iter': 0.63707, 'accuracy': 0.78704, 'precision': 0.69118, 'recall': 0.95918, 'f1': 0.80342, 'auc': 0.88758}\n",
      "> Epoch 15: took 58.7s (avg 35.3s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 16, 'time_epoch': 68.76119, 'eta': 1104.05208, 'eta_hours': 0.30668, 'loss': 0.2112999, 'lr': 0.00085967, 'params': 168897, 'time_iter': 1.27336, 'accuracy': 0.94316, 'precision': 0.94359, 'recall': 0.93165, 'f1': 0.93758, 'auc': 0.97643}\n",
      "val: {'epoch': 16, 'time_epoch': 4.72202, 'loss': 0.7384754, 'lr': 0, 'params': 168897, 'time_iter': 0.67457, 'accuracy': 0.68519, 'precision': 0.5974, 'recall': 0.93878, 'f1': 0.73016, 'auc': 0.75925}\n",
      "test: {'epoch': 16, 'time_epoch': 4.38307, 'loss': 0.71275746, 'lr': 0, 'params': 168897, 'time_iter': 0.62615, 'accuracy': 0.71296, 'precision': 0.61538, 'recall': 0.97959, 'f1': 0.75591, 'auc': 0.87098}\n",
      "> Epoch 16: took 78.0s (avg 37.8s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 17, 'time_epoch': 61.70169, 'eta': 1120.81029, 'eta_hours': 0.31134, 'loss': 0.17454177, 'lr': 0.00083457, 'params': 168897, 'time_iter': 1.14262, 'accuracy': 0.95708, 'precision': 0.95431, 'recall': 0.9519, 'f1': 0.95311, 'auc': 0.9826}\n",
      "val: {'epoch': 17, 'time_epoch': 1.25224, 'loss': 0.53263885, 'lr': 0, 'params': 168897, 'time_iter': 0.17889, 'accuracy': 0.80556, 'precision': 0.75, 'recall': 0.85714, 'f1': 0.8, 'auc': 0.84677}\n",
      "test: {'epoch': 17, 'time_epoch': 1.30684, 'loss': 0.48539058, 'lr': 0, 'params': 168897, 'time_iter': 0.18669, 'accuracy': 0.81481, 'precision': 0.74576, 'recall': 0.89796, 'f1': 0.81481, 'auc': 0.89831}\n",
      "> Epoch 17: took 64.3s (avg 39.3s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 18, 'time_epoch': 19.75923, 'eta': 1060.87713, 'eta_hours': 0.29469, 'loss': 0.18568803, 'lr': 0.00080783, 'params': 168897, 'time_iter': 0.36591, 'accuracy': 0.95012, 'precision': 0.9467, 'recall': 0.9443, 'f1': 0.9455, 'auc': 0.98101}\n",
      "val: {'epoch': 18, 'time_epoch': 1.47999, 'loss': 0.59226796, 'lr': 0, 'params': 168897, 'time_iter': 0.21143, 'accuracy': 0.75, 'precision': 0.67742, 'recall': 0.85714, 'f1': 0.75676, 'auc': 0.84642}\n",
      "test: {'epoch': 18, 'time_epoch': 1.46854, 'loss': 0.58476837, 'lr': 0, 'params': 168897, 'time_iter': 0.20979, 'accuracy': 0.77778, 'precision': 0.68657, 'recall': 0.93878, 'f1': 0.7931, 'auc': 0.90003}\n",
      "> Epoch 18: took 22.8s (avg 38.4s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 19, 'time_epoch': 19.28794, 'eta': 1004.25443, 'eta_hours': 0.27896, 'loss': 0.14192119, 'lr': 0.0007796, 'params': 168897, 'time_iter': 0.35718, 'accuracy': 0.971, 'precision': 0.97194, 'recall': 0.96456, 'f1': 0.96823, 'auc': 0.98994}\n",
      "val: {'epoch': 19, 'time_epoch': 1.18968, 'loss': 0.61787962, 'lr': 0, 'params': 168897, 'time_iter': 0.16995, 'accuracy': 0.77778, 'precision': 0.85714, 'recall': 0.61224, 'f1': 0.71429, 'auc': 0.83673}\n",
      "test: {'epoch': 19, 'time_epoch': 1.1703, 'loss': 0.6088165, 'lr': 0, 'params': 168897, 'time_iter': 0.16719, 'accuracy': 0.76852, 'precision': 0.875, 'recall': 0.57143, 'f1': 0.69136, 'auc': 0.86544}\n",
      "> Epoch 19: took 21.7s (avg 37.6s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 20, 'time_epoch': 17.65453, 'eta': 948.93176, 'eta_hours': 0.26359, 'loss': 0.14104456, 'lr': 0.00075, 'params': 168897, 'time_iter': 0.32694, 'accuracy': 0.96868, 'precision': 0.97668, 'recall': 0.95443, 'f1': 0.96543, 'auc': 0.98967}\n",
      "val: {'epoch': 20, 'time_epoch': 1.18472, 'loss': 0.47682051, 'lr': 0, 'params': 168897, 'time_iter': 0.16925, 'accuracy': 0.84259, 'precision': 0.84783, 'recall': 0.79592, 'f1': 0.82105, 'auc': 0.84296}\n",
      "test: {'epoch': 20, 'time_epoch': 1.2399, 'loss': 0.5288597, 'lr': 0, 'params': 168897, 'time_iter': 0.17713, 'accuracy': 0.81481, 'precision': 0.80851, 'recall': 0.77551, 'f1': 0.79167, 'auc': 0.91352}\n",
      "> Epoch 20: took 20.1s (avg 36.7s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 21, 'time_epoch': 20.73993, 'eta': 900.96034, 'eta_hours': 0.25027, 'loss': 0.13039108, 'lr': 0.00071919, 'params': 168897, 'time_iter': 0.38407, 'accuracy': 0.96984, 'precision': 0.96709, 'recall': 0.96709, 'f1': 0.96709, 'auc': 0.98975}\n",
      "val: {'epoch': 21, 'time_epoch': 1.19504, 'loss': 0.53976689, 'lr': 0, 'params': 168897, 'time_iter': 0.17072, 'accuracy': 0.81481, 'precision': 0.87179, 'recall': 0.69388, 'f1': 0.77273, 'auc': 0.83016}\n",
      "test: {'epoch': 21, 'time_epoch': 1.28989, 'loss': 0.57280137, 'lr': 0, 'params': 168897, 'time_iter': 0.18427, 'accuracy': 0.80556, 'precision': 0.86842, 'recall': 0.67347, 'f1': 0.75862, 'auc': 0.86441}\n",
      "> Epoch 21: took 23.3s (avg 36.1s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 22, 'time_epoch': 17.6753, 'eta': 851.75928, 'eta_hours': 0.2366, 'loss': 0.10303902, 'lr': 0.0006873, 'params': 168897, 'time_iter': 0.32732, 'accuracy': 0.98144, 'precision': 0.97975, 'recall': 0.97975, 'f1': 0.97975, 'auc': 0.99311}\n",
      "val: {'epoch': 22, 'time_epoch': 1.1758, 'loss': 0.6343424, 'lr': 0, 'params': 168897, 'time_iter': 0.16797, 'accuracy': 0.77778, 'precision': 0.71186, 'recall': 0.85714, 'f1': 0.77778, 'auc': 0.81425}\n",
      "test: {'epoch': 22, 'time_epoch': 1.13009, 'loss': 0.50994881, 'lr': 0, 'params': 168897, 'time_iter': 0.16144, 'accuracy': 0.82407, 'precision': 0.75, 'recall': 0.91837, 'f1': 0.82569, 'auc': 0.86648}\n",
      "> Epoch 22: took 20.1s (avg 35.4s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 23, 'time_epoch': 17.47819, 'eta': 804.97181, 'eta_hours': 0.2236, 'loss': 0.12830921, 'lr': 0.00065451, 'params': 168897, 'time_iter': 0.32367, 'accuracy': 0.971, 'precision': 0.96717, 'recall': 0.96962, 'f1': 0.96839, 'auc': 0.98679}\n",
      "val: {'epoch': 23, 'time_epoch': 1.13064, 'loss': 0.69159356, 'lr': 0, 'params': 168897, 'time_iter': 0.16152, 'accuracy': 0.75926, 'precision': 0.79487, 'recall': 0.63265, 'f1': 0.70455, 'auc': 0.81148}\n",
      "test: {'epoch': 23, 'time_epoch': 1.1393, 'loss': 0.67452894, 'lr': 0, 'params': 168897, 'time_iter': 0.16276, 'accuracy': 0.75926, 'precision': 0.81081, 'recall': 0.61224, 'f1': 0.69767, 'auc': 0.82947}\n",
      "> Epoch 23: took 19.8s (avg 34.8s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 24, 'time_epoch': 20.29457, 'eta': 763.34547, 'eta_hours': 0.21204, 'loss': 0.10971065, 'lr': 0.00062096, 'params': 168897, 'time_iter': 0.37583, 'accuracy': 0.97796, 'precision': 0.97959, 'recall': 0.97215, 'f1': 0.97586, 'auc': 0.99172}\n",
      "val: {'epoch': 24, 'time_epoch': 1.05511, 'loss': 0.63922986, 'lr': 0, 'params': 168897, 'time_iter': 0.15073, 'accuracy': 0.78704, 'precision': 0.90625, 'recall': 0.59184, 'f1': 0.71605, 'auc': 0.80491}\n",
      "test: {'epoch': 24, 'time_epoch': 1.05106, 'loss': 0.81272173, 'lr': 0, 'params': 168897, 'time_iter': 0.15015, 'accuracy': 0.72222, 'precision': 0.88, 'recall': 0.44898, 'f1': 0.59459, 'auc': 0.76133}\n",
      "> Epoch 24: took 22.5s (avg 34.3s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 25, 'time_epoch': 17.30849, 'eta': 720.60366, 'eta_hours': 0.20017, 'loss': 0.11931892, 'lr': 0.00058682, 'params': 168897, 'time_iter': 0.32053, 'accuracy': 0.97332, 'precision': 0.9697, 'recall': 0.97215, 'f1': 0.97092, 'auc': 0.98756}\n",
      "val: {'epoch': 25, 'time_epoch': 1.17496, 'loss': 0.6925662, 'lr': 0, 'params': 168897, 'time_iter': 0.16785, 'accuracy': 0.75, 'precision': 0.78947, 'recall': 0.61224, 'f1': 0.68966, 'auc': 0.82463}\n",
      "test: {'epoch': 25, 'time_epoch': 1.09995, 'loss': 0.59666473, 'lr': 0, 'params': 168897, 'time_iter': 0.15714, 'accuracy': 0.7963, 'precision': 0.86486, 'recall': 0.65306, 'f1': 0.74419, 'auc': 0.83673}\n",
      "> Epoch 25: took 19.7s (avg 33.7s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 26, 'time_epoch': 17.58976, 'eta': 679.9854, 'eta_hours': 0.18888, 'loss': 0.09818184, 'lr': 0.00055226, 'params': 168897, 'time_iter': 0.32574, 'accuracy': 0.97912, 'precision': 0.97722, 'recall': 0.97722, 'f1': 0.97722, 'auc': 0.99179}\n",
      "val: {'epoch': 26, 'time_epoch': 1.21439, 'loss': 0.53579847, 'lr': 0, 'params': 168897, 'time_iter': 0.17348, 'accuracy': 0.82407, 'precision': 0.82609, 'recall': 0.77551, 'f1': 0.8, 'auc': 0.85922}\n",
      "test: {'epoch': 26, 'time_epoch': 1.12506, 'loss': 0.5827676, 'lr': 0, 'params': 168897, 'time_iter': 0.16072, 'accuracy': 0.7963, 'precision': 0.78723, 'recall': 0.7551, 'f1': 0.77083, 'auc': 0.89727}\n",
      "> Epoch 26: took 20.0s (avg 33.2s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 27, 'time_epoch': 17.63546, 'eta': 641.04793, 'eta_hours': 0.17807, 'loss': 0.08632263, 'lr': 0.00051745, 'params': 168897, 'time_iter': 0.32658, 'accuracy': 0.98376, 'precision': 0.97985, 'recall': 0.98481, 'f1': 0.98232, 'auc': 0.99343}\n",
      "val: {'epoch': 27, 'time_epoch': 1.23976, 'loss': 0.6465467, 'lr': 0, 'params': 168897, 'time_iter': 0.17711, 'accuracy': 0.7963, 'precision': 0.74545, 'recall': 0.83673, 'f1': 0.78846, 'auc': 0.8146}\n",
      "test: {'epoch': 27, 'time_epoch': 1.18964, 'loss': 0.53322606, 'lr': 0, 'params': 168897, 'time_iter': 0.16995, 'accuracy': 0.83333, 'precision': 0.79245, 'recall': 0.85714, 'f1': 0.82353, 'auc': 0.90246}\n",
      "> Epoch 27: took 20.1s (avg 32.8s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 28, 'time_epoch': 20.00001, 'eta': 605.29183, 'eta_hours': 0.16814, 'loss': 0.07608393, 'lr': 0.00048255, 'params': 168897, 'time_iter': 0.37037, 'accuracy': 0.98608, 'precision': 0.98728, 'recall': 0.98228, 'f1': 0.98477, 'auc': 0.99074}\n",
      "val: {'epoch': 28, 'time_epoch': 1.23696, 'loss': 0.66593867, 'lr': 0, 'params': 168897, 'time_iter': 0.17671, 'accuracy': 0.77778, 'precision': 0.90323, 'recall': 0.57143, 'f1': 0.7, 'auc': 0.85092}\n",
      "test: {'epoch': 28, 'time_epoch': 1.1663, 'loss': 0.70766976, 'lr': 0, 'params': 168897, 'time_iter': 0.16661, 'accuracy': 0.77778, 'precision': 0.90323, 'recall': 0.57143, 'f1': 0.7, 'auc': 0.80353}\n",
      "> Epoch 28: took 22.5s (avg 32.4s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 29, 'time_epoch': 17.70428, 'eta': 569.05565, 'eta_hours': 0.15807, 'loss': 0.07606129, 'lr': 0.00044774, 'params': 168897, 'time_iter': 0.32786, 'accuracy': 0.9884, 'precision': 0.98246, 'recall': 0.99241, 'f1': 0.98741, 'auc': 0.99151}\n",
      "val: {'epoch': 29, 'time_epoch': 1.30017, 'loss': 0.57247127, 'lr': 0, 'params': 168897, 'time_iter': 0.18574, 'accuracy': 0.81481, 'precision': 0.82222, 'recall': 0.7551, 'f1': 0.78723, 'auc': 0.84434}\n",
      "test: {'epoch': 29, 'time_epoch': 1.13487, 'loss': 0.62007744, 'lr': 0, 'params': 168897, 'time_iter': 0.16212, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.85749}\n",
      "> Epoch 29: took 20.2s (avg 32.0s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 30, 'time_epoch': 17.56003, 'eta': 533.92666, 'eta_hours': 0.14831, 'loss': 0.06603991, 'lr': 0.00041318, 'params': 168897, 'time_iter': 0.32519, 'accuracy': 0.99072, 'precision': 0.98987, 'recall': 0.98987, 'f1': 0.98987, 'auc': 0.99171}\n",
      "val: {'epoch': 30, 'time_epoch': 1.20474, 'loss': 0.59681799, 'lr': 0, 'params': 168897, 'time_iter': 0.17211, 'accuracy': 0.80556, 'precision': 0.85, 'recall': 0.69388, 'f1': 0.76404, 'auc': 0.83743}\n",
      "test: {'epoch': 30, 'time_epoch': 1.18938, 'loss': 0.55494033, 'lr': 0, 'params': 168897, 'time_iter': 0.16991, 'accuracy': 0.81481, 'precision': 0.85366, 'recall': 0.71429, 'f1': 0.77778, 'auc': 0.86717}\n",
      "> Epoch 30: took 20.0s (avg 31.6s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 31, 'time_epoch': 17.67502, 'eta': 499.96041, 'eta_hours': 0.13888, 'loss': 0.07605274, 'lr': 0.00037904, 'params': 168897, 'time_iter': 0.32732, 'accuracy': 0.98608, 'precision': 0.98481, 'recall': 0.98481, 'f1': 0.98481, 'auc': 0.99142}\n",
      "val: {'epoch': 31, 'time_epoch': 1.16017, 'loss': 0.76668772, 'lr': 0, 'params': 168897, 'time_iter': 0.16574, 'accuracy': 0.75926, 'precision': 0.69492, 'recall': 0.83673, 'f1': 0.75926, 'auc': 0.81875}\n",
      "test: {'epoch': 31, 'time_epoch': 1.21493, 'loss': 0.69281907, 'lr': 0, 'params': 168897, 'time_iter': 0.17356, 'accuracy': 0.75926, 'precision': 0.67692, 'recall': 0.89796, 'f1': 0.77193, 'auc': 0.87323}\n",
      "> Epoch 31: took 20.1s (avg 31.2s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 32, 'time_epoch': 17.57969, 'eta': 466.93241, 'eta_hours': 0.1297, 'loss': 0.06724422, 'lr': 0.00034549, 'params': 168897, 'time_iter': 0.32555, 'accuracy': 0.99072, 'precision': 0.99237, 'recall': 0.98734, 'f1': 0.98985, 'auc': 0.99284}\n",
      "val: {'epoch': 32, 'time_epoch': 1.12985, 'loss': 0.70082386, 'lr': 0, 'params': 168897, 'time_iter': 0.16141, 'accuracy': 0.7963, 'precision': 0.74545, 'recall': 0.83673, 'f1': 0.78846, 'auc': 0.84054}\n",
      "test: {'epoch': 32, 'time_epoch': 1.18253, 'loss': 0.72375463, 'lr': 0, 'params': 168897, 'time_iter': 0.16893, 'accuracy': 0.75, 'precision': 0.67742, 'recall': 0.85714, 'f1': 0.75676, 'auc': 0.88378}\n",
      "> Epoch 32: took 20.0s (avg 30.9s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 33, 'time_epoch': 20.10522, 'eta': 436.00161, 'eta_hours': 0.12111, 'loss': 0.06612874, 'lr': 0.0003127, 'params': 168897, 'time_iter': 0.37232, 'accuracy': 0.98956, 'precision': 0.98492, 'recall': 0.99241, 'f1': 0.98865, 'auc': 0.99022}\n",
      "val: {'epoch': 33, 'time_epoch': 1.06947, 'loss': 0.66949209, 'lr': 0, 'params': 168897, 'time_iter': 0.15278, 'accuracy': 0.80556, 'precision': 0.75926, 'recall': 0.83673, 'f1': 0.79612, 'auc': 0.83881}\n",
      "test: {'epoch': 33, 'time_epoch': 1.08747, 'loss': 0.61444185, 'lr': 0, 'params': 168897, 'time_iter': 0.15535, 'accuracy': 0.80556, 'precision': 0.75926, 'recall': 0.83673, 'f1': 0.79612, 'auc': 0.88343}\n",
      "> Epoch 33: took 22.3s (avg 30.7s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 34, 'time_epoch': 17.83922, 'eta': 404.71827, 'eta_hours': 0.11242, 'loss': 0.07107227, 'lr': 0.00028081, 'params': 168897, 'time_iter': 0.33036, 'accuracy': 0.98724, 'precision': 0.98731, 'recall': 0.98481, 'f1': 0.98606, 'auc': 0.99277}\n",
      "val: {'epoch': 34, 'time_epoch': 1.23042, 'loss': 0.70302039, 'lr': 0, 'params': 168897, 'time_iter': 0.17577, 'accuracy': 0.7963, 'precision': 0.74545, 'recall': 0.83673, 'f1': 0.78846, 'auc': 0.83258}\n",
      "test: {'epoch': 34, 'time_epoch': 1.12996, 'loss': 0.66579135, 'lr': 0, 'params': 168897, 'time_iter': 0.16142, 'accuracy': 0.7963, 'precision': 0.73684, 'recall': 0.85714, 'f1': 0.79245, 'auc': 0.899}\n",
      "> Epoch 34: took 20.3s (avg 30.4s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 35, 'time_epoch': 19.57172, 'eta': 374.85559, 'eta_hours': 0.10413, 'loss': 0.05765719, 'lr': 0.00025, 'params': 168897, 'time_iter': 0.36244, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99358}\n",
      "val: {'epoch': 35, 'time_epoch': 1.52971, 'loss': 0.65142364, 'lr': 0, 'params': 168897, 'time_iter': 0.21853, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.85057}\n",
      "test: {'epoch': 35, 'time_epoch': 1.4852, 'loss': 0.55551691, 'lr': 0, 'params': 168897, 'time_iter': 0.21217, 'accuracy': 0.81481, 'precision': 0.82222, 'recall': 0.7551, 'f1': 0.78723, 'auc': 0.88931}\n",
      "> Epoch 35: took 22.7s (avg 30.1s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 36, 'time_epoch': 19.25428, 'eta': 345.43763, 'eta_hours': 0.09595, 'loss': 0.0619962, 'lr': 0.0002204, 'params': 168897, 'time_iter': 0.35656, 'accuracy': 0.99072, 'precision': 0.99237, 'recall': 0.98734, 'f1': 0.98985, 'auc': 0.99329}\n",
      "val: {'epoch': 36, 'time_epoch': 1.25208, 'loss': 0.6508637, 'lr': 0, 'params': 168897, 'time_iter': 0.17887, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.85801}\n",
      "test: {'epoch': 36, 'time_epoch': 1.41593, 'loss': 0.58844646, 'lr': 0, 'params': 168897, 'time_iter': 0.20228, 'accuracy': 0.81481, 'precision': 0.80851, 'recall': 0.77551, 'f1': 0.79167, 'auc': 0.89329}\n",
      "> Epoch 36: took 22.0s (avg 29.9s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 37, 'time_epoch': 22.82304, 'eta': 317.68159, 'eta_hours': 0.08824, 'loss': 0.05631215, 'lr': 0.00019217, 'params': 168897, 'time_iter': 0.42265, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99102}\n",
      "val: {'epoch': 37, 'time_epoch': 1.53072, 'loss': 0.64167378, 'lr': 0, 'params': 168897, 'time_iter': 0.21867, 'accuracy': 0.80556, 'precision': 0.79167, 'recall': 0.77551, 'f1': 0.78351, 'auc': 0.85645}\n",
      "test: {'epoch': 37, 'time_epoch': 1.51195, 'loss': 0.61276984, 'lr': 0, 'params': 168897, 'time_iter': 0.21599, 'accuracy': 0.7963, 'precision': 0.78723, 'recall': 0.7551, 'f1': 0.77083, 'auc': 0.89}\n",
      "> Epoch 37: took 26.0s (avg 29.8s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 38, 'time_epoch': 23.31068, 'eta': 290.31605, 'eta_hours': 0.08064, 'loss': 0.05593095, 'lr': 0.00016543, 'params': 168897, 'time_iter': 0.43168, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99399}\n",
      "val: {'epoch': 38, 'time_epoch': 1.54291, 'loss': 0.64919357, 'lr': 0, 'params': 168897, 'time_iter': 0.22042, 'accuracy': 0.80556, 'precision': 0.76923, 'recall': 0.81633, 'f1': 0.79208, 'auc': 0.84642}\n",
      "test: {'epoch': 38, 'time_epoch': 1.49741, 'loss': 0.58962668, 'lr': 0, 'params': 168897, 'time_iter': 0.21392, 'accuracy': 0.82407, 'precision': 0.8, 'recall': 0.81633, 'f1': 0.80808, 'auc': 0.89035}\n",
      "> Epoch 38: took 26.5s (avg 29.7s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 39, 'time_epoch': 23.03515, 'eta': 263.08438, 'eta_hours': 0.07308, 'loss': 0.05575092, 'lr': 0.00014033, 'params': 168897, 'time_iter': 0.42658, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99103}\n",
      "val: {'epoch': 39, 'time_epoch': 1.4819, 'loss': 0.65193355, 'lr': 0, 'params': 168897, 'time_iter': 0.2117, 'accuracy': 0.80556, 'precision': 0.79167, 'recall': 0.77551, 'f1': 0.78351, 'auc': 0.8523}\n",
      "test: {'epoch': 39, 'time_epoch': 1.52039, 'loss': 0.60665493, 'lr': 0, 'params': 168897, 'time_iter': 0.2172, 'accuracy': 0.80556, 'precision': 0.79167, 'recall': 0.77551, 'f1': 0.78351, 'auc': 0.8907}\n",
      "> Epoch 39: took 26.1s (avg 29.6s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 40, 'time_epoch': 22.67652, 'eta': 235.97869, 'eta_hours': 0.06555, 'loss': 0.06704626, 'lr': 0.00011698, 'params': 168897, 'time_iter': 0.41994, 'accuracy': 0.98956, 'precision': 0.98492, 'recall': 0.99241, 'f1': 0.98865, 'auc': 0.99183}\n",
      "val: {'epoch': 40, 'time_epoch': 1.44997, 'loss': 0.69942842, 'lr': 0, 'params': 168897, 'time_iter': 0.20714, 'accuracy': 0.7963, 'precision': 0.81395, 'recall': 0.71429, 'f1': 0.76087, 'auc': 0.85161}\n",
      "test: {'epoch': 40, 'time_epoch': 1.45374, 'loss': 0.59768726, 'lr': 0, 'params': 168897, 'time_iter': 0.20768, 'accuracy': 0.82407, 'precision': 0.84091, 'recall': 0.7551, 'f1': 0.7957, 'auc': 0.87167}\n",
      "> Epoch 40: took 25.7s (avg 29.5s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 41, 'time_epoch': 24.14896, 'eta': 209.36438, 'eta_hours': 0.05816, 'loss': 0.05579444, 'lr': 9.549e-05, 'params': 168897, 'time_iter': 0.4472, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99506}\n",
      "val: {'epoch': 41, 'time_epoch': 1.54142, 'loss': 0.6614223, 'lr': 0, 'params': 168897, 'time_iter': 0.2202, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.85126}\n",
      "test: {'epoch': 41, 'time_epoch': 1.45695, 'loss': 0.63109177, 'lr': 0, 'params': 168897, 'time_iter': 0.20814, 'accuracy': 0.81481, 'precision': 0.79592, 'recall': 0.79592, 'f1': 0.79592, 'auc': 0.89}\n",
      "> Epoch 41: took 27.2s (avg 29.5s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 42, 'time_epoch': 23.26452, 'eta': 182.72076, 'eta_hours': 0.05076, 'loss': 0.05478762, 'lr': 7.598e-05, 'params': 168897, 'time_iter': 0.43082, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99225}\n",
      "val: {'epoch': 42, 'time_epoch': 1.48322, 'loss': 0.66428193, 'lr': 0, 'params': 168897, 'time_iter': 0.21189, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.85507}\n",
      "test: {'epoch': 42, 'time_epoch': 1.51507, 'loss': 0.62436934, 'lr': 0, 'params': 168897, 'time_iter': 0.21644, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.89346}\n",
      "> Epoch 42: took 26.3s (avg 29.4s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 43, 'time_epoch': 23.70058, 'eta': 156.29019, 'eta_hours': 0.04341, 'loss': 0.05861062, 'lr': 5.853e-05, 'params': 168897, 'time_iter': 0.4389, 'accuracy': 0.99188, 'precision': 0.9899, 'recall': 0.99241, 'f1': 0.99115, 'auc': 0.99289}\n",
      "val: {'epoch': 43, 'time_epoch': 1.47023, 'loss': 0.67572848, 'lr': 0, 'params': 168897, 'time_iter': 0.21003, 'accuracy': 0.80556, 'precision': 0.81818, 'recall': 0.73469, 'f1': 0.77419, 'auc': 0.85611}\n",
      "test: {'epoch': 43, 'time_epoch': 1.42903, 'loss': 0.60566881, 'lr': 0, 'params': 168897, 'time_iter': 0.20415, 'accuracy': 0.81481, 'precision': 0.82222, 'recall': 0.7551, 'f1': 0.78723, 'auc': 0.89208}\n",
      "> Epoch 43: took 26.7s (avg 29.4s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 44, 'time_epoch': 25.84917, 'eta': 130.2197, 'eta_hours': 0.03617, 'loss': 0.05453325, 'lr': 4.323e-05, 'params': 168897, 'time_iter': 0.47869, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99586}\n",
      "val: {'epoch': 44, 'time_epoch': 1.58908, 'loss': 0.65242811, 'lr': 0, 'params': 168897, 'time_iter': 0.22701, 'accuracy': 0.81481, 'precision': 0.77358, 'recall': 0.83673, 'f1': 0.80392, 'auc': 0.84365}\n",
      "test: {'epoch': 44, 'time_epoch': 1.41042, 'loss': 0.57896144, 'lr': 0, 'params': 168897, 'time_iter': 0.20149, 'accuracy': 0.84259, 'precision': 0.80769, 'recall': 0.85714, 'f1': 0.83168, 'auc': 0.9009}\n",
      "> Epoch 44: took 28.9s (avg 29.3s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 45, 'time_epoch': 19.75079, 'eta': 103.62853, 'eta_hours': 0.02879, 'loss': 0.05441374, 'lr': 3.015e-05, 'params': 168897, 'time_iter': 0.36576, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99277}\n",
      "val: {'epoch': 45, 'time_epoch': 1.22608, 'loss': 0.66503785, 'lr': 0, 'params': 168897, 'time_iter': 0.17515, 'accuracy': 0.80556, 'precision': 0.81818, 'recall': 0.73469, 'f1': 0.77419, 'auc': 0.85853}\n",
      "test: {'epoch': 45, 'time_epoch': 1.124, 'loss': 0.61002218, 'lr': 0, 'params': 168897, 'time_iter': 0.16057, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.9028}\n",
      "> Epoch 45: took 22.2s (avg 29.2s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 46, 'time_epoch': 25.23206, 'eta': 77.67831, 'eta_hours': 0.02158, 'loss': 0.06058177, 'lr': 1.937e-05, 'params': 168897, 'time_iter': 0.46726, 'accuracy': 0.99072, 'precision': 0.98741, 'recall': 0.99241, 'f1': 0.9899, 'auc': 0.99472}\n",
      "val: {'epoch': 46, 'time_epoch': 1.5593, 'loss': 0.64810085, 'lr': 0, 'params': 168897, 'time_iter': 0.22276, 'accuracy': 0.78704, 'precision': 0.77083, 'recall': 0.7551, 'f1': 0.76289, 'auc': 0.85368}\n",
      "test: {'epoch': 46, 'time_epoch': 1.54714, 'loss': 0.60666791, 'lr': 0, 'params': 168897, 'time_iter': 0.22102, 'accuracy': 0.82407, 'precision': 0.8125, 'recall': 0.79592, 'f1': 0.80412, 'auc': 0.90142}\n",
      "> Epoch 46: took 28.4s (avg 29.2s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 47, 'time_epoch': 30.01018, 'eta': 51.9571, 'eta_hours': 0.01443, 'loss': 0.05434655, 'lr': 1.093e-05, 'params': 168897, 'time_iter': 0.55574, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99226}\n",
      "val: {'epoch': 47, 'time_epoch': 1.47939, 'loss': 0.66539586, 'lr': 0, 'params': 168897, 'time_iter': 0.21134, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.85507}\n",
      "test: {'epoch': 47, 'time_epoch': 1.51384, 'loss': 0.61507782, 'lr': 0, 'params': 168897, 'time_iter': 0.21626, 'accuracy': 0.82407, 'precision': 0.8125, 'recall': 0.79592, 'f1': 0.80412, 'auc': 0.90107}\n",
      "> Epoch 47: took 33.1s (avg 29.3s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 48, 'time_epoch': 25.70496, 'eta': 25.97296, 'eta_hours': 0.00721, 'loss': 0.05431436, 'lr': 4.87e-06, 'params': 168897, 'time_iter': 0.47602, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99279}\n",
      "val: {'epoch': 48, 'time_epoch': 1.65719, 'loss': 0.6676597, 'lr': 0, 'params': 168897, 'time_iter': 0.23674, 'accuracy': 0.7963, 'precision': 0.78723, 'recall': 0.7551, 'f1': 0.77083, 'auc': 0.85368}\n",
      "test: {'epoch': 48, 'time_epoch': 1.47758, 'loss': 0.61797532, 'lr': 0, 'params': 168897, 'time_iter': 0.21108, 'accuracy': 0.82407, 'precision': 0.8125, 'recall': 0.79592, 'f1': 0.80412, 'auc': 0.90107}\n",
      "> Epoch 48: took 28.9s (avg 29.2s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "train: {'epoch': 49, 'time_epoch': 25.20381, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.05430347, 'lr': 1.22e-06, 'params': 168897, 'time_iter': 0.46674, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99258}\n",
      "val: {'epoch': 49, 'time_epoch': 2.1144, 'loss': 0.64821057, 'lr': 0, 'params': 168897, 'time_iter': 0.30206, 'accuracy': 0.7963, 'precision': 0.78723, 'recall': 0.7551, 'f1': 0.77083, 'auc': 0.8523}\n",
      "test: {'epoch': 49, 'time_epoch': 1.95515, 'loss': 0.61930503, 'lr': 0, 'params': 168897, 'time_iter': 0.27931, 'accuracy': 0.81481, 'precision': 0.79592, 'recall': 0.79592, 'f1': 0.79592, 'auc': 0.90176}\n",
      "> Epoch 49: took 29.4s (avg 29.3s) | Best so far: epoch 10\ttrain_loss: 0.3096 train_accuracy: 0.9165\tval_loss: 0.4320 val_accuracy: 0.8426\ttest_loss: 0.5148 test_accuracy: 0.7778\n",
      "Avg time per epoch: 29.25s\n",
      "Total train loop time: 0.41h\n",
      "Task done, results saved in results\\neural-Gender\\0\n",
      "10\n",
      "{'epoch': 10, 'time_epoch': 4.42309, 'loss': 0.51475258, 'lr': 0, 'params': 168897, 'time_iter': 0.63187, 'accuracy': 0.77778, 'precision': 0.82051, 'recall': 0.65306, 'f1': 0.72727, 'auc': 0.87963}\n",
      "{'epoch': 10, 'time_epoch': 50.32207, 'eta': 987.72843, 'eta_hours': 0.27437, 'loss': 0.30961184, 'lr': 0.00096985, 'params': 168897, 'time_iter': 0.93189, 'accuracy': 0.91647, 'precision': 0.91948, 'recall': 0.8962, 'f1': 0.90769, 'auc': 0.95227}\n",
      "{'epoch': 10, 'time_epoch': 4.74184, 'loss': 0.43203809, 'lr': 0, 'params': 168897, 'time_iter': 0.67741, 'accuracy': 0.84259, 'precision': 0.88095, 'recall': 0.7551, 'f1': 0.81319, 'auc': 0.86925}\n",
      "Results aggregated across runs saved in results\\neural-Gender\\agg\n",
      "[*] All done: 2024-02-26 18:41:51.211171\n"
     ]
    }
   ],
   "source": [
    "#Gender - Using Exphormer\n",
    "%run main.py --cfg configs/Exphormer/neural-Gender.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ad6c06-9183-453c-9902-030e44dab28f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-02 02:56:15.513534\n",
      "[*] Loaded dataset 'HCPGender' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1078000, 1000], edge_index=[2, 49133748], y=[1078])\n",
      "  undirected: True\n",
      "  num graphs: 1078\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 2\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [01:59<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:02:00.24\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [01:20<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:21.23\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPGender\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 2\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 50\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Gender\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Gender\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 2\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 135681\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 10.82492, 'eta': 530.42112, 'eta_hours': 0.14734, 'loss': 0.690931, 'lr': 0.0, 'params': 135681, 'time_iter': 0.20046, 'accuracy': 0.53828, 'precision': 0.45161, 'recall': 0.03544, 'f1': 0.06573, 'auc': 0.48277}\n",
      "...computing epoch stats took: 0.06s\n",
      "val: {'epoch': 0, 'time_epoch': 0.81938, 'loss': 0.68669379, 'lr': 0, 'params': 135681, 'time_iter': 0.11705, 'accuracy': 0.5463, 'precision': 0.5, 'recall': 0.04082, 'f1': 0.07547, 'auc': 0.5614}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 0, 'time_epoch': 0.80822, 'loss': 0.68846102, 'lr': 0, 'params': 135681, 'time_iter': 0.11546, 'accuracy': 0.55556, 'precision': 0.66667, 'recall': 0.04082, 'f1': 0.07692, 'auc': 0.49948}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 0: took 12.5s (avg 12.5s) | Best so far: epoch 0\ttrain_loss: 0.6909 train_accuracy: 0.5383\tval_loss: 0.6867 val_accuracy: 0.5463\ttest_loss: 0.6885 test_accuracy: 0.5556\n",
      "train: {'epoch': 1, 'time_epoch': 22.05687, 'eta': 789.16307, 'eta_hours': 0.21921, 'loss': 0.67200005, 'lr': 0.0002, 'params': 135681, 'time_iter': 0.40846, 'accuracy': 0.59629, 'precision': 0.58736, 'recall': 0.4, 'f1': 0.4759, 'auc': 0.63877}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 1, 'time_epoch': 0.82704, 'loss': 0.65397558, 'lr': 0, 'params': 135681, 'time_iter': 0.11815, 'accuracy': 0.61111, 'precision': 0.6, 'recall': 0.42857, 'f1': 0.5, 'auc': 0.73539}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 0.80022, 'loss': 0.64714445, 'lr': 0, 'params': 135681, 'time_iter': 0.11432, 'accuracy': 0.7037, 'precision': 0.69767, 'recall': 0.61224, 'f1': 0.65217, 'auc': 0.76617}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 23.7s (avg 18.1s) | Best so far: epoch 1\ttrain_loss: 0.6720 train_accuracy: 0.5963\tval_loss: 0.6540 val_accuracy: 0.6111\ttest_loss: 0.6471 test_accuracy: 0.7037\n",
      "train: {'epoch': 2, 'time_epoch': 10.30923, 'eta': 676.65932, 'eta_hours': 0.18796, 'loss': 0.63738216, 'lr': 0.0004, 'params': 135681, 'time_iter': 0.19091, 'accuracy': 0.68561, 'precision': 0.69375, 'recall': 0.56203, 'f1': 0.62098, 'auc': 0.76338}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 0.8066, 'loss': 0.70089106, 'lr': 0, 'params': 135681, 'time_iter': 0.11523, 'accuracy': 0.5463, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75925}\n",
      "...computing epoch stats took: 0.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: {'epoch': 2, 'time_epoch': 0.8084, 'loss': 0.70227986, 'lr': 0, 'params': 135681, 'time_iter': 0.11549, 'accuracy': 0.5463, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.73815}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 12.0s (avg 16.1s) | Best so far: epoch 1\ttrain_loss: 0.6720 train_accuracy: 0.5963\tval_loss: 0.6540 val_accuracy: 0.6111\ttest_loss: 0.6471 test_accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'epoch': 3, 'time_epoch': 10.27502, 'eta': 614.8595, 'eta_hours': 0.17079, 'loss': 0.57610925, 'lr': 0.0006, 'params': 135681, 'time_iter': 0.19028, 'accuracy': 0.79814, 'precision': 0.80441, 'recall': 0.73924, 'f1': 0.77045, 'auc': 0.84754}\n",
      "val: {'epoch': 3, 'time_epoch': 0.81355, 'loss': 0.64413121, 'lr': 0, 'params': 135681, 'time_iter': 0.11622, 'accuracy': 0.62037, 'precision': 0.54762, 'recall': 0.93878, 'f1': 0.69173, 'auc': 0.85576}\n",
      "test: {'epoch': 3, 'time_epoch': 0.81319, 'loss': 0.62058291, 'lr': 0, 'params': 135681, 'time_iter': 0.11617, 'accuracy': 0.67593, 'precision': 0.58537, 'recall': 0.97959, 'f1': 0.73282, 'auc': 0.90176}\n",
      "> Epoch 3: took 11.9s (avg 15.0s) | Best so far: epoch 3\ttrain_loss: 0.5761 train_accuracy: 0.7981\tval_loss: 0.6441 val_accuracy: 0.6204\ttest_loss: 0.6206 test_accuracy: 0.6759\n",
      "train: {'epoch': 4, 'time_epoch': 10.30325, 'eta': 573.92367, 'eta_hours': 0.15942, 'loss': 0.53278893, 'lr': 0.0008, 'params': 135681, 'time_iter': 0.1908, 'accuracy': 0.81323, 'precision': 0.81793, 'recall': 0.76203, 'f1': 0.78899, 'auc': 0.85271}\n",
      "val: {'epoch': 4, 'time_epoch': 0.81775, 'loss': 0.6556436, 'lr': 0, 'params': 135681, 'time_iter': 0.11682, 'accuracy': 0.61111, 'precision': 0.54023, 'recall': 0.95918, 'f1': 0.69118, 'auc': 0.81252}\n",
      "test: {'epoch': 4, 'time_epoch': 0.79945, 'loss': 0.66194271, 'lr': 0, 'params': 135681, 'time_iter': 0.11421, 'accuracy': 0.59259, 'precision': 0.52688, 'recall': 1.0, 'f1': 0.69014, 'auc': 0.86648}\n",
      "> Epoch 4: took 11.9s (avg 14.4s) | Best so far: epoch 3\ttrain_loss: 0.5761 train_accuracy: 0.7981\tval_loss: 0.6441 val_accuracy: 0.6204\ttest_loss: 0.6206 test_accuracy: 0.6759\n",
      "train: {'epoch': 5, 'time_epoch': 21.94951, 'eta': 628.60457, 'eta_hours': 0.17461, 'loss': 0.49374969, 'lr': 0.001, 'params': 135681, 'time_iter': 0.40647, 'accuracy': 0.82715, 'precision': 0.81218, 'recall': 0.81013, 'f1': 0.81115, 'auc': 0.8738}\n",
      "val: {'epoch': 5, 'time_epoch': 0.79794, 'loss': 0.80742714, 'lr': 0, 'params': 135681, 'time_iter': 0.11399, 'accuracy': 0.46296, 'precision': 0.45794, 'recall': 1.0, 'f1': 0.62821, 'auc': 0.66724}\n",
      "test: {'epoch': 5, 'time_epoch': 0.80356, 'loss': 0.79629133, 'lr': 0, 'params': 135681, 'time_iter': 0.11479, 'accuracy': 0.47222, 'precision': 0.46226, 'recall': 1.0, 'f1': 0.63226, 'auc': 0.73366}\n",
      "> Epoch 5: took 23.6s (avg 15.9s) | Best so far: epoch 3\ttrain_loss: 0.5761 train_accuracy: 0.7981\tval_loss: 0.6441 val_accuracy: 0.6204\ttest_loss: 0.6206 test_accuracy: 0.6759\n",
      "train: {'epoch': 6, 'time_epoch': 10.29629, 'eta': 589.80702, 'eta_hours': 0.16384, 'loss': 0.44022035, 'lr': 0.00099878, 'params': 135681, 'time_iter': 0.19067, 'accuracy': 0.86195, 'precision': 0.84328, 'recall': 0.85823, 'f1': 0.85069, 'auc': 0.89699}\n",
      "val: {'epoch': 6, 'time_epoch': 0.80724, 'loss': 0.5067997, 'lr': 0, 'params': 135681, 'time_iter': 0.11532, 'accuracy': 0.76852, 'precision': 0.83333, 'recall': 0.61224, 'f1': 0.70588, 'auc': 0.87893}\n",
      "test: {'epoch': 6, 'time_epoch': 0.81358, 'loss': 0.52430759, 'lr': 0, 'params': 135681, 'time_iter': 0.11623, 'accuracy': 0.77778, 'precision': 0.90323, 'recall': 0.57143, 'f1': 0.7, 'auc': 0.85818}\n",
      "> Epoch 6: took 11.9s (avg 15.4s) | Best so far: epoch 6\ttrain_loss: 0.4402 train_accuracy: 0.8619\tval_loss: 0.5068 val_accuracy: 0.7685\ttest_loss: 0.5243 test_accuracy: 0.7778\n",
      "train: {'epoch': 7, 'time_epoch': 10.30373, 'eta': 558.17384, 'eta_hours': 0.15505, 'loss': 0.39707793, 'lr': 0.00099513, 'params': 135681, 'time_iter': 0.19081, 'accuracy': 0.88283, 'precision': 0.875, 'recall': 0.86835, 'f1': 0.87166, 'auc': 0.91895}\n",
      "val: {'epoch': 7, 'time_epoch': 0.80672, 'loss': 0.47702401, 'lr': 0, 'params': 135681, 'time_iter': 0.11525, 'accuracy': 0.81481, 'precision': 0.89189, 'recall': 0.67347, 'f1': 0.76744, 'auc': 0.88343}\n",
      "test: {'epoch': 7, 'time_epoch': 0.80689, 'loss': 0.53327731, 'lr': 0, 'params': 135681, 'time_iter': 0.11527, 'accuracy': 0.76852, 'precision': 0.83333, 'recall': 0.61224, 'f1': 0.70588, 'auc': 0.84089}\n",
      "> Epoch 7: took 11.9s (avg 14.9s) | Best so far: epoch 7\ttrain_loss: 0.3971 train_accuracy: 0.8828\tval_loss: 0.4770 val_accuracy: 0.8148\ttest_loss: 0.5333 test_accuracy: 0.7685\n",
      "train: {'epoch': 8, 'time_epoch': 10.31451, 'eta': 531.32965, 'eta_hours': 0.14759, 'loss': 0.393961, 'lr': 0.00098907, 'params': 135681, 'time_iter': 0.19101, 'accuracy': 0.87123, 'precision': 0.84804, 'recall': 0.87595, 'f1': 0.86177, 'auc': 0.92157}\n",
      "val: {'epoch': 8, 'time_epoch': 0.80699, 'loss': 0.44228428, 'lr': 0, 'params': 135681, 'time_iter': 0.11528, 'accuracy': 0.82407, 'precision': 0.73438, 'recall': 0.95918, 'f1': 0.83186, 'auc': 0.89727}\n",
      "test: {'epoch': 8, 'time_epoch': 0.81561, 'loss': 0.55682625, 'lr': 0, 'params': 135681, 'time_iter': 0.11652, 'accuracy': 0.72222, 'precision': 0.6338, 'recall': 0.91837, 'f1': 0.75, 'auc': 0.87513}\n",
      "> Epoch 8: took 12.0s (avg 14.6s) | Best so far: epoch 8\ttrain_loss: 0.3940 train_accuracy: 0.8712\tval_loss: 0.4423 val_accuracy: 0.8241\ttest_loss: 0.5568 test_accuracy: 0.7222\n",
      "train: {'epoch': 9, 'time_epoch': 10.33788, 'eta': 507.88486, 'eta_hours': 0.14108, 'loss': 0.34577715, 'lr': 0.00098063, 'params': 135681, 'time_iter': 0.19144, 'accuracy': 0.89675, 'precision': 0.87685, 'recall': 0.90127, 'f1': 0.88889, 'auc': 0.94193}\n",
      "val: {'epoch': 9, 'time_epoch': 0.83239, 'loss': 0.85621348, 'lr': 0, 'params': 135681, 'time_iter': 0.11891, 'accuracy': 0.51852, 'precision': 0.48485, 'recall': 0.97959, 'f1': 0.64865, 'auc': 0.56589}\n",
      "test: {'epoch': 9, 'time_epoch': 0.80769, 'loss': 0.90161771, 'lr': 0, 'params': 135681, 'time_iter': 0.11538, 'accuracy': 0.5, 'precision': 0.47573, 'recall': 1.0, 'f1': 0.64474, 'auc': 0.57143}\n",
      "> Epoch 9: took 12.0s (avg 14.4s) | Best so far: epoch 8\ttrain_loss: 0.3940 train_accuracy: 0.8712\tval_loss: 0.4423 val_accuracy: 0.8241\ttest_loss: 0.5568 test_accuracy: 0.7222\n",
      "train: {'epoch': 10, 'time_epoch': 10.45053, 'eta': 487.22255, 'eta_hours': 0.13534, 'loss': 0.30761497, 'lr': 0.00096985, 'params': 135681, 'time_iter': 0.19353, 'accuracy': 0.91879, 'precision': 0.92428, 'recall': 0.8962, 'f1': 0.91003, 'auc': 0.94435}\n",
      "val: {'epoch': 10, 'time_epoch': 0.81605, 'loss': 0.59248153, 'lr': 0, 'params': 135681, 'time_iter': 0.11658, 'accuracy': 0.75, 'precision': 0.89286, 'recall': 0.5102, 'f1': 0.64935, 'auc': 0.86787}\n",
      "test: {'epoch': 10, 'time_epoch': 0.81583, 'loss': 0.60696754, 'lr': 0, 'params': 135681, 'time_iter': 0.11655, 'accuracy': 0.73148, 'precision': 0.91667, 'recall': 0.44898, 'f1': 0.60274, 'auc': 0.86856}\n",
      "> Epoch 10: took 12.1s (avg 14.1s) | Best so far: epoch 8\ttrain_loss: 0.3940 train_accuracy: 0.8712\tval_loss: 0.4423 val_accuracy: 0.8241\ttest_loss: 0.5568 test_accuracy: 0.7222\n",
      "train: {'epoch': 11, 'time_epoch': 10.42737, 'eta': 468.18885, 'eta_hours': 0.13005, 'loss': 0.26373673, 'lr': 0.00095677, 'params': 135681, 'time_iter': 0.1931, 'accuracy': 0.93271, 'precision': 0.92231, 'recall': 0.93165, 'f1': 0.92695, 'auc': 0.96154}\n",
      "val: {'epoch': 11, 'time_epoch': 0.82758, 'loss': 0.50635825, 'lr': 0, 'params': 135681, 'time_iter': 0.11823, 'accuracy': 0.77778, 'precision': 0.69231, 'recall': 0.91837, 'f1': 0.78947, 'auc': 0.85057}\n",
      "test: {'epoch': 11, 'time_epoch': 0.81042, 'loss': 0.46278039, 'lr': 0, 'params': 135681, 'time_iter': 0.11577, 'accuracy': 0.80556, 'precision': 0.71212, 'recall': 0.95918, 'f1': 0.81739, 'auc': 0.92217}\n",
      "> Epoch 11: took 12.1s (avg 14.0s) | Best so far: epoch 8\ttrain_loss: 0.3940 train_accuracy: 0.8712\tval_loss: 0.4423 val_accuracy: 0.8241\ttest_loss: 0.5568 test_accuracy: 0.7222\n",
      "train: {'epoch': 12, 'time_epoch': 10.39483, 'eta': 450.38662, 'eta_hours': 0.12511, 'loss': 0.27577393, 'lr': 0.00094147, 'params': 135681, 'time_iter': 0.1925, 'accuracy': 0.92111, 'precision': 0.91603, 'recall': 0.91139, 'f1': 0.91371, 'auc': 0.95511}\n",
      "val: {'epoch': 12, 'time_epoch': 0.81674, 'loss': 0.91580693, 'lr': 0, 'params': 135681, 'time_iter': 0.11668, 'accuracy': 0.61111, 'precision': 0.88889, 'recall': 0.16327, 'f1': 0.27586, 'auc': 0.68212}\n",
      "test: {'epoch': 12, 'time_epoch': 0.81111, 'loss': 0.92220536, 'lr': 0, 'params': 135681, 'time_iter': 0.11587, 'accuracy': 0.60185, 'precision': 0.875, 'recall': 0.14286, 'f1': 0.24561, 'auc': 0.62539}\n",
      "> Epoch 12: took 12.1s (avg 13.8s) | Best so far: epoch 8\ttrain_loss: 0.3940 train_accuracy: 0.8712\tval_loss: 0.4423 val_accuracy: 0.8241\ttest_loss: 0.5568 test_accuracy: 0.7222\n",
      "train: {'epoch': 13, 'time_epoch': 10.38483, 'eta': 433.61686, 'eta_hours': 0.12045, 'loss': 0.24848933, 'lr': 0.00092402, 'params': 135681, 'time_iter': 0.19231, 'accuracy': 0.92923, 'precision': 0.9196, 'recall': 0.92658, 'f1': 0.92308, 'auc': 0.96974}\n",
      "val: {'epoch': 13, 'time_epoch': 0.82107, 'loss': 0.87160475, 'lr': 0, 'params': 135681, 'time_iter': 0.1173, 'accuracy': 0.57407, 'precision': 0.51613, 'recall': 0.97959, 'f1': 0.67606, 'auc': 0.67831}\n",
      "test: {'epoch': 13, 'time_epoch': 0.81019, 'loss': 0.81573859, 'lr': 0, 'params': 135681, 'time_iter': 0.11574, 'accuracy': 0.62037, 'precision': 0.54444, 'recall': 1.0, 'f1': 0.70504, 'auc': 0.75822}\n",
      "> Epoch 13: took 12.0s (avg 13.7s) | Best so far: epoch 8\ttrain_loss: 0.3940 train_accuracy: 0.8712\tval_loss: 0.4423 val_accuracy: 0.8241\ttest_loss: 0.5568 test_accuracy: 0.7222\n",
      "train: {'epoch': 14, 'time_epoch': 10.40778, 'eta': 417.75197, 'eta_hours': 0.11604, 'loss': 0.2156196, 'lr': 0.00090451, 'params': 135681, 'time_iter': 0.19274, 'accuracy': 0.94664, 'precision': 0.95325, 'recall': 0.92911, 'f1': 0.94103, 'auc': 0.97831}\n",
      "val: {'epoch': 14, 'time_epoch': 0.81365, 'loss': 0.50503135, 'lr': 0, 'params': 135681, 'time_iter': 0.11624, 'accuracy': 0.82407, 'precision': 0.875, 'recall': 0.71429, 'f1': 0.78652, 'auc': 0.87132}\n",
      "test: {'epoch': 14, 'time_epoch': 0.81629, 'loss': 0.52348845, 'lr': 0, 'params': 135681, 'time_iter': 0.11661, 'accuracy': 0.7963, 'precision': 0.88571, 'recall': 0.63265, 'f1': 0.7381, 'auc': 0.88343}\n",
      "> Epoch 14: took 12.1s (avg 13.6s) | Best so far: epoch 8\ttrain_loss: 0.3940 train_accuracy: 0.8712\tval_loss: 0.4423 val_accuracy: 0.8241\ttest_loss: 0.5568 test_accuracy: 0.7222\n",
      "train: {'epoch': 15, 'time_epoch': 10.2771, 'eta': 402.29151, 'eta_hours': 0.11175, 'loss': 0.2130201, 'lr': 0.00088302, 'params': 135681, 'time_iter': 0.19032, 'accuracy': 0.94548, 'precision': 0.92857, 'recall': 0.95443, 'f1': 0.94132, 'auc': 0.97873}\n",
      "val: {'epoch': 15, 'time_epoch': 0.82047, 'loss': 0.79971163, 'lr': 0, 'params': 135681, 'time_iter': 0.11721, 'accuracy': 0.67593, 'precision': 0.9375, 'recall': 0.30612, 'f1': 0.46154, 'auc': 0.81287}\n",
      "test: {'epoch': 15, 'time_epoch': 0.81676, 'loss': 0.86750735, 'lr': 0, 'params': 135681, 'time_iter': 0.11668, 'accuracy': 0.65741, 'precision': 0.92857, 'recall': 0.26531, 'f1': 0.4127, 'auc': 0.79142}\n",
      "> Epoch 15: took 11.9s (avg 13.5s) | Best so far: epoch 8\ttrain_loss: 0.3940 train_accuracy: 0.8712\tval_loss: 0.4423 val_accuracy: 0.8241\ttest_loss: 0.5568 test_accuracy: 0.7222\n",
      "train: {'epoch': 16, 'time_epoch': 10.48918, 'eta': 387.85256, 'eta_hours': 0.10774, 'loss': 0.20590282, 'lr': 0.00085967, 'params': 135681, 'time_iter': 0.19424, 'accuracy': 0.94316, 'precision': 0.94819, 'recall': 0.92658, 'f1': 0.93726, 'auc': 0.97716}\n",
      "val: {'epoch': 16, 'time_epoch': 0.80866, 'loss': 0.90250216, 'lr': 0, 'params': 135681, 'time_iter': 0.11552, 'accuracy': 0.66667, 'precision': 0.93333, 'recall': 0.28571, 'f1': 0.4375, 'auc': 0.74888}\n",
      "test: {'epoch': 16, 'time_epoch': 0.82513, 'loss': 0.91441942, 'lr': 0, 'params': 135681, 'time_iter': 0.11788, 'accuracy': 0.65741, 'precision': 0.92857, 'recall': 0.26531, 'f1': 0.4127, 'auc': 0.75683}\n",
      "> Epoch 16: took 12.2s (avg 13.4s) | Best so far: epoch 8\ttrain_loss: 0.3940 train_accuracy: 0.8712\tval_loss: 0.4423 val_accuracy: 0.8241\ttest_loss: 0.5568 test_accuracy: 0.7222\n",
      "train: {'epoch': 17, 'time_epoch': 10.35362, 'eta': 373.61147, 'eta_hours': 0.10378, 'loss': 0.18486587, 'lr': 0.00083457, 'params': 135681, 'time_iter': 0.19173, 'accuracy': 0.95592, 'precision': 0.94514, 'recall': 0.95949, 'f1': 0.95226, 'auc': 0.98697}\n",
      "val: {'epoch': 17, 'time_epoch': 0.82995, 'loss': 0.5379861, 'lr': 0, 'params': 135681, 'time_iter': 0.11856, 'accuracy': 0.78704, 'precision': 0.78261, 'recall': 0.73469, 'f1': 0.75789, 'auc': 0.84677}\n",
      "test: {'epoch': 17, 'time_epoch': 0.81101, 'loss': 0.60539449, 'lr': 0, 'params': 135681, 'time_iter': 0.11586, 'accuracy': 0.76852, 'precision': 0.78571, 'recall': 0.67347, 'f1': 0.72527, 'auc': 0.86337}\n",
      "> Epoch 17: took 12.0s (avg 13.3s) | Best so far: epoch 8\ttrain_loss: 0.3940 train_accuracy: 0.8712\tval_loss: 0.4423 val_accuracy: 0.8241\ttest_loss: 0.5568 test_accuracy: 0.7222\n",
      "train: {'epoch': 18, 'time_epoch': 10.39136, 'eta': 359.84117, 'eta_hours': 0.09996, 'loss': 0.16220877, 'lr': 0.00080783, 'params': 135681, 'time_iter': 0.19243, 'accuracy': 0.96288, 'precision': 0.95718, 'recall': 0.96203, 'f1': 0.9596, 'auc': 0.985}\n",
      "val: {'epoch': 18, 'time_epoch': 0.80095, 'loss': 0.46102585, 'lr': 0, 'params': 135681, 'time_iter': 0.11442, 'accuracy': 0.84259, 'precision': 0.86364, 'recall': 0.77551, 'f1': 0.8172, 'auc': 0.86648}\n",
      "test: {'epoch': 18, 'time_epoch': 0.81293, 'loss': 0.52834307, 'lr': 0, 'params': 135681, 'time_iter': 0.11613, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.87305}\n",
      "> Epoch 18: took 12.0s (avg 13.3s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 19, 'time_epoch': 10.37913, 'eta': 346.39041, 'eta_hours': 0.09622, 'loss': 0.15804555, 'lr': 0.0007796, 'params': 135681, 'time_iter': 0.19221, 'accuracy': 0.95708, 'precision': 0.95202, 'recall': 0.95443, 'f1': 0.95322, 'auc': 0.98895}\n",
      "val: {'epoch': 19, 'time_epoch': 0.81204, 'loss': 1.01799619, 'lr': 0, 'params': 135681, 'time_iter': 0.11601, 'accuracy': 0.58333, 'precision': 0.52326, 'recall': 0.91837, 'f1': 0.66667, 'auc': 0.67624}\n",
      "test: {'epoch': 19, 'time_epoch': 0.80593, 'loss': 0.92886032, 'lr': 0, 'params': 135681, 'time_iter': 0.11513, 'accuracy': 0.62037, 'precision': 0.54545, 'recall': 0.97959, 'f1': 0.70073, 'auc': 0.70425}\n",
      "> Epoch 19: took 12.0s (avg 13.2s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 20, 'time_epoch': 10.40322, 'eta': 333.26547, 'eta_hours': 0.09257, 'loss': 0.14987104, 'lr': 0.00075, 'params': 135681, 'time_iter': 0.19265, 'accuracy': 0.96636, 'precision': 0.95522, 'recall': 0.97215, 'f1': 0.96361, 'auc': 0.98912}\n",
      "val: {'epoch': 20, 'time_epoch': 0.84373, 'loss': 0.65114913, 'lr': 0, 'params': 135681, 'time_iter': 0.12053, 'accuracy': 0.76852, 'precision': 0.875, 'recall': 0.57143, 'f1': 0.69136, 'auc': 0.82843}\n",
      "test: {'epoch': 20, 'time_epoch': 0.82735, 'loss': 0.67895263, 'lr': 0, 'params': 135681, 'time_iter': 0.11819, 'accuracy': 0.75, 'precision': 0.92308, 'recall': 0.4898, 'f1': 0.64, 'auc': 0.80457}\n",
      "> Epoch 20: took 12.1s (avg 13.2s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 21, 'time_epoch': 10.45464, 'eta': 320.45339, 'eta_hours': 0.08901, 'loss': 0.12678076, 'lr': 0.00071919, 'params': 135681, 'time_iter': 0.1936, 'accuracy': 0.97216, 'precision': 0.95802, 'recall': 0.98228, 'f1': 0.97, 'auc': 0.99257}\n",
      "val: {'epoch': 21, 'time_epoch': 0.81801, 'loss': 1.08171323, 'lr': 0, 'params': 135681, 'time_iter': 0.11686, 'accuracy': 0.58333, 'precision': 0.52222, 'recall': 0.95918, 'f1': 0.67626, 'auc': 0.76444}\n",
      "test: {'epoch': 21, 'time_epoch': 0.82312, 'loss': 1.00663273, 'lr': 0, 'params': 135681, 'time_iter': 0.11759, 'accuracy': 0.61111, 'precision': 0.53933, 'recall': 0.97959, 'f1': 0.69565, 'auc': 0.8101}\n",
      "> Epoch 21: took 12.1s (avg 13.1s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 22, 'time_epoch': 21.99439, 'eta': 321.39297, 'eta_hours': 0.08928, 'loss': 0.1312974, 'lr': 0.0006873, 'params': 135681, 'time_iter': 0.4073, 'accuracy': 0.96984, 'precision': 0.96474, 'recall': 0.96962, 'f1': 0.96717, 'auc': 0.98911}\n",
      "val: {'epoch': 22, 'time_epoch': 0.81434, 'loss': 0.57618837, 'lr': 0, 'params': 135681, 'time_iter': 0.11633, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.82843}\n",
      "test: {'epoch': 22, 'time_epoch': 0.8098, 'loss': 0.48256627, 'lr': 0, 'params': 135681, 'time_iter': 0.11569, 'accuracy': 0.83333, 'precision': 0.84444, 'recall': 0.77551, 'f1': 0.80851, 'auc': 0.89865}\n",
      "> Epoch 22: took 23.6s (avg 13.6s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 23, 'time_epoch': 10.38992, 'eta': 307.84988, 'eta_hours': 0.08551, 'loss': 0.12594845, 'lr': 0.00065451, 'params': 135681, 'time_iter': 0.19241, 'accuracy': 0.971, 'precision': 0.96954, 'recall': 0.96709, 'f1': 0.96831, 'auc': 0.98991}\n",
      "val: {'epoch': 23, 'time_epoch': 0.82256, 'loss': 0.58593812, 'lr': 0, 'params': 135681, 'time_iter': 0.11751, 'accuracy': 0.80556, 'precision': 0.75926, 'recall': 0.83673, 'f1': 0.79612, 'auc': 0.81667}\n",
      "test: {'epoch': 23, 'time_epoch': 0.8109, 'loss': 0.6389171, 'lr': 0, 'params': 135681, 'time_iter': 0.11584, 'accuracy': 0.75926, 'precision': 0.70175, 'recall': 0.81633, 'f1': 0.75472, 'auc': 0.86752}\n",
      "> Epoch 23: took 12.1s (avg 13.5s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 24, 'time_epoch': 10.37195, 'eta': 294.54107, 'eta_hours': 0.08182, 'loss': 0.11572598, 'lr': 0.00062096, 'params': 135681, 'time_iter': 0.19207, 'accuracy': 0.97448, 'precision': 0.96509, 'recall': 0.97975, 'f1': 0.97236, 'auc': 0.9928}\n",
      "val: {'epoch': 24, 'time_epoch': 0.81502, 'loss': 0.95050501, 'lr': 0, 'params': 135681, 'time_iter': 0.11643, 'accuracy': 0.64815, 'precision': 0.57143, 'recall': 0.89796, 'f1': 0.69841, 'auc': 0.72951}\n",
      "test: {'epoch': 24, 'time_epoch': 0.80437, 'loss': 0.89002242, 'lr': 0, 'params': 135681, 'time_iter': 0.11491, 'accuracy': 0.66667, 'precision': 0.57831, 'recall': 0.97959, 'f1': 0.72727, 'auc': 0.78762}\n",
      "> Epoch 24: took 12.0s (avg 13.4s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 25, 'time_epoch': 10.40196, 'eta': 281.48587, 'eta_hours': 0.07819, 'loss': 0.12973394, 'lr': 0.00058682, 'params': 135681, 'time_iter': 0.19263, 'accuracy': 0.96868, 'precision': 0.96939, 'recall': 0.96203, 'f1': 0.96569, 'auc': 0.98791}\n",
      "val: {'epoch': 25, 'time_epoch': 0.81333, 'loss': 0.53996084, 'lr': 0, 'params': 135681, 'time_iter': 0.11619, 'accuracy': 0.83333, 'precision': 0.82979, 'recall': 0.79592, 'f1': 0.8125, 'auc': 0.84642}\n",
      "test: {'epoch': 25, 'time_epoch': 0.82043, 'loss': 0.52850218, 'lr': 0, 'params': 135681, 'time_iter': 0.1172, 'accuracy': 0.83333, 'precision': 0.86047, 'recall': 0.7551, 'f1': 0.80435, 'auc': 0.85126}\n",
      "> Epoch 25: took 12.1s (avg 13.4s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 26, 'time_epoch': 10.45668, 'eta': 268.67382, 'eta_hours': 0.07463, 'loss': 0.11275729, 'lr': 0.00055226, 'params': 135681, 'time_iter': 0.19364, 'accuracy': 0.97448, 'precision': 0.97455, 'recall': 0.96962, 'f1': 0.97208, 'auc': 0.98986}\n",
      "val: {'epoch': 26, 'time_epoch': 0.83737, 'loss': 0.67666117, 'lr': 0, 'params': 135681, 'time_iter': 0.11962, 'accuracy': 0.76852, 'precision': 0.7069, 'recall': 0.83673, 'f1': 0.76636, 'auc': 0.84711}\n",
      "test: {'epoch': 26, 'time_epoch': 0.82725, 'loss': 0.55842126, 'lr': 0, 'params': 135681, 'time_iter': 0.11818, 'accuracy': 0.78704, 'precision': 0.70312, 'recall': 0.91837, 'f1': 0.79646, 'auc': 0.90488}\n",
      "> Epoch 26: took 12.2s (avg 13.3s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 27, 'time_epoch': 10.36072, 'eta': 255.95461, 'eta_hours': 0.0711, 'loss': 0.10014867, 'lr': 0.00051745, 'params': 135681, 'time_iter': 0.19187, 'accuracy': 0.98028, 'precision': 0.98462, 'recall': 0.97215, 'f1': 0.97834, 'auc': 0.9921}\n",
      "val: {'epoch': 27, 'time_epoch': 0.85385, 'loss': 0.61998488, 'lr': 0, 'params': 135681, 'time_iter': 0.12198, 'accuracy': 0.7963, 'precision': 0.81395, 'recall': 0.71429, 'f1': 0.76087, 'auc': 0.85887}\n",
      "test: {'epoch': 27, 'time_epoch': 0.82555, 'loss': 0.62626062, 'lr': 0, 'params': 135681, 'time_iter': 0.11794, 'accuracy': 0.7963, 'precision': 0.86486, 'recall': 0.65306, 'f1': 0.74419, 'auc': 0.87167}\n",
      "> Epoch 27: took 12.1s (avg 13.3s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 28, 'time_epoch': 10.41248, 'eta': 243.43555, 'eta_hours': 0.06762, 'loss': 0.08561754, 'lr': 0.00048255, 'params': 135681, 'time_iter': 0.19282, 'accuracy': 0.98608, 'precision': 0.97995, 'recall': 0.98987, 'f1': 0.98489, 'auc': 0.99141}\n",
      "val: {'epoch': 28, 'time_epoch': 0.82325, 'loss': 0.68289874, 'lr': 0, 'params': 135681, 'time_iter': 0.11761, 'accuracy': 0.77778, 'precision': 0.80488, 'recall': 0.67347, 'f1': 0.73333, 'auc': 0.85576}\n",
      "test: {'epoch': 28, 'time_epoch': 0.81498, 'loss': 0.66376841, 'lr': 0, 'params': 135681, 'time_iter': 0.11643, 'accuracy': 0.7963, 'precision': 0.86486, 'recall': 0.65306, 'f1': 0.74419, 'auc': 0.86268}\n",
      "> Epoch 28: took 12.1s (avg 13.3s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 29, 'time_epoch': 22.04967, 'eta': 238.81505, 'eta_hours': 0.06634, 'loss': 0.09988844, 'lr': 0.00044774, 'params': 135681, 'time_iter': 0.40833, 'accuracy': 0.97912, 'precision': 0.97481, 'recall': 0.97975, 'f1': 0.97727, 'auc': 0.9918}\n",
      "val: {'epoch': 29, 'time_epoch': 0.81928, 'loss': 0.58931021, 'lr': 0, 'params': 135681, 'time_iter': 0.11704, 'accuracy': 0.80556, 'precision': 0.83333, 'recall': 0.71429, 'f1': 0.76923, 'auc': 0.85507}\n",
      "test: {'epoch': 29, 'time_epoch': 0.81342, 'loss': 0.51739055, 'lr': 0, 'params': 135681, 'time_iter': 0.1162, 'accuracy': 0.84259, 'precision': 0.88095, 'recall': 0.7551, 'f1': 0.81319, 'auc': 0.88862}\n",
      "> Epoch 29: took 23.7s (avg 13.6s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 30, 'time_epoch': 10.45534, 'eta': 225.96388, 'eta_hours': 0.06277, 'loss': 0.09097344, 'lr': 0.00041318, 'params': 135681, 'time_iter': 0.19362, 'accuracy': 0.98376, 'precision': 0.97985, 'recall': 0.98481, 'f1': 0.98232, 'auc': 0.99025}\n",
      "val: {'epoch': 30, 'time_epoch': 0.80949, 'loss': 0.80322424, 'lr': 0, 'params': 135681, 'time_iter': 0.11564, 'accuracy': 0.74074, 'precision': 0.66154, 'recall': 0.87755, 'f1': 0.75439, 'auc': 0.80232}\n",
      "test: {'epoch': 30, 'time_epoch': 0.83212, 'loss': 0.72395347, 'lr': 0, 'params': 135681, 'time_iter': 0.11887, 'accuracy': 0.75, 'precision': 0.65714, 'recall': 0.93878, 'f1': 0.77311, 'auc': 0.87029}\n",
      "> Epoch 30: took 12.1s (avg 13.6s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 31, 'time_epoch': 22.06199, 'eta': 219.79119, 'eta_hours': 0.06105, 'loss': 0.10111854, 'lr': 0.00037904, 'params': 135681, 'time_iter': 0.40856, 'accuracy': 0.97912, 'precision': 0.97243, 'recall': 0.98228, 'f1': 0.97733, 'auc': 0.99154}\n",
      "val: {'epoch': 31, 'time_epoch': 0.82294, 'loss': 0.69984385, 'lr': 0, 'params': 135681, 'time_iter': 0.11756, 'accuracy': 0.77778, 'precision': 0.77778, 'recall': 0.71429, 'f1': 0.74468, 'auc': 0.8229}\n",
      "test: {'epoch': 31, 'time_epoch': 0.80755, 'loss': 0.5871739, 'lr': 0, 'params': 135681, 'time_iter': 0.11536, 'accuracy': 0.82407, 'precision': 0.82609, 'recall': 0.77551, 'f1': 0.8, 'auc': 0.87236}\n",
      "> Epoch 31: took 23.7s (avg 13.9s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 32, 'time_epoch': 33.72222, 'eta': 218.6623, 'eta_hours': 0.06074, 'loss': 0.06766695, 'lr': 0.00034549, 'params': 135681, 'time_iter': 0.62449, 'accuracy': 0.98956, 'precision': 0.98492, 'recall': 0.99241, 'f1': 0.98865, 'auc': 0.99318}\n",
      "val: {'epoch': 32, 'time_epoch': 0.79977, 'loss': 0.66249391, 'lr': 0, 'params': 135681, 'time_iter': 0.11425, 'accuracy': 0.7963, 'precision': 0.76471, 'recall': 0.79592, 'f1': 0.78, 'auc': 0.83639}\n",
      "test: {'epoch': 32, 'time_epoch': 0.81419, 'loss': 0.57216973, 'lr': 0, 'params': 135681, 'time_iter': 0.11631, 'accuracy': 0.82407, 'precision': 0.8, 'recall': 0.81633, 'f1': 0.80808, 'auc': 0.88689}\n",
      "> Epoch 32: took 35.4s (avg 14.5s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 33, 'time_epoch': 10.25575, 'eta': 204.57312, 'eta_hours': 0.05683, 'loss': 0.067213, 'lr': 0.0003127, 'params': 135681, 'time_iter': 0.18992, 'accuracy': 0.9884, 'precision': 0.98489, 'recall': 0.98987, 'f1': 0.98737, 'auc': 0.99306}\n",
      "val: {'epoch': 33, 'time_epoch': 0.81211, 'loss': 0.65915963, 'lr': 0, 'params': 135681, 'time_iter': 0.11602, 'accuracy': 0.78704, 'precision': 0.74074, 'recall': 0.81633, 'f1': 0.7767, 'auc': 0.83224}\n",
      "test: {'epoch': 33, 'time_epoch': 0.83923, 'loss': 0.64675367, 'lr': 0, 'params': 135681, 'time_iter': 0.11989, 'accuracy': 0.78704, 'precision': 0.74074, 'recall': 0.81633, 'f1': 0.7767, 'auc': 0.88585}\n",
      "> Epoch 33: took 11.9s (avg 14.4s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 34, 'time_epoch': 10.281, 'eta': 190.7138, 'eta_hours': 0.05298, 'loss': 0.07430083, 'lr': 0.00028081, 'params': 135681, 'time_iter': 0.19039, 'accuracy': 0.98492, 'precision': 0.9799, 'recall': 0.98734, 'f1': 0.98361, 'auc': 0.99542}\n",
      "val: {'epoch': 34, 'time_epoch': 0.82669, 'loss': 0.67536667, 'lr': 0, 'params': 135681, 'time_iter': 0.1181, 'accuracy': 0.7963, 'precision': 0.76471, 'recall': 0.79592, 'f1': 0.78, 'auc': 0.84365}\n",
      "test: {'epoch': 34, 'time_epoch': 0.79413, 'loss': 0.60965061, 'lr': 0, 'params': 135681, 'time_iter': 0.11345, 'accuracy': 0.80556, 'precision': 0.76923, 'recall': 0.81633, 'f1': 0.79208, 'auc': 0.88551}\n",
      "> Epoch 34: took 11.9s (avg 14.4s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 35, 'time_epoch': 10.30682, 'eta': 177.06333, 'eta_hours': 0.04918, 'loss': 0.06031421, 'lr': 0.00025, 'params': 135681, 'time_iter': 0.19087, 'accuracy': 0.99188, 'precision': 0.9899, 'recall': 0.99241, 'f1': 0.99115, 'auc': 0.99345}\n",
      "val: {'epoch': 35, 'time_epoch': 0.80593, 'loss': 0.59795339, 'lr': 0, 'params': 135681, 'time_iter': 0.11513, 'accuracy': 0.81481, 'precision': 0.79592, 'recall': 0.79592, 'f1': 0.79592, 'auc': 0.85092}\n",
      "test: {'epoch': 35, 'time_epoch': 0.7993, 'loss': 0.59980684, 'lr': 0, 'params': 135681, 'time_iter': 0.11419, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.88551}\n",
      "> Epoch 35: took 11.9s (avg 14.3s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 36, 'time_epoch': 10.28699, 'eta': 163.58662, 'eta_hours': 0.04544, 'loss': 0.06574728, 'lr': 0.0002204, 'params': 135681, 'time_iter': 0.1905, 'accuracy': 0.98956, 'precision': 0.98492, 'recall': 0.99241, 'f1': 0.98865, 'auc': 0.99163}\n",
      "val: {'epoch': 36, 'time_epoch': 0.80334, 'loss': 0.63405792, 'lr': 0, 'params': 135681, 'time_iter': 0.11476, 'accuracy': 0.80556, 'precision': 0.78, 'recall': 0.79592, 'f1': 0.78788, 'auc': 0.84538}\n",
      "test: {'epoch': 36, 'time_epoch': 0.80384, 'loss': 0.55324495, 'lr': 0, 'params': 135681, 'time_iter': 0.11483, 'accuracy': 0.83333, 'precision': 0.82979, 'recall': 0.79592, 'f1': 0.8125, 'auc': 0.8862}\n",
      "> Epoch 36: took 11.9s (avg 14.2s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 37, 'time_epoch': 10.27048, 'eta': 150.27258, 'eta_hours': 0.04174, 'loss': 0.05442859, 'lr': 0.00019217, 'params': 135681, 'time_iter': 0.19019, 'accuracy': 0.9942, 'precision': 0.99242, 'recall': 0.99494, 'f1': 0.99368, 'auc': 0.9903}\n",
      "val: {'epoch': 37, 'time_epoch': 0.85598, 'loss': 0.62846434, 'lr': 0, 'params': 135681, 'time_iter': 0.12228, 'accuracy': 0.81481, 'precision': 0.79592, 'recall': 0.79592, 'f1': 0.79592, 'auc': 0.84504}\n",
      "test: {'epoch': 37, 'time_epoch': 0.80977, 'loss': 0.55068249, 'lr': 0, 'params': 135681, 'time_iter': 0.11568, 'accuracy': 0.82407, 'precision': 0.82609, 'recall': 0.77551, 'f1': 0.8, 'auc': 0.88585}\n",
      "> Epoch 37: took 12.0s (avg 14.2s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 38, 'time_epoch': 10.29167, 'eta': 137.1206, 'eta_hours': 0.03809, 'loss': 0.08146512, 'lr': 0.00016543, 'params': 135681, 'time_iter': 0.19059, 'accuracy': 0.98492, 'precision': 0.97512, 'recall': 0.99241, 'f1': 0.98369, 'auc': 0.98987}\n",
      "val: {'epoch': 38, 'time_epoch': 0.80231, 'loss': 0.71097481, 'lr': 0, 'params': 135681, 'time_iter': 0.11462, 'accuracy': 0.78704, 'precision': 0.79545, 'recall': 0.71429, 'f1': 0.75269, 'auc': 0.84573}\n",
      "test: {'epoch': 38, 'time_epoch': 0.81754, 'loss': 0.64830539, 'lr': 0, 'params': 135681, 'time_iter': 0.11679, 'accuracy': 0.7963, 'precision': 0.84615, 'recall': 0.67347, 'f1': 0.75, 'auc': 0.8734}\n",
      "> Epoch 38: took 11.9s (avg 14.1s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 39, 'time_epoch': 21.99985, 'eta': 127.03867, 'eta_hours': 0.03529, 'loss': 0.07683928, 'lr': 0.00014033, 'params': 135681, 'time_iter': 0.4074, 'accuracy': 0.98376, 'precision': 0.98473, 'recall': 0.97975, 'f1': 0.98223, 'auc': 0.9943}\n",
      "val: {'epoch': 39, 'time_epoch': 0.81945, 'loss': 0.7221865, 'lr': 0, 'params': 135681, 'time_iter': 0.11706, 'accuracy': 0.77778, 'precision': 0.7907, 'recall': 0.69388, 'f1': 0.73913, 'auc': 0.84815}\n",
      "test: {'epoch': 39, 'time_epoch': 0.80472, 'loss': 0.65381864, 'lr': 0, 'params': 135681, 'time_iter': 0.11496, 'accuracy': 0.78704, 'precision': 0.825, 'recall': 0.67347, 'f1': 0.74157, 'auc': 0.88101}\n",
      "> Epoch 39: took 23.6s (avg 14.4s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 40, 'time_epoch': 10.29857, 'eta': 113.80681, 'eta_hours': 0.03161, 'loss': 0.05944169, 'lr': 0.00011698, 'params': 135681, 'time_iter': 0.19071, 'accuracy': 0.99188, 'precision': 0.98744, 'recall': 0.99494, 'f1': 0.99117, 'auc': 0.99352}\n",
      "val: {'epoch': 40, 'time_epoch': 0.82794, 'loss': 0.68477443, 'lr': 0, 'params': 135681, 'time_iter': 0.11828, 'accuracy': 0.7963, 'precision': 0.77551, 'recall': 0.77551, 'f1': 0.77551, 'auc': 0.84815}\n",
      "test: {'epoch': 40, 'time_epoch': 0.80963, 'loss': 0.59412619, 'lr': 0, 'params': 135681, 'time_iter': 0.11566, 'accuracy': 0.82407, 'precision': 0.8, 'recall': 0.81633, 'f1': 0.80808, 'auc': 0.87478}\n",
      "> Epoch 40: took 12.0s (avg 14.3s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 41, 'time_epoch': 10.3453, 'eta': 100.72353, 'eta_hours': 0.02798, 'loss': 0.05837735, 'lr': 9.549e-05, 'params': 135681, 'time_iter': 0.19158, 'accuracy': 0.99188, 'precision': 0.9899, 'recall': 0.99241, 'f1': 0.99115, 'auc': 0.99196}\n",
      "val: {'epoch': 41, 'time_epoch': 0.8257, 'loss': 0.69411316, 'lr': 0, 'params': 135681, 'time_iter': 0.11796, 'accuracy': 0.7963, 'precision': 0.77551, 'recall': 0.77551, 'f1': 0.77551, 'auc': 0.84331}\n",
      "test: {'epoch': 41, 'time_epoch': 0.81123, 'loss': 0.59009854, 'lr': 0, 'params': 135681, 'time_iter': 0.11589, 'accuracy': 0.82407, 'precision': 0.8125, 'recall': 0.79592, 'f1': 0.80412, 'auc': 0.87132}\n",
      "> Epoch 41: took 12.0s (avg 14.3s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 42, 'time_epoch': 33.6455, 'eta': 91.56066, 'eta_hours': 0.02543, 'loss': 0.07587507, 'lr': 7.598e-05, 'params': 135681, 'time_iter': 0.62306, 'accuracy': 0.98724, 'precision': 0.98, 'recall': 0.99241, 'f1': 0.98616, 'auc': 0.99162}\n",
      "val: {'epoch': 42, 'time_epoch': 0.84707, 'loss': 0.68890092, 'lr': 0, 'params': 135681, 'time_iter': 0.12101, 'accuracy': 0.80556, 'precision': 0.78, 'recall': 0.79592, 'f1': 0.78788, 'auc': 0.83743}\n",
      "test: {'epoch': 42, 'time_epoch': 0.87137, 'loss': 0.6009582, 'lr': 0, 'params': 135681, 'time_iter': 0.12448, 'accuracy': 0.82407, 'precision': 0.8, 'recall': 0.81633, 'f1': 0.80808, 'auc': 0.87478}\n",
      "> Epoch 42: took 35.4s (avg 14.7s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 43, 'time_epoch': 10.39231, 'eta': 78.11405, 'eta_hours': 0.0217, 'loss': 0.06835525, 'lr': 5.853e-05, 'params': 135681, 'time_iter': 0.19245, 'accuracy': 0.9884, 'precision': 0.98005, 'recall': 0.99494, 'f1': 0.98744, 'auc': 0.9945}\n",
      "val: {'epoch': 43, 'time_epoch': 0.81656, 'loss': 0.69275797, 'lr': 0, 'params': 135681, 'time_iter': 0.11665, 'accuracy': 0.7963, 'precision': 0.77551, 'recall': 0.77551, 'f1': 0.77551, 'auc': 0.84123}\n",
      "test: {'epoch': 43, 'time_epoch': 0.81675, 'loss': 0.58173612, 'lr': 0, 'params': 135681, 'time_iter': 0.11668, 'accuracy': 0.83333, 'precision': 0.81633, 'recall': 0.81633, 'f1': 0.81633, 'auc': 0.87478}\n",
      "> Epoch 43: took 12.1s (avg 14.7s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 44, 'time_epoch': 10.4076, 'eta': 64.80488, 'eta_hours': 0.018, 'loss': 0.0520431, 'lr': 4.323e-05, 'params': 135681, 'time_iter': 0.19273, 'accuracy': 0.9942, 'precision': 0.99242, 'recall': 0.99494, 'f1': 0.99368, 'auc': 0.99246}\n",
      "val: {'epoch': 44, 'time_epoch': 0.8101, 'loss': 0.68458298, 'lr': 0, 'params': 135681, 'time_iter': 0.11573, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.8478}\n",
      "test: {'epoch': 44, 'time_epoch': 0.80811, 'loss': 0.59697653, 'lr': 0, 'params': 135681, 'time_iter': 0.11544, 'accuracy': 0.80556, 'precision': 0.83333, 'recall': 0.71429, 'f1': 0.76923, 'auc': 0.88066}\n",
      "> Epoch 44: took 12.0s (avg 14.6s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 45, 'time_epoch': 10.40651, 'eta': 51.62178, 'eta_hours': 0.01434, 'loss': 0.05687725, 'lr': 3.015e-05, 'params': 135681, 'time_iter': 0.19271, 'accuracy': 0.99188, 'precision': 0.99239, 'recall': 0.98987, 'f1': 0.99113, 'auc': 0.99636}\n",
      "val: {'epoch': 45, 'time_epoch': 0.81826, 'loss': 0.68622628, 'lr': 0, 'params': 135681, 'time_iter': 0.11689, 'accuracy': 0.80556, 'precision': 0.78, 'recall': 0.79592, 'f1': 0.78788, 'auc': 0.84227}\n",
      "test: {'epoch': 45, 'time_epoch': 0.81756, 'loss': 0.58754596, 'lr': 0, 'params': 135681, 'time_iter': 0.11679, 'accuracy': 0.83333, 'precision': 0.81633, 'recall': 0.81633, 'f1': 0.81633, 'auc': 0.87997}\n",
      "> Epoch 45: took 12.1s (avg 14.6s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 46, 'time_epoch': 22.06812, 'eta': 39.30119, 'eta_hours': 0.01092, 'loss': 0.07575598, 'lr': 1.937e-05, 'params': 135681, 'time_iter': 0.40867, 'accuracy': 0.98608, 'precision': 0.98237, 'recall': 0.98734, 'f1': 0.98485, 'auc': 0.993}\n",
      "val: {'epoch': 46, 'time_epoch': 0.83391, 'loss': 0.68888531, 'lr': 0, 'params': 135681, 'time_iter': 0.11913, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.8478}\n",
      "test: {'epoch': 46, 'time_epoch': 0.82259, 'loss': 0.59891925, 'lr': 0, 'params': 135681, 'time_iter': 0.11751, 'accuracy': 0.80556, 'precision': 0.83333, 'recall': 0.71429, 'f1': 0.76923, 'auc': 0.88343}\n",
      "> Epoch 46: took 23.8s (avg 14.8s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 47, 'time_epoch': 10.37874, 'eta': 26.08739, 'eta_hours': 0.00725, 'loss': 0.05554635, 'lr': 1.093e-05, 'params': 135681, 'time_iter': 0.1922, 'accuracy': 0.99188, 'precision': 0.98744, 'recall': 0.99494, 'f1': 0.99117, 'auc': 0.99253}\n",
      "val: {'epoch': 47, 'time_epoch': 0.82332, 'loss': 0.69676563, 'lr': 0, 'params': 135681, 'time_iter': 0.11762, 'accuracy': 0.7963, 'precision': 0.76471, 'recall': 0.79592, 'f1': 0.78, 'auc': 0.84158}\n",
      "test: {'epoch': 47, 'time_epoch': 0.82016, 'loss': 0.6042097, 'lr': 0, 'params': 135681, 'time_iter': 0.11717, 'accuracy': 0.82407, 'precision': 0.8, 'recall': 0.81633, 'f1': 0.80808, 'auc': 0.88309}\n",
      "> Epoch 47: took 12.0s (avg 14.7s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 48, 'time_epoch': 10.37257, 'eta': 12.98918, 'eta_hours': 0.00361, 'loss': 0.06253745, 'lr': 4.87e-06, 'params': 135681, 'time_iter': 0.19208, 'accuracy': 0.98956, 'precision': 0.99235, 'recall': 0.98481, 'f1': 0.98856, 'auc': 0.99418}\n",
      "val: {'epoch': 48, 'time_epoch': 0.80864, 'loss': 0.71743116, 'lr': 0, 'params': 135681, 'time_iter': 0.11552, 'accuracy': 0.78704, 'precision': 0.79545, 'recall': 0.71429, 'f1': 0.75269, 'auc': 0.84711}\n",
      "test: {'epoch': 48, 'time_epoch': 0.82185, 'loss': 0.63247291, 'lr': 0, 'params': 135681, 'time_iter': 0.11741, 'accuracy': 0.80556, 'precision': 0.83333, 'recall': 0.71429, 'f1': 0.76923, 'auc': 0.87444}\n",
      "> Epoch 48: took 12.0s (avg 14.7s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "train: {'epoch': 49, 'time_epoch': 22.07274, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.05513569, 'lr': 1.22e-06, 'params': 135681, 'time_iter': 0.40875, 'accuracy': 0.99304, 'precision': 0.98992, 'recall': 0.99494, 'f1': 0.99242, 'auc': 0.99563}\n",
      "val: {'epoch': 49, 'time_epoch': 0.81743, 'loss': 0.68185138, 'lr': 0, 'params': 135681, 'time_iter': 0.11678, 'accuracy': 0.80556, 'precision': 0.78, 'recall': 0.79592, 'f1': 0.78788, 'auc': 0.84452}\n",
      "test: {'epoch': 49, 'time_epoch': 0.8193, 'loss': 0.57977381, 'lr': 0, 'params': 135681, 'time_iter': 0.11704, 'accuracy': 0.83333, 'precision': 0.81633, 'recall': 0.81633, 'f1': 0.81633, 'auc': 0.88516}\n",
      "> Epoch 49: took 23.7s (avg 14.8s) | Best so far: epoch 18\ttrain_loss: 0.1622 train_accuracy: 0.9629\tval_loss: 0.4610 val_accuracy: 0.8426\ttest_loss: 0.5283 test_accuracy: 0.7963\n",
      "Avg time per epoch: 14.83s\n",
      "Total train loop time: 0.21h\n",
      "Task done, results saved in results\\neural-Gender\\0\n",
      "18\n",
      "{'epoch': 18, 'time_epoch': 0.81293, 'loss': 0.52834307, 'lr': 0, 'params': 135681, 'time_iter': 0.11613, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.87305}\n",
      "{'epoch': 18, 'time_epoch': 10.39136, 'eta': 359.84117, 'eta_hours': 0.09996, 'loss': 0.16220877, 'lr': 0.00080783, 'params': 135681, 'time_iter': 0.19243, 'accuracy': 0.96288, 'precision': 0.95718, 'recall': 0.96203, 'f1': 0.9596, 'auc': 0.985}\n",
      "{'epoch': 18, 'time_epoch': 0.80095, 'loss': 0.46102585, 'lr': 0, 'params': 135681, 'time_iter': 0.11442, 'accuracy': 0.84259, 'precision': 0.86364, 'recall': 0.77551, 'f1': 0.8172, 'auc': 0.86648}\n",
      "Results aggregated across runs saved in results\\neural-Gender\\agg\n",
      "[*] All done: 2024-03-02 03:12:02.645547\n"
     ]
    }
   ],
   "source": [
    "#Gender - Using Exphormer with 2 layers 0.1 drop 0.1 att drop\n",
    "%run main.py --cfg configs/Exphormer/neural-Gender.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd39ea7e-3319-4a62-bd1b-4feb01f00458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-02 03:40:39.841188\n",
      "[*] Loaded dataset 'HCPGender' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1078000, 1000], edge_index=[2, 49133748], y=[1078])\n",
      "  undirected: True\n",
      "  num graphs: 1078\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n",
      "  num classes: 2\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [01:51<00:00,  9.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:52.16\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [01:20<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:21.15\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPGender\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.3\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 2\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 55\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Gender\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Gender\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 2\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 135681\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 10.74151, 'eta': 580.04164, 'eta_hours': 0.16112, 'loss': 0.69114738, 'lr': 0.0, 'params': 135681, 'time_iter': 0.19892, 'accuracy': 0.5348, 'precision': 0.4, 'recall': 0.03038, 'f1': 0.05647, 'auc': 0.47827}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 0, 'time_epoch': 0.80709, 'loss': 0.68720105, 'lr': 0, 'params': 135681, 'time_iter': 0.1153, 'accuracy': 0.55556, 'precision': 0.66667, 'recall': 0.04082, 'f1': 0.07692, 'auc': 0.55483}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 0, 'time_epoch': 0.80331, 'loss': 0.68863256, 'lr': 0, 'params': 135681, 'time_iter': 0.11476, 'accuracy': 0.5463, 'precision': 0.5, 'recall': 0.02041, 'f1': 0.03922, 'auc': 0.4936}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 0: took 12.4s (avg 12.4s) | Best so far: epoch 0\ttrain_loss: 0.6911 train_accuracy: 0.5348\tval_loss: 0.6872 val_accuracy: 0.5556\ttest_loss: 0.6886 test_accuracy: 0.5463\n",
      "train: {'epoch': 1, 'time_epoch': 22.07095, 'eta': 869.53021, 'eta_hours': 0.24154, 'loss': 0.67200166, 'lr': 0.0002, 'params': 135681, 'time_iter': 0.40872, 'accuracy': 0.59513, 'precision': 0.58333, 'recall': 0.40759, 'f1': 0.47988, 'auc': 0.6325}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 1, 'time_epoch': 0.80254, 'loss': 0.65374027, 'lr': 0, 'params': 135681, 'time_iter': 0.11465, 'accuracy': 0.62037, 'precision': 0.625, 'recall': 0.40816, 'f1': 0.49383, 'auc': 0.73158}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 0.80207, 'loss': 0.64618161, 'lr': 0, 'params': 135681, 'time_iter': 0.11458, 'accuracy': 0.69444, 'precision': 0.72222, 'recall': 0.53061, 'f1': 0.61176, 'auc': 0.75649}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 23.7s (avg 18.0s) | Best so far: epoch 1\ttrain_loss: 0.6720 train_accuracy: 0.5951\tval_loss: 0.6537 val_accuracy: 0.6204\ttest_loss: 0.6462 test_accuracy: 0.6944\n",
      "train: {'epoch': 2, 'time_epoch': 10.32256, 'eta': 747.67373, 'eta_hours': 0.20769, 'loss': 0.63992071, 'lr': 0.0004, 'params': 135681, 'time_iter': 0.19116, 'accuracy': 0.67981, 'precision': 0.68889, 'recall': 0.54937, 'f1': 0.61127, 'auc': 0.75004}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 0.79335, 'loss': 0.66367174, 'lr': 0, 'params': 135681, 'time_iter': 0.11334, 'accuracy': 0.55556, 'precision': 1.0, 'recall': 0.02041, 'f1': 0.04, 'auc': 0.80491}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 0.80011, 'loss': 0.66790719, 'lr': 0, 'params': 135681, 'time_iter': 0.1143, 'accuracy': 0.5463, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.77551}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 11.9s (avg 16.0s) | Best so far: epoch 1\ttrain_loss: 0.6720 train_accuracy: 0.5951\tval_loss: 0.6537 val_accuracy: 0.6204\ttest_loss: 0.6462 test_accuracy: 0.6944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'epoch': 3, 'time_epoch': 10.2913, 'eta': 681.18557, 'eta_hours': 0.18922, 'loss': 0.58149624, 'lr': 0.0006, 'params': 135681, 'time_iter': 0.19058, 'accuracy': 0.77726, 'precision': 0.77961, 'recall': 0.71646, 'f1': 0.7467, 'auc': 0.84696}\n",
      "val: {'epoch': 3, 'time_epoch': 0.80324, 'loss': 0.54902794, 'lr': 0, 'params': 135681, 'time_iter': 0.11475, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.89277}\n",
      "test: {'epoch': 3, 'time_epoch': 0.79613, 'loss': 0.56099733, 'lr': 0, 'params': 135681, 'time_iter': 0.11373, 'accuracy': 0.7963, 'precision': 0.77551, 'recall': 0.77551, 'f1': 0.77551, 'auc': 0.87755}\n",
      "> Epoch 3: took 11.9s (avg 15.0s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 4, 'time_epoch': 10.2203, 'eta': 636.46621, 'eta_hours': 0.1768, 'loss': 0.51733843, 'lr': 0.0008, 'params': 135681, 'time_iter': 0.18926, 'accuracy': 0.83643, 'precision': 0.83777, 'recall': 0.79747, 'f1': 0.81712, 'auc': 0.86658}\n",
      "val: {'epoch': 4, 'time_epoch': 0.8023, 'loss': 0.56306657, 'lr': 0, 'params': 135681, 'time_iter': 0.11461, 'accuracy': 0.74074, 'precision': 0.67213, 'recall': 0.83673, 'f1': 0.74545, 'auc': 0.83535}\n",
      "test: {'epoch': 4, 'time_epoch': 0.79107, 'loss': 0.56098873, 'lr': 0, 'params': 135681, 'time_iter': 0.11301, 'accuracy': 0.73148, 'precision': 0.64286, 'recall': 0.91837, 'f1': 0.7563, 'auc': 0.89761}\n",
      "> Epoch 4: took 11.8s (avg 14.4s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 5, 'time_epoch': 21.91716, 'eta': 698.77085, 'eta_hours': 0.1941, 'loss': 0.47842365, 'lr': 0.001, 'params': 135681, 'time_iter': 0.40587, 'accuracy': 0.84223, 'precision': 0.83636, 'recall': 0.81519, 'f1': 0.82564, 'auc': 0.89374}\n",
      "val: {'epoch': 5, 'time_epoch': 0.80225, 'loss': 0.53423298, 'lr': 0, 'params': 135681, 'time_iter': 0.11461, 'accuracy': 0.75, 'precision': 0.68333, 'recall': 0.83673, 'f1': 0.75229, 'auc': 0.85922}\n",
      "test: {'epoch': 5, 'time_epoch': 0.80596, 'loss': 0.48247783, 'lr': 0, 'params': 135681, 'time_iter': 0.11514, 'accuracy': 0.83333, 'precision': 0.73846, 'recall': 0.97959, 'f1': 0.84211, 'auc': 0.93255}\n",
      "> Epoch 5: took 23.5s (avg 15.9s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 6, 'time_epoch': 10.29544, 'eta': 657.32033, 'eta_hours': 0.18259, 'loss': 0.44343766, 'lr': 0.00099901, 'params': 135681, 'time_iter': 0.19066, 'accuracy': 0.85847, 'precision': 0.84557, 'recall': 0.84557, 'f1': 0.84557, 'auc': 0.90225}\n",
      "val: {'epoch': 6, 'time_epoch': 0.80333, 'loss': 0.53649105, 'lr': 0, 'params': 135681, 'time_iter': 0.11476, 'accuracy': 0.75, 'precision': 0.66667, 'recall': 0.89796, 'f1': 0.76522, 'auc': 0.83812}\n",
      "test: {'epoch': 6, 'time_epoch': 0.80726, 'loss': 0.49785086, 'lr': 0, 'params': 135681, 'time_iter': 0.11532, 'accuracy': 0.78704, 'precision': 0.70312, 'recall': 0.91837, 'f1': 0.79646, 'auc': 0.88689}\n",
      "> Epoch 6: took 11.9s (avg 15.3s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 7, 'time_epoch': 10.29849, 'eta': 623.67652, 'eta_hours': 0.17324, 'loss': 0.40190391, 'lr': 0.00099606, 'params': 135681, 'time_iter': 0.19071, 'accuracy': 0.87819, 'precision': 0.87371, 'recall': 0.85823, 'f1': 0.8659, 'auc': 0.92369}\n",
      "val: {'epoch': 7, 'time_epoch': 0.80512, 'loss': 0.49858065, 'lr': 0, 'params': 135681, 'time_iter': 0.11502, 'accuracy': 0.80556, 'precision': 0.91176, 'recall': 0.63265, 'f1': 0.74699, 'auc': 0.8651}\n",
      "test: {'epoch': 7, 'time_epoch': 0.81419, 'loss': 0.54748223, 'lr': 0, 'params': 135681, 'time_iter': 0.11631, 'accuracy': 0.75, 'precision': 0.86667, 'recall': 0.53061, 'f1': 0.65823, 'auc': 0.87098}\n",
      "> Epoch 7: took 11.9s (avg 14.9s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 8, 'time_epoch': 10.3387, 'eta': 595.42607, 'eta_hours': 0.1654, 'loss': 0.39365521, 'lr': 0.00099114, 'params': 135681, 'time_iter': 0.19146, 'accuracy': 0.87703, 'precision': 0.88127, 'recall': 0.84557, 'f1': 0.86305, 'auc': 0.91656}\n",
      "val: {'epoch': 8, 'time_epoch': 0.81286, 'loss': 0.7287896, 'lr': 0, 'params': 135681, 'time_iter': 0.11612, 'accuracy': 0.61111, 'precision': 0.54217, 'recall': 0.91837, 'f1': 0.68182, 'auc': 0.80284}\n",
      "test: {'epoch': 8, 'time_epoch': 0.81163, 'loss': 0.69313758, 'lr': 0, 'params': 135681, 'time_iter': 0.11595, 'accuracy': 0.62963, 'precision': 0.55172, 'recall': 0.97959, 'f1': 0.70588, 'auc': 0.82567}\n",
      "> Epoch 8: took 12.0s (avg 14.6s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 9, 'time_epoch': 10.47805, 'eta': 571.38504, 'eta_hours': 0.15872, 'loss': 0.3494345, 'lr': 0.00098429, 'params': 135681, 'time_iter': 0.19404, 'accuracy': 0.89675, 'precision': 0.90263, 'recall': 0.86835, 'f1': 0.88516, 'auc': 0.94866}\n",
      "val: {'epoch': 9, 'time_epoch': 0.81953, 'loss': 0.50482633, 'lr': 0, 'params': 135681, 'time_iter': 0.11708, 'accuracy': 0.76852, 'precision': 0.85294, 'recall': 0.59184, 'f1': 0.6988, 'auc': 0.85991}\n",
      "test: {'epoch': 9, 'time_epoch': 0.81025, 'loss': 0.53472709, 'lr': 0, 'params': 135681, 'time_iter': 0.11575, 'accuracy': 0.71296, 'precision': 0.8, 'recall': 0.4898, 'f1': 0.60759, 'auc': 0.91629}\n",
      "> Epoch 9: took 12.1s (avg 14.3s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 10, 'time_epoch': 10.41873, 'eta': 549.57274, 'eta_hours': 0.15266, 'loss': 0.30992923, 'lr': 0.00097553, 'params': 135681, 'time_iter': 0.19294, 'accuracy': 0.90835, 'precision': 0.91799, 'recall': 0.87848, 'f1': 0.8978, 'auc': 0.95544}\n",
      "val: {'epoch': 10, 'time_epoch': 0.83375, 'loss': 0.51492411, 'lr': 0, 'params': 135681, 'time_iter': 0.11911, 'accuracy': 0.77778, 'precision': 0.69841, 'recall': 0.89796, 'f1': 0.78571, 'auc': 0.86614}\n",
      "test: {'epoch': 10, 'time_epoch': 0.81585, 'loss': 0.46467099, 'lr': 0, 'params': 135681, 'time_iter': 0.11655, 'accuracy': 0.82407, 'precision': 0.72059, 'recall': 1.0, 'f1': 0.83761, 'auc': 0.91422}\n",
      "> Epoch 10: took 12.1s (avg 14.1s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 11, 'time_epoch': 10.44367, 'eta': 529.74872, 'eta_hours': 0.14715, 'loss': 0.27423686, 'lr': 0.00096489, 'params': 135681, 'time_iter': 0.1934, 'accuracy': 0.92459, 'precision': 0.90842, 'recall': 0.92911, 'f1': 0.91865, 'auc': 0.95886}\n",
      "val: {'epoch': 11, 'time_epoch': 0.8285, 'loss': 0.76438633, 'lr': 0, 'params': 135681, 'time_iter': 0.11836, 'accuracy': 0.63889, 'precision': 0.56098, 'recall': 0.93878, 'f1': 0.70229, 'auc': 0.8063}\n",
      "test: {'epoch': 11, 'time_epoch': 0.80781, 'loss': 0.71596793, 'lr': 0, 'params': 135681, 'time_iter': 0.1154, 'accuracy': 0.67593, 'precision': 0.58537, 'recall': 0.97959, 'f1': 0.73282, 'auc': 0.86787}\n",
      "> Epoch 11: took 12.1s (avg 14.0s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 12, 'time_epoch': 10.39807, 'eta': 511.22052, 'eta_hours': 0.14201, 'loss': 0.25829001, 'lr': 0.00095241, 'params': 135681, 'time_iter': 0.19256, 'accuracy': 0.92807, 'precision': 0.94164, 'recall': 0.89873, 'f1': 0.91969, 'auc': 0.96662}\n",
      "val: {'epoch': 12, 'time_epoch': 0.82019, 'loss': 0.54300308, 'lr': 0, 'params': 135681, 'time_iter': 0.11717, 'accuracy': 0.75926, 'precision': 0.70175, 'recall': 0.81633, 'f1': 0.75472, 'auc': 0.83846}\n",
      "test: {'epoch': 12, 'time_epoch': 0.8189, 'loss': 0.41273461, 'lr': 0, 'params': 135681, 'time_iter': 0.11699, 'accuracy': 0.82407, 'precision': 0.73438, 'recall': 0.95918, 'f1': 0.83186, 'auc': 0.91387}\n",
      "> Epoch 12: took 12.1s (avg 13.8s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 13, 'time_epoch': 10.41879, 'eta': 493.91444, 'eta_hours': 0.1372, 'loss': 0.28519633, 'lr': 0.00093815, 'params': 135681, 'time_iter': 0.19294, 'accuracy': 0.90719, 'precision': 0.90488, 'recall': 0.89114, 'f1': 0.89796, 'auc': 0.95731}\n",
      "val: {'epoch': 13, 'time_epoch': 0.82949, 'loss': 0.48730841, 'lr': 0, 'params': 135681, 'time_iter': 0.1185, 'accuracy': 0.80556, 'precision': 0.75926, 'recall': 0.83673, 'f1': 0.79612, 'auc': 0.85022}\n",
      "test: {'epoch': 13, 'time_epoch': 0.81749, 'loss': 0.31002679, 'lr': 0, 'params': 135681, 'time_iter': 0.11678, 'accuracy': 0.89815, 'precision': 0.83929, 'recall': 0.95918, 'f1': 0.89524, 'auc': 0.94223}\n",
      "> Epoch 13: took 12.1s (avg 13.7s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 14, 'time_epoch': 10.50171, 'eta': 477.7478, 'eta_hours': 0.13271, 'loss': 0.23624121, 'lr': 0.00092216, 'params': 135681, 'time_iter': 0.19448, 'accuracy': 0.93852, 'precision': 0.93622, 'recall': 0.92911, 'f1': 0.93266, 'auc': 0.97258}\n",
      "val: {'epoch': 14, 'time_epoch': 0.83529, 'loss': 0.88894098, 'lr': 0, 'params': 135681, 'time_iter': 0.11933, 'accuracy': 0.62037, 'precision': 0.9, 'recall': 0.18367, 'f1': 0.30508, 'auc': 0.81633}\n",
      "test: {'epoch': 14, 'time_epoch': 0.82855, 'loss': 0.99012595, 'lr': 0, 'params': 135681, 'time_iter': 0.11836, 'accuracy': 0.58333, 'precision': 0.83333, 'recall': 0.10204, 'f1': 0.18182, 'auc': 0.72466}\n",
      "> Epoch 14: took 12.2s (avg 13.6s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 15, 'time_epoch': 10.32077, 'eta': 461.84821, 'eta_hours': 0.12829, 'loss': 0.21655817, 'lr': 0.00090451, 'params': 135681, 'time_iter': 0.19113, 'accuracy': 0.93852, 'precision': 0.92118, 'recall': 0.94684, 'f1': 0.93383, 'auc': 0.97627}\n",
      "val: {'epoch': 15, 'time_epoch': 0.85464, 'loss': 0.57859547, 'lr': 0, 'params': 135681, 'time_iter': 0.12209, 'accuracy': 0.76852, 'precision': 0.7069, 'recall': 0.83673, 'f1': 0.76636, 'auc': 0.84123}\n",
      "test: {'epoch': 15, 'time_epoch': 0.84318, 'loss': 0.44972509, 'lr': 0, 'params': 135681, 'time_iter': 0.12045, 'accuracy': 0.81481, 'precision': 0.7377, 'recall': 0.91837, 'f1': 0.81818, 'auc': 0.92252}\n",
      "> Epoch 15: took 12.0s (avg 13.5s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 16, 'time_epoch': 10.76409, 'eta': 447.59591, 'eta_hours': 0.12433, 'loss': 0.20946833, 'lr': 0.00088526, 'params': 135681, 'time_iter': 0.19933, 'accuracy': 0.94432, 'precision': 0.94602, 'recall': 0.93165, 'f1': 0.93878, 'auc': 0.97682}\n",
      "val: {'epoch': 16, 'time_epoch': 0.84472, 'loss': 1.08952484, 'lr': 0, 'params': 135681, 'time_iter': 0.12067, 'accuracy': 0.58333, 'precision': 1.0, 'recall': 0.08163, 'f1': 0.15094, 'auc': 0.72743}\n",
      "test: {'epoch': 16, 'time_epoch': 0.82722, 'loss': 1.1248847, 'lr': 0, 'params': 135681, 'time_iter': 0.11817, 'accuracy': 0.56481, 'precision': 0.75, 'recall': 0.06122, 'f1': 0.11321, 'auc': 0.59322}\n",
      "> Epoch 16: took 12.5s (avg 13.4s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 17, 'time_epoch': 10.73939, 'eta': 433.68042, 'eta_hours': 0.12047, 'loss': 0.17997098, 'lr': 0.00086448, 'params': 135681, 'time_iter': 0.19888, 'accuracy': 0.96056, 'precision': 0.95929, 'recall': 0.95443, 'f1': 0.95685, 'auc': 0.9815}\n",
      "val: {'epoch': 17, 'time_epoch': 0.8556, 'loss': 0.6615797, 'lr': 0, 'params': 135681, 'time_iter': 0.12223, 'accuracy': 0.74074, 'precision': 0.66667, 'recall': 0.85714, 'f1': 0.75, 'auc': 0.80975}\n",
      "test: {'epoch': 17, 'time_epoch': 0.8341, 'loss': 0.58108464, 'lr': 0, 'params': 135681, 'time_iter': 0.11916, 'accuracy': 0.75926, 'precision': 0.65753, 'recall': 0.97959, 'f1': 0.78689, 'auc': 0.92217}\n",
      "> Epoch 17: took 12.5s (avg 13.4s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 18, 'time_epoch': 10.75024, 'eta': 420.11981, 'eta_hours': 0.1167, 'loss': 0.16919044, 'lr': 0.00084227, 'params': 135681, 'time_iter': 0.19908, 'accuracy': 0.9594, 'precision': 0.95685, 'recall': 0.95443, 'f1': 0.95564, 'auc': 0.97692}\n",
      "val: {'epoch': 18, 'time_epoch': 0.81999, 'loss': 0.81874517, 'lr': 0, 'params': 135681, 'time_iter': 0.11714, 'accuracy': 0.68519, 'precision': 0.5974, 'recall': 0.93878, 'f1': 0.73016, 'auc': 0.81218}\n",
      "test: {'epoch': 18, 'time_epoch': 0.80816, 'loss': 0.72894188, 'lr': 0, 'params': 135681, 'time_iter': 0.11545, 'accuracy': 0.71296, 'precision': 0.6125, 'recall': 1.0, 'f1': 0.75969, 'auc': 0.92529}\n",
      "> Epoch 18: took 12.4s (avg 13.3s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 19, 'time_epoch': 10.7641, 'eta': 406.86449, 'eta_hours': 0.11302, 'loss': 0.15075744, 'lr': 0.00081871, 'params': 135681, 'time_iter': 0.19934, 'accuracy': 0.96752, 'precision': 0.97172, 'recall': 0.95696, 'f1': 0.96429, 'auc': 0.98335}\n",
      "val: {'epoch': 19, 'time_epoch': 0.85449, 'loss': 0.54177389, 'lr': 0, 'params': 135681, 'time_iter': 0.12207, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.86441}\n",
      "test: {'epoch': 19, 'time_epoch': 0.93568, 'loss': 0.47079185, 'lr': 0, 'params': 135681, 'time_iter': 0.13367, 'accuracy': 0.84259, 'precision': 0.88095, 'recall': 0.7551, 'f1': 0.81319, 'auc': 0.89727}\n",
      "> Epoch 19: took 12.6s (avg 13.3s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 20, 'time_epoch': 10.81027, 'eta': 393.92118, 'eta_hours': 0.10942, 'loss': 0.14721366, 'lr': 0.00079389, 'params': 135681, 'time_iter': 0.20019, 'accuracy': 0.96752, 'precision': 0.95309, 'recall': 0.97722, 'f1': 0.965, 'auc': 0.98651}\n",
      "val: {'epoch': 20, 'time_epoch': 0.83896, 'loss': 0.69304895, 'lr': 0, 'params': 135681, 'time_iter': 0.11985, 'accuracy': 0.74074, 'precision': 0.65672, 'recall': 0.89796, 'f1': 0.75862, 'auc': 0.8478}\n",
      "test: {'epoch': 20, 'time_epoch': 0.84196, 'loss': 0.61707139, 'lr': 0, 'params': 135681, 'time_iter': 0.12028, 'accuracy': 0.77778, 'precision': 0.67123, 'recall': 1.0, 'f1': 0.80328, 'auc': 0.87617}\n",
      "> Epoch 20: took 12.5s (avg 13.3s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 21, 'time_epoch': 10.79095, 'eta': 381.14281, 'eta_hours': 0.10587, 'loss': 0.10797523, 'lr': 0.00076791, 'params': 135681, 'time_iter': 0.19983, 'accuracy': 0.98144, 'precision': 0.97975, 'recall': 0.97975, 'f1': 0.97975, 'auc': 0.9884}\n",
      "val: {'epoch': 21, 'time_epoch': 0.81813, 'loss': 0.70368214, 'lr': 0, 'params': 135681, 'time_iter': 0.11688, 'accuracy': 0.76852, 'precision': 0.9, 'recall': 0.55102, 'f1': 0.68354, 'auc': 0.80318}\n",
      "test: {'epoch': 21, 'time_epoch': 0.8141, 'loss': 0.76594471, 'lr': 0, 'params': 135681, 'time_iter': 0.1163, 'accuracy': 0.73148, 'precision': 0.91667, 'recall': 0.44898, 'f1': 0.60274, 'auc': 0.82705}\n",
      "> Epoch 21: took 12.5s (avg 13.2s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 22, 'time_epoch': 22.02071, 'eta': 384.16128, 'eta_hours': 0.10671, 'loss': 0.13831512, 'lr': 0.00074088, 'params': 135681, 'time_iter': 0.40779, 'accuracy': 0.96636, 'precision': 0.96684, 'recall': 0.95949, 'f1': 0.96315, 'auc': 0.98856}\n",
      "val: {'epoch': 22, 'time_epoch': 0.80473, 'loss': 0.62018828, 'lr': 0, 'params': 135681, 'time_iter': 0.11496, 'accuracy': 0.7963, 'precision': 0.82927, 'recall': 0.69388, 'f1': 0.75556, 'auc': 0.80906}\n",
      "test: {'epoch': 22, 'time_epoch': 0.80282, 'loss': 0.468597, 'lr': 0, 'params': 135681, 'time_iter': 0.11469, 'accuracy': 0.83333, 'precision': 0.89744, 'recall': 0.71429, 'f1': 0.79545, 'auc': 0.8862}\n",
      "> Epoch 22: took 23.7s (avg 13.7s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n",
      "train: {'epoch': 23, 'time_epoch': 10.31041, 'eta': 369.96734, 'eta_hours': 0.10277, 'loss': 0.14141739, 'lr': 0.00071289, 'params': 135681, 'time_iter': 0.19093, 'accuracy': 0.96404, 'precision': 0.9596, 'recall': 0.96203, 'f1': 0.96081, 'auc': 0.98496}\n",
      "val: {'epoch': 23, 'time_epoch': 0.80175, 'loss': 0.86466636, 'lr': 0, 'params': 135681, 'time_iter': 0.11454, 'accuracy': 0.71296, 'precision': 0.90909, 'recall': 0.40816, 'f1': 0.56338, 'auc': 0.72086}\n",
      "test: {'epoch': 23, 'time_epoch': 0.80114, 'loss': 1.07027368, 'lr': 0, 'params': 135681, 'time_iter': 0.11445, 'accuracy': 0.64815, 'precision': 0.86667, 'recall': 0.26531, 'f1': 0.40625, 'auc': 0.70183}\n",
      "> Epoch 23: took 11.9s (avg 13.6s) | Best so far: epoch 3\ttrain_loss: 0.5815 train_accuracy: 0.7773\tval_loss: 0.5490 val_accuracy: 0.8056\ttest_loss: 0.5610 test_accuracy: 0.7963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gender - Using Exphormer with 2 layers 0.3 drop 0.1 att drop\n",
    "%run main.py --cfg configs/Exphormer/neural-Gender.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7855680-3fc2-40ba-8de6-a2e20031f93d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-02 03:49:51.096835\n",
      "[*] Loaded dataset 'HCPGender' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1078000, 1000], edge_index=[2, 49133748], y=[1078])\n",
      "  undirected: True\n",
      "  num graphs: 1078\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 2\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [02:10<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:02:12.70\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [01:23<00:00, 12.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:25.39\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPGender\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.3\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.3\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 2\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 55\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Gender\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Gender\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 2\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 135681\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 13.51481, 'eta': 729.79965, 'eta_hours': 0.20272, 'loss': 0.69115163, 'lr': 0.0, 'params': 135681, 'time_iter': 0.25027, 'accuracy': 0.53364, 'precision': 0.3871, 'recall': 0.03038, 'f1': 0.05634, 'auc': 0.47843}\n",
      "...computing epoch stats took: 0.06s\n",
      "val: {'epoch': 0, 'time_epoch': 1.10799, 'loss': 0.68718019, 'lr': 0, 'params': 135681, 'time_iter': 0.15828, 'accuracy': 0.55556, 'precision': 0.66667, 'recall': 0.04082, 'f1': 0.07692, 'auc': 0.55517}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 0, 'time_epoch': 1.13241, 'loss': 0.68862953, 'lr': 0, 'params': 135681, 'time_iter': 0.16177, 'accuracy': 0.5463, 'precision': 0.5, 'recall': 0.02041, 'f1': 0.03922, 'auc': 0.49291}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 15.9s (avg 15.9s) | Best so far: epoch 0\ttrain_loss: 0.6912 train_accuracy: 0.5336\tval_loss: 0.6872 val_accuracy: 0.5556\ttest_loss: 0.6886 test_accuracy: 0.5463\n",
      "train: {'epoch': 1, 'time_epoch': 24.51158, 'eta': 1007.6992, 'eta_hours': 0.27992, 'loss': 0.67197656, 'lr': 0.0002, 'params': 135681, 'time_iter': 0.45392, 'accuracy': 0.59513, 'precision': 0.58214, 'recall': 0.41266, 'f1': 0.48296, 'auc': 0.63166}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 1, 'time_epoch': 1.05574, 'loss': 0.65326861, 'lr': 0, 'params': 135681, 'time_iter': 0.15082, 'accuracy': 0.60185, 'precision': 0.58824, 'recall': 0.40816, 'f1': 0.48193, 'auc': 0.72916}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 1.04632, 'loss': 0.64535622, 'lr': 0, 'params': 135681, 'time_iter': 0.14947, 'accuracy': 0.68519, 'precision': 0.68293, 'recall': 0.57143, 'f1': 0.62222, 'auc': 0.75891}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 26.7s (avg 21.3s) | Best so far: epoch 1\ttrain_loss: 0.6720 train_accuracy: 0.5951\tval_loss: 0.6533 val_accuracy: 0.6018\ttest_loss: 0.6454 test_accuracy: 0.6852\n",
      "train: {'epoch': 2, 'time_epoch': 12.64746, 'eta': 878.34672, 'eta_hours': 0.24399, 'loss': 0.64014581, 'lr': 0.0004, 'params': 135681, 'time_iter': 0.23421, 'accuracy': 0.67517, 'precision': 0.6873, 'recall': 0.53418, 'f1': 0.60114, 'auc': 0.74828}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 2, 'time_epoch': 1.08309, 'loss': 0.69117187, 'lr': 0, 'params': 135681, 'time_iter': 0.15473, 'accuracy': 0.5463, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75891}\n",
      "...computing epoch stats took: 0.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: {'epoch': 2, 'time_epoch': 1.02937, 'loss': 0.69138048, 'lr': 0, 'params': 135681, 'time_iter': 0.14705, 'accuracy': 0.5463, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.76029}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 14.8s (avg 19.1s) | Best so far: epoch 1\ttrain_loss: 0.6720 train_accuracy: 0.5951\tval_loss: 0.6533 val_accuracy: 0.6018\ttest_loss: 0.6454 test_accuracy: 0.6852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'epoch': 3, 'time_epoch': 12.73296, 'eta': 808.43676, 'eta_hours': 0.22457, 'loss': 0.5836662, 'lr': 0.0006, 'params': 135681, 'time_iter': 0.2358, 'accuracy': 0.78306, 'precision': 0.78889, 'recall': 0.71899, 'f1': 0.75232, 'auc': 0.84659}\n",
      "val: {'epoch': 3, 'time_epoch': 1.07506, 'loss': 0.61945873, 'lr': 0, 'params': 135681, 'time_iter': 0.15358, 'accuracy': 0.64815, 'precision': 1.0, 'recall': 0.22449, 'f1': 0.36667, 'auc': 0.87444}\n",
      "test: {'epoch': 3, 'time_epoch': 1.06872, 'loss': 0.62539848, 'lr': 0, 'params': 135681, 'time_iter': 0.15267, 'accuracy': 0.65741, 'precision': 0.92857, 'recall': 0.26531, 'f1': 0.4127, 'auc': 0.85714}\n",
      "> Epoch 3: took 14.9s (avg 18.1s) | Best so far: epoch 3\ttrain_loss: 0.5837 train_accuracy: 0.7831\tval_loss: 0.6195 val_accuracy: 0.6482\ttest_loss: 0.6254 test_accuracy: 0.6574\n",
      "train: {'epoch': 4, 'time_epoch': 12.80299, 'eta': 762.09797, 'eta_hours': 0.21169, 'loss': 0.50060515, 'lr': 0.0008, 'params': 135681, 'time_iter': 0.23709, 'accuracy': 0.85267, 'precision': 0.85829, 'recall': 0.81266, 'f1': 0.83485, 'auc': 0.90218}\n",
      "val: {'epoch': 4, 'time_epoch': 1.07602, 'loss': 0.72337357, 'lr': 0, 'params': 135681, 'time_iter': 0.15372, 'accuracy': 0.50926, 'precision': 0.48, 'recall': 0.97959, 'f1': 0.6443, 'auc': 0.81771}\n",
      "test: {'epoch': 4, 'time_epoch': 1.09349, 'loss': 0.72320347, 'lr': 0, 'params': 135681, 'time_iter': 0.15621, 'accuracy': 0.50926, 'precision': 0.48039, 'recall': 1.0, 'f1': 0.64901, 'auc': 0.89139}\n",
      "> Epoch 4: took 15.0s (avg 17.5s) | Best so far: epoch 3\ttrain_loss: 0.5837 train_accuracy: 0.7831\tval_loss: 0.6195 val_accuracy: 0.6482\ttest_loss: 0.6254 test_accuracy: 0.6574\n",
      "train: {'epoch': 5, 'time_epoch': 24.41262, 'eta': 821.74975, 'eta_hours': 0.22826, 'loss': 0.47426921, 'lr': 0.001, 'params': 135681, 'time_iter': 0.45209, 'accuracy': 0.84571, 'precision': 0.83081, 'recall': 0.83291, 'f1': 0.83186, 'auc': 0.90597}\n",
      "val: {'epoch': 5, 'time_epoch': 1.04437, 'loss': 0.51804837, 'lr': 0, 'params': 135681, 'time_iter': 0.1492, 'accuracy': 0.77778, 'precision': 0.90323, 'recall': 0.57143, 'f1': 0.7, 'auc': 0.8779}\n",
      "test: {'epoch': 5, 'time_epoch': 1.05042, 'loss': 0.55401947, 'lr': 0, 'params': 135681, 'time_iter': 0.15006, 'accuracy': 0.72222, 'precision': 0.88, 'recall': 0.44898, 'f1': 0.59459, 'auc': 0.89381}\n",
      "> Epoch 5: took 26.6s (avg 19.0s) | Best so far: epoch 5\ttrain_loss: 0.4743 train_accuracy: 0.8457\tval_loss: 0.5180 val_accuracy: 0.7778\ttest_loss: 0.5540 test_accuracy: 0.7222\n",
      "train: {'epoch': 6, 'time_epoch': 12.82198, 'eta': 777.90443, 'eta_hours': 0.21608, 'loss': 0.45743944, 'lr': 0.00099901, 'params': 135681, 'time_iter': 0.23744, 'accuracy': 0.83527, 'precision': 0.80929, 'recall': 0.83797, 'f1': 0.82338, 'auc': 0.89792}\n",
      "val: {'epoch': 6, 'time_epoch': 1.03221, 'loss': 0.48371504, 'lr': 0, 'params': 135681, 'time_iter': 0.14746, 'accuracy': 0.80556, 'precision': 0.76923, 'recall': 0.81633, 'f1': 0.79208, 'auc': 0.86821}\n",
      "test: {'epoch': 6, 'time_epoch': 1.02581, 'loss': 0.45659143, 'lr': 0, 'params': 135681, 'time_iter': 0.14654, 'accuracy': 0.82407, 'precision': 0.75, 'recall': 0.91837, 'f1': 0.82569, 'auc': 0.89035}\n",
      "> Epoch 6: took 14.9s (avg 18.4s) | Best so far: epoch 6\ttrain_loss: 0.4574 train_accuracy: 0.8353\tval_loss: 0.4837 val_accuracy: 0.8056\ttest_loss: 0.4566 test_accuracy: 0.8241\n",
      "train: {'epoch': 7, 'time_epoch': 12.691, 'eta': 741.04546, 'eta_hours': 0.20585, 'loss': 0.41879171, 'lr': 0.00099606, 'params': 135681, 'time_iter': 0.23502, 'accuracy': 0.85731, 'precision': 0.8617, 'recall': 0.82025, 'f1': 0.84047, 'auc': 0.917}\n",
      "val: {'epoch': 7, 'time_epoch': 1.04068, 'loss': 0.45538231, 'lr': 0, 'params': 135681, 'time_iter': 0.14867, 'accuracy': 0.82407, 'precision': 0.8125, 'recall': 0.79592, 'f1': 0.80412, 'auc': 0.87478}\n",
      "test: {'epoch': 7, 'time_epoch': 1.00716, 'loss': 0.44998614, 'lr': 0, 'params': 135681, 'time_iter': 0.14388, 'accuracy': 0.83333, 'precision': 0.78182, 'recall': 0.87755, 'f1': 0.82692, 'auc': 0.899}\n",
      "> Epoch 7: took 14.8s (avg 17.9s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 8, 'time_epoch': 12.64767, 'eta': 709.33566, 'eta_hours': 0.19704, 'loss': 0.37949416, 'lr': 0.00099114, 'params': 135681, 'time_iter': 0.23422, 'accuracy': 0.88167, 'precision': 0.89067, 'recall': 0.84557, 'f1': 0.86753, 'auc': 0.93061}\n",
      "val: {'epoch': 8, 'time_epoch': 1.0425, 'loss': 0.85394875, 'lr': 0, 'params': 135681, 'time_iter': 0.14893, 'accuracy': 0.56481, 'precision': 1.0, 'recall': 0.04082, 'f1': 0.07843, 'auc': 0.523}\n",
      "test: {'epoch': 8, 'time_epoch': 1.09483, 'loss': 0.88454633, 'lr': 0, 'params': 135681, 'time_iter': 0.1564, 'accuracy': 0.55556, 'precision': 1.0, 'recall': 0.02041, 'f1': 0.04, 'auc': 0.4386}\n",
      "> Epoch 8: took 14.8s (avg 17.6s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 9, 'time_epoch': 12.78676, 'eta': 682.06423, 'eta_hours': 0.18946, 'loss': 0.34540503, 'lr': 0.00098429, 'params': 135681, 'time_iter': 0.23679, 'accuracy': 0.89327, 'precision': 0.88161, 'recall': 0.88608, 'f1': 0.88384, 'auc': 0.92898}\n",
      "val: {'epoch': 9, 'time_epoch': 1.06024, 'loss': 0.84076468, 'lr': 0, 'params': 135681, 'time_iter': 0.15146, 'accuracy': 0.5463, 'precision': 0.5, 'recall': 0.95918, 'f1': 0.65734, 'auc': 0.76167}\n",
      "test: {'epoch': 9, 'time_epoch': 1.07913, 'loss': 0.81762804, 'lr': 0, 'params': 135681, 'time_iter': 0.15416, 'accuracy': 0.56481, 'precision': 0.51042, 'recall': 1.0, 'f1': 0.67586, 'auc': 0.75441}\n",
      "> Epoch 9: took 15.0s (avg 17.3s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 10, 'time_epoch': 12.81541, 'eta': 657.54094, 'eta_hours': 0.18265, 'loss': 0.31170574, 'lr': 0.00097553, 'params': 135681, 'time_iter': 0.23732, 'accuracy': 0.91067, 'precision': 0.91623, 'recall': 0.88608, 'f1': 0.9009, 'auc': 0.95846}\n",
      "val: {'epoch': 10, 'time_epoch': 1.06084, 'loss': 0.73490258, 'lr': 0, 'params': 135681, 'time_iter': 0.15155, 'accuracy': 0.64815, 'precision': 0.56471, 'recall': 0.97959, 'f1': 0.71642, 'auc': 0.85368}\n",
      "test: {'epoch': 10, 'time_epoch': 1.0435, 'loss': 0.66983098, 'lr': 0, 'params': 135681, 'time_iter': 0.14907, 'accuracy': 0.68519, 'precision': 0.59036, 'recall': 1.0, 'f1': 0.74242, 'auc': 0.9111}\n",
      "> Epoch 10: took 15.0s (avg 17.1s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 11, 'time_epoch': 12.7321, 'eta': 634.67046, 'eta_hours': 0.1763, 'loss': 0.30559965, 'lr': 0.00096489, 'params': 135681, 'time_iter': 0.23578, 'accuracy': 0.90139, 'precision': 0.89744, 'recall': 0.88608, 'f1': 0.89172, 'auc': 0.95283}\n",
      "val: {'epoch': 11, 'time_epoch': 1.01723, 'loss': 0.7403376, 'lr': 0, 'params': 135681, 'time_iter': 0.14532, 'accuracy': 0.62037, 'precision': 0.54651, 'recall': 0.95918, 'f1': 0.6963, 'auc': 0.85022}\n",
      "test: {'epoch': 11, 'time_epoch': 1.02452, 'loss': 0.70527393, 'lr': 0, 'params': 135681, 'time_iter': 0.14636, 'accuracy': 0.62963, 'precision': 0.55056, 'recall': 1.0, 'f1': 0.71014, 'auc': 0.92944}\n",
      "> Epoch 11: took 14.8s (avg 16.9s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 12, 'time_epoch': 12.8166, 'eta': 613.63271, 'eta_hours': 0.17045, 'loss': 0.25793045, 'lr': 0.00095241, 'params': 135681, 'time_iter': 0.23734, 'accuracy': 0.93387, 'precision': 0.9225, 'recall': 0.93418, 'f1': 0.9283, 'auc': 0.96865}\n",
      "val: {'epoch': 12, 'time_epoch': 1.08889, 'loss': 0.55876421, 'lr': 0, 'params': 135681, 'time_iter': 0.15556, 'accuracy': 0.75, 'precision': 0.82353, 'recall': 0.57143, 'f1': 0.6747, 'auc': 0.84815}\n",
      "test: {'epoch': 12, 'time_epoch': 1.05583, 'loss': 0.57717209, 'lr': 0, 'params': 135681, 'time_iter': 0.15083, 'accuracy': 0.73148, 'precision': 0.85714, 'recall': 0.4898, 'f1': 0.62338, 'auc': 0.84573}\n",
      "> Epoch 12: took 15.0s (avg 16.8s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 13, 'time_epoch': 12.66889, 'eta': 593.33684, 'eta_hours': 0.16482, 'loss': 0.2583172, 'lr': 0.00093815, 'params': 135681, 'time_iter': 0.23461, 'accuracy': 0.92807, 'precision': 0.92583, 'recall': 0.91646, 'f1': 0.92112, 'auc': 0.97117}\n",
      "val: {'epoch': 13, 'time_epoch': 1.12293, 'loss': 0.50161607, 'lr': 0, 'params': 135681, 'time_iter': 0.16042, 'accuracy': 0.76852, 'precision': 0.6875, 'recall': 0.89796, 'f1': 0.77876, 'auc': 0.86648}\n",
      "test: {'epoch': 13, 'time_epoch': 1.05562, 'loss': 0.43333565, 'lr': 0, 'params': 135681, 'time_iter': 0.1508, 'accuracy': 0.84259, 'precision': 0.75, 'recall': 0.97959, 'f1': 0.84956, 'auc': 0.93082}\n",
      "> Epoch 13: took 14.9s (avg 16.6s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 14, 'time_epoch': 13.01291, 'eta': 574.97529, 'eta_hours': 0.15972, 'loss': 0.22422129, 'lr': 0.00092216, 'params': 135681, 'time_iter': 0.24098, 'accuracy': 0.93619, 'precision': 0.94503, 'recall': 0.91392, 'f1': 0.92921, 'auc': 0.97942}\n",
      "val: {'epoch': 14, 'time_epoch': 1.04815, 'loss': 0.69344798, 'lr': 0, 'params': 135681, 'time_iter': 0.14974, 'accuracy': 0.71296, 'precision': 0.875, 'recall': 0.42857, 'f1': 0.57534, 'auc': 0.82428}\n",
      "test: {'epoch': 14, 'time_epoch': 1.06346, 'loss': 0.76447436, 'lr': 0, 'params': 135681, 'time_iter': 0.15192, 'accuracy': 0.67593, 'precision': 0.88889, 'recall': 0.32653, 'f1': 0.47761, 'auc': 0.8274}\n",
      "> Epoch 14: took 15.2s (avg 16.6s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 15, 'time_epoch': 12.85407, 'eta': 556.89513, 'eta_hours': 0.15469, 'loss': 0.20430232, 'lr': 0.00090451, 'params': 135681, 'time_iter': 0.23804, 'accuracy': 0.94664, 'precision': 0.94629, 'recall': 0.93671, 'f1': 0.94148, 'auc': 0.98309}\n",
      "val: {'epoch': 15, 'time_epoch': 1.0943, 'loss': 0.53721871, 'lr': 0, 'params': 135681, 'time_iter': 0.15633, 'accuracy': 0.77778, 'precision': 0.7451, 'recall': 0.77551, 'f1': 0.76, 'auc': 0.84089}\n",
      "test: {'epoch': 15, 'time_epoch': 1.05459, 'loss': 0.45068721, 'lr': 0, 'params': 135681, 'time_iter': 0.15066, 'accuracy': 0.81481, 'precision': 0.78431, 'recall': 0.81633, 'f1': 0.8, 'auc': 0.90107}\n",
      "> Epoch 15: took 15.1s (avg 16.5s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 16, 'time_epoch': 13.86268, 'eta': 541.68437, 'eta_hours': 0.15047, 'loss': 0.21075425, 'lr': 0.00088526, 'params': 135681, 'time_iter': 0.25672, 'accuracy': 0.94084, 'precision': 0.93655, 'recall': 0.93418, 'f1': 0.93536, 'auc': 0.97784}\n",
      "val: {'epoch': 16, 'time_epoch': 1.35013, 'loss': 0.67606177, 'lr': 0, 'params': 135681, 'time_iter': 0.19288, 'accuracy': 0.73148, 'precision': 0.85714, 'recall': 0.4898, 'f1': 0.62338, 'auc': 0.78485}\n",
      "test: {'epoch': 16, 'time_epoch': 1.42858, 'loss': 0.69230256, 'lr': 0, 'params': 135681, 'time_iter': 0.20408, 'accuracy': 0.7037, 'precision': 0.81481, 'recall': 0.44898, 'f1': 0.57895, 'auc': 0.83328}\n",
      "> Epoch 16: took 16.7s (avg 16.5s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 17, 'time_epoch': 14.28591, 'eta': 527.49337, 'eta_hours': 0.14653, 'loss': 0.16702342, 'lr': 0.00086448, 'params': 135681, 'time_iter': 0.26455, 'accuracy': 0.96288, 'precision': 0.96658, 'recall': 0.9519, 'f1': 0.95918, 'auc': 0.98431}\n",
      "val: {'epoch': 17, 'time_epoch': 1.06714, 'loss': 0.59959292, 'lr': 0, 'params': 135681, 'time_iter': 0.15245, 'accuracy': 0.75926, 'precision': 0.67692, 'recall': 0.89796, 'f1': 0.77193, 'auc': 0.84106}\n",
      "test: {'epoch': 17, 'time_epoch': 1.13857, 'loss': 0.53993869, 'lr': 0, 'params': 135681, 'time_iter': 0.16265, 'accuracy': 0.78704, 'precision': 0.69118, 'recall': 0.95918, 'f1': 0.80342, 'auc': 0.90591}\n",
      "> Epoch 17: took 16.6s (avg 16.5s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 18, 'time_epoch': 12.98291, 'eta': 510.82353, 'eta_hours': 0.1419, 'loss': 0.16316147, 'lr': 0.00084227, 'params': 135681, 'time_iter': 0.24042, 'accuracy': 0.96056, 'precision': 0.95012, 'recall': 0.96456, 'f1': 0.95729, 'auc': 0.97962}\n",
      "val: {'epoch': 18, 'time_epoch': 1.05818, 'loss': 0.65900383, 'lr': 0, 'params': 135681, 'time_iter': 0.15117, 'accuracy': 0.75926, 'precision': 0.74468, 'recall': 0.71429, 'f1': 0.72917, 'auc': 0.83051}\n",
      "test: {'epoch': 18, 'time_epoch': 1.03387, 'loss': 0.43797737, 'lr': 0, 'params': 135681, 'time_iter': 0.1477, 'accuracy': 0.85185, 'precision': 0.83673, 'recall': 0.83673, 'f1': 0.83673, 'auc': 0.88136}\n",
      "> Epoch 18: took 15.1s (avg 16.4s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 19, 'time_epoch': 12.83338, 'eta': 494.26071, 'eta_hours': 0.13729, 'loss': 0.15498163, 'lr': 0.00081871, 'params': 135681, 'time_iter': 0.23766, 'accuracy': 0.96056, 'precision': 0.95929, 'recall': 0.95443, 'f1': 0.95685, 'auc': 0.97964}\n",
      "val: {'epoch': 19, 'time_epoch': 1.06277, 'loss': 0.63080579, 'lr': 0, 'params': 135681, 'time_iter': 0.15182, 'accuracy': 0.75, 'precision': 0.68333, 'recall': 0.83673, 'f1': 0.75229, 'auc': 0.80457}\n",
      "test: {'epoch': 19, 'time_epoch': 1.06954, 'loss': 0.60554627, 'lr': 0, 'params': 135681, 'time_iter': 0.15279, 'accuracy': 0.76852, 'precision': 0.68182, 'recall': 0.91837, 'f1': 0.78261, 'auc': 0.87305}\n",
      "> Epoch 19: took 15.0s (avg 16.3s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 20, 'time_epoch': 13.36733, 'eta': 478.91756, 'eta_hours': 0.13303, 'loss': 0.13140601, 'lr': 0.00079389, 'params': 135681, 'time_iter': 0.24754, 'accuracy': 0.97332, 'precision': 0.97208, 'recall': 0.96962, 'f1': 0.97085, 'auc': 0.98556}\n",
      "val: {'epoch': 20, 'time_epoch': 1.08921, 'loss': 0.60410644, 'lr': 0, 'params': 135681, 'time_iter': 0.1556, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.81944}\n",
      "test: {'epoch': 20, 'time_epoch': 1.33003, 'loss': 0.4351891, 'lr': 0, 'params': 135681, 'time_iter': 0.19, 'accuracy': 0.86111, 'precision': 0.88636, 'recall': 0.79592, 'f1': 0.83871, 'auc': 0.87651}\n",
      "> Epoch 20: took 15.8s (avg 16.3s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 21, 'time_epoch': 13.75118, 'eta': 464.3298, 'eta_hours': 0.12898, 'loss': 0.12367635, 'lr': 0.00076791, 'params': 135681, 'time_iter': 0.25465, 'accuracy': 0.97564, 'precision': 0.98196, 'recall': 0.96456, 'f1': 0.97318, 'auc': 0.98624}\n",
      "val: {'epoch': 21, 'time_epoch': 1.15781, 'loss': 0.63740735, 'lr': 0, 'params': 135681, 'time_iter': 0.1654, 'accuracy': 0.77778, 'precision': 0.76596, 'recall': 0.73469, 'f1': 0.75, 'auc': 0.8184}\n",
      "test: {'epoch': 21, 'time_epoch': 1.13685, 'loss': 0.47597424, 'lr': 0, 'params': 135681, 'time_iter': 0.16241, 'accuracy': 0.83333, 'precision': 0.80392, 'recall': 0.83673, 'f1': 0.82, 'auc': 0.89312}\n",
      "> Epoch 21: took 16.1s (avg 16.3s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 22, 'time_epoch': 24.54358, 'eta': 464.8303, 'eta_hours': 0.12912, 'loss': 0.13385863, 'lr': 0.00074088, 'params': 135681, 'time_iter': 0.45451, 'accuracy': 0.971, 'precision': 0.96717, 'recall': 0.96962, 'f1': 0.96839, 'auc': 0.98637}\n",
      "val: {'epoch': 22, 'time_epoch': 1.07169, 'loss': 0.73658067, 'lr': 0, 'params': 135681, 'time_iter': 0.1531, 'accuracy': 0.73148, 'precision': 0.88462, 'recall': 0.46939, 'f1': 0.61333, 'auc': 0.83258}\n",
      "test: {'epoch': 22, 'time_epoch': 1.09158, 'loss': 0.77537623, 'lr': 0, 'params': 135681, 'time_iter': 0.15594, 'accuracy': 0.73148, 'precision': 0.88462, 'recall': 0.46939, 'f1': 0.61333, 'auc': 0.83466}\n",
      "> Epoch 22: took 26.8s (avg 16.8s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 23, 'time_epoch': 13.01914, 'eta': 448.35807, 'eta_hours': 0.12454, 'loss': 0.1387151, 'lr': 0.00071289, 'params': 135681, 'time_iter': 0.2411, 'accuracy': 0.96868, 'precision': 0.97917, 'recall': 0.9519, 'f1': 0.96534, 'auc': 0.98501}\n",
      "val: {'epoch': 23, 'time_epoch': 1.06998, 'loss': 0.63380479, 'lr': 0, 'params': 135681, 'time_iter': 0.15285, 'accuracy': 0.77778, 'precision': 0.7451, 'recall': 0.77551, 'f1': 0.76, 'auc': 0.8101}\n",
      "test: {'epoch': 23, 'time_epoch': 1.06088, 'loss': 0.50242011, 'lr': 0, 'params': 135681, 'time_iter': 0.15155, 'accuracy': 0.81481, 'precision': 0.75439, 'recall': 0.87755, 'f1': 0.81132, 'auc': 0.89831}\n",
      "> Epoch 23: took 15.2s (avg 16.7s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 24, 'time_epoch': 13.04291, 'eta': 432.1906, 'eta_hours': 0.12005, 'loss': 0.14222619, 'lr': 0.00068406, 'params': 135681, 'time_iter': 0.24154, 'accuracy': 0.96056, 'precision': 0.95696, 'recall': 0.95696, 'f1': 0.95696, 'auc': 0.98724}\n",
      "val: {'epoch': 24, 'time_epoch': 1.06585, 'loss': 1.21388673, 'lr': 0, 'params': 135681, 'time_iter': 0.15226, 'accuracy': 0.56481, 'precision': 0.51087, 'recall': 0.95918, 'f1': 0.66667, 'auc': 0.77032}\n",
      "test: {'epoch': 24, 'time_epoch': 1.06483, 'loss': 1.1540291, 'lr': 0, 'params': 135681, 'time_iter': 0.15212, 'accuracy': 0.59259, 'precision': 0.52688, 'recall': 1.0, 'f1': 0.69014, 'auc': 0.73469}\n",
      "> Epoch 24: took 15.2s (avg 16.6s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 25, 'time_epoch': 12.77605, 'eta': 415.96583, 'eta_hours': 0.11555, 'loss': 0.12203076, 'lr': 0.00065451, 'params': 135681, 'time_iter': 0.23659, 'accuracy': 0.97332, 'precision': 0.97208, 'recall': 0.96962, 'f1': 0.97085, 'auc': 0.99101}\n",
      "val: {'epoch': 25, 'time_epoch': 1.07473, 'loss': 0.65596464, 'lr': 0, 'params': 135681, 'time_iter': 0.15353, 'accuracy': 0.78704, 'precision': 0.90625, 'recall': 0.59184, 'f1': 0.71605, 'auc': 0.83293}\n",
      "test: {'epoch': 25, 'time_epoch': 1.08575, 'loss': 0.74407539, 'lr': 0, 'params': 135681, 'time_iter': 0.15511, 'accuracy': 0.75926, 'precision': 0.89655, 'recall': 0.53061, 'f1': 0.66667, 'auc': 0.84988}\n",
      "> Epoch 25: took 15.0s (avg 16.6s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 26, 'time_epoch': 12.68205, 'eta': 399.89904, 'eta_hours': 0.11108, 'loss': 0.13026511, 'lr': 0.00062434, 'params': 135681, 'time_iter': 0.23485, 'accuracy': 0.96636, 'precision': 0.9598, 'recall': 0.96709, 'f1': 0.96343, 'auc': 0.9862}\n",
      "val: {'epoch': 26, 'time_epoch': 1.07062, 'loss': 0.64180167, 'lr': 0, 'params': 135681, 'time_iter': 0.15295, 'accuracy': 0.77778, 'precision': 0.7907, 'recall': 0.69388, 'f1': 0.73913, 'auc': 0.84089}\n",
      "test: {'epoch': 26, 'time_epoch': 1.06057, 'loss': 0.47051275, 'lr': 0, 'params': 135681, 'time_iter': 0.15151, 'accuracy': 0.83333, 'precision': 0.84444, 'recall': 0.77551, 'f1': 0.80851, 'auc': 0.89208}\n",
      "> Epoch 26: took 14.9s (avg 16.5s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 27, 'time_epoch': 12.70708, 'eta': 384.09816, 'eta_hours': 0.10669, 'loss': 0.12699649, 'lr': 0.00059369, 'params': 135681, 'time_iter': 0.23532, 'accuracy': 0.96636, 'precision': 0.96212, 'recall': 0.96456, 'f1': 0.96334, 'auc': 0.98807}\n",
      "val: {'epoch': 27, 'time_epoch': 1.03914, 'loss': 0.67120845, 'lr': 0, 'params': 135681, 'time_iter': 0.14845, 'accuracy': 0.77778, 'precision': 0.70492, 'recall': 0.87755, 'f1': 0.78182, 'auc': 0.81736}\n",
      "test: {'epoch': 27, 'time_epoch': 1.00557, 'loss': 0.78806873, 'lr': 0, 'params': 135681, 'time_iter': 0.14365, 'accuracy': 0.73148, 'precision': 0.63514, 'recall': 0.95918, 'f1': 0.76423, 'auc': 0.89485}\n",
      "> Epoch 27: took 14.8s (avg 16.4s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n",
      "train: {'epoch': 28, 'time_epoch': 12.49553, 'eta': 368.32097, 'eta_hours': 0.10231, 'loss': 0.10479387, 'lr': 0.00056267, 'params': 135681, 'time_iter': 0.2314, 'accuracy': 0.97564, 'precision': 0.97949, 'recall': 0.96709, 'f1': 0.97325, 'auc': 0.98721}\n",
      "val: {'epoch': 28, 'time_epoch': 1.02323, 'loss': 0.66790422, 'lr': 0, 'params': 135681, 'time_iter': 0.14618, 'accuracy': 0.77778, 'precision': 0.7907, 'recall': 0.69388, 'f1': 0.73913, 'auc': 0.82532}\n",
      "test: {'epoch': 28, 'time_epoch': 1.05389, 'loss': 0.51451539, 'lr': 0, 'params': 135681, 'time_iter': 0.15056, 'accuracy': 0.81481, 'precision': 0.87179, 'recall': 0.69388, 'f1': 0.77273, 'auc': 0.87029}\n",
      "> Epoch 28: took 14.6s (avg 16.4s) | Best so far: epoch 7\ttrain_loss: 0.4188 train_accuracy: 0.8573\tval_loss: 0.4554 val_accuracy: 0.8241\ttest_loss: 0.4500 test_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gender - Using Exphormer with 2 layers 0.3 drop 0.3 att drop\n",
    "%run main.py --cfg configs/Exphormer/neural-Gender.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "793c433e-998f-4a08-a7da-23910a4d26f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-02 04:01:50.450435\n",
      "[*] Loaded dataset 'HCPGender' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1078000, 1000], edge_index=[2, 49133748], y=[1078])\n",
      "  undirected: True\n",
      "  num graphs: 1078\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 2\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [04:19<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:04:20.77\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [01:23<00:00, 12.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:25.58\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPGender\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.3\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 2\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 55\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Gender\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Gender\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 2\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 135681\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 13.66936, 'eta': 738.14524, 'eta_hours': 0.20504, 'loss': 0.69092794, 'lr': 0.0, 'params': 135681, 'time_iter': 0.25314, 'accuracy': 0.53828, 'precision': 0.45161, 'recall': 0.03544, 'f1': 0.06573, 'auc': 0.48305}\n",
      "...computing epoch stats took: 0.05s\n",
      "val: {'epoch': 0, 'time_epoch': 1.08134, 'loss': 0.68669106, 'lr': 0, 'params': 135681, 'time_iter': 0.15448, 'accuracy': 0.5463, 'precision': 0.5, 'recall': 0.04082, 'f1': 0.07547, 'auc': 0.56105}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 0, 'time_epoch': 1.10161, 'loss': 0.6884975, 'lr': 0, 'params': 135681, 'time_iter': 0.15737, 'accuracy': 0.55556, 'precision': 0.66667, 'recall': 0.04082, 'f1': 0.07692, 'auc': 0.49879}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 15.9s (avg 15.9s) | Best so far: epoch 0\ttrain_loss: 0.6909 train_accuracy: 0.5383\tval_loss: 0.6867 val_accuracy: 0.5463\ttest_loss: 0.6885 test_accuracy: 0.5556\n",
      "train: {'epoch': 1, 'time_epoch': 24.82759, 'eta': 1020.16912, 'eta_hours': 0.28338, 'loss': 0.67216495, 'lr': 0.0002, 'params': 135681, 'time_iter': 0.45977, 'accuracy': 0.59745, 'precision': 0.58889, 'recall': 0.40253, 'f1': 0.4782, 'auc': 0.63798}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 1, 'time_epoch': 1.077, 'loss': 0.65410282, 'lr': 0, 'params': 135681, 'time_iter': 0.15386, 'accuracy': 0.61111, 'precision': 0.6, 'recall': 0.42857, 'f1': 0.5, 'auc': 0.73504}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 1.09821, 'loss': 0.64743641, 'lr': 0, 'params': 135681, 'time_iter': 0.15689, 'accuracy': 0.7037, 'precision': 0.69767, 'recall': 0.61224, 'f1': 0.65217, 'auc': 0.76098}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 27.1s (avg 21.5s) | Best so far: epoch 1\ttrain_loss: 0.6722 train_accuracy: 0.5975\tval_loss: 0.6541 val_accuracy: 0.6111\ttest_loss: 0.6474 test_accuracy: 0.7037\n",
      "train: {'epoch': 2, 'time_epoch': 12.9671, 'eta': 892.04358, 'eta_hours': 0.24779, 'loss': 0.63938481, 'lr': 0.0004, 'params': 135681, 'time_iter': 0.24013, 'accuracy': 0.68097, 'precision': 0.69108, 'recall': 0.54937, 'f1': 0.61213, 'auc': 0.75862}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 2, 'time_epoch': 1.10266, 'loss': 0.69680324, 'lr': 0, 'params': 135681, 'time_iter': 0.15752, 'accuracy': 0.5463, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.79661}\n",
      "...computing epoch stats took: 0.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: {'epoch': 2, 'time_epoch': 1.07177, 'loss': 0.69846459, 'lr': 0, 'params': 135681, 'time_iter': 0.15311, 'accuracy': 0.5463, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.7551}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 15.2s (avg 19.4s) | Best so far: epoch 1\ttrain_loss: 0.6722 train_accuracy: 0.5975\tval_loss: 0.6541 val_accuracy: 0.6111\ttest_loss: 0.6474 test_accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'epoch': 3, 'time_epoch': 12.96336, 'eta': 821.44949, 'eta_hours': 0.22818, 'loss': 0.57219061, 'lr': 0.0006, 'params': 135681, 'time_iter': 0.24006, 'accuracy': 0.7993, 'precision': 0.81006, 'recall': 0.73418, 'f1': 0.77025, 'auc': 0.86153}\n",
      "val: {'epoch': 3, 'time_epoch': 1.12273, 'loss': 0.60572115, 'lr': 0, 'params': 135681, 'time_iter': 0.16039, 'accuracy': 0.7037, 'precision': 0.61333, 'recall': 0.93878, 'f1': 0.74194, 'auc': 0.88136}\n",
      "test: {'epoch': 3, 'time_epoch': 1.05881, 'loss': 0.61437171, 'lr': 0, 'params': 135681, 'time_iter': 0.15126, 'accuracy': 0.67593, 'precision': 0.5875, 'recall': 0.95918, 'f1': 0.72868, 'auc': 0.87444}\n",
      "> Epoch 3: took 15.2s (avg 18.4s) | Best so far: epoch 3\ttrain_loss: 0.5722 train_accuracy: 0.7993\tval_loss: 0.6057 val_accuracy: 0.7037\ttest_loss: 0.6144 test_accuracy: 0.6759\n",
      "train: {'epoch': 4, 'time_epoch': 13.0893, 'eta': 775.16713, 'eta_hours': 0.21532, 'loss': 0.51646921, 'lr': 0.0008, 'params': 135681, 'time_iter': 0.24239, 'accuracy': 0.82831, 'precision': 0.85185, 'recall': 0.75696, 'f1': 0.80161, 'auc': 0.88205}\n",
      "val: {'epoch': 4, 'time_epoch': 1.0546, 'loss': 0.68499049, 'lr': 0, 'params': 135681, 'time_iter': 0.15066, 'accuracy': 0.5463, 'precision': 0.5, 'recall': 0.97959, 'f1': 0.66207, 'auc': 0.85092}\n",
      "test: {'epoch': 4, 'time_epoch': 1.06227, 'loss': 0.69451034, 'lr': 0, 'params': 135681, 'time_iter': 0.15175, 'accuracy': 0.5463, 'precision': 0.5, 'recall': 1.0, 'f1': 0.66667, 'auc': 0.86233}\n",
      "> Epoch 4: took 15.3s (avg 17.7s) | Best so far: epoch 3\ttrain_loss: 0.5722 train_accuracy: 0.7993\tval_loss: 0.6057 val_accuracy: 0.7037\ttest_loss: 0.6144 test_accuracy: 0.6759\n",
      "train: {'epoch': 5, 'time_epoch': 24.63072, 'eta': 834.20407, 'eta_hours': 0.23172, 'loss': 0.4795928, 'lr': 0.001, 'params': 135681, 'time_iter': 0.45612, 'accuracy': 0.83991, 'precision': 0.83204, 'recall': 0.81519, 'f1': 0.82353, 'auc': 0.89638}\n",
      "val: {'epoch': 5, 'time_epoch': 1.14222, 'loss': 0.60812993, 'lr': 0, 'params': 135681, 'time_iter': 0.16317, 'accuracy': 0.71296, 'precision': 0.61842, 'recall': 0.95918, 'f1': 0.752, 'auc': 0.85057}\n",
      "test: {'epoch': 5, 'time_epoch': 0.94901, 'loss': 0.62611034, 'lr': 0, 'params': 135681, 'time_iter': 0.13557, 'accuracy': 0.65741, 'precision': 0.56977, 'recall': 1.0, 'f1': 0.72593, 'auc': 0.90834}\n",
      "> Epoch 5: took 26.8s (avg 19.2s) | Best so far: epoch 5\ttrain_loss: 0.4796 train_accuracy: 0.8399\tval_loss: 0.6081 val_accuracy: 0.7130\ttest_loss: 0.6261 test_accuracy: 0.6574\n",
      "train: {'epoch': 6, 'time_epoch': 13.28884, 'eta': 791.56307, 'eta_hours': 0.21988, 'loss': 0.43193666, 'lr': 0.00099901, 'params': 135681, 'time_iter': 0.24609, 'accuracy': 0.86427, 'precision': 0.84406, 'recall': 0.86329, 'f1': 0.85357, 'auc': 0.91307}\n",
      "val: {'epoch': 6, 'time_epoch': 1.08504, 'loss': 0.59516206, 'lr': 0, 'params': 135681, 'time_iter': 0.15501, 'accuracy': 0.68519, 'precision': 0.59494, 'recall': 0.95918, 'f1': 0.73438, 'auc': 0.86441}\n",
      "test: {'epoch': 6, 'time_epoch': 1.05716, 'loss': 0.56993613, 'lr': 0, 'params': 135681, 'time_iter': 0.15102, 'accuracy': 0.71296, 'precision': 0.6125, 'recall': 1.0, 'f1': 0.75969, 'auc': 0.92356}\n",
      "> Epoch 6: took 15.5s (avg 18.7s) | Best so far: epoch 5\ttrain_loss: 0.4796 train_accuracy: 0.8399\tval_loss: 0.6081 val_accuracy: 0.7130\ttest_loss: 0.6261 test_accuracy: 0.6574\n",
      "train: {'epoch': 7, 'time_epoch': 12.80789, 'eta': 753.43447, 'eta_hours': 0.20929, 'loss': 0.39947443, 'lr': 0.00099606, 'params': 135681, 'time_iter': 0.23718, 'accuracy': 0.87703, 'precision': 0.87147, 'recall': 0.85823, 'f1': 0.8648, 'auc': 0.92795}\n",
      "val: {'epoch': 7, 'time_epoch': 1.06418, 'loss': 0.50154045, 'lr': 0, 'params': 135681, 'time_iter': 0.15203, 'accuracy': 0.80556, 'precision': 0.91176, 'recall': 0.63265, 'f1': 0.74699, 'auc': 0.84158}\n",
      "test: {'epoch': 7, 'time_epoch': 1.09811, 'loss': 0.45786938, 'lr': 0, 'params': 135681, 'time_iter': 0.15687, 'accuracy': 0.81481, 'precision': 0.83721, 'recall': 0.73469, 'f1': 0.78261, 'auc': 0.90972}\n",
      "> Epoch 7: took 15.0s (avg 18.2s) | Best so far: epoch 7\ttrain_loss: 0.3995 train_accuracy: 0.8770\tval_loss: 0.5015 val_accuracy: 0.8056\ttest_loss: 0.4579 test_accuracy: 0.8148\n",
      "train: {'epoch': 8, 'time_epoch': 12.84342, 'eta': 721.11432, 'eta_hours': 0.20031, 'loss': 0.3469045, 'lr': 0.00099114, 'params': 135681, 'time_iter': 0.23784, 'accuracy': 0.90719, 'precision': 0.91339, 'recall': 0.88101, 'f1': 0.89691, 'auc': 0.93817}\n",
      "val: {'epoch': 8, 'time_epoch': 1.07122, 'loss': 0.85181678, 'lr': 0, 'params': 135681, 'time_iter': 0.15303, 'accuracy': 0.57407, 'precision': 1.0, 'recall': 0.06122, 'f1': 0.11538, 'auc': 0.72881}\n",
      "test: {'epoch': 8, 'time_epoch': 1.0459, 'loss': 0.8954476, 'lr': 0, 'params': 135681, 'time_iter': 0.14941, 'accuracy': 0.55556, 'precision': 1.0, 'recall': 0.02041, 'f1': 0.04, 'auc': 0.67347}\n",
      "> Epoch 8: took 15.0s (avg 17.9s) | Best so far: epoch 7\ttrain_loss: 0.3995 train_accuracy: 0.8770\tval_loss: 0.5015 val_accuracy: 0.8056\ttest_loss: 0.4579 test_accuracy: 0.8148\n",
      "train: {'epoch': 9, 'time_epoch': 12.69857, 'eta': 692.0377, 'eta_hours': 0.19223, 'loss': 0.32723274, 'lr': 0.00098429, 'params': 135681, 'time_iter': 0.23516, 'accuracy': 0.90487, 'precision': 0.88642, 'recall': 0.90886, 'f1': 0.8975, 'auc': 0.94466}\n",
      "val: {'epoch': 9, 'time_epoch': 1.04586, 'loss': 0.55553046, 'lr': 0, 'params': 135681, 'time_iter': 0.14941, 'accuracy': 0.74074, 'precision': 0.86207, 'recall': 0.5102, 'f1': 0.64103, 'auc': 0.82705}\n",
      "test: {'epoch': 9, 'time_epoch': 1.03339, 'loss': 0.51683905, 'lr': 0, 'params': 135681, 'time_iter': 0.14763, 'accuracy': 0.78704, 'precision': 0.90625, 'recall': 0.59184, 'f1': 0.71605, 'auc': 0.89623}\n",
      "> Epoch 9: took 14.8s (avg 17.6s) | Best so far: epoch 7\ttrain_loss: 0.3995 train_accuracy: 0.8770\tval_loss: 0.5015 val_accuracy: 0.8056\ttest_loss: 0.4579 test_accuracy: 0.8148\n",
      "train: {'epoch': 10, 'time_epoch': 12.50913, 'eta': 665.18112, 'eta_hours': 0.18477, 'loss': 0.32832458, 'lr': 0.00097553, 'params': 135681, 'time_iter': 0.23165, 'accuracy': 0.90023, 'precision': 0.90339, 'recall': 0.87595, 'f1': 0.88946, 'auc': 0.93684}\n",
      "val: {'epoch': 10, 'time_epoch': 1.07218, 'loss': 0.92041444, 'lr': 0, 'params': 135681, 'time_iter': 0.15317, 'accuracy': 0.52778, 'precision': 0.49, 'recall': 1.0, 'f1': 0.65772, 'auc': 0.73227}\n",
      "test: {'epoch': 10, 'time_epoch': 1.02584, 'loss': 0.97989934, 'lr': 0, 'params': 135681, 'time_iter': 0.14655, 'accuracy': 0.49074, 'precision': 0.47115, 'recall': 1.0, 'f1': 0.64052, 'auc': 0.79229}\n",
      "> Epoch 10: took 14.7s (avg 17.3s) | Best so far: epoch 7\ttrain_loss: 0.3995 train_accuracy: 0.8770\tval_loss: 0.5015 val_accuracy: 0.8056\ttest_loss: 0.4579 test_accuracy: 0.8148\n",
      "train: {'epoch': 11, 'time_epoch': 12.66097, 'eta': 641.25989, 'eta_hours': 0.17813, 'loss': 0.2858389, 'lr': 0.00096489, 'params': 135681, 'time_iter': 0.23446, 'accuracy': 0.91299, 'precision': 0.90609, 'recall': 0.9038, 'f1': 0.90494, 'auc': 0.96092}\n",
      "val: {'epoch': 11, 'time_epoch': 1.08338, 'loss': 0.51271658, 'lr': 0, 'params': 135681, 'time_iter': 0.15477, 'accuracy': 0.7963, 'precision': 0.72881, 'recall': 0.87755, 'f1': 0.7963, 'auc': 0.85022}\n",
      "test: {'epoch': 11, 'time_epoch': 1.02699, 'loss': 0.44179484, 'lr': 0, 'params': 135681, 'time_iter': 0.14671, 'accuracy': 0.82407, 'precision': 0.72727, 'recall': 0.97959, 'f1': 0.83478, 'auc': 0.92321}\n",
      "> Epoch 11: took 14.8s (avg 17.1s) | Best so far: epoch 7\ttrain_loss: 0.3995 train_accuracy: 0.8770\tval_loss: 0.5015 val_accuracy: 0.8056\ttest_loss: 0.4579 test_accuracy: 0.8148\n",
      "train: {'epoch': 12, 'time_epoch': 12.63256, 'eta': 618.97922, 'eta_hours': 0.17194, 'loss': 0.25069121, 'lr': 0.00095241, 'params': 135681, 'time_iter': 0.23394, 'accuracy': 0.93155, 'precision': 0.92211, 'recall': 0.92911, 'f1': 0.9256, 'auc': 0.96941}\n",
      "val: {'epoch': 12, 'time_epoch': 1.05622, 'loss': 0.52625055, 'lr': 0, 'params': 135681, 'time_iter': 0.15089, 'accuracy': 0.76852, 'precision': 0.69355, 'recall': 0.87755, 'f1': 0.77477, 'auc': 0.87686}\n",
      "test: {'epoch': 12, 'time_epoch': 1.05508, 'loss': 0.48386739, 'lr': 0, 'params': 135681, 'time_iter': 0.15073, 'accuracy': 0.78704, 'precision': 0.68571, 'recall': 0.97959, 'f1': 0.80672, 'auc': 0.93739}\n",
      "> Epoch 12: took 14.8s (avg 16.9s) | Best so far: epoch 7\ttrain_loss: 0.3995 train_accuracy: 0.8770\tval_loss: 0.5015 val_accuracy: 0.8056\ttest_loss: 0.4579 test_accuracy: 0.8148\n",
      "train: {'epoch': 13, 'time_epoch': 12.74692, 'eta': 598.41178, 'eta_hours': 0.16623, 'loss': 0.25905537, 'lr': 0.00093815, 'params': 135681, 'time_iter': 0.23605, 'accuracy': 0.92691, 'precision': 0.93455, 'recall': 0.9038, 'f1': 0.91892, 'auc': 0.95705}\n",
      "val: {'epoch': 13, 'time_epoch': 1.05172, 'loss': 0.42256496, 'lr': 0, 'params': 135681, 'time_iter': 0.15025, 'accuracy': 0.85185, 'precision': 0.83673, 'recall': 0.83673, 'f1': 0.83673, 'auc': 0.87928}\n",
      "test: {'epoch': 13, 'time_epoch': 1.08301, 'loss': 0.40540667, 'lr': 0, 'params': 135681, 'time_iter': 0.15472, 'accuracy': 0.86111, 'precision': 0.77419, 'recall': 0.97959, 'f1': 0.86486, 'auc': 0.93601}\n",
      "> Epoch 13: took 14.9s (avg 16.8s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 14, 'time_epoch': 12.70787, 'eta': 578.78294, 'eta_hours': 0.16077, 'loss': 0.22817885, 'lr': 0.00092216, 'params': 135681, 'time_iter': 0.23533, 'accuracy': 0.93968, 'precision': 0.93199, 'recall': 0.93671, 'f1': 0.93434, 'auc': 0.97165}\n",
      "val: {'epoch': 14, 'time_epoch': 1.05855, 'loss': 0.49629595, 'lr': 0, 'params': 135681, 'time_iter': 0.15122, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.88516}\n",
      "test: {'epoch': 14, 'time_epoch': 1.03804, 'loss': 0.43034889, 'lr': 0, 'params': 135681, 'time_iter': 0.14829, 'accuracy': 0.82407, 'precision': 0.8, 'recall': 0.81633, 'f1': 0.80808, 'auc': 0.91629}\n",
      "> Epoch 14: took 14.9s (avg 16.7s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 15, 'time_epoch': 12.53545, 'eta': 559.59894, 'eta_hours': 0.15544, 'loss': 0.21659667, 'lr': 0.00090451, 'params': 135681, 'time_iter': 0.23214, 'accuracy': 0.94084, 'precision': 0.91748, 'recall': 0.95696, 'f1': 0.9368, 'auc': 0.97552}\n",
      "val: {'epoch': 15, 'time_epoch': 1.03249, 'loss': 0.46004898, 'lr': 0, 'params': 135681, 'time_iter': 0.1475, 'accuracy': 0.82407, 'precision': 0.8, 'recall': 0.81633, 'f1': 0.80808, 'auc': 0.86441}\n",
      "test: {'epoch': 15, 'time_epoch': 1.03357, 'loss': 0.32482869, 'lr': 0, 'params': 135681, 'time_iter': 0.14765, 'accuracy': 0.88889, 'precision': 0.84906, 'recall': 0.91837, 'f1': 0.88235, 'auc': 0.94984}\n",
      "> Epoch 15: took 14.7s (avg 16.5s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 16, 'time_epoch': 12.66611, 'eta': 541.48919, 'eta_hours': 0.15041, 'loss': 0.21899924, 'lr': 0.00088526, 'params': 135681, 'time_iter': 0.23456, 'accuracy': 0.93968, 'precision': 0.92346, 'recall': 0.94684, 'f1': 0.935, 'auc': 0.96893}\n",
      "val: {'epoch': 16, 'time_epoch': 1.05095, 'loss': 0.46933365, 'lr': 0, 'params': 135681, 'time_iter': 0.15014, 'accuracy': 0.83333, 'precision': 0.81633, 'recall': 0.81633, 'f1': 0.81633, 'auc': 0.88066}\n",
      "test: {'epoch': 16, 'time_epoch': 1.02284, 'loss': 0.35718232, 'lr': 0, 'params': 135681, 'time_iter': 0.14612, 'accuracy': 0.86111, 'precision': 0.81481, 'recall': 0.89796, 'f1': 0.85437, 'auc': 0.9495}\n",
      "> Epoch 16: took 14.8s (avg 16.4s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 17, 'time_epoch': 12.71353, 'eta': 524.08176, 'eta_hours': 0.14558, 'loss': 0.21278701, 'lr': 0.00086448, 'params': 135681, 'time_iter': 0.23544, 'accuracy': 0.942, 'precision': 0.93893, 'recall': 0.93418, 'f1': 0.93655, 'auc': 0.97668}\n",
      "val: {'epoch': 17, 'time_epoch': 1.07016, 'loss': 0.6981104, 'lr': 0, 'params': 135681, 'time_iter': 0.15288, 'accuracy': 0.71296, 'precision': 0.63235, 'recall': 0.87755, 'f1': 0.73504, 'auc': 0.80526}\n",
      "test: {'epoch': 17, 'time_epoch': 1.07052, 'loss': 0.68353263, 'lr': 0, 'params': 135681, 'time_iter': 0.15293, 'accuracy': 0.71296, 'precision': 0.61538, 'recall': 0.97959, 'f1': 0.75591, 'auc': 0.85438}\n",
      "> Epoch 17: took 14.9s (avg 16.3s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 18, 'time_epoch': 12.63967, 'eta': 507.02848, 'eta_hours': 0.14084, 'loss': 0.2012807, 'lr': 0.00084227, 'params': 135681, 'time_iter': 0.23407, 'accuracy': 0.93968, 'precision': 0.92982, 'recall': 0.93924, 'f1': 0.93451, 'auc': 0.97218}\n",
      "val: {'epoch': 18, 'time_epoch': 1.06832, 'loss': 0.72125521, 'lr': 0, 'params': 135681, 'time_iter': 0.15262, 'accuracy': 0.73148, 'precision': 0.95455, 'recall': 0.42857, 'f1': 0.59155, 'auc': 0.8146}\n",
      "test: {'epoch': 18, 'time_epoch': 1.04196, 'loss': 0.84150124, 'lr': 0, 'params': 135681, 'time_iter': 0.14885, 'accuracy': 0.67593, 'precision': 0.88889, 'recall': 0.32653, 'f1': 0.47761, 'auc': 0.79557}\n",
      "> Epoch 18: took 14.8s (avg 16.3s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 19, 'time_epoch': 12.61982, 'eta': 490.38182, 'eta_hours': 0.13622, 'loss': 0.15188735, 'lr': 0.00081871, 'params': 135681, 'time_iter': 0.2337, 'accuracy': 0.96868, 'precision': 0.96701, 'recall': 0.96456, 'f1': 0.96578, 'auc': 0.97868}\n",
      "val: {'epoch': 19, 'time_epoch': 1.07344, 'loss': 0.5794199, 'lr': 0, 'params': 135681, 'time_iter': 0.15335, 'accuracy': 0.78704, 'precision': 0.74074, 'recall': 0.81633, 'f1': 0.7767, 'auc': 0.84573}\n",
      "test: {'epoch': 19, 'time_epoch': 1.11995, 'loss': 0.42330095, 'lr': 0, 'params': 135681, 'time_iter': 0.15999, 'accuracy': 0.84259, 'precision': 0.78571, 'recall': 0.89796, 'f1': 0.8381, 'auc': 0.90661}\n",
      "> Epoch 19: took 14.9s (avg 16.2s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 20, 'time_epoch': 12.84816, 'eta': 474.48836, 'eta_hours': 0.1318, 'loss': 0.15126279, 'lr': 0.00079389, 'params': 135681, 'time_iter': 0.23793, 'accuracy': 0.9652, 'precision': 0.9597, 'recall': 0.96456, 'f1': 0.96212, 'auc': 0.98684}\n",
      "val: {'epoch': 20, 'time_epoch': 1.03072, 'loss': 0.5305787, 'lr': 0, 'params': 135681, 'time_iter': 0.14725, 'accuracy': 0.81481, 'precision': 0.77358, 'recall': 0.83673, 'f1': 0.80392, 'auc': 0.85611}\n",
      "test: {'epoch': 20, 'time_epoch': 1.07446, 'loss': 0.41705395, 'lr': 0, 'params': 135681, 'time_iter': 0.15349, 'accuracy': 0.84259, 'precision': 0.78571, 'recall': 0.89796, 'f1': 0.8381, 'auc': 0.92079}\n",
      "> Epoch 20: took 15.0s (avg 16.1s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 21, 'time_epoch': 12.86294, 'eta': 458.89393, 'eta_hours': 0.12747, 'loss': 0.12083845, 'lr': 0.00076791, 'params': 135681, 'time_iter': 0.2382, 'accuracy': 0.97912, 'precision': 0.97964, 'recall': 0.97468, 'f1': 0.97716, 'auc': 0.98498}\n",
      "val: {'epoch': 21, 'time_epoch': 1.06405, 'loss': 0.60042328, 'lr': 0, 'params': 135681, 'time_iter': 0.15201, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.83051}\n",
      "test: {'epoch': 21, 'time_epoch': 1.04243, 'loss': 0.37301564, 'lr': 0, 'params': 135681, 'time_iter': 0.14892, 'accuracy': 0.87963, 'precision': 0.8913, 'recall': 0.83673, 'f1': 0.86316, 'auc': 0.9239}\n",
      "> Epoch 21: took 15.0s (avg 16.1s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 22, 'time_epoch': 24.63737, 'eta': 459.91882, 'eta_hours': 0.12776, 'loss': 0.14517839, 'lr': 0.00074088, 'params': 135681, 'time_iter': 0.45625, 'accuracy': 0.9652, 'precision': 0.96438, 'recall': 0.95949, 'f1': 0.96193, 'auc': 0.98817}\n",
      "val: {'epoch': 22, 'time_epoch': 1.14066, 'loss': 0.61689369, 'lr': 0, 'params': 135681, 'time_iter': 0.16295, 'accuracy': 0.7963, 'precision': 0.81395, 'recall': 0.71429, 'f1': 0.76087, 'auc': 0.84296}\n",
      "test: {'epoch': 22, 'time_epoch': 1.09963, 'loss': 0.46486528, 'lr': 0, 'params': 135681, 'time_iter': 0.15709, 'accuracy': 0.85185, 'precision': 0.86667, 'recall': 0.79592, 'f1': 0.82979, 'auc': 0.90038}\n",
      "> Epoch 22: took 26.9s (avg 16.6s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 23, 'time_epoch': 13.27342, 'eta': 444.12677, 'eta_hours': 0.12337, 'loss': 0.14747536, 'lr': 0.00071289, 'params': 135681, 'time_iter': 0.2458, 'accuracy': 0.96288, 'precision': 0.95949, 'recall': 0.95949, 'f1': 0.95949, 'auc': 0.98257}\n",
      "val: {'epoch': 23, 'time_epoch': 1.1326, 'loss': 0.66500778, 'lr': 0, 'params': 135681, 'time_iter': 0.1618, 'accuracy': 0.77778, 'precision': 0.7193, 'recall': 0.83673, 'f1': 0.77358, 'auc': 0.82878}\n",
      "test: {'epoch': 23, 'time_epoch': 1.128, 'loss': 0.71877029, 'lr': 0, 'params': 135681, 'time_iter': 0.16114, 'accuracy': 0.73148, 'precision': 0.65152, 'recall': 0.87755, 'f1': 0.74783, 'auc': 0.88862}\n",
      "> Epoch 23: took 15.6s (avg 16.5s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 24, 'time_epoch': 13.13671, 'eta': 428.37215, 'eta_hours': 0.11899, 'loss': 0.15204114, 'lr': 0.00068406, 'params': 135681, 'time_iter': 0.24327, 'accuracy': 0.95708, 'precision': 0.95202, 'recall': 0.95443, 'f1': 0.95322, 'auc': 0.98632}\n",
      "val: {'epoch': 24, 'time_epoch': 1.09902, 'loss': 0.94592925, 'lr': 0, 'params': 135681, 'time_iter': 0.157, 'accuracy': 0.66667, 'precision': 0.58667, 'recall': 0.89796, 'f1': 0.70968, 'auc': 0.76617}\n",
      "test: {'epoch': 24, 'time_epoch': 1.07315, 'loss': 0.89667763, 'lr': 0, 'params': 135681, 'time_iter': 0.15331, 'accuracy': 0.67593, 'precision': 0.58333, 'recall': 1.0, 'f1': 0.73684, 'auc': 0.75528}\n",
      "> Epoch 24: took 15.4s (avg 16.5s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 25, 'time_epoch': 12.82466, 'eta': 412.47085, 'eta_hours': 0.11458, 'loss': 0.12958252, 'lr': 0.00065451, 'params': 135681, 'time_iter': 0.23749, 'accuracy': 0.96984, 'precision': 0.96241, 'recall': 0.97215, 'f1': 0.96725, 'auc': 0.98339}\n",
      "val: {'epoch': 25, 'time_epoch': 1.06386, 'loss': 0.60542608, 'lr': 0, 'params': 135681, 'time_iter': 0.15198, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.85956}\n",
      "test: {'epoch': 25, 'time_epoch': 1.07668, 'loss': 0.5201222, 'lr': 0, 'params': 135681, 'time_iter': 0.15381, 'accuracy': 0.82407, 'precision': 0.8125, 'recall': 0.79592, 'f1': 0.80412, 'auc': 0.87772}\n",
      "> Epoch 25: took 15.0s (avg 16.4s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 26, 'time_epoch': 12.78859, 'eta': 396.76005, 'eta_hours': 0.11021, 'loss': 0.10859522, 'lr': 0.00062434, 'params': 135681, 'time_iter': 0.23683, 'accuracy': 0.97448, 'precision': 0.97455, 'recall': 0.96962, 'f1': 0.97208, 'auc': 0.98543}\n",
      "val: {'epoch': 26, 'time_epoch': 1.01559, 'loss': 0.59245234, 'lr': 0, 'params': 135681, 'time_iter': 0.14508, 'accuracy': 0.81481, 'precision': 0.91429, 'recall': 0.65306, 'f1': 0.7619, 'auc': 0.84158}\n",
      "test: {'epoch': 26, 'time_epoch': 1.04453, 'loss': 0.61323176, 'lr': 0, 'params': 135681, 'time_iter': 0.14922, 'accuracy': 0.7963, 'precision': 0.88571, 'recall': 0.63265, 'f1': 0.7381, 'auc': 0.85057}\n",
      "> Epoch 26: took 14.9s (avg 16.4s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 27, 'time_epoch': 12.79831, 'eta': 381.26734, 'eta_hours': 0.10591, 'loss': 0.13165656, 'lr': 0.00059369, 'params': 135681, 'time_iter': 0.23701, 'accuracy': 0.96868, 'precision': 0.96465, 'recall': 0.96709, 'f1': 0.96587, 'auc': 0.98666}\n",
      "val: {'epoch': 27, 'time_epoch': 1.1078, 'loss': 0.69979066, 'lr': 0, 'params': 135681, 'time_iter': 0.15826, 'accuracy': 0.77778, 'precision': 0.85714, 'recall': 0.61224, 'f1': 0.71429, 'auc': 0.83673}\n",
      "test: {'epoch': 27, 'time_epoch': 1.04568, 'loss': 0.69082081, 'lr': 0, 'params': 135681, 'time_iter': 0.14938, 'accuracy': 0.75926, 'precision': 0.81081, 'recall': 0.61224, 'f1': 0.69767, 'auc': 0.88897}\n",
      "> Epoch 27: took 15.0s (avg 16.3s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 28, 'time_epoch': 14.06442, 'eta': 367.09559, 'eta_hours': 0.10197, 'loss': 0.10747862, 'lr': 0.00056267, 'params': 135681, 'time_iter': 0.26045, 'accuracy': 0.97796, 'precision': 0.97475, 'recall': 0.97722, 'f1': 0.97598, 'auc': 0.98503}\n",
      "val: {'epoch': 28, 'time_epoch': 1.34707, 'loss': 0.63045663, 'lr': 0, 'params': 135681, 'time_iter': 0.19244, 'accuracy': 0.7963, 'precision': 0.76471, 'recall': 0.79592, 'f1': 0.78, 'auc': 0.8274}\n",
      "test: {'epoch': 28, 'time_epoch': 1.34743, 'loss': 0.4882711, 'lr': 0, 'params': 135681, 'time_iter': 0.19249, 'accuracy': 0.83333, 'precision': 0.77193, 'recall': 0.89796, 'f1': 0.83019, 'auc': 0.91664}\n",
      "> Epoch 28: took 16.9s (avg 16.3s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 29, 'time_epoch': 25.09185, 'eta': 362.12051, 'eta_hours': 0.10059, 'loss': 0.10743827, 'lr': 0.0005314, 'params': 135681, 'time_iter': 0.46466, 'accuracy': 0.9768, 'precision': 0.97229, 'recall': 0.97722, 'f1': 0.97475, 'auc': 0.98188}\n",
      "val: {'epoch': 29, 'time_epoch': 1.10415, 'loss': 0.73149231, 'lr': 0, 'params': 135681, 'time_iter': 0.15774, 'accuracy': 0.77778, 'precision': 0.90323, 'recall': 0.57143, 'f1': 0.7, 'auc': 0.85195}\n",
      "test: {'epoch': 29, 'time_epoch': 1.06622, 'loss': 0.84898711, 'lr': 0, 'params': 135681, 'time_iter': 0.15232, 'accuracy': 0.74074, 'precision': 0.88889, 'recall': 0.4898, 'f1': 0.63158, 'auc': 0.85126}\n",
      "> Epoch 29: took 27.3s (avg 16.7s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 30, 'time_epoch': 12.53404, 'eta': 346.12541, 'eta_hours': 0.09615, 'loss': 0.11998838, 'lr': 0.0005, 'params': 135681, 'time_iter': 0.23211, 'accuracy': 0.97216, 'precision': 0.97201, 'recall': 0.96709, 'f1': 0.96954, 'auc': 0.98307}\n",
      "val: {'epoch': 30, 'time_epoch': 1.05154, 'loss': 0.55728923, 'lr': 0, 'params': 135681, 'time_iter': 0.15022, 'accuracy': 0.82407, 'precision': 0.8, 'recall': 0.81633, 'f1': 0.80808, 'auc': 0.84469}\n",
      "test: {'epoch': 30, 'time_epoch': 0.98267, 'loss': 0.59801941, 'lr': 0, 'params': 135681, 'time_iter': 0.14038, 'accuracy': 0.80556, 'precision': 0.72581, 'recall': 0.91837, 'f1': 0.81081, 'auc': 0.9111}\n",
      "> Epoch 30: took 14.6s (avg 16.6s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 31, 'time_epoch': 24.13061, 'eta': 338.68166, 'eta_hours': 0.09408, 'loss': 0.11710427, 'lr': 0.0004686, 'params': 135681, 'time_iter': 0.44686, 'accuracy': 0.97216, 'precision': 0.96491, 'recall': 0.97468, 'f1': 0.96977, 'auc': 0.98589}\n",
      "val: {'epoch': 31, 'time_epoch': 1.03162, 'loss': 0.57292553, 'lr': 0, 'params': 135681, 'time_iter': 0.14737, 'accuracy': 0.81481, 'precision': 0.78431, 'recall': 0.81633, 'f1': 0.8, 'auc': 0.84607}\n",
      "test: {'epoch': 31, 'time_epoch': 1.03995, 'loss': 0.60190675, 'lr': 0, 'params': 135681, 'time_iter': 0.14856, 'accuracy': 0.7963, 'precision': 0.72131, 'recall': 0.89796, 'f1': 0.8, 'auc': 0.89658}\n",
      "> Epoch 31: took 26.2s (avg 16.9s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 32, 'time_epoch': 36.06703, 'eta': 338.1842, 'eta_hours': 0.09394, 'loss': 0.1026233, 'lr': 0.00043733, 'params': 135681, 'time_iter': 0.66791, 'accuracy': 0.98028, 'precision': 0.98462, 'recall': 0.97215, 'f1': 0.97834, 'auc': 0.98642}\n",
      "val: {'epoch': 32, 'time_epoch': 1.03983, 'loss': 0.64326749, 'lr': 0, 'params': 135681, 'time_iter': 0.14855, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.86942}\n",
      "test: {'epoch': 32, 'time_epoch': 1.06484, 'loss': 0.58369115, 'lr': 0, 'params': 135681, 'time_iter': 0.15212, 'accuracy': 0.80556, 'precision': 0.79167, 'recall': 0.77551, 'f1': 0.78351, 'auc': 0.87271}\n",
      "> Epoch 32: took 38.2s (avg 17.6s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 33, 'time_epoch': 12.89211, 'eta': 321.28048, 'eta_hours': 0.08924, 'loss': 0.08032686, 'lr': 0.00040631, 'params': 135681, 'time_iter': 0.23874, 'accuracy': 0.98724, 'precision': 0.9898, 'recall': 0.98228, 'f1': 0.98602, 'auc': 0.98868}\n",
      "val: {'epoch': 33, 'time_epoch': 1.07637, 'loss': 0.62633455, 'lr': 0, 'params': 135681, 'time_iter': 0.15377, 'accuracy': 0.80556, 'precision': 0.81818, 'recall': 0.73469, 'f1': 0.77419, 'auc': 0.85161}\n",
      "test: {'epoch': 33, 'time_epoch': 1.12233, 'loss': 0.54334433, 'lr': 0, 'params': 135681, 'time_iter': 0.16033, 'accuracy': 0.82407, 'precision': 0.77778, 'recall': 0.85714, 'f1': 0.81553, 'auc': 0.8862}\n",
      "> Epoch 33: took 15.1s (avg 17.5s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 34, 'time_epoch': 12.67753, 'eta': 304.48339, 'eta_hours': 0.08458, 'loss': 0.09174001, 'lr': 0.00037566, 'params': 135681, 'time_iter': 0.23477, 'accuracy': 0.98028, 'precision': 0.9725, 'recall': 0.98481, 'f1': 0.97862, 'auc': 0.99127}\n",
      "val: {'epoch': 34, 'time_epoch': 1.03489, 'loss': 0.60566327, 'lr': 0, 'params': 135681, 'time_iter': 0.14784, 'accuracy': 0.81481, 'precision': 0.83721, 'recall': 0.73469, 'f1': 0.78261, 'auc': 0.86544}\n",
      "test: {'epoch': 34, 'time_epoch': 1.01238, 'loss': 0.53308189, 'lr': 0, 'params': 135681, 'time_iter': 0.14463, 'accuracy': 0.83333, 'precision': 0.82979, 'recall': 0.79592, 'f1': 0.8125, 'auc': 0.88066}\n",
      "> Epoch 34: took 14.8s (avg 17.4s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 35, 'time_epoch': 12.78001, 'eta': 287.96924, 'eta_hours': 0.07999, 'loss': 0.07774708, 'lr': 0.00034549, 'params': 135681, 'time_iter': 0.23667, 'accuracy': 0.98492, 'precision': 0.98477, 'recall': 0.98228, 'f1': 0.98352, 'auc': 0.98994}\n",
      "val: {'epoch': 35, 'time_epoch': 1.08188, 'loss': 0.74296077, 'lr': 0, 'params': 135681, 'time_iter': 0.15455, 'accuracy': 0.77778, 'precision': 0.82051, 'recall': 0.65306, 'f1': 0.72727, 'auc': 0.87928}\n",
      "test: {'epoch': 35, 'time_epoch': 1.09171, 'loss': 0.64275265, 'lr': 0, 'params': 135681, 'time_iter': 0.15596, 'accuracy': 0.80556, 'precision': 0.85, 'recall': 0.69388, 'f1': 0.76404, 'auc': 0.84677}\n",
      "> Epoch 35: took 15.0s (avg 17.4s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 36, 'time_epoch': 12.72426, 'eta': 271.62983, 'eta_hours': 0.07545, 'loss': 0.08644581, 'lr': 0.00031594, 'params': 135681, 'time_iter': 0.23563, 'accuracy': 0.98376, 'precision': 0.98473, 'recall': 0.97975, 'f1': 0.98223, 'auc': 0.98657}\n",
      "val: {'epoch': 36, 'time_epoch': 1.21759, 'loss': 0.58330242, 'lr': 0, 'params': 135681, 'time_iter': 0.17394, 'accuracy': 0.83333, 'precision': 0.77193, 'recall': 0.89796, 'f1': 0.83019, 'auc': 0.85126}\n",
      "test: {'epoch': 36, 'time_epoch': 1.24249, 'loss': 0.70266836, 'lr': 0, 'params': 135681, 'time_iter': 0.1775, 'accuracy': 0.78704, 'precision': 0.69118, 'recall': 0.95918, 'f1': 0.80342, 'auc': 0.89554}\n",
      "> Epoch 36: took 15.3s (avg 17.3s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 37, 'time_epoch': 12.93908, 'eta': 255.57678, 'eta_hours': 0.07099, 'loss': 0.07325007, 'lr': 0.00028711, 'params': 135681, 'time_iter': 0.23961, 'accuracy': 0.9884, 'precision': 0.98734, 'recall': 0.98734, 'f1': 0.98734, 'auc': 0.98499}\n",
      "val: {'epoch': 37, 'time_epoch': 1.15645, 'loss': 0.61457294, 'lr': 0, 'params': 135681, 'time_iter': 0.16521, 'accuracy': 0.81481, 'precision': 0.77358, 'recall': 0.83673, 'f1': 0.80392, 'auc': 0.84089}\n",
      "test: {'epoch': 37, 'time_epoch': 1.08738, 'loss': 0.60859019, 'lr': 0, 'params': 135681, 'time_iter': 0.15534, 'accuracy': 0.7963, 'precision': 0.72131, 'recall': 0.89796, 'f1': 0.8, 'auc': 0.89813}\n",
      "> Epoch 37: took 15.2s (avg 17.2s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 38, 'time_epoch': 12.96268, 'eta': 239.69311, 'eta_hours': 0.06658, 'loss': 0.08451518, 'lr': 0.00025912, 'params': 135681, 'time_iter': 0.24005, 'accuracy': 0.9826, 'precision': 0.975, 'recall': 0.98734, 'f1': 0.98113, 'auc': 0.98797}\n",
      "val: {'epoch': 38, 'time_epoch': 1.11789, 'loss': 0.77335156, 'lr': 0, 'params': 135681, 'time_iter': 0.1597, 'accuracy': 0.77778, 'precision': 0.85714, 'recall': 0.61224, 'f1': 0.71429, 'auc': 0.86406}\n",
      "test: {'epoch': 38, 'time_epoch': 1.14614, 'loss': 0.80244168, 'lr': 0, 'params': 135681, 'time_iter': 0.16373, 'accuracy': 0.75, 'precision': 0.86667, 'recall': 0.53061, 'f1': 0.65823, 'auc': 0.83535}\n",
      "> Epoch 38: took 15.3s (avg 17.2s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 39, 'time_epoch': 24.43938, 'eta': 228.25925, 'eta_hours': 0.06341, 'loss': 0.07775577, 'lr': 0.00023209, 'params': 135681, 'time_iter': 0.45258, 'accuracy': 0.98376, 'precision': 0.98228, 'recall': 0.98228, 'f1': 0.98228, 'auc': 0.98955}\n",
      "val: {'epoch': 39, 'time_epoch': 1.05903, 'loss': 0.64881104, 'lr': 0, 'params': 135681, 'time_iter': 0.15129, 'accuracy': 0.7963, 'precision': 0.78723, 'recall': 0.7551, 'f1': 0.77083, 'auc': 0.85265}\n",
      "test: {'epoch': 39, 'time_epoch': 1.05241, 'loss': 0.54232082, 'lr': 0, 'params': 135681, 'time_iter': 0.15034, 'accuracy': 0.84259, 'precision': 0.83333, 'recall': 0.81633, 'f1': 0.82474, 'auc': 0.89277}\n",
      "> Epoch 39: took 26.6s (avg 17.4s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 40, 'time_epoch': 12.74455, 'eta': 212.19762, 'eta_hours': 0.05894, 'loss': 0.06941063, 'lr': 0.00020611, 'params': 135681, 'time_iter': 0.23601, 'accuracy': 0.9884, 'precision': 0.98489, 'recall': 0.98987, 'f1': 0.98737, 'auc': 0.9865}\n",
      "val: {'epoch': 40, 'time_epoch': 1.05551, 'loss': 0.76646651, 'lr': 0, 'params': 135681, 'time_iter': 0.15079, 'accuracy': 0.78704, 'precision': 0.84211, 'recall': 0.65306, 'f1': 0.73563, 'auc': 0.85714}\n",
      "test: {'epoch': 40, 'time_epoch': 1.03079, 'loss': 0.68272877, 'lr': 0, 'params': 135681, 'time_iter': 0.14726, 'accuracy': 0.78704, 'precision': 0.825, 'recall': 0.67347, 'f1': 0.74157, 'auc': 0.8779}\n",
      "> Epoch 40: took 14.9s (avg 17.4s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 41, 'time_epoch': 12.77398, 'eta': 196.30305, 'eta_hours': 0.05453, 'loss': 0.09094103, 'lr': 0.00018129, 'params': 135681, 'time_iter': 0.23656, 'accuracy': 0.98028, 'precision': 0.98462, 'recall': 0.97215, 'f1': 0.97834, 'auc': 0.98644}\n",
      "val: {'epoch': 41, 'time_epoch': 1.0538, 'loss': 0.59708611, 'lr': 0, 'params': 135681, 'time_iter': 0.15054, 'accuracy': 0.83333, 'precision': 0.78182, 'recall': 0.87755, 'f1': 0.82692, 'auc': 0.83691}\n",
      "test: {'epoch': 41, 'time_epoch': 1.05363, 'loss': 0.65869203, 'lr': 0, 'params': 135681, 'time_iter': 0.15052, 'accuracy': 0.7963, 'precision': 0.70769, 'recall': 0.93878, 'f1': 0.80702, 'auc': 0.90176}\n",
      "> Epoch 41: took 14.9s (avg 17.3s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n",
      "train: {'epoch': 42, 'time_epoch': 36.04532, 'eta': 187.04796, 'eta_hours': 0.05196, 'loss': 0.10788434, 'lr': 0.00015773, 'params': 135681, 'time_iter': 0.66751, 'accuracy': 0.97448, 'precision': 0.96977, 'recall': 0.97468, 'f1': 0.97222, 'auc': 0.98862}\n",
      "val: {'epoch': 42, 'time_epoch': 1.09918, 'loss': 0.68664715, 'lr': 0, 'params': 135681, 'time_iter': 0.15703, 'accuracy': 0.7963, 'precision': 0.81395, 'recall': 0.71429, 'f1': 0.76087, 'auc': 0.86268}\n",
      "test: {'epoch': 42, 'time_epoch': 1.07199, 'loss': 0.55026267, 'lr': 0, 'params': 135681, 'time_iter': 0.15314, 'accuracy': 0.84259, 'precision': 0.84783, 'recall': 0.79592, 'f1': 0.82105, 'auc': 0.89796}\n",
      "> Epoch 42: took 38.3s (avg 17.8s) | Best so far: epoch 13\ttrain_loss: 0.2591 train_accuracy: 0.9269\tval_loss: 0.4226 val_accuracy: 0.8518\ttest_loss: 0.4054 test_accuracy: 0.8611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gender - Using Exphormer with 2 layers 0.1 drop 0.3 att drop   BEST\n",
    "%run main.py --cfg configs/Exphormer/neural-Gender.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a323bd4c-49ad-4996-8ff3-564a1bc632b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-02 12:19:16.010856\n",
      "[*] Loaded dataset 'HCPGender' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1078000, 1000], edge_index=[2, 49133748], y=[1078])\n",
      "  undirected: True\n",
      "  num graphs: 1078\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 2\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [02:06<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:02:07.04\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [01:22<00:00, 13.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:22.89\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPGender\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.5\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 2\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 60\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Gender\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Gender\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 2\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 135681\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 11.3307, 'eta': 668.5113, 'eta_hours': 0.1857, 'loss': 0.69093634, 'lr': 0.0, 'params': 135681, 'time_iter': 0.20983, 'accuracy': 0.53712, 'precision': 0.43333, 'recall': 0.03291, 'f1': 0.06118, 'auc': 0.48271}\n",
      "...computing epoch stats took: 0.07s\n",
      "val: {'epoch': 0, 'time_epoch': 0.82469, 'loss': 0.68669828, 'lr': 0, 'params': 135681, 'time_iter': 0.11781, 'accuracy': 0.5463, 'precision': 0.5, 'recall': 0.04082, 'f1': 0.07547, 'auc': 0.56209}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 0, 'time_epoch': 0.82612, 'loss': 0.68848399, 'lr': 0, 'params': 135681, 'time_iter': 0.11802, 'accuracy': 0.55556, 'precision': 0.66667, 'recall': 0.04082, 'f1': 0.07692, 'auc': 0.49879}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 0: took 13.1s (avg 13.1s) | Best so far: epoch 0\ttrain_loss: 0.6909 train_accuracy: 0.5371\tval_loss: 0.6867 val_accuracy: 0.5463\ttest_loss: 0.6885 test_accuracy: 0.5556\n",
      "train: {'epoch': 1, 'time_epoch': 22.22439, 'eta': 973.09764, 'eta_hours': 0.2703, 'loss': 0.67213129, 'lr': 0.0002, 'params': 135681, 'time_iter': 0.41156, 'accuracy': 0.59513, 'precision': 0.58456, 'recall': 0.40253, 'f1': 0.47676, 'auc': 0.63868}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 1, 'time_epoch': 0.81865, 'loss': 0.65325555, 'lr': 0, 'params': 135681, 'time_iter': 0.11695, 'accuracy': 0.61111, 'precision': 0.6, 'recall': 0.42857, 'f1': 0.5, 'auc': 0.74023}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 0.81243, 'loss': 0.64672792, 'lr': 0, 'params': 135681, 'time_iter': 0.11606, 'accuracy': 0.72222, 'precision': 0.71111, 'recall': 0.65306, 'f1': 0.68085, 'auc': 0.76444}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 23.9s (avg 18.5s) | Best so far: epoch 1\ttrain_loss: 0.6721 train_accuracy: 0.5951\tval_loss: 0.6533 val_accuracy: 0.6111\ttest_loss: 0.6467 test_accuracy: 0.7222\n",
      "train: {'epoch': 2, 'time_epoch': 10.29999, 'eta': 833.2465, 'eta_hours': 0.23146, 'loss': 0.63795371, 'lr': 0.0004, 'params': 135681, 'time_iter': 0.19074, 'accuracy': 0.69026, 'precision': 0.7, 'recall': 0.56709, 'f1': 0.62657, 'auc': 0.76093}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 0.81603, 'loss': 0.69615217, 'lr': 0, 'params': 135681, 'time_iter': 0.11658, 'accuracy': 0.5463, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.77551}\n",
      "...computing epoch stats took: 0.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: {'epoch': 2, 'time_epoch': 0.80929, 'loss': 0.6967879, 'lr': 0, 'params': 135681, 'time_iter': 0.11561, 'accuracy': 0.5463, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.75683}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 12.0s (avg 16.3s) | Best so far: epoch 1\ttrain_loss: 0.6721 train_accuracy: 0.5951\tval_loss: 0.6533 val_accuracy: 0.6111\ttest_loss: 0.6467 test_accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'epoch': 3, 'time_epoch': 10.25063, 'eta': 757.47992, 'eta_hours': 0.21041, 'loss': 0.58250575, 'lr': 0.0006, 'params': 135681, 'time_iter': 0.18983, 'accuracy': 0.78306, 'precision': 0.78889, 'recall': 0.71899, 'f1': 0.75232, 'auc': 0.8447}\n",
      "val: {'epoch': 3, 'time_epoch': 0.8037, 'loss': 0.56852216, 'lr': 0, 'params': 135681, 'time_iter': 0.11481, 'accuracy': 0.80556, 'precision': 0.75926, 'recall': 0.83673, 'f1': 0.79612, 'auc': 0.8779}\n",
      "test: {'epoch': 3, 'time_epoch': 0.80192, 'loss': 0.56960362, 'lr': 0, 'params': 135681, 'time_iter': 0.11456, 'accuracy': 0.76852, 'precision': 0.7069, 'recall': 0.83673, 'f1': 0.76636, 'auc': 0.88343}\n",
      "> Epoch 3: took 11.9s (avg 15.2s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 4, 'time_epoch': 10.27803, 'eta': 708.22117, 'eta_hours': 0.19673, 'loss': 0.51874722, 'lr': 0.0008, 'params': 135681, 'time_iter': 0.19033, 'accuracy': 0.82715, 'precision': 0.82199, 'recall': 0.79494, 'f1': 0.80824, 'auc': 0.88763}\n",
      "val: {'epoch': 4, 'time_epoch': 0.81024, 'loss': 0.73807819, 'lr': 0, 'params': 135681, 'time_iter': 0.11575, 'accuracy': 0.48148, 'precision': 0.46667, 'recall': 1.0, 'f1': 0.63636, 'auc': 0.79177}\n",
      "test: {'epoch': 4, 'time_epoch': 0.79626, 'loss': 0.74120326, 'lr': 0, 'params': 135681, 'time_iter': 0.11375, 'accuracy': 0.49074, 'precision': 0.47115, 'recall': 1.0, 'f1': 0.64052, 'auc': 0.80664}\n",
      "> Epoch 4: took 11.9s (avg 14.5s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 5, 'time_epoch': 21.89427, 'eta': 776.50211, 'eta_hours': 0.2157, 'loss': 0.47442818, 'lr': 0.001, 'params': 135681, 'time_iter': 0.40545, 'accuracy': 0.84455, 'precision': 0.84252, 'recall': 0.81266, 'f1': 0.82732, 'auc': 0.89816}\n",
      "val: {'epoch': 5, 'time_epoch': 0.79561, 'loss': 0.51066279, 'lr': 0, 'params': 135681, 'time_iter': 0.11366, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.84192}\n",
      "test: {'epoch': 5, 'time_epoch': 0.80236, 'loss': 0.46755285, 'lr': 0, 'params': 135681, 'time_iter': 0.11462, 'accuracy': 0.87037, 'precision': 0.87234, 'recall': 0.83673, 'f1': 0.85417, 'auc': 0.89796}\n",
      "> Epoch 5: took 23.5s (avg 16.0s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 6, 'time_epoch': 10.27071, 'eta': 731.01177, 'eta_hours': 0.20306, 'loss': 0.43168182, 'lr': 0.00099918, 'params': 135681, 'time_iter': 0.1902, 'accuracy': 0.85963, 'precision': 0.85492, 'recall': 0.83544, 'f1': 0.84507, 'auc': 0.91663}\n",
      "val: {'epoch': 6, 'time_epoch': 0.80252, 'loss': 0.5349688, 'lr': 0, 'params': 135681, 'time_iter': 0.11465, 'accuracy': 0.75, 'precision': 0.66667, 'recall': 0.89796, 'f1': 0.76522, 'auc': 0.84365}\n",
      "test: {'epoch': 6, 'time_epoch': 0.80167, 'loss': 0.53021498, 'lr': 0, 'params': 135681, 'time_iter': 0.11452, 'accuracy': 0.74074, 'precision': 0.64789, 'recall': 0.93878, 'f1': 0.76667, 'auc': 0.91941}\n",
      "> Epoch 6: took 11.9s (avg 15.4s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 7, 'time_epoch': 10.32532, 'eta': 694.6813, 'eta_hours': 0.19297, 'loss': 0.37229948, 'lr': 0.00099674, 'params': 135681, 'time_iter': 0.19121, 'accuracy': 0.90139, 'precision': 0.91223, 'recall': 0.86835, 'f1': 0.88975, 'auc': 0.93337}\n",
      "val: {'epoch': 7, 'time_epoch': 0.80356, 'loss': 0.4742911, 'lr': 0, 'params': 135681, 'time_iter': 0.11479, 'accuracy': 0.80556, 'precision': 0.76923, 'recall': 0.81633, 'f1': 0.79208, 'auc': 0.86337}\n",
      "test: {'epoch': 7, 'time_epoch': 0.81124, 'loss': 0.43864622, 'lr': 0, 'params': 135681, 'time_iter': 0.11589, 'accuracy': 0.81481, 'precision': 0.76364, 'recall': 0.85714, 'f1': 0.80769, 'auc': 0.93635}\n",
      "> Epoch 7: took 12.0s (avg 15.0s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 8, 'time_epoch': 10.32753, 'eta': 664.14225, 'eta_hours': 0.18448, 'loss': 0.34191445, 'lr': 0.00099268, 'params': 135681, 'time_iter': 0.19125, 'accuracy': 0.90371, 'precision': 0.9127, 'recall': 0.87342, 'f1': 0.89263, 'auc': 0.94338}\n",
      "val: {'epoch': 8, 'time_epoch': 0.81037, 'loss': 0.74759017, 'lr': 0, 'params': 135681, 'time_iter': 0.11577, 'accuracy': 0.60185, 'precision': 0.8, 'recall': 0.16327, 'f1': 0.27119, 'auc': 0.79004}\n",
      "test: {'epoch': 8, 'time_epoch': 0.80499, 'loss': 0.75446225, 'lr': 0, 'params': 135681, 'time_iter': 0.115, 'accuracy': 0.62037, 'precision': 0.9, 'recall': 0.18367, 'f1': 0.30508, 'auc': 0.81598}\n",
      "> Epoch 8: took 12.0s (avg 14.7s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 9, 'time_epoch': 10.23696, 'eta': 637.19269, 'eta_hours': 0.177, 'loss': 0.30690869, 'lr': 0.00098701, 'params': 135681, 'time_iter': 0.18957, 'accuracy': 0.91879, 'precision': 0.91139, 'recall': 0.91139, 'f1': 0.91139, 'auc': 0.94944}\n",
      "val: {'epoch': 9, 'time_epoch': 0.79688, 'loss': 0.54546618, 'lr': 0, 'params': 135681, 'time_iter': 0.11384, 'accuracy': 0.76852, 'precision': 0.7, 'recall': 0.85714, 'f1': 0.77064, 'auc': 0.85541}\n",
      "test: {'epoch': 9, 'time_epoch': 0.80574, 'loss': 0.46244322, 'lr': 0, 'params': 135681, 'time_iter': 0.11511, 'accuracy': 0.81481, 'precision': 0.74576, 'recall': 0.89796, 'f1': 0.81481, 'auc': 0.90834}\n",
      "> Epoch 9: took 11.9s (avg 14.4s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 10, 'time_epoch': 10.27788, 'eta': 613.46406, 'eta_hours': 0.17041, 'loss': 0.30104376, 'lr': 0.00097975, 'params': 135681, 'time_iter': 0.19033, 'accuracy': 0.91415, 'precision': 0.90025, 'recall': 0.91392, 'f1': 0.90704, 'auc': 0.95228}\n",
      "val: {'epoch': 10, 'time_epoch': 0.79764, 'loss': 0.49861991, 'lr': 0, 'params': 135681, 'time_iter': 0.11395, 'accuracy': 0.7963, 'precision': 0.73684, 'recall': 0.85714, 'f1': 0.79245, 'auc': 0.85057}\n",
      "test: {'epoch': 10, 'time_epoch': 0.79741, 'loss': 0.36936734, 'lr': 0, 'params': 135681, 'time_iter': 0.11392, 'accuracy': 0.86111, 'precision': 0.82692, 'recall': 0.87755, 'f1': 0.85149, 'auc': 0.93047}\n",
      "> Epoch 10: took 11.9s (avg 14.2s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 11, 'time_epoch': 10.29068, 'eta': 592.0284, 'eta_hours': 0.16445, 'loss': 0.2799046, 'lr': 0.00097092, 'params': 135681, 'time_iter': 0.19057, 'accuracy': 0.91879, 'precision': 0.90727, 'recall': 0.91646, 'f1': 0.91184, 'auc': 0.95392}\n",
      "val: {'epoch': 11, 'time_epoch': 0.81465, 'loss': 0.90341657, 'lr': 0, 'params': 135681, 'time_iter': 0.11638, 'accuracy': 0.56481, 'precision': 0.51087, 'recall': 0.95918, 'f1': 0.66667, 'auc': 0.70114}\n",
      "test: {'epoch': 11, 'time_epoch': 0.80759, 'loss': 0.91841449, 'lr': 0, 'params': 135681, 'time_iter': 0.11537, 'accuracy': 0.56481, 'precision': 0.51042, 'recall': 1.0, 'f1': 0.67586, 'auc': 0.7698}\n",
      "> Epoch 11: took 11.9s (avg 14.0s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 12, 'time_epoch': 10.26157, 'eta': 572.20213, 'eta_hours': 0.15895, 'loss': 0.27665722, 'lr': 0.00096056, 'params': 135681, 'time_iter': 0.19003, 'accuracy': 0.91647, 'precision': 0.91094, 'recall': 0.90633, 'f1': 0.90863, 'auc': 0.96607}\n",
      "val: {'epoch': 12, 'time_epoch': 0.80988, 'loss': 1.11267036, 'lr': 0, 'params': 135681, 'time_iter': 0.1157, 'accuracy': 0.47222, 'precision': 0.46226, 'recall': 1.0, 'f1': 0.63226, 'auc': 0.53286}\n",
      "test: {'epoch': 12, 'time_epoch': 0.8002, 'loss': 1.09950268, 'lr': 0, 'params': 135681, 'time_iter': 0.11431, 'accuracy': 0.48148, 'precision': 0.46667, 'recall': 1.0, 'f1': 0.63636, 'auc': 0.53874}\n",
      "> Epoch 12: took 11.9s (avg 13.8s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 13, 'time_epoch': 10.29761, 'eta': 553.86065, 'eta_hours': 0.15385, 'loss': 0.25523155, 'lr': 0.0009487, 'params': 135681, 'time_iter': 0.1907, 'accuracy': 0.92575, 'precision': 0.93438, 'recall': 0.90127, 'f1': 0.91753, 'auc': 0.97022}\n",
      "val: {'epoch': 13, 'time_epoch': 0.80165, 'loss': 0.8506149, 'lr': 0, 'params': 135681, 'time_iter': 0.11452, 'accuracy': 0.60185, 'precision': 0.53488, 'recall': 0.93878, 'f1': 0.68148, 'auc': 0.8056}\n",
      "test: {'epoch': 13, 'time_epoch': 0.79746, 'loss': 0.79508275, 'lr': 0, 'params': 135681, 'time_iter': 0.11392, 'accuracy': 0.63889, 'precision': 0.55682, 'recall': 1.0, 'f1': 0.71533, 'auc': 0.86856}\n",
      "> Epoch 13: took 11.9s (avg 13.7s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 14, 'time_epoch': 10.28723, 'eta': 536.56055, 'eta_hours': 0.14904, 'loss': 0.22656549, 'lr': 0.00093537, 'params': 135681, 'time_iter': 0.1905, 'accuracy': 0.94432, 'precision': 0.953, 'recall': 0.92405, 'f1': 0.9383, 'auc': 0.9703}\n",
      "val: {'epoch': 14, 'time_epoch': 0.81959, 'loss': 0.57578527, 'lr': 0, 'params': 135681, 'time_iter': 0.11708, 'accuracy': 0.75926, 'precision': 0.70909, 'recall': 0.79592, 'f1': 0.75, 'auc': 0.85022}\n",
      "test: {'epoch': 14, 'time_epoch': 0.80519, 'loss': 0.4188663, 'lr': 0, 'params': 135681, 'time_iter': 0.11503, 'accuracy': 0.83333, 'precision': 0.74603, 'recall': 0.95918, 'f1': 0.83929, 'auc': 0.93878}\n",
      "> Epoch 14: took 11.9s (avg 13.6s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 15, 'time_epoch': 10.317, 'eta': 520.21892, 'eta_hours': 0.14451, 'loss': 0.2251714, 'lr': 0.00092063, 'params': 135681, 'time_iter': 0.19106, 'accuracy': 0.93503, 'precision': 0.92269, 'recall': 0.93671, 'f1': 0.92965, 'auc': 0.97714}\n",
      "val: {'epoch': 15, 'time_epoch': 0.80527, 'loss': 0.56502345, 'lr': 0, 'params': 135681, 'time_iter': 0.11504, 'accuracy': 0.76852, 'precision': 0.7069, 'recall': 0.83673, 'f1': 0.76636, 'auc': 0.85783}\n",
      "test: {'epoch': 15, 'time_epoch': 0.80098, 'loss': 0.42693872, 'lr': 0, 'params': 135681, 'time_iter': 0.11443, 'accuracy': 0.80556, 'precision': 0.71875, 'recall': 0.93878, 'f1': 0.81416, 'auc': 0.93739}\n",
      "> Epoch 15: took 11.9s (avg 13.5s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 16, 'time_epoch': 10.26422, 'eta': 504.45258, 'eta_hours': 0.14013, 'loss': 0.20596339, 'lr': 0.00090451, 'params': 135681, 'time_iter': 0.19008, 'accuracy': 0.942, 'precision': 0.93451, 'recall': 0.93924, 'f1': 0.93687, 'auc': 0.97867}\n",
      "val: {'epoch': 16, 'time_epoch': 0.82401, 'loss': 0.49209007, 'lr': 0, 'params': 135681, 'time_iter': 0.11772, 'accuracy': 0.80556, 'precision': 0.81818, 'recall': 0.73469, 'f1': 0.77419, 'auc': 0.83673}\n",
      "test: {'epoch': 16, 'time_epoch': 0.8023, 'loss': 0.42067661, 'lr': 0, 'params': 135681, 'time_iter': 0.11461, 'accuracy': 0.84259, 'precision': 0.9, 'recall': 0.73469, 'f1': 0.80899, 'auc': 0.9239}\n",
      "> Epoch 16: took 11.9s (avg 13.4s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 17, 'time_epoch': 10.26959, 'eta': 489.31011, 'eta_hours': 0.13592, 'loss': 0.19645502, 'lr': 0.00088707, 'params': 135681, 'time_iter': 0.19018, 'accuracy': 0.94548, 'precision': 0.93284, 'recall': 0.94937, 'f1': 0.94103, 'auc': 0.9789}\n",
      "val: {'epoch': 17, 'time_epoch': 0.85668, 'loss': 0.54481328, 'lr': 0, 'params': 135681, 'time_iter': 0.12238, 'accuracy': 0.80556, 'precision': 0.91176, 'recall': 0.63265, 'f1': 0.74699, 'auc': 0.84434}\n",
      "test: {'epoch': 17, 'time_epoch': 0.86417, 'loss': 0.69710569, 'lr': 0, 'params': 135681, 'time_iter': 0.12345, 'accuracy': 0.74074, 'precision': 0.88889, 'recall': 0.4898, 'f1': 0.63158, 'auc': 0.85749}\n",
      "> Epoch 17: took 12.0s (avg 13.3s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 18, 'time_epoch': 10.32975, 'eta': 474.81038, 'eta_hours': 0.13189, 'loss': 0.17064248, 'lr': 0.00086837, 'params': 135681, 'time_iter': 0.19129, 'accuracy': 0.95708, 'precision': 0.9475, 'recall': 0.95949, 'f1': 0.95346, 'auc': 0.97982}\n",
      "val: {'epoch': 18, 'time_epoch': 0.79984, 'loss': 0.70678634, 'lr': 0, 'params': 135681, 'time_iter': 0.11426, 'accuracy': 0.72222, 'precision': 0.65079, 'recall': 0.83673, 'f1': 0.73214, 'auc': 0.86164}\n",
      "test: {'epoch': 18, 'time_epoch': 0.81161, 'loss': 0.58790873, 'lr': 0, 'params': 135681, 'time_iter': 0.11594, 'accuracy': 0.77778, 'precision': 0.69231, 'recall': 0.91837, 'f1': 0.78947, 'auc': 0.85922}\n",
      "> Epoch 18: took 12.0s (avg 13.2s) | Best so far: epoch 3\ttrain_loss: 0.5825 train_accuracy: 0.7831\tval_loss: 0.5685 val_accuracy: 0.8056\ttest_loss: 0.5696 test_accuracy: 0.7685\n",
      "train: {'epoch': 19, 'time_epoch': 10.36606, 'eta': 460.80028, 'eta_hours': 0.128, 'loss': 0.14965299, 'lr': 0.00084847, 'params': 135681, 'time_iter': 0.19196, 'accuracy': 0.96404, 'precision': 0.97396, 'recall': 0.94684, 'f1': 0.96021, 'auc': 0.98203}\n",
      "val: {'epoch': 19, 'time_epoch': 0.80501, 'loss': 0.54696063, 'lr': 0, 'params': 135681, 'time_iter': 0.115, 'accuracy': 0.81481, 'precision': 0.87179, 'recall': 0.69388, 'f1': 0.77273, 'auc': 0.83431}\n",
      "test: {'epoch': 19, 'time_epoch': 0.80381, 'loss': 0.58676165, 'lr': 0, 'params': 135681, 'time_iter': 0.11483, 'accuracy': 0.76852, 'precision': 0.875, 'recall': 0.57143, 'f1': 0.69136, 'auc': 0.85472}\n",
      "> Epoch 19: took 12.0s (avg 13.2s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 20, 'time_epoch': 10.34883, 'eta': 447.10523, 'eta_hours': 0.1242, 'loss': 0.13769392, 'lr': 0.00082743, 'params': 135681, 'time_iter': 0.19165, 'accuracy': 0.96984, 'precision': 0.96474, 'recall': 0.96962, 'f1': 0.96717, 'auc': 0.98814}\n",
      "val: {'epoch': 20, 'time_epoch': 0.81758, 'loss': 0.55076669, 'lr': 0, 'params': 135681, 'time_iter': 0.1168, 'accuracy': 0.81481, 'precision': 0.80851, 'recall': 0.77551, 'f1': 0.79167, 'auc': 0.83812}\n",
      "test: {'epoch': 20, 'time_epoch': 0.80944, 'loss': 0.52968196, 'lr': 0, 'params': 135681, 'time_iter': 0.11563, 'accuracy': 0.78704, 'precision': 0.78261, 'recall': 0.73469, 'f1': 0.75789, 'auc': 0.90211}\n",
      "> Epoch 20: took 12.0s (avg 13.1s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 21, 'time_epoch': 10.31665, 'eta': 433.65879, 'eta_hours': 0.12046, 'loss': 0.12719572, 'lr': 0.00080532, 'params': 135681, 'time_iter': 0.19105, 'accuracy': 0.9768, 'precision': 0.9771, 'recall': 0.97215, 'f1': 0.97462, 'auc': 0.98804}\n",
      "val: {'epoch': 21, 'time_epoch': 0.82537, 'loss': 0.84893631, 'lr': 0, 'params': 135681, 'time_iter': 0.11791, 'accuracy': 0.69444, 'precision': 0.61429, 'recall': 0.87755, 'f1': 0.72269, 'auc': 0.78762}\n",
      "test: {'epoch': 21, 'time_epoch': 0.82292, 'loss': 0.70552373, 'lr': 0, 'params': 135681, 'time_iter': 0.11756, 'accuracy': 0.75, 'precision': 0.64865, 'recall': 0.97959, 'f1': 0.78049, 'auc': 0.85783}\n",
      "> Epoch 21: took 12.0s (avg 13.1s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 22, 'time_epoch': 21.90555, 'eta': 439.12753, 'eta_hours': 0.12198, 'loss': 0.15363275, 'lr': 0.00078222, 'params': 135681, 'time_iter': 0.40566, 'accuracy': 0.96056, 'precision': 0.96164, 'recall': 0.9519, 'f1': 0.95674, 'auc': 0.98624}\n",
      "val: {'epoch': 22, 'time_epoch': 0.80358, 'loss': 0.59258066, 'lr': 0, 'params': 135681, 'time_iter': 0.1148, 'accuracy': 0.78704, 'precision': 0.76, 'recall': 0.77551, 'f1': 0.76768, 'auc': 0.84504}\n",
      "test: {'epoch': 22, 'time_epoch': 0.80324, 'loss': 0.44741523, 'lr': 0, 'params': 135681, 'time_iter': 0.11475, 'accuracy': 0.82407, 'precision': 0.78846, 'recall': 0.83673, 'f1': 0.81188, 'auc': 0.9118}\n",
      "> Epoch 22: took 23.5s (avg 13.5s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 23, 'time_epoch': 10.28739, 'eta': 424.88784, 'eta_hours': 0.11802, 'loss': 0.14706179, 'lr': 0.0007582, 'params': 135681, 'time_iter': 0.19051, 'accuracy': 0.9652, 'precision': 0.96915, 'recall': 0.95443, 'f1': 0.96173, 'auc': 0.98311}\n",
      "val: {'epoch': 23, 'time_epoch': 0.80943, 'loss': 0.77334532, 'lr': 0, 'params': 135681, 'time_iter': 0.11563, 'accuracy': 0.74074, 'precision': 0.92, 'recall': 0.46939, 'f1': 0.62162, 'auc': 0.79453}\n",
      "test: {'epoch': 23, 'time_epoch': 0.8066, 'loss': 0.90207261, 'lr': 0, 'params': 135681, 'time_iter': 0.11523, 'accuracy': 0.69444, 'precision': 0.94444, 'recall': 0.34694, 'f1': 0.50746, 'auc': 0.81045}\n",
      "> Epoch 23: took 11.9s (avg 13.4s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 24, 'time_epoch': 10.25256, 'eta': 410.91557, 'eta_hours': 0.11414, 'loss': 0.14549733, 'lr': 0.00073333, 'params': 135681, 'time_iter': 0.18986, 'accuracy': 0.95708, 'precision': 0.95897, 'recall': 0.94684, 'f1': 0.95287, 'auc': 0.98836}\n",
      "val: {'epoch': 24, 'time_epoch': 0.80379, 'loss': 1.02228173, 'lr': 0, 'params': 135681, 'time_iter': 0.11483, 'accuracy': 0.64815, 'precision': 0.56962, 'recall': 0.91837, 'f1': 0.70312, 'auc': 0.66724}\n",
      "test: {'epoch': 24, 'time_epoch': 0.79891, 'loss': 1.03678742, 'lr': 0, 'params': 135681, 'time_iter': 0.11413, 'accuracy': 0.63889, 'precision': 0.55682, 'recall': 1.0, 'f1': 0.71533, 'auc': 0.69146}\n",
      "> Epoch 24: took 11.9s (avg 13.4s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 25, 'time_epoch': 10.22872, 'eta': 397.19825, 'eta_hours': 0.11033, 'loss': 0.12772148, 'lr': 0.00070771, 'params': 135681, 'time_iter': 0.18942, 'accuracy': 0.96868, 'precision': 0.96939, 'recall': 0.96203, 'f1': 0.96569, 'auc': 0.98724}\n",
      "val: {'epoch': 25, 'time_epoch': 0.79753, 'loss': 0.61826413, 'lr': 0, 'params': 135681, 'time_iter': 0.11393, 'accuracy': 0.80556, 'precision': 0.9375, 'recall': 0.61224, 'f1': 0.74074, 'auc': 0.81771}\n",
      "test: {'epoch': 25, 'time_epoch': 0.80105, 'loss': 0.66498833, 'lr': 0, 'params': 135681, 'time_iter': 0.11444, 'accuracy': 0.77778, 'precision': 0.93103, 'recall': 0.55102, 'f1': 0.69231, 'auc': 0.89761}\n",
      "> Epoch 25: took 11.8s (avg 13.3s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 26, 'time_epoch': 10.28044, 'eta': 383.80256, 'eta_hours': 0.10661, 'loss': 0.11569897, 'lr': 0.0006814, 'params': 135681, 'time_iter': 0.19038, 'accuracy': 0.97448, 'precision': 0.97215, 'recall': 0.97215, 'f1': 0.97215, 'auc': 0.98735}\n",
      "val: {'epoch': 26, 'time_epoch': 0.80768, 'loss': 0.63307955, 'lr': 0, 'params': 135681, 'time_iter': 0.11538, 'accuracy': 0.80556, 'precision': 0.81818, 'recall': 0.73469, 'f1': 0.77419, 'auc': 0.81563}\n",
      "test: {'epoch': 26, 'time_epoch': 0.79737, 'loss': 0.48241259, 'lr': 0, 'params': 135681, 'time_iter': 0.11391, 'accuracy': 0.81481, 'precision': 0.79592, 'recall': 0.79592, 'f1': 0.79592, 'auc': 0.90488}\n",
      "> Epoch 26: took 11.9s (avg 13.3s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 27, 'time_epoch': 10.22277, 'eta': 370.56349, 'eta_hours': 0.10293, 'loss': 0.12035753, 'lr': 0.00065451, 'params': 135681, 'time_iter': 0.18931, 'accuracy': 0.96984, 'precision': 0.97674, 'recall': 0.95696, 'f1': 0.96675, 'auc': 0.9881}\n",
      "val: {'epoch': 27, 'time_epoch': 0.79656, 'loss': 0.67393606, 'lr': 0, 'params': 135681, 'time_iter': 0.11379, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.81909}\n",
      "test: {'epoch': 27, 'time_epoch': 0.79761, 'loss': 0.40222855, 'lr': 0, 'params': 135681, 'time_iter': 0.11394, 'accuracy': 0.86111, 'precision': 0.86957, 'recall': 0.81633, 'f1': 0.84211, 'auc': 0.93532}\n",
      "> Epoch 27: took 11.8s (avg 13.2s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 28, 'time_epoch': 10.24358, 'eta': 357.55468, 'eta_hours': 0.09932, 'loss': 0.10992466, 'lr': 0.00062711, 'params': 135681, 'time_iter': 0.1897, 'accuracy': 0.97448, 'precision': 0.96509, 'recall': 0.97975, 'f1': 0.97236, 'auc': 0.9882}\n",
      "val: {'epoch': 28, 'time_epoch': 0.81144, 'loss': 0.7749915, 'lr': 0, 'params': 135681, 'time_iter': 0.11592, 'accuracy': 0.75, 'precision': 0.68966, 'recall': 0.81633, 'f1': 0.74766, 'auc': 0.83743}\n",
      "test: {'epoch': 28, 'time_epoch': 0.79869, 'loss': 0.61586567, 'lr': 0, 'params': 135681, 'time_iter': 0.1141, 'accuracy': 0.77778, 'precision': 0.67606, 'recall': 0.97959, 'f1': 0.8, 'auc': 0.9118}\n",
      "> Epoch 28: took 11.9s (avg 13.2s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 29, 'time_epoch': 21.81904, 'eta': 356.30568, 'eta_hours': 0.09897, 'loss': 0.10180924, 'lr': 0.0005993, 'params': 135681, 'time_iter': 0.40406, 'accuracy': 0.97796, 'precision': 0.96766, 'recall': 0.98481, 'f1': 0.97616, 'auc': 0.98879}\n",
      "val: {'epoch': 29, 'time_epoch': 0.8126, 'loss': 0.79566501, 'lr': 0, 'params': 135681, 'time_iter': 0.11609, 'accuracy': 0.75, 'precision': 0.69643, 'recall': 0.79592, 'f1': 0.74286, 'auc': 0.80785}\n",
      "test: {'epoch': 29, 'time_epoch': 0.80565, 'loss': 0.60142826, 'lr': 0, 'params': 135681, 'time_iter': 0.11509, 'accuracy': 0.78704, 'precision': 0.69697, 'recall': 0.93878, 'f1': 0.8, 'auc': 0.89865}\n",
      "> Epoch 29: took 23.5s (avg 13.5s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 30, 'time_epoch': 10.27262, 'eta': 342.92809, 'eta_hours': 0.09526, 'loss': 0.10118367, 'lr': 0.00057116, 'params': 135681, 'time_iter': 0.19023, 'accuracy': 0.98028, 'precision': 0.98711, 'recall': 0.96962, 'f1': 0.97829, 'auc': 0.98726}\n",
      "val: {'epoch': 30, 'time_epoch': 0.79848, 'loss': 0.75634182, 'lr': 0, 'params': 135681, 'time_iter': 0.11407, 'accuracy': 0.76852, 'precision': 0.73077, 'recall': 0.77551, 'f1': 0.75248, 'auc': 0.82878}\n",
      "test: {'epoch': 30, 'time_epoch': 0.7978, 'loss': 0.54604928, 'lr': 0, 'params': 135681, 'time_iter': 0.11397, 'accuracy': 0.83333, 'precision': 0.77193, 'recall': 0.89796, 'f1': 0.83019, 'auc': 0.89554}\n",
      "> Epoch 30: took 11.9s (avg 13.5s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 31, 'time_epoch': 21.8463, 'eta': 339.87153, 'eta_hours': 0.09441, 'loss': 0.09295, 'lr': 0.00054279, 'params': 135681, 'time_iter': 0.40456, 'accuracy': 0.98028, 'precision': 0.9725, 'recall': 0.98481, 'f1': 0.97862, 'auc': 0.98658}\n",
      "val: {'epoch': 31, 'time_epoch': 0.82296, 'loss': 0.8266339, 'lr': 0, 'params': 135681, 'time_iter': 0.11757, 'accuracy': 0.75, 'precision': 0.82353, 'recall': 0.57143, 'f1': 0.6747, 'auc': 0.79488}\n",
      "test: {'epoch': 31, 'time_epoch': 0.81173, 'loss': 0.91345706, 'lr': 0, 'params': 135681, 'time_iter': 0.11596, 'accuracy': 0.71296, 'precision': 0.875, 'recall': 0.42857, 'f1': 0.57534, 'auc': 0.85195}\n",
      "> Epoch 31: took 23.5s (avg 13.8s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 32, 'time_epoch': 33.53027, 'eta': 345.23581, 'eta_hours': 0.0959, 'loss': 0.10470078, 'lr': 0.00051428, 'params': 135681, 'time_iter': 0.62093, 'accuracy': 0.97564, 'precision': 0.97462, 'recall': 0.97215, 'f1': 0.97338, 'auc': 0.98956}\n",
      "val: {'epoch': 32, 'time_epoch': 0.80095, 'loss': 0.79070666, 'lr': 0, 'params': 135681, 'time_iter': 0.11442, 'accuracy': 0.75926, 'precision': 0.72549, 'recall': 0.7551, 'f1': 0.74, 'auc': 0.83881}\n",
      "test: {'epoch': 32, 'time_epoch': 0.80039, 'loss': 0.53876151, 'lr': 0, 'params': 135681, 'time_iter': 0.11434, 'accuracy': 0.81481, 'precision': 0.74576, 'recall': 0.89796, 'f1': 0.81481, 'auc': 0.89658}\n",
      "> Epoch 32: took 35.2s (avg 14.4s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 33, 'time_epoch': 10.25662, 'eta': 330.51467, 'eta_hours': 0.09181, 'loss': 0.06951708, 'lr': 0.00048572, 'params': 135681, 'time_iter': 0.18994, 'accuracy': 0.98724, 'precision': 0.98731, 'recall': 0.98481, 'f1': 0.98606, 'auc': 0.99118}\n",
      "val: {'epoch': 33, 'time_epoch': 0.81252, 'loss': 0.6758634, 'lr': 0, 'params': 135681, 'time_iter': 0.11607, 'accuracy': 0.7963, 'precision': 0.8, 'recall': 0.73469, 'f1': 0.76596, 'auc': 0.83639}\n",
      "test: {'epoch': 33, 'time_epoch': 0.79861, 'loss': 0.49783167, 'lr': 0, 'params': 135681, 'time_iter': 0.11409, 'accuracy': 0.83333, 'precision': 0.79245, 'recall': 0.85714, 'f1': 0.82353, 'auc': 0.92148}\n",
      "> Epoch 33: took 11.9s (avg 14.4s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 34, 'time_epoch': 10.20142, 'eta': 316.00922, 'eta_hours': 0.08778, 'loss': 0.08296893, 'lr': 0.00045721, 'params': 135681, 'time_iter': 0.18892, 'accuracy': 0.98028, 'precision': 0.97015, 'recall': 0.98734, 'f1': 0.97867, 'auc': 0.99438}\n",
      "val: {'epoch': 34, 'time_epoch': 0.7943, 'loss': 0.72930795, 'lr': 0, 'params': 135681, 'time_iter': 0.11347, 'accuracy': 0.78704, 'precision': 0.73214, 'recall': 0.83673, 'f1': 0.78095, 'auc': 0.84192}\n",
      "test: {'epoch': 34, 'time_epoch': 0.79815, 'loss': 0.60227171, 'lr': 0, 'params': 135681, 'time_iter': 0.11402, 'accuracy': 0.80556, 'precision': 0.70588, 'recall': 0.97959, 'f1': 0.82051, 'auc': 0.9118}\n",
      "> Epoch 34: took 11.8s (avg 14.3s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 35, 'time_epoch': 10.23344, 'eta': 301.76423, 'eta_hours': 0.08382, 'loss': 0.06348361, 'lr': 0.00042884, 'params': 135681, 'time_iter': 0.18951, 'accuracy': 0.98956, 'precision': 0.98737, 'recall': 0.98987, 'f1': 0.98862, 'auc': 0.99113}\n",
      "val: {'epoch': 35, 'time_epoch': 0.80594, 'loss': 0.6307592, 'lr': 0, 'params': 135681, 'time_iter': 0.11513, 'accuracy': 0.80556, 'precision': 0.85, 'recall': 0.69388, 'f1': 0.76404, 'auc': 0.82532}\n",
      "test: {'epoch': 35, 'time_epoch': 0.79218, 'loss': 0.55810133, 'lr': 0, 'params': 135681, 'time_iter': 0.11317, 'accuracy': 0.83333, 'precision': 0.84444, 'recall': 0.77551, 'f1': 0.80851, 'auc': 0.90522}\n",
      "> Epoch 35: took 11.9s (avg 14.2s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 36, 'time_epoch': 10.27042, 'eta': 287.75908, 'eta_hours': 0.07993, 'loss': 0.06875218, 'lr': 0.0004007, 'params': 135681, 'time_iter': 0.19019, 'accuracy': 0.98608, 'precision': 0.98481, 'recall': 0.98481, 'f1': 0.98481, 'auc': 0.98946}\n",
      "val: {'epoch': 36, 'time_epoch': 0.80295, 'loss': 0.81429968, 'lr': 0, 'params': 135681, 'time_iter': 0.11471, 'accuracy': 0.75926, 'precision': 0.71698, 'recall': 0.77551, 'f1': 0.7451, 'auc': 0.82567}\n",
      "test: {'epoch': 36, 'time_epoch': 0.80422, 'loss': 0.54005585, 'lr': 0, 'params': 135681, 'time_iter': 0.11489, 'accuracy': 0.82407, 'precision': 0.75862, 'recall': 0.89796, 'f1': 0.82243, 'auc': 0.91698}\n",
      "> Epoch 36: took 11.9s (avg 14.2s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 37, 'time_epoch': 10.26361, 'eta': 273.94654, 'eta_hours': 0.0761, 'loss': 0.05619769, 'lr': 0.00037289, 'params': 135681, 'time_iter': 0.19007, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.98901}\n",
      "val: {'epoch': 37, 'time_epoch': 0.81928, 'loss': 0.65833819, 'lr': 0, 'params': 135681, 'time_iter': 0.11704, 'accuracy': 0.81481, 'precision': 0.87179, 'recall': 0.69388, 'f1': 0.77273, 'auc': 0.82013}\n",
      "test: {'epoch': 37, 'time_epoch': 0.80101, 'loss': 0.57059877, 'lr': 0, 'params': 135681, 'time_iter': 0.11443, 'accuracy': 0.83333, 'precision': 0.86047, 'recall': 0.7551, 'f1': 0.80435, 'auc': 0.91058}\n",
      "> Epoch 37: took 11.9s (avg 14.1s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 38, 'time_epoch': 10.28929, 'eta': 260.32983, 'eta_hours': 0.07231, 'loss': 0.0832787, 'lr': 0.00034549, 'params': 135681, 'time_iter': 0.19054, 'accuracy': 0.9826, 'precision': 0.97739, 'recall': 0.98481, 'f1': 0.98108, 'auc': 0.98997}\n",
      "val: {'epoch': 38, 'time_epoch': 0.80663, 'loss': 0.85081842, 'lr': 0, 'params': 135681, 'time_iter': 0.11523, 'accuracy': 0.75926, 'precision': 0.71698, 'recall': 0.77551, 'f1': 0.7451, 'auc': 0.81546}\n",
      "test: {'epoch': 38, 'time_epoch': 0.80578, 'loss': 0.63815743, 'lr': 0, 'params': 135681, 'time_iter': 0.11511, 'accuracy': 0.80556, 'precision': 0.73333, 'recall': 0.89796, 'f1': 0.80734, 'auc': 0.90626}\n",
      "> Epoch 38: took 11.9s (avg 14.0s) | Best so far: epoch 19\ttrain_loss: 0.1497 train_accuracy: 0.9640\tval_loss: 0.5470 val_accuracy: 0.8148\ttest_loss: 0.5868 test_accuracy: 0.7685\n",
      "train: {'epoch': 39, 'time_epoch': 21.90107, 'eta': 252.68537, 'eta_hours': 0.07019, 'loss': 0.08236771, 'lr': 0.0003186, 'params': 135681, 'time_iter': 0.40558, 'accuracy': 0.98144, 'precision': 0.98465, 'recall': 0.97468, 'f1': 0.97964, 'auc': 0.99174}\n",
      "val: {'epoch': 39, 'time_epoch': 0.83141, 'loss': 0.66237242, 'lr': 0, 'params': 135681, 'time_iter': 0.11877, 'accuracy': 0.82407, 'precision': 0.89474, 'recall': 0.69388, 'f1': 0.78161, 'auc': 0.81633}\n",
      "test: {'epoch': 39, 'time_epoch': 0.79637, 'loss': 0.66425532, 'lr': 0, 'params': 135681, 'time_iter': 0.11377, 'accuracy': 0.81481, 'precision': 0.91429, 'recall': 0.65306, 'f1': 0.7619, 'auc': 0.87721}\n",
      "> Epoch 39: took 23.6s (avg 14.3s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 40, 'time_epoch': 10.29694, 'eta': 238.96795, 'eta_hours': 0.06638, 'loss': 0.05941012, 'lr': 0.00029229, 'params': 135681, 'time_iter': 0.19068, 'accuracy': 0.99072, 'precision': 0.99237, 'recall': 0.98734, 'f1': 0.98985, 'auc': 0.99039}\n",
      "val: {'epoch': 40, 'time_epoch': 0.81163, 'loss': 0.69245183, 'lr': 0, 'params': 135681, 'time_iter': 0.11595, 'accuracy': 0.80556, 'precision': 0.88889, 'recall': 0.65306, 'f1': 0.75294, 'auc': 0.8184}\n",
      "test: {'epoch': 40, 'time_epoch': 0.80079, 'loss': 0.75725977, 'lr': 0, 'params': 135681, 'time_iter': 0.1144, 'accuracy': 0.77778, 'precision': 0.85714, 'recall': 0.61224, 'f1': 0.71429, 'auc': 0.87997}\n",
      "> Epoch 40: took 11.9s (avg 14.2s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 41, 'time_epoch': 10.2502, 'eta': 225.39338, 'eta_hours': 0.06261, 'loss': 0.07865795, 'lr': 0.00026667, 'params': 135681, 'time_iter': 0.18982, 'accuracy': 0.9826, 'precision': 0.98223, 'recall': 0.97975, 'f1': 0.98099, 'auc': 0.98865}\n",
      "val: {'epoch': 41, 'time_epoch': 0.80964, 'loss': 0.71445177, 'lr': 0, 'params': 135681, 'time_iter': 0.11566, 'accuracy': 0.7963, 'precision': 0.77551, 'recall': 0.77551, 'f1': 0.77551, 'auc': 0.81719}\n",
      "test: {'epoch': 41, 'time_epoch': 0.80721, 'loss': 0.57999123, 'lr': 0, 'params': 135681, 'time_iter': 0.11532, 'accuracy': 0.81481, 'precision': 0.80851, 'recall': 0.77551, 'f1': 0.79167, 'auc': 0.89658}\n",
      "> Epoch 41: took 11.9s (avg 14.2s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 42, 'time_epoch': 33.47196, 'eta': 221.15412, 'eta_hours': 0.06143, 'loss': 0.09705788, 'lr': 0.0002418, 'params': 135681, 'time_iter': 0.61985, 'accuracy': 0.97796, 'precision': 0.97959, 'recall': 0.97215, 'f1': 0.97586, 'auc': 0.98842}\n",
      "val: {'epoch': 42, 'time_epoch': 0.80347, 'loss': 0.68859139, 'lr': 0, 'params': 135681, 'time_iter': 0.11478, 'accuracy': 0.80556, 'precision': 0.79167, 'recall': 0.77551, 'f1': 0.78351, 'auc': 0.8312}\n",
      "test: {'epoch': 42, 'time_epoch': 0.80431, 'loss': 0.62092672, 'lr': 0, 'params': 135681, 'time_iter': 0.1149, 'accuracy': 0.81481, 'precision': 0.80851, 'recall': 0.77551, 'f1': 0.79167, 'auc': 0.91318}\n",
      "> Epoch 42: took 35.1s (avg 14.6s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 43, 'time_epoch': 10.2481, 'eta': 207.14107, 'eta_hours': 0.05754, 'loss': 0.08398086, 'lr': 0.00021778, 'params': 135681, 'time_iter': 0.18978, 'accuracy': 0.98144, 'precision': 0.97257, 'recall': 0.98734, 'f1': 0.9799, 'auc': 0.99181}\n",
      "val: {'epoch': 43, 'time_epoch': 0.80575, 'loss': 0.75229014, 'lr': 0, 'params': 135681, 'time_iter': 0.11511, 'accuracy': 0.77778, 'precision': 0.73585, 'recall': 0.79592, 'f1': 0.76471, 'auc': 0.81581}\n",
      "test: {'epoch': 43, 'time_epoch': 0.80296, 'loss': 0.50914565, 'lr': 0, 'params': 135681, 'time_iter': 0.11471, 'accuracy': 0.84259, 'precision': 0.77586, 'recall': 0.91837, 'f1': 0.84112, 'auc': 0.90419}\n",
      "> Epoch 43: took 11.9s (avg 14.6s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 44, 'time_epoch': 10.21953, 'eta': 193.28582, 'eta_hours': 0.05369, 'loss': 0.05662619, 'lr': 0.00019468, 'params': 135681, 'time_iter': 0.18925, 'accuracy': 0.99188, 'precision': 0.99239, 'recall': 0.98987, 'f1': 0.99113, 'auc': 0.98949}\n",
      "val: {'epoch': 44, 'time_epoch': 0.79903, 'loss': 0.67350284, 'lr': 0, 'params': 135681, 'time_iter': 0.11415, 'accuracy': 0.81481, 'precision': 0.85366, 'recall': 0.71429, 'f1': 0.77778, 'auc': 0.81806}\n",
      "test: {'epoch': 44, 'time_epoch': 0.80212, 'loss': 0.66426733, 'lr': 0, 'params': 135681, 'time_iter': 0.11459, 'accuracy': 0.80556, 'precision': 0.86842, 'recall': 0.67347, 'f1': 0.75862, 'auc': 0.91491}\n",
      "> Epoch 44: took 11.8s (avg 14.5s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 45, 'time_epoch': 10.23371, 'eta': 179.59297, 'eta_hours': 0.04989, 'loss': 0.05741346, 'lr': 0.00017257, 'params': 135681, 'time_iter': 0.18951, 'accuracy': 0.99072, 'precision': 0.99237, 'recall': 0.98734, 'f1': 0.98985, 'auc': 0.99258}\n",
      "val: {'epoch': 45, 'time_epoch': 0.8067, 'loss': 0.72135927, 'lr': 0, 'params': 135681, 'time_iter': 0.11524, 'accuracy': 0.80556, 'precision': 0.78, 'recall': 0.79592, 'f1': 0.78788, 'auc': 0.82497}\n",
      "test: {'epoch': 45, 'time_epoch': 0.80593, 'loss': 0.48542833, 'lr': 0, 'params': 135681, 'time_iter': 0.11513, 'accuracy': 0.85185, 'precision': 0.8, 'recall': 0.89796, 'f1': 0.84615, 'auc': 0.91041}\n",
      "> Epoch 45: took 11.9s (avg 14.5s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 46, 'time_epoch': 21.95039, 'eta': 169.28809, 'eta_hours': 0.04702, 'loss': 0.08544856, 'lr': 0.00015153, 'params': 135681, 'time_iter': 0.40649, 'accuracy': 0.98028, 'precision': 0.97727, 'recall': 0.97975, 'f1': 0.97851, 'auc': 0.99153}\n",
      "val: {'epoch': 46, 'time_epoch': 0.82027, 'loss': 0.68402061, 'lr': 0, 'params': 135681, 'time_iter': 0.11718, 'accuracy': 0.81481, 'precision': 0.83721, 'recall': 0.73469, 'f1': 0.78261, 'auc': 0.8184}\n",
      "test: {'epoch': 46, 'time_epoch': 0.80089, 'loss': 0.62855762, 'lr': 0, 'params': 135681, 'time_iter': 0.11441, 'accuracy': 0.81481, 'precision': 0.83721, 'recall': 0.73469, 'f1': 0.78261, 'auc': 0.90868}\n",
      "> Epoch 46: took 23.6s (avg 14.7s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 47, 'time_epoch': 10.27247, 'eta': 155.57851, 'eta_hours': 0.04322, 'loss': 0.05153861, 'lr': 0.00013163, 'params': 135681, 'time_iter': 0.19023, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99111}\n",
      "val: {'epoch': 47, 'time_epoch': 0.8059, 'loss': 0.74595966, 'lr': 0, 'params': 135681, 'time_iter': 0.11513, 'accuracy': 0.7963, 'precision': 0.77551, 'recall': 0.77551, 'f1': 0.77551, 'auc': 0.82705}\n",
      "test: {'epoch': 47, 'time_epoch': 0.80275, 'loss': 0.57754388, 'lr': 0, 'params': 135681, 'time_iter': 0.11468, 'accuracy': 0.83333, 'precision': 0.81633, 'recall': 0.81633, 'f1': 0.81633, 'auc': 0.89952}\n",
      "> Epoch 47: took 11.9s (avg 14.6s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 48, 'time_epoch': 10.26007, 'eta': 142.00643, 'eta_hours': 0.03945, 'loss': 0.07040253, 'lr': 0.00011293, 'params': 135681, 'time_iter': 0.19, 'accuracy': 0.98492, 'precision': 0.98724, 'recall': 0.97975, 'f1': 0.98348, 'auc': 0.99027}\n",
      "val: {'epoch': 48, 'time_epoch': 0.80688, 'loss': 0.66234429, 'lr': 0, 'params': 135681, 'time_iter': 0.11527, 'accuracy': 0.82407, 'precision': 0.85714, 'recall': 0.73469, 'f1': 0.79121, 'auc': 0.82048}\n",
      "test: {'epoch': 48, 'time_epoch': 0.80228, 'loss': 0.65524789, 'lr': 0, 'params': 135681, 'time_iter': 0.11461, 'accuracy': 0.78704, 'precision': 0.79545, 'recall': 0.71429, 'f1': 0.75269, 'auc': 0.91007}\n",
      "> Epoch 48: took 11.9s (avg 14.5s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 49, 'time_epoch': 21.84223, 'eta': 130.88327, 'eta_hours': 0.03636, 'loss': 0.06071039, 'lr': 9.549e-05, 'params': 135681, 'time_iter': 0.40449, 'accuracy': 0.98956, 'precision': 0.98985, 'recall': 0.98734, 'f1': 0.98859, 'auc': 0.99254}\n",
      "val: {'epoch': 49, 'time_epoch': 0.81393, 'loss': 0.73106248, 'lr': 0, 'params': 135681, 'time_iter': 0.11628, 'accuracy': 0.78704, 'precision': 0.76, 'recall': 0.77551, 'f1': 0.76768, 'auc': 0.83155}\n",
      "test: {'epoch': 49, 'time_epoch': 0.80319, 'loss': 0.61063165, 'lr': 0, 'params': 135681, 'time_iter': 0.11474, 'accuracy': 0.82407, 'precision': 0.8, 'recall': 0.81633, 'f1': 0.80808, 'auc': 0.90384}\n",
      "> Epoch 49: took 23.5s (avg 14.7s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 50, 'time_epoch': 10.23678, 'eta': 117.29173, 'eta_hours': 0.03258, 'loss': 0.05344115, 'lr': 7.937e-05, 'params': 135681, 'time_iter': 0.18957, 'accuracy': 0.99072, 'precision': 0.98987, 'recall': 0.98987, 'f1': 0.98987, 'auc': 0.99244}\n",
      "val: {'epoch': 50, 'time_epoch': 0.79021, 'loss': 0.69994676, 'lr': 0, 'params': 135681, 'time_iter': 0.11289, 'accuracy': 0.80556, 'precision': 0.79167, 'recall': 0.77551, 'f1': 0.78351, 'auc': 0.82705}\n",
      "test: {'epoch': 50, 'time_epoch': 0.79724, 'loss': 0.62053171, 'lr': 0, 'params': 135681, 'time_iter': 0.11389, 'accuracy': 0.83333, 'precision': 0.81633, 'recall': 0.81633, 'f1': 0.81633, 'auc': 0.90522}\n",
      "> Epoch 50: took 11.8s (avg 14.7s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 51, 'time_epoch': 10.23023, 'eta': 103.82821, 'eta_hours': 0.02884, 'loss': 0.05624148, 'lr': 6.463e-05, 'params': 135681, 'time_iter': 0.18945, 'accuracy': 0.98956, 'precision': 0.99235, 'recall': 0.98481, 'f1': 0.98856, 'auc': 0.99191}\n",
      "val: {'epoch': 51, 'time_epoch': 0.80153, 'loss': 0.698464, 'lr': 0, 'params': 135681, 'time_iter': 0.1145, 'accuracy': 0.80556, 'precision': 0.79167, 'recall': 0.77551, 'f1': 0.78351, 'auc': 0.82048}\n",
      "test: {'epoch': 51, 'time_epoch': 0.80264, 'loss': 0.64088138, 'lr': 0, 'params': 135681, 'time_iter': 0.11466, 'accuracy': 0.81481, 'precision': 0.79592, 'recall': 0.79592, 'f1': 0.79592, 'auc': 0.90695}\n",
      "> Epoch 51: took 11.9s (avg 14.6s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 52, 'time_epoch': 10.27103, 'eta': 90.49209, 'eta_hours': 0.02514, 'loss': 0.06250329, 'lr': 5.13e-05, 'params': 135681, 'time_iter': 0.1902, 'accuracy': 0.9884, 'precision': 0.98734, 'recall': 0.98734, 'f1': 0.98734, 'auc': 0.99116}\n",
      "val: {'epoch': 52, 'time_epoch': 0.80359, 'loss': 0.64610776, 'lr': 0, 'params': 135681, 'time_iter': 0.1148, 'accuracy': 0.82407, 'precision': 0.84091, 'recall': 0.7551, 'f1': 0.7957, 'auc': 0.80595}\n",
      "test: {'epoch': 52, 'time_epoch': 0.81579, 'loss': 0.63086505, 'lr': 0, 'params': 135681, 'time_iter': 0.11654, 'accuracy': 0.81481, 'precision': 0.82222, 'recall': 0.7551, 'f1': 0.78723, 'auc': 0.91456}\n",
      "> Epoch 52: took 11.9s (avg 14.6s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 53, 'time_epoch': 10.24609, 'eta': 77.26672, 'eta_hours': 0.02146, 'loss': 0.06058281, 'lr': 3.944e-05, 'params': 135681, 'time_iter': 0.18974, 'accuracy': 0.9884, 'precision': 0.98982, 'recall': 0.98481, 'f1': 0.98731, 'auc': 0.99217}\n",
      "val: {'epoch': 53, 'time_epoch': 0.8004, 'loss': 0.71451703, 'lr': 0, 'params': 135681, 'time_iter': 0.11434, 'accuracy': 0.7963, 'precision': 0.77551, 'recall': 0.77551, 'f1': 0.77551, 'auc': 0.82255}\n",
      "test: {'epoch': 53, 'time_epoch': 0.79918, 'loss': 0.6184255, 'lr': 0, 'params': 135681, 'time_iter': 0.11417, 'accuracy': 0.81481, 'precision': 0.79592, 'recall': 0.79592, 'f1': 0.79592, 'auc': 0.90764}\n",
      "> Epoch 53: took 11.9s (avg 14.5s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 54, 'time_epoch': 10.27011, 'eta': 64.15187, 'eta_hours': 0.01782, 'loss': 0.05078109, 'lr': 2.908e-05, 'params': 135681, 'time_iter': 0.19019, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99247}\n",
      "val: {'epoch': 54, 'time_epoch': 0.80149, 'loss': 0.65781453, 'lr': 0, 'params': 135681, 'time_iter': 0.1145, 'accuracy': 0.81481, 'precision': 0.80851, 'recall': 0.77551, 'f1': 0.79167, 'auc': 0.81287}\n",
      "test: {'epoch': 54, 'time_epoch': 0.80032, 'loss': 0.62562087, 'lr': 0, 'params': 135681, 'time_iter': 0.11433, 'accuracy': 0.81481, 'precision': 0.80851, 'recall': 0.77551, 'f1': 0.79167, 'auc': 0.91283}\n",
      "> Epoch 54: took 11.9s (avg 14.5s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 55, 'time_epoch': 10.3256, 'eta': 51.14258, 'eta_hours': 0.01421, 'loss': 0.05086689, 'lr': 2.025e-05, 'params': 135681, 'time_iter': 0.19121, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99115}\n",
      "val: {'epoch': 55, 'time_epoch': 0.80487, 'loss': 0.68589602, 'lr': 0, 'params': 135681, 'time_iter': 0.11498, 'accuracy': 0.80556, 'precision': 0.79167, 'recall': 0.77551, 'f1': 0.78351, 'auc': 0.81356}\n",
      "test: {'epoch': 55, 'time_epoch': 0.82246, 'loss': 0.62819724, 'lr': 0, 'params': 135681, 'time_iter': 0.11749, 'accuracy': 0.82407, 'precision': 0.8125, 'recall': 0.79592, 'f1': 0.80412, 'auc': 0.91145}\n",
      "> Epoch 55: took 12.0s (avg 14.4s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 56, 'time_epoch': 10.3363, 'eta': 38.22803, 'eta_hours': 0.01062, 'loss': 0.05631819, 'lr': 1.299e-05, 'params': 135681, 'time_iter': 0.19141, 'accuracy': 0.99072, 'precision': 0.99237, 'recall': 0.98734, 'f1': 0.98985, 'auc': 0.99322}\n",
      "val: {'epoch': 56, 'time_epoch': 0.80492, 'loss': 0.6769015, 'lr': 0, 'params': 135681, 'time_iter': 0.11499, 'accuracy': 0.81481, 'precision': 0.80851, 'recall': 0.77551, 'f1': 0.79167, 'auc': 0.81702}\n",
      "test: {'epoch': 56, 'time_epoch': 0.81394, 'loss': 0.6289195, 'lr': 0, 'params': 135681, 'time_iter': 0.11628, 'accuracy': 0.82407, 'precision': 0.8125, 'recall': 0.79592, 'f1': 0.80412, 'auc': 0.91128}\n",
      "> Epoch 56: took 12.0s (avg 14.4s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 57, 'time_epoch': 21.861, 'eta': 25.79978, 'eta_hours': 0.00717, 'loss': 0.05074296, 'lr': 7.32e-06, 'params': 135681, 'time_iter': 0.40483, 'accuracy': 0.99304, 'precision': 0.99241, 'recall': 0.99241, 'f1': 0.99241, 'auc': 0.99374}\n",
      "val: {'epoch': 57, 'time_epoch': 0.80429, 'loss': 0.69252796, 'lr': 0, 'params': 135681, 'time_iter': 0.1149, 'accuracy': 0.80556, 'precision': 0.79167, 'recall': 0.77551, 'f1': 0.78351, 'auc': 0.81736}\n",
      "test: {'epoch': 57, 'time_epoch': 0.80164, 'loss': 0.62742574, 'lr': 0, 'params': 135681, 'time_iter': 0.11452, 'accuracy': 0.81481, 'precision': 0.80851, 'recall': 0.77551, 'f1': 0.79167, 'auc': 0.90937}\n",
      "> Epoch 57: took 23.5s (avg 14.5s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 58, 'time_epoch': 33.4373, 'eta': 13.24798, 'eta_hours': 0.00368, 'loss': 0.05800267, 'lr': 3.26e-06, 'params': 135681, 'time_iter': 0.61921, 'accuracy': 0.99072, 'precision': 0.98741, 'recall': 0.99241, 'f1': 0.9899, 'auc': 0.99352}\n",
      "val: {'epoch': 58, 'time_epoch': 0.80977, 'loss': 0.65251068, 'lr': 0, 'params': 135681, 'time_iter': 0.11568, 'accuracy': 0.82407, 'precision': 0.82609, 'recall': 0.77551, 'f1': 0.8, 'auc': 0.81563}\n",
      "test: {'epoch': 58, 'time_epoch': 0.80625, 'loss': 0.63819643, 'lr': 0, 'params': 135681, 'time_iter': 0.11518, 'accuracy': 0.81481, 'precision': 0.80851, 'recall': 0.77551, 'f1': 0.79167, 'auc': 0.91249}\n",
      "> Epoch 58: took 35.1s (avg 14.9s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "train: {'epoch': 59, 'time_epoch': 10.2601, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.05540402, 'lr': 8.2e-07, 'params': 135681, 'time_iter': 0.19, 'accuracy': 0.99072, 'precision': 0.99237, 'recall': 0.98734, 'f1': 0.98985, 'auc': 0.9931}\n",
      "val: {'epoch': 59, 'time_epoch': 0.80942, 'loss': 0.65206981, 'lr': 0, 'params': 135681, 'time_iter': 0.11563, 'accuracy': 0.80556, 'precision': 0.80435, 'recall': 0.7551, 'f1': 0.77895, 'auc': 0.81356}\n",
      "test: {'epoch': 59, 'time_epoch': 0.80162, 'loss': 0.63314278, 'lr': 0, 'params': 135681, 'time_iter': 0.11452, 'accuracy': 0.81481, 'precision': 0.82222, 'recall': 0.7551, 'f1': 0.78723, 'auc': 0.91041}\n",
      "> Epoch 59: took 11.9s (avg 14.8s) | Best so far: epoch 39\ttrain_loss: 0.0824 train_accuracy: 0.9814\tval_loss: 0.6624 val_accuracy: 0.8241\ttest_loss: 0.6643 test_accuracy: 0.8148\n",
      "Avg time per epoch: 14.84s\n",
      "Total train loop time: 0.25h\n",
      "Task done, results saved in results\\neural-Gender\\0\n",
      "39\n",
      "{'epoch': 39, 'time_epoch': 0.79637, 'loss': 0.66425532, 'lr': 0, 'params': 135681, 'time_iter': 0.11377, 'accuracy': 0.81481, 'precision': 0.91429, 'recall': 0.65306, 'f1': 0.7619, 'auc': 0.87721}\n",
      "{'epoch': 39, 'time_epoch': 21.90107, 'eta': 252.68537, 'eta_hours': 0.07019, 'loss': 0.08236771, 'lr': 0.0003186, 'params': 135681, 'time_iter': 0.40558, 'accuracy': 0.98144, 'precision': 0.98465, 'recall': 0.97468, 'f1': 0.97964, 'auc': 0.99174}\n",
      "{'epoch': 39, 'time_epoch': 0.83141, 'loss': 0.66237242, 'lr': 0, 'params': 135681, 'time_iter': 0.11877, 'accuracy': 0.82407, 'precision': 0.89474, 'recall': 0.69388, 'f1': 0.78161, 'auc': 0.81633}\n",
      "Results aggregated across runs saved in results\\neural-Gender\\agg\n",
      "[*] All done: 2024-03-02 12:37:43.732793\n"
     ]
    }
   ],
   "source": [
    "#Gender - Using Exphormer with 2 layers 0.1 drop 0.5 att drop\n",
    "%run main.py --cfg configs/Exphormer/neural-Gender.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd21411-31b6-4002-8609-2826ccfaec65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-02 13:05:28.225071\n",
      "[*] Loaded dataset 'HCPGender' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1078000, 1000], edge_index=[2, 49133748], y=[1078])\n",
      "  undirected: True\n",
      "  num graphs: 1078\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 2\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [02:01<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:02:04.40\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [01:21<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:23.20\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPGender\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.3\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: CustomGatedGCN+Exphormer\n",
      "  layers: 2\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 60\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Gender\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Gender\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 2\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 178435\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 820.33211, 'eta': 48399.5942, 'eta_hours': 13.44433, 'loss': 0.699708, 'lr': 0.0, 'params': 178435, 'time_iter': 15.19134, 'accuracy': 0.4652, 'precision': 0.46043, 'recall': 0.97215, 'f1': 0.6249, 'auc': 0.51775}\n",
      "...computing epoch stats took: 0.10s\n",
      "val: {'epoch': 0, 'time_epoch': 43.6054, 'loss': 0.69825561, 'lr': 0, 'params': 178435, 'time_iter': 6.22934, 'accuracy': 0.47222, 'precision': 0.46078, 'recall': 0.95918, 'f1': 0.62252, 'auc': 0.47907}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 0, 'time_epoch': 33.88554, 'loss': 0.69483298, 'lr': 0, 'params': 178435, 'time_iter': 4.84079, 'accuracy': 0.50926, 'precision': 0.47959, 'recall': 0.95918, 'f1': 0.63946, 'auc': 0.57558}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 0: took 897.9s (avg 897.9s) | Best so far: epoch 0\ttrain_loss: 0.6997 train_accuracy: 0.4652\tval_loss: 0.6983 val_accuracy: 0.4722\ttest_loss: 0.6948 test_accuracy: 0.5093\n",
      "train: {'epoch': 1, 'time_epoch': 876.25569, 'eta': 49201.04612, 'eta_hours': 13.66696, 'loss': 0.67290682, 'lr': 0.0002, 'params': 178435, 'time_iter': 16.22696, 'accuracy': 0.60441, 'precision': 0.56, 'recall': 0.63797, 'f1': 0.59645, 'auc': 0.65971}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 1, 'time_epoch': 43.57031, 'loss': 0.66267391, 'lr': 0, 'params': 178435, 'time_iter': 6.22433, 'accuracy': 0.64815, 'precision': 0.62791, 'recall': 0.55102, 'f1': 0.58696, 'auc': 0.72086}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 33.86352, 'loss': 0.65089397, 'lr': 0, 'params': 178435, 'time_iter': 4.83765, 'accuracy': 0.72222, 'precision': 0.71111, 'recall': 0.65306, 'f1': 0.68085, 'auc': 0.76894}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 953.7s (avg 925.8s) | Best so far: epoch 1\ttrain_loss: 0.6729 train_accuracy: 0.6044\tval_loss: 0.6627 val_accuracy: 0.6482\ttest_loss: 0.6509 test_accuracy: 0.7222\n",
      "train: {'epoch': 2, 'time_epoch': 871.74203, 'eta': 48798.26677, 'eta_hours': 13.55507, 'loss': 0.62642444, 'lr': 0.0004, 'params': 178435, 'time_iter': 16.14337, 'accuracy': 0.74014, 'precision': 0.71429, 'recall': 0.72152, 'f1': 0.71788, 'auc': 0.81321}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 43.55962, 'loss': 0.59599504, 'lr': 0, 'params': 178435, 'time_iter': 6.2228, 'accuracy': 0.83333, 'precision': 0.82979, 'recall': 0.79592, 'f1': 0.8125, 'auc': 0.88447}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 33.86994, 'loss': 0.59441476, 'lr': 0, 'params': 178435, 'time_iter': 4.83856, 'accuracy': 0.81481, 'precision': 0.80851, 'recall': 0.77551, 'f1': 0.79167, 'auc': 0.8945}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 949.2s (avg 933.6s) | Best so far: epoch 2\ttrain_loss: 0.6264 train_accuracy: 0.7401\tval_loss: 0.5960 val_accuracy: 0.8333\ttest_loss: 0.5944 test_accuracy: 0.8148\n",
      "train: {'epoch': 3, 'time_epoch': 913.49034, 'eta': 48745.48242, 'eta_hours': 13.54041, 'loss': 0.56364056, 'lr': 0.0006, 'params': 178435, 'time_iter': 16.91649, 'accuracy': 0.81555, 'precision': 0.79208, 'recall': 0.81013, 'f1': 0.801, 'auc': 0.87939}\n",
      "val: {'epoch': 3, 'time_epoch': 43.559, 'loss': 0.69682928, 'lr': 0, 'params': 178435, 'time_iter': 6.22271, 'accuracy': 0.5463, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.78208}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: {'epoch': 3, 'time_epoch': 33.86534, 'loss': 0.70188952, 'lr': 0, 'params': 178435, 'time_iter': 4.83791, 'accuracy': 0.5463, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.77793}\n",
      "> Epoch 3: took 990.9s (avg 948.0s) | Best so far: epoch 2\ttrain_loss: 0.6264 train_accuracy: 0.7401\tval_loss: 0.5960 val_accuracy: 0.8333\ttest_loss: 0.5944 test_accuracy: 0.8148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'epoch': 4, 'time_epoch': 885.05841, 'eta': 48035.66438, 'eta_hours': 13.34324, 'loss': 0.51249624, 'lr': 0.0008, 'params': 178435, 'time_iter': 16.38997, 'accuracy': 0.84687, 'precision': 0.83979, 'recall': 0.82278, 'f1': 0.8312, 'auc': 0.90021}\n",
      "val: {'epoch': 4, 'time_epoch': 43.53682, 'loss': 0.63365412, 'lr': 0, 'params': 178435, 'time_iter': 6.21955, 'accuracy': 0.62037, 'precision': 0.83333, 'recall': 0.20408, 'f1': 0.32787, 'auc': 0.88516}\n",
      "test: {'epoch': 4, 'time_epoch': 33.8565, 'loss': 0.64534994, 'lr': 0, 'params': 178435, 'time_iter': 4.83664, 'accuracy': 0.62037, 'precision': 0.9, 'recall': 0.18367, 'f1': 0.30508, 'auc': 0.91076}\n",
      "> Epoch 4: took 962.5s (avg 950.9s) | Best so far: epoch 2\ttrain_loss: 0.6264 train_accuracy: 0.7401\tval_loss: 0.5960 val_accuracy: 0.8333\ttest_loss: 0.5944 test_accuracy: 0.8148\n",
      "train: {'epoch': 5, 'time_epoch': 820.38234, 'eta': 46685.34831, 'eta_hours': 12.96815, 'loss': 0.4686815, 'lr': 0.001, 'params': 178435, 'time_iter': 15.19227, 'accuracy': 0.85499, 'precision': 0.84615, 'recall': 0.83544, 'f1': 0.84076, 'auc': 0.90421}\n",
      "val: {'epoch': 5, 'time_epoch': 43.55315, 'loss': 0.55545259, 'lr': 0, 'params': 178435, 'time_iter': 6.22188, 'accuracy': 0.75, 'precision': 0.86667, 'recall': 0.53061, 'f1': 0.65823, 'auc': 0.84365}\n",
      "test: {'epoch': 5, 'time_epoch': 33.85547, 'loss': 0.53771384, 'lr': 0, 'params': 178435, 'time_iter': 4.8365, 'accuracy': 0.78704, 'precision': 0.90625, 'recall': 0.59184, 'f1': 0.71605, 'auc': 0.89035}\n",
      "> Epoch 5: took 897.8s (avg 942.0s) | Best so far: epoch 2\ttrain_loss: 0.6264 train_accuracy: 0.7401\tval_loss: 0.5960 val_accuracy: 0.8333\ttest_loss: 0.5944 test_accuracy: 0.8148\n"
     ]
    }
   ],
   "source": [
    "#Gender - Using CustomGatedGCN+Exphormer with 2 layers 0.1 drop 0.3 att drop\n",
    "%run main.py --cfg configs/Exphormer/neural-Gender.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93529261-1cb9-4e98-9fee-22ed2e475e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07ee6e-f166-4be1-8186-a03219e03f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337a9aa-aa88-4304-8629-a60c8cd80808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28906f9-33b7-4ccc-a72f-92885f90fa18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cd929f4-35fc-42b9-90dc-2436bb3a2ef7",
   "metadata": {},
   "source": [
    "## Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cceee1-cacf-4d34-a81b-2c668fbde124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-27 10:02:02.311586\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 7\n",
      "Parsed RWSE PE kernel times / steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "Precomputing Positional Encoding statistics: ['RWSE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [03:46<00:00, 32.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:03:49.71\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): GPSModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): RWSENodeEncoder(\n",
      "        (linear_x): Linear(in_features=400, out_features=48, bias=True)\n",
      "        (raw_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (pe_encoder): Linear(in_features=16, out_features=16, bias=True)\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (1): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (2): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (3): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (4): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (5): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (6): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (7): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (8): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (9): GPSLayer(\n",
      "        summary: dim_h=64, local_gnn_type=CustomGatedGCN, global_model_type=Transformer, heads=4\n",
      "        (local_model): GatedGCNLayer()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout_local): Dropout(p=0.0, inplace=False)\n",
      "        (dropout_attn): Dropout(p=0.0, inplace=False)\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "            (Layer_1): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: RWSE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_edge: 64\n",
      "  dim_inner: 64\n",
      "  dropout: 0.0\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 3\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.5\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: None\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.0\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: CustomGatedGCN+Transformer\n",
      "  layers: 10\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: GPSModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 35\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act-GPS+RWSE\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: True\n",
      "  kernel:\n",
      "    times: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "    times_func: range(1,17)\n",
      "  layers: 3\n",
      "  model: Linear\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: BatchNorm\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: False\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 0\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act-GPS+RWSE\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 575015\n",
      "Start from epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'epoch': 0, 'time_epoch': 71.02125, 'eta': 2414.72239, 'eta_hours': 0.67076, 'loss': 1.94689568, 'lr': 0.0, 'params': 575015, 'time_iter': 0.19041, 'accuracy': 0.14965, 'f1': 0.0721, 'auc': 0.51635}\n",
      "...computing epoch stats took: 0.16s\n",
      "val: {'epoch': 0, 'time_epoch': 4.11041, 'loss': 1.94562352, 'lr': 0, 'params': 575015, 'time_iter': 0.08746, 'accuracy': 0.15188, 'f1': 0.07822, 'auc': 0.52817}\n",
      "...computing epoch stats took: 0.07s\n",
      "test: {'epoch': 0, 'time_epoch': 4.07675, 'loss': 1.94980761, 'lr': 0, 'params': 575015, 'time_iter': 0.08674, 'accuracy': 0.13826, 'f1': 0.06842, 'auc': 0.51239}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 79.5s (avg 79.5s) | Best so far: epoch 0\ttrain_loss: 1.9469 train_accuracy: 0.1497\tval_loss: 1.9456 val_accuracy: 0.1519\ttest_loss: 1.9498 test_accuracy: 0.1383\n",
      "train: {'epoch': 1, 'time_epoch': 70.32917, 'eta': 2332.28195, 'eta_hours': 0.64786, 'loss': 1.71839829, 'lr': 0.0002, 'params': 575015, 'time_iter': 0.18855, 'accuracy': 0.58263, 'f1': 0.57252, 'auc': 0.89224}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 1, 'time_epoch': 4.76587, 'loss': 1.51732183, 'lr': 0, 'params': 575015, 'time_iter': 0.1014, 'accuracy': 0.81989, 'f1': 0.82168, 'auc': 0.96454}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 3.84133, 'loss': 1.51839718, 'lr': 0, 'params': 575015, 'time_iter': 0.08173, 'accuracy': 0.79463, 'f1': 0.7825, 'auc': 0.96961}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 1: took 79.0s (avg 79.3s) | Best so far: epoch 1\ttrain_loss: 1.7184 train_accuracy: 0.5826\tval_loss: 1.5173 val_accuracy: 0.8199\ttest_loss: 1.5184 test_accuracy: 0.7946\n",
      "train: {'epoch': 2, 'time_epoch': 72.25046, 'eta': 2278.40942, 'eta_hours': 0.63289, 'loss': 1.29274287, 'lr': 0.0004, 'params': 575015, 'time_iter': 0.1937, 'accuracy': 0.86194, 'f1': 0.86109, 'auc': 0.97073}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 2, 'time_epoch': 4.0492, 'loss': 1.11537664, 'lr': 0, 'params': 575015, 'time_iter': 0.08615, 'accuracy': 0.88172, 'f1': 0.88232, 'auc': 0.97611}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 2, 'time_epoch': 4.58555, 'loss': 1.10977914, 'lr': 0, 'params': 575015, 'time_iter': 0.09756, 'accuracy': 0.88188, 'f1': 0.8776, 'auc': 0.97655}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 2: took 81.0s (avg 79.8s) | Best so far: epoch 2\ttrain_loss: 1.2927 train_accuracy: 0.8619\tval_loss: 1.1154 val_accuracy: 0.8817\ttest_loss: 1.1098 test_accuracy: 0.8819\n",
      "train: {'epoch': 3, 'time_epoch': 68.73564, 'eta': 2188.10804, 'eta_hours': 0.60781, 'loss': 0.90925493, 'lr': 0.0006, 'params': 575015, 'time_iter': 0.18428, 'accuracy': 0.89973, 'f1': 0.89908, 'auc': 0.98042}\n",
      "val: {'epoch': 3, 'time_epoch': 3.75744, 'loss': 0.83740294, 'lr': 0, 'params': 575015, 'time_iter': 0.07995, 'accuracy': 0.85349, 'f1': 0.85188, 'auc': 0.9702}\n",
      "test: {'epoch': 3, 'time_epoch': 5.00566, 'loss': 0.84620029, 'lr': 0, 'params': 575015, 'time_iter': 0.1065, 'accuracy': 0.85369, 'f1': 0.8489, 'auc': 0.97067}\n",
      "> Epoch 3: took 77.6s (avg 79.3s) | Best so far: epoch 2\ttrain_loss: 1.2927 train_accuracy: 0.8619\tval_loss: 1.1154 val_accuracy: 0.8817\ttest_loss: 1.1098 test_accuracy: 0.8819\n",
      "train: {'epoch': 4, 'time_epoch': 74.61187, 'eta': 2141.69035, 'eta_hours': 0.59491, 'loss': 0.63859719, 'lr': 0.0008, 'params': 575015, 'time_iter': 0.20003, 'accuracy': 0.90863, 'f1': 0.90837, 'auc': 0.98032}\n",
      "val: {'epoch': 4, 'time_epoch': 4.99561, 'loss': 0.56547139, 'lr': 0, 'params': 575015, 'time_iter': 0.10629, 'accuracy': 0.90054, 'f1': 0.90313, 'auc': 0.98688}\n",
      "test: {'epoch': 4, 'time_epoch': 3.92734, 'loss': 0.59204425, 'lr': 0, 'params': 575015, 'time_iter': 0.08356, 'accuracy': 0.88993, 'f1': 0.89224, 'auc': 0.98499}\n",
      "> Epoch 4: took 83.7s (avg 80.1s) | Best so far: epoch 4\ttrain_loss: 0.6386 train_accuracy: 0.9086\tval_loss: 0.5655 val_accuracy: 0.9005\ttest_loss: 0.5920 test_accuracy: 0.8899\n",
      "train: {'epoch': 5, 'time_epoch': 68.20661, 'eta': 2054.91582, 'eta_hours': 0.57081, 'loss': 0.48182566, 'lr': 0.001, 'params': 575015, 'time_iter': 0.18286, 'accuracy': 0.91065, 'f1': 0.9103, 'auc': 0.9831}\n",
      "val: {'epoch': 5, 'time_epoch': 3.95243, 'loss': 0.43388603, 'lr': 0, 'params': 575015, 'time_iter': 0.08409, 'accuracy': 0.90323, 'f1': 0.90575, 'auc': 0.98919}\n",
      "test: {'epoch': 5, 'time_epoch': 3.82587, 'loss': 0.37869201, 'lr': 0, 'params': 575015, 'time_iter': 0.0814, 'accuracy': 0.92752, 'f1': 0.92615, 'auc': 0.99316}\n",
      "> Epoch 5: took 76.1s (avg 79.5s) | Best so far: epoch 5\ttrain_loss: 0.4818 train_accuracy: 0.9106\tval_loss: 0.4339 val_accuracy: 0.9032\ttest_loss: 0.3787 test_accuracy: 0.9275\n",
      "train: {'epoch': 6, 'time_epoch': 74.18556, 'eta': 1997.36223, 'eta_hours': 0.55482, 'loss': 0.34947845, 'lr': 0.00099726, 'params': 575015, 'time_iter': 0.19889, 'accuracy': 0.93147, 'f1': 0.93132, 'auc': 0.98826}\n",
      "val: {'epoch': 6, 'time_epoch': 4.80428, 'loss': 0.60038007, 'lr': 0, 'params': 575015, 'time_iter': 0.10222, 'accuracy': 0.83199, 'f1': 0.83335, 'auc': 0.97473}\n",
      "test: {'epoch': 6, 'time_epoch': 4.81054, 'loss': 0.44698219, 'lr': 0, 'params': 575015, 'time_iter': 0.10235, 'accuracy': 0.88322, 'f1': 0.87451, 'auc': 0.98642}\n",
      "> Epoch 6: took 83.9s (avg 80.1s) | Best so far: epoch 5\ttrain_loss: 0.4818 train_accuracy: 0.9106\tval_loss: 0.4339 val_accuracy: 0.9032\ttest_loss: 0.3787 test_accuracy: 0.9275\n",
      "train: {'epoch': 7, 'time_epoch': 75.88653, 'eta': 1941.39141, 'eta_hours': 0.53928, 'loss': 0.26720789, 'lr': 0.00098907, 'params': 575015, 'time_iter': 0.20345, 'accuracy': 0.94793, 'f1': 0.94776, 'auc': 0.99118}\n",
      "val: {'epoch': 7, 'time_epoch': 3.90433, 'loss': 0.34048106, 'lr': 0, 'params': 575015, 'time_iter': 0.08307, 'accuracy': 0.91935, 'f1': 0.92032, 'auc': 0.98871}\n",
      "test: {'epoch': 7, 'time_epoch': 4.0071, 'loss': 0.30435876, 'lr': 0, 'params': 575015, 'time_iter': 0.08526, 'accuracy': 0.93154, 'f1': 0.93341, 'auc': 0.98998}\n",
      "> Epoch 7: took 83.9s (avg 80.6s) | Best so far: epoch 7\ttrain_loss: 0.2672 train_accuracy: 0.9479\tval_loss: 0.3405 val_accuracy: 0.9194\ttest_loss: 0.3044 test_accuracy: 0.9315\n",
      "train: {'epoch': 8, 'time_epoch': 71.71576, 'eta': 1868.94599, 'eta_hours': 0.51915, 'loss': 0.22062072, 'lr': 0.00097553, 'params': 575015, 'time_iter': 0.19227, 'accuracy': 0.95314, 'f1': 0.95313, 'auc': 0.99344}\n",
      "val: {'epoch': 8, 'time_epoch': 4.14669, 'loss': 0.28372722, 'lr': 0, 'params': 575015, 'time_iter': 0.08823, 'accuracy': 0.93548, 'f1': 0.93728, 'auc': 0.99359}\n",
      "test: {'epoch': 8, 'time_epoch': 5.01666, 'loss': 0.24281143, 'lr': 0, 'params': 575015, 'time_iter': 0.10674, 'accuracy': 0.94899, 'f1': 0.94924, 'auc': 0.99238}\n",
      "> Epoch 8: took 81.0s (avg 80.6s) | Best so far: epoch 8\ttrain_loss: 0.2206 train_accuracy: 0.9531\tval_loss: 0.2837 val_accuracy: 0.9355\ttest_loss: 0.2428 test_accuracy: 0.9490\n",
      "train: {'epoch': 9, 'time_epoch': 79.87593, 'eta': 1817.04693, 'eta_hours': 0.50474, 'loss': 0.17010872, 'lr': 0.00095677, 'params': 575015, 'time_iter': 0.21414, 'accuracy': 0.96389, 'f1': 0.9638, 'auc': 0.99608}\n",
      "val: {'epoch': 9, 'time_epoch': 3.76684, 'loss': 0.15324918, 'lr': 0, 'params': 575015, 'time_iter': 0.08015, 'accuracy': 0.9664, 'f1': 0.96704, 'auc': 0.99678}\n",
      "test: {'epoch': 9, 'time_epoch': 3.92503, 'loss': 0.16449998, 'lr': 0, 'params': 575015, 'time_iter': 0.08351, 'accuracy': 0.96779, 'f1': 0.96776, 'auc': 0.99633}\n",
      "> Epoch 9: took 87.6s (avg 81.3s) | Best so far: epoch 9\ttrain_loss: 0.1701 train_accuracy: 0.9639\tval_loss: 0.1532 val_accuracy: 0.9664\ttest_loss: 0.1645 test_accuracy: 0.9678\n",
      "train: {'epoch': 10, 'time_epoch': 68.28706, 'eta': 1734.77636, 'eta_hours': 0.48188, 'loss': 0.15106644, 'lr': 0.00093301, 'params': 575015, 'time_iter': 0.18308, 'accuracy': 0.96691, 'f1': 0.96686, 'auc': 0.99663}\n",
      "val: {'epoch': 10, 'time_epoch': 4.40883, 'loss': 0.13067867, 'lr': 0, 'params': 575015, 'time_iter': 0.0938, 'accuracy': 0.96909, 'f1': 0.9697, 'auc': 0.99726}\n",
      "test: {'epoch': 10, 'time_epoch': 3.8546, 'loss': 0.13278664, 'lr': 0, 'params': 575015, 'time_iter': 0.08201, 'accuracy': 0.96913, 'f1': 0.96852, 'auc': 0.99801}\n",
      "> Epoch 10: took 76.6s (avg 80.9s) | Best so far: epoch 10\ttrain_loss: 0.1511 train_accuracy: 0.9669\tval_loss: 0.1307 val_accuracy: 0.9691\ttest_loss: 0.1328 test_accuracy: 0.9691\n",
      "train: {'epoch': 11, 'time_epoch': 78.95964, 'eta': 1675.29215, 'eta_hours': 0.46536, 'loss': 0.11915014, 'lr': 0.00090451, 'params': 575015, 'time_iter': 0.21169, 'accuracy': 0.97447, 'f1': 0.97443, 'auc': 0.9981}\n",
      "val: {'epoch': 11, 'time_epoch': 4.48698, 'loss': 0.14431029, 'lr': 0, 'params': 575015, 'time_iter': 0.09547, 'accuracy': 0.9664, 'f1': 0.96724, 'auc': 0.99816}\n",
      "test: {'epoch': 11, 'time_epoch': 5.25245, 'loss': 0.11924126, 'lr': 0, 'params': 575015, 'time_iter': 0.11175, 'accuracy': 0.97315, 'f1': 0.97308, 'auc': 0.99861}\n",
      "> Epoch 11: took 88.8s (avg 81.6s) | Best so far: epoch 10\ttrain_loss: 0.1511 train_accuracy: 0.9669\tval_loss: 0.1307 val_accuracy: 0.9691\ttest_loss: 0.1328 test_accuracy: 0.9691\n",
      "train: {'epoch': 12, 'time_epoch': 72.64355, 'eta': 1602.12296, 'eta_hours': 0.44503, 'loss': 0.10109167, 'lr': 0.00087157, 'params': 575015, 'time_iter': 0.19475, 'accuracy': 0.97716, 'f1': 0.97715, 'auc': 0.998}\n",
      "val: {'epoch': 12, 'time_epoch': 4.08382, 'loss': 0.167131, 'lr': 0, 'params': 575015, 'time_iter': 0.08689, 'accuracy': 0.95161, 'f1': 0.95331, 'auc': 0.99736}\n",
      "test: {'epoch': 12, 'time_epoch': 4.19629, 'loss': 0.17829828, 'lr': 0, 'params': 575015, 'time_iter': 0.08928, 'accuracy': 0.95168, 'f1': 0.95071, 'auc': 0.99764}\n",
      "> Epoch 12: took 81.0s (avg 81.5s) | Best so far: epoch 10\ttrain_loss: 0.1511 train_accuracy: 0.9669\tval_loss: 0.1307 val_accuracy: 0.9691\ttest_loss: 0.1328 test_accuracy: 0.9691\n",
      "train: {'epoch': 13, 'time_epoch': 77.45008, 'eta': 1536.23865, 'eta_hours': 0.42673, 'loss': 0.0916343, 'lr': 0.00083457, 'params': 575015, 'time_iter': 0.20764, 'accuracy': 0.97783, 'f1': 0.9778, 'auc': 0.99859}\n",
      "val: {'epoch': 13, 'time_epoch': 4.83564, 'loss': 0.16862817, 'lr': 0, 'params': 575015, 'time_iter': 0.10289, 'accuracy': 0.95833, 'f1': 0.95963, 'auc': 0.99604}\n",
      "test: {'epoch': 13, 'time_epoch': 4.55127, 'loss': 0.13478944, 'lr': 0, 'params': 575015, 'time_iter': 0.09684, 'accuracy': 0.96913, 'f1': 0.96938, 'auc': 0.99725}\n",
      "> Epoch 13: took 87.0s (avg 81.9s) | Best so far: epoch 10\ttrain_loss: 0.1511 train_accuracy: 0.9669\tval_loss: 0.1307 val_accuracy: 0.9691\ttest_loss: 0.1328 test_accuracy: 0.9691\n",
      "train: {'epoch': 14, 'time_epoch': 75.83304, 'eta': 1466.65619, 'eta_hours': 0.4074, 'loss': 0.08211557, 'lr': 0.00079389, 'params': 575015, 'time_iter': 0.20331, 'accuracy': 0.98236, 'f1': 0.98228, 'auc': 0.99853}\n",
      "val: {'epoch': 14, 'time_epoch': 4.18287, 'loss': 0.2102042, 'lr': 0, 'params': 575015, 'time_iter': 0.089, 'accuracy': 0.94892, 'f1': 0.95171, 'auc': 0.99526}\n",
      "test: {'epoch': 14, 'time_epoch': 4.65972, 'loss': 0.20428239, 'lr': 0, 'params': 575015, 'time_iter': 0.09914, 'accuracy': 0.95034, 'f1': 0.94836, 'auc': 0.99653}\n",
      "> Epoch 14: took 84.8s (avg 82.1s) | Best so far: epoch 10\ttrain_loss: 0.1511 train_accuracy: 0.9669\tval_loss: 0.1307 val_accuracy: 0.9691\ttest_loss: 0.1328 test_accuracy: 0.9691\n",
      "train: {'epoch': 15, 'time_epoch': 79.13636, 'eta': 1400.21509, 'eta_hours': 0.38895, 'loss': 0.07221167, 'lr': 0.00075, 'params': 575015, 'time_iter': 0.21216, 'accuracy': 0.98421, 'f1': 0.98423, 'auc': 0.99908}\n",
      "val: {'epoch': 15, 'time_epoch': 4.00308, 'loss': 0.21666213, 'lr': 0, 'params': 575015, 'time_iter': 0.08517, 'accuracy': 0.95296, 'f1': 0.95395, 'auc': 0.99477}\n",
      "test: {'epoch': 15, 'time_epoch': 3.78415, 'loss': 0.18127598, 'lr': 0, 'params': 575015, 'time_iter': 0.08051, 'accuracy': 0.95973, 'f1': 0.95732, 'auc': 0.99751}\n",
      "> Epoch 15: took 87.0s (avg 82.4s) | Best so far: epoch 10\ttrain_loss: 0.1511 train_accuracy: 0.9669\tval_loss: 0.1307 val_accuracy: 0.9691\ttest_loss: 0.1328 test_accuracy: 0.9691\n",
      "train: {'epoch': 16, 'time_epoch': 76.32507, 'eta': 1329.30378, 'eta_hours': 0.36925, 'loss': 0.06572016, 'lr': 0.00070337, 'params': 575015, 'time_iter': 0.20462, 'accuracy': 0.98589, 'f1': 0.98585, 'auc': 0.99907}\n",
      "val: {'epoch': 16, 'time_epoch': 3.8704, 'loss': 0.15887363, 'lr': 0, 'params': 575015, 'time_iter': 0.08235, 'accuracy': 0.96237, 'f1': 0.96306, 'auc': 0.99547}\n",
      "test: {'epoch': 16, 'time_epoch': 4.02128, 'loss': 0.20546515, 'lr': 0, 'params': 575015, 'time_iter': 0.08556, 'accuracy': 0.9557, 'f1': 0.95518, 'auc': 0.99402}\n",
      "> Epoch 16: took 84.3s (avg 82.5s) | Best so far: epoch 10\ttrain_loss: 0.1511 train_accuracy: 0.9669\tval_loss: 0.1307 val_accuracy: 0.9691\ttest_loss: 0.1328 test_accuracy: 0.9691\n",
      "train: {'epoch': 17, 'time_epoch': 70.75187, 'eta': 1252.52736, 'eta_hours': 0.34792, 'loss': 0.04341913, 'lr': 0.00065451, 'params': 575015, 'time_iter': 0.18968, 'accuracy': 0.98992, 'f1': 0.98987, 'auc': 0.99963}\n",
      "val: {'epoch': 17, 'time_epoch': 3.87939, 'loss': 0.12753002, 'lr': 0, 'params': 575015, 'time_iter': 0.08254, 'accuracy': 0.96774, 'f1': 0.96804, 'auc': 0.9992}\n",
      "test: {'epoch': 17, 'time_epoch': 4.55401, 'loss': 0.11398143, 'lr': 0, 'params': 575015, 'time_iter': 0.09689, 'accuracy': 0.97047, 'f1': 0.97068, 'auc': 0.99824}\n",
      "> Epoch 17: took 79.3s (avg 82.3s) | Best so far: epoch 10\ttrain_loss: 0.1511 train_accuracy: 0.9669\tval_loss: 0.1307 val_accuracy: 0.9691\ttest_loss: 0.1328 test_accuracy: 0.9691\n",
      "train: {'epoch': 18, 'time_epoch': 81.07302, 'eta': 1185.0766, 'eta_hours': 0.32919, 'loss': 0.03979711, 'lr': 0.00060396, 'params': 575015, 'time_iter': 0.21735, 'accuracy': 0.99244, 'f1': 0.99243, 'auc': 0.9997}\n",
      "val: {'epoch': 18, 'time_epoch': 4.42594, 'loss': 0.09454954, 'lr': 0, 'params': 575015, 'time_iter': 0.09417, 'accuracy': 0.97446, 'f1': 0.9749, 'auc': 0.99906}\n",
      "test: {'epoch': 18, 'time_epoch': 4.76793, 'loss': 0.09761891, 'lr': 0, 'params': 575015, 'time_iter': 0.10145, 'accuracy': 0.97987, 'f1': 0.97958, 'auc': 0.99878}\n",
      "> Epoch 18: took 90.4s (avg 82.8s) | Best so far: epoch 18\ttrain_loss: 0.0398 train_accuracy: 0.9924\tval_loss: 0.0945 val_accuracy: 0.9745\ttest_loss: 0.0976 test_accuracy: 0.9799\n",
      "train: {'epoch': 19, 'time_epoch': 68.48246, 'eta': 1106.82069, 'eta_hours': 0.30745, 'loss': 0.03756781, 'lr': 0.00055226, 'params': 575015, 'time_iter': 0.1836, 'accuracy': 0.99278, 'f1': 0.99278, 'auc': 0.99947}\n",
      "val: {'epoch': 19, 'time_epoch': 4.07445, 'loss': 0.10588527, 'lr': 0, 'params': 575015, 'time_iter': 0.08669, 'accuracy': 0.97715, 'f1': 0.97731, 'auc': 0.99843}\n",
      "test: {'epoch': 19, 'time_epoch': 3.79334, 'loss': 0.0872452, 'lr': 0, 'params': 575015, 'time_iter': 0.08071, 'accuracy': 0.98255, 'f1': 0.9825, 'auc': 0.99953}\n",
      "> Epoch 19: took 76.4s (avg 82.4s) | Best so far: epoch 19\ttrain_loss: 0.0376 train_accuracy: 0.9928\tval_loss: 0.1059 val_accuracy: 0.9771\ttest_loss: 0.0872 test_accuracy: 0.9826\n",
      "train: {'epoch': 20, 'time_epoch': 73.81763, 'eta': 1033.05237, 'eta_hours': 0.28696, 'loss': 0.02959197, 'lr': 0.0005, 'params': 575015, 'time_iter': 0.1979, 'accuracy': 0.99563, 'f1': 0.99562, 'auc': 0.99965}\n",
      "val: {'epoch': 20, 'time_epoch': 4.12119, 'loss': 0.10605146, 'lr': 0, 'params': 575015, 'time_iter': 0.08768, 'accuracy': 0.97581, 'f1': 0.97618, 'auc': 0.9986}\n",
      "test: {'epoch': 20, 'time_epoch': 4.05191, 'loss': 0.11036139, 'lr': 0, 'params': 575015, 'time_iter': 0.08621, 'accuracy': 0.97584, 'f1': 0.97588, 'auc': 0.99891}\n",
      "> Epoch 20: took 82.1s (avg 82.4s) | Best so far: epoch 19\ttrain_loss: 0.0376 train_accuracy: 0.9928\tval_loss: 0.1059 val_accuracy: 0.9771\ttest_loss: 0.0872 test_accuracy: 0.9826\n",
      "train: {'epoch': 21, 'time_epoch': 81.61414, 'eta': 963.88659, 'eta_hours': 0.26775, 'loss': 0.02607234, 'lr': 0.00044774, 'params': 575015, 'time_iter': 0.2188, 'accuracy': 0.99412, 'f1': 0.99409, 'auc': 0.99981}\n",
      "val: {'epoch': 21, 'time_epoch': 4.03967, 'loss': 0.1141535, 'lr': 0, 'params': 575015, 'time_iter': 0.08595, 'accuracy': 0.97581, 'f1': 0.97612, 'auc': 0.9968}\n",
      "test: {'epoch': 21, 'time_epoch': 5.53466, 'loss': 0.10908, 'lr': 0, 'params': 575015, 'time_iter': 0.11776, 'accuracy': 0.97181, 'f1': 0.97173, 'auc': 0.99946}\n",
      "> Epoch 21: took 91.3s (avg 82.8s) | Best so far: epoch 19\ttrain_loss: 0.0376 train_accuracy: 0.9928\tval_loss: 0.1059 val_accuracy: 0.9771\ttest_loss: 0.0872 test_accuracy: 0.9826\n",
      "train: {'epoch': 22, 'time_epoch': 69.8094, 'eta': 887.47935, 'eta_hours': 0.24652, 'loss': 0.01581012, 'lr': 0.00039604, 'params': 575015, 'time_iter': 0.18716, 'accuracy': 0.99731, 'f1': 0.99731, 'auc': 0.9999}\n",
      "val: {'epoch': 22, 'time_epoch': 4.0898, 'loss': 0.1826923, 'lr': 0, 'params': 575015, 'time_iter': 0.08702, 'accuracy': 0.96371, 'f1': 0.96446, 'auc': 0.9967}\n",
      "test: {'epoch': 22, 'time_epoch': 4.29378, 'loss': 0.15326629, 'lr': 0, 'params': 575015, 'time_iter': 0.09136, 'accuracy': 0.96913, 'f1': 0.96827, 'auc': 0.99857}\n",
      "> Epoch 22: took 78.3s (avg 82.6s) | Best so far: epoch 19\ttrain_loss: 0.0376 train_accuracy: 0.9928\tval_loss: 0.1059 val_accuracy: 0.9771\ttest_loss: 0.0872 test_accuracy: 0.9826\n",
      "train: {'epoch': 23, 'time_epoch': 77.63291, 'eta': 815.20771, 'eta_hours': 0.22645, 'loss': 0.01427819, 'lr': 0.00034549, 'params': 575015, 'time_iter': 0.20813, 'accuracy': 0.99748, 'f1': 0.99748, 'auc': 0.99992}\n",
      "val: {'epoch': 23, 'time_epoch': 5.29786, 'loss': 0.11680006, 'lr': 0, 'params': 575015, 'time_iter': 0.11272, 'accuracy': 0.97849, 'f1': 0.97855, 'auc': 0.99802}\n",
      "test: {'epoch': 23, 'time_epoch': 4.40422, 'loss': 0.13448573, 'lr': 0, 'params': 575015, 'time_iter': 0.09371, 'accuracy': 0.9745, 'f1': 0.97438, 'auc': 0.99854}\n",
      "> Epoch 23: took 87.4s (avg 82.8s) | Best so far: epoch 23\ttrain_loss: 0.0143 train_accuracy: 0.9975\tval_loss: 0.1168 val_accuracy: 0.9785\ttest_loss: 0.1345 test_accuracy: 0.9745\n",
      "train: {'epoch': 24, 'time_epoch': 77.27588, 'eta': 742.36435, 'eta_hours': 0.20621, 'loss': 0.01300094, 'lr': 0.00029663, 'params': 575015, 'time_iter': 0.20717, 'accuracy': 0.99798, 'f1': 0.99797, 'auc': 0.99984}\n",
      "val: {'epoch': 24, 'time_epoch': 3.84344, 'loss': 0.1276397, 'lr': 0, 'params': 575015, 'time_iter': 0.08178, 'accuracy': 0.97715, 'f1': 0.97716, 'auc': 0.99656}\n",
      "test: {'epoch': 24, 'time_epoch': 3.97291, 'loss': 0.14050325, 'lr': 0, 'params': 575015, 'time_iter': 0.08453, 'accuracy': 0.9745, 'f1': 0.97444, 'auc': 0.99854}\n",
      "> Epoch 24: took 85.2s (avg 82.9s) | Best so far: epoch 23\ttrain_loss: 0.0143 train_accuracy: 0.9975\tval_loss: 0.1168 val_accuracy: 0.9785\ttest_loss: 0.1345 test_accuracy: 0.9745\n",
      "train: {'epoch': 25, 'time_epoch': 76.53332, 'eta': 668.92299, 'eta_hours': 0.18581, 'loss': 0.01282502, 'lr': 0.00025, 'params': 575015, 'time_iter': 0.20518, 'accuracy': 0.99832, 'f1': 0.9983, 'auc': 0.99985}\n",
      "val: {'epoch': 25, 'time_epoch': 4.96036, 'loss': 0.10050612, 'lr': 0, 'params': 575015, 'time_iter': 0.10554, 'accuracy': 0.97984, 'f1': 0.98005, 'auc': 0.99814}\n",
      "test: {'epoch': 25, 'time_epoch': 4.82327, 'loss': 0.13483525, 'lr': 0, 'params': 575015, 'time_iter': 0.10262, 'accuracy': 0.97315, 'f1': 0.97309, 'auc': 0.99922}\n",
      "> Epoch 25: took 86.4s (avg 83.1s) | Best so far: epoch 25\ttrain_loss: 0.0128 train_accuracy: 0.9983\tval_loss: 0.1005 val_accuracy: 0.9798\ttest_loss: 0.1348 test_accuracy: 0.9731\n",
      "train: {'epoch': 26, 'time_epoch': 76.88725, 'eta': 595.35747, 'eta_hours': 0.16538, 'loss': 0.00907001, 'lr': 0.00020611, 'params': 575015, 'time_iter': 0.20613, 'accuracy': 0.99866, 'f1': 0.99865, 'auc': 0.99988}\n",
      "val: {'epoch': 26, 'time_epoch': 4.36141, 'loss': 0.13648122, 'lr': 0, 'params': 575015, 'time_iter': 0.0928, 'accuracy': 0.97043, 'f1': 0.97109, 'auc': 0.99832}\n",
      "test: {'epoch': 26, 'time_epoch': 4.74653, 'loss': 0.12997512, 'lr': 0, 'params': 575015, 'time_iter': 0.10099, 'accuracy': 0.97584, 'f1': 0.97573, 'auc': 0.99815}\n",
      "> Epoch 26: took 86.1s (avg 83.2s) | Best so far: epoch 25\ttrain_loss: 0.0128 train_accuracy: 0.9983\tval_loss: 0.1005 val_accuracy: 0.9798\ttest_loss: 0.1348 test_accuracy: 0.9731\n",
      "train: {'epoch': 27, 'time_epoch': 76.41754, 'eta': 521.43725, 'eta_hours': 0.14484, 'loss': 0.00982131, 'lr': 0.00016543, 'params': 575015, 'time_iter': 0.20487, 'accuracy': 0.99866, 'f1': 0.99865, 'auc': 0.99986}\n",
      "val: {'epoch': 27, 'time_epoch': 4.51567, 'loss': 0.11008951, 'lr': 0, 'params': 575015, 'time_iter': 0.09608, 'accuracy': 0.97849, 'f1': 0.97883, 'auc': 0.99836}\n",
      "test: {'epoch': 27, 'time_epoch': 4.50233, 'loss': 0.114107, 'lr': 0, 'params': 575015, 'time_iter': 0.09579, 'accuracy': 0.97987, 'f1': 0.97955, 'auc': 0.99855}\n",
      "> Epoch 27: took 85.5s (avg 83.3s) | Best so far: epoch 25\ttrain_loss: 0.0128 train_accuracy: 0.9983\tval_loss: 0.1005 val_accuracy: 0.9798\ttest_loss: 0.1348 test_accuracy: 0.9731\n",
      "train: {'epoch': 28, 'time_epoch': 78.30919, 'eta': 447.73617, 'eta_hours': 0.12437, 'loss': 0.00645256, 'lr': 0.00012843, 'params': 575015, 'time_iter': 0.20994, 'accuracy': 0.99933, 'f1': 0.99934, 'auc': 0.99999}\n",
      "val: {'epoch': 28, 'time_epoch': 4.13543, 'loss': 0.10805318, 'lr': 0, 'params': 575015, 'time_iter': 0.08799, 'accuracy': 0.97849, 'f1': 0.97878, 'auc': 0.99787}\n",
      "test: {'epoch': 28, 'time_epoch': 4.46451, 'loss': 0.13259816, 'lr': 0, 'params': 575015, 'time_iter': 0.09499, 'accuracy': 0.97718, 'f1': 0.97697, 'auc': 0.99844}\n",
      "> Epoch 28: took 87.0s (avg 83.4s) | Best so far: epoch 25\ttrain_loss: 0.0128 train_accuracy: 0.9983\tval_loss: 0.1005 val_accuracy: 0.9798\ttest_loss: 0.1348 test_accuracy: 0.9731\n",
      "train: {'epoch': 29, 'time_epoch': 76.6113, 'eta': 373.44491, 'eta_hours': 0.10373, 'loss': 0.00457687, 'lr': 9.549e-05, 'params': 575015, 'time_iter': 0.20539, 'accuracy': 0.99966, 'f1': 0.99966, 'auc': 1.0}\n",
      "val: {'epoch': 29, 'time_epoch': 4.05537, 'loss': 0.10337697, 'lr': 0, 'params': 575015, 'time_iter': 0.08628, 'accuracy': 0.98253, 'f1': 0.9827, 'auc': 0.9986}\n",
      "test: {'epoch': 29, 'time_epoch': 4.17154, 'loss': 0.12174213, 'lr': 0, 'params': 575015, 'time_iter': 0.08876, 'accuracy': 0.9745, 'f1': 0.97413, 'auc': 0.99886}\n",
      "> Epoch 29: took 84.9s (avg 83.4s) | Best so far: epoch 29\ttrain_loss: 0.0046 train_accuracy: 0.9997\tval_loss: 0.1034 val_accuracy: 0.9825\ttest_loss: 0.1217 test_accuracy: 0.9745\n",
      "train: {'epoch': 30, 'time_epoch': 77.45408, 'eta': 299.11272, 'eta_hours': 0.08309, 'loss': 0.00693597, 'lr': 6.699e-05, 'params': 575015, 'time_iter': 0.20765, 'accuracy': 0.99916, 'f1': 0.99915, 'auc': 0.99984}\n",
      "val: {'epoch': 30, 'time_epoch': 3.81864, 'loss': 0.09465934, 'lr': 0, 'params': 575015, 'time_iter': 0.08125, 'accuracy': 0.98118, 'f1': 0.98121, 'auc': 0.99766}\n",
      "test: {'epoch': 30, 'time_epoch': 3.93453, 'loss': 0.11534802, 'lr': 0, 'params': 575015, 'time_iter': 0.08371, 'accuracy': 0.97987, 'f1': 0.9797, 'auc': 0.99896}\n",
      "> Epoch 30: took 85.3s (avg 83.5s) | Best so far: epoch 29\ttrain_loss: 0.0046 train_accuracy: 0.9997\tval_loss: 0.1034 val_accuracy: 0.9825\ttest_loss: 0.1217 test_accuracy: 0.9745\n",
      "train: {'epoch': 31, 'time_epoch': 71.5295, 'eta': 224.02997, 'eta_hours': 0.06223, 'loss': 0.00325217, 'lr': 4.323e-05, 'params': 575015, 'time_iter': 0.19177, 'accuracy': 0.99983, 'f1': 0.99982, 'auc': 1.0}\n",
      "val: {'epoch': 31, 'time_epoch': 4.59442, 'loss': 0.12519252, 'lr': 0, 'params': 575015, 'time_iter': 0.09775, 'accuracy': 0.97446, 'f1': 0.97474, 'auc': 0.99741}\n",
      "test: {'epoch': 31, 'time_epoch': 4.41322, 'loss': 0.1255772, 'lr': 0, 'params': 575015, 'time_iter': 0.0939, 'accuracy': 0.97718, 'f1': 0.97684, 'auc': 0.99893}\n",
      "> Epoch 31: took 80.7s (avg 83.4s) | Best so far: epoch 29\ttrain_loss: 0.0046 train_accuracy: 0.9997\tval_loss: 0.1034 val_accuracy: 0.9825\ttest_loss: 0.1217 test_accuracy: 0.9745\n",
      "train: {'epoch': 32, 'time_epoch': 80.08324, 'eta': 149.68099, 'eta_hours': 0.04158, 'loss': 0.00301682, 'lr': 2.447e-05, 'params': 575015, 'time_iter': 0.2147, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 32, 'time_epoch': 5.19296, 'loss': 0.09798995, 'lr': 0, 'params': 575015, 'time_iter': 0.11049, 'accuracy': 0.98387, 'f1': 0.98403, 'auc': 0.99773}\n",
      "test: {'epoch': 32, 'time_epoch': 3.88473, 'loss': 0.12867443, 'lr': 0, 'params': 575015, 'time_iter': 0.08265, 'accuracy': 0.97584, 'f1': 0.97544, 'auc': 0.99919}\n",
      "> Epoch 32: took 89.3s (avg 83.6s) | Best so far: epoch 32\ttrain_loss: 0.0030 train_accuracy: 0.9998\tval_loss: 0.0980 val_accuracy: 0.9839\ttest_loss: 0.1287 test_accuracy: 0.9758\n",
      "train: {'epoch': 33, 'time_epoch': 73.21612, 'eta': 74.79272, 'eta_hours': 0.02078, 'loss': 0.00264551, 'lr': 1.093e-05, 'params': 575015, 'time_iter': 0.19629, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 33, 'time_epoch': 4.69958, 'loss': 0.10909367, 'lr': 0, 'params': 575015, 'time_iter': 0.09999, 'accuracy': 0.98253, 'f1': 0.98284, 'auc': 0.99823}\n",
      "test: {'epoch': 33, 'time_epoch': 4.07141, 'loss': 0.1216894, 'lr': 0, 'params': 575015, 'time_iter': 0.08663, 'accuracy': 0.97852, 'f1': 0.97822, 'auc': 0.99901}\n",
      "> Epoch 33: took 82.1s (avg 83.5s) | Best so far: epoch 32\ttrain_loss: 0.0030 train_accuracy: 0.9998\tval_loss: 0.0980 val_accuracy: 0.9839\ttest_loss: 0.1287 test_accuracy: 0.9758\n",
      "train: {'epoch': 34, 'time_epoch': 80.93831, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.00279983, 'lr': 2.74e-06, 'params': 575015, 'time_iter': 0.21699, 'accuracy': 0.99983, 'f1': 0.99984, 'auc': 1.0}\n",
      "val: {'epoch': 34, 'time_epoch': 5.08861, 'loss': 0.09907588, 'lr': 0, 'params': 575015, 'time_iter': 0.10827, 'accuracy': 0.98387, 'f1': 0.98411, 'auc': 0.99779}\n",
      "test: {'epoch': 34, 'time_epoch': 3.93446, 'loss': 0.1243646, 'lr': 0, 'params': 575015, 'time_iter': 0.08371, 'accuracy': 0.97584, 'f1': 0.97535, 'auc': 0.99914}\n",
      "> Epoch 34: took 90.1s (avg 83.7s) | Best so far: epoch 32\ttrain_loss: 0.0030 train_accuracy: 0.9998\tval_loss: 0.0980 val_accuracy: 0.9839\ttest_loss: 0.1287 test_accuracy: 0.9758\n",
      "Avg time per epoch: 83.73s\n",
      "Total train loop time: 0.81h\n",
      "Task done, results saved in results\\neural-Act-GPS+RWSE\\0\n",
      "32\n",
      "{'epoch': 32, 'time_epoch': 3.88473, 'loss': 0.12867443, 'lr': 0, 'params': 575015, 'time_iter': 0.08265, 'accuracy': 0.97584, 'f1': 0.97544, 'auc': 0.99919}\n",
      "{'epoch': 32, 'time_epoch': 80.08324, 'eta': 149.68099, 'eta_hours': 0.04158, 'loss': 0.00301682, 'lr': 2.447e-05, 'params': 575015, 'time_iter': 0.2147, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "{'epoch': 32, 'time_epoch': 5.19296, 'loss': 0.09798995, 'lr': 0, 'params': 575015, 'time_iter': 0.11049, 'accuracy': 0.98387, 'f1': 0.98403, 'auc': 0.99773}\n",
      "Results aggregated across runs saved in results\\neural-Act-GPS+RWSE\\agg\n",
      "[*] All done: 2024-02-27 10:55:24.950653\n"
     ]
    }
   ],
   "source": [
    "#Activity  - using CustomGatedGCN+Transformer\n",
    "%run main.py --cfg configs/GPS/neural-Act-GPS+RWSE.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846350fa-d6ad-4cbe-9c1a-4480fef49865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-25 23:01:54.459499\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 7\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [05:52<00:00, 21.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:05:56.62\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [01:55<00:00, 64.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:59.29\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=400, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: CustomGatedGCN+Exphormer\n",
      "  layers: 5\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 50\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 304204\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 67.55033, 'eta': 3309.96634, 'eta_hours': 0.91944, 'loss': 1.94724506, 'lr': 0.0, 'params': 304204, 'time_iter': 0.1811, 'accuracy': 0.14931, 'f1': 0.07356, 'auc': 0.52043}\n",
      "...computing epoch stats took: 0.14s\n",
      "val: {'epoch': 0, 'time_epoch': 3.75285, 'loss': 1.95215375, 'lr': 0, 'params': 304204, 'time_iter': 0.07985, 'accuracy': 0.13306, 'f1': 0.0599, 'auc': 0.5161}\n",
      "...computing epoch stats took: 0.05s\n",
      "test: {'epoch': 0, 'time_epoch': 3.78463, 'loss': 1.95612958, 'lr': 0, 'params': 304204, 'time_iter': 0.08052, 'accuracy': 0.13154, 'f1': 0.06336, 'auc': 0.53248}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 75.3s (avg 75.3s) | Best so far: epoch 0\ttrain_loss: 1.9472 train_accuracy: 0.1493\tval_loss: 1.9522 val_accuracy: 0.1331\ttest_loss: 1.9561 test_accuracy: 0.1315\n",
      "train: {'epoch': 1, 'time_epoch': 66.35276, 'eta': 3213.67426, 'eta_hours': 0.89269, 'loss': 1.68815943, 'lr': 0.0002, 'params': 304204, 'time_iter': 0.17789, 'accuracy': 0.61606, 'f1': 0.59259, 'auc': 0.9072}\n",
      "...computing epoch stats took: 0.04s\n",
      "val: {'epoch': 1, 'time_epoch': 3.82942, 'loss': 1.51161451, 'lr': 0, 'params': 304204, 'time_iter': 0.08148, 'accuracy': 0.77285, 'f1': 0.76497, 'auc': 0.97158}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 3.9808, 'loss': 1.50728266, 'lr': 0, 'params': 304204, 'time_iter': 0.0847, 'accuracy': 0.80671, 'f1': 0.79503, 'auc': 0.97499}\n",
      "...computing epoch stats took: 0.03s\n",
      "> Epoch 1: took 74.3s (avg 74.8s) | Best so far: epoch 1\ttrain_loss: 1.6882 train_accuracy: 0.6161\tval_loss: 1.5116 val_accuracy: 0.7729\ttest_loss: 1.5073 test_accuracy: 0.8067\n",
      "train: {'epoch': 2, 'time_epoch': 75.3965, 'eta': 3279.02698, 'eta_hours': 0.91084, 'loss': 1.29571938, 'lr': 0.0004, 'params': 304204, 'time_iter': 0.20214, 'accuracy': 0.85472, 'f1': 0.85095, 'auc': 0.97474}\n",
      "...computing epoch stats took: 0.05s\n",
      "val: {'epoch': 2, 'time_epoch': 4.64312, 'loss': 1.09922305, 'lr': 0, 'params': 304204, 'time_iter': 0.09879, 'accuracy': 0.88172, 'f1': 0.88771, 'auc': 0.98684}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 2, 'time_epoch': 4.78896, 'loss': 1.09238215, 'lr': 0, 'params': 304204, 'time_iter': 0.10189, 'accuracy': 0.90604, 'f1': 0.90572, 'auc': 0.9871}\n",
      "...computing epoch stats took: 0.06s\n",
      "> Epoch 2: took 85.0s (avg 78.2s) | Best so far: epoch 2\ttrain_loss: 1.2957 train_accuracy: 0.8547\tval_loss: 1.0992 val_accuracy: 0.8817\ttest_loss: 1.0924 test_accuracy: 0.9060\n",
      "train: {'epoch': 3, 'time_epoch': 67.88348, 'eta': 3187.6053, 'eta_hours': 0.88545, 'loss': 0.89168277, 'lr': 0.0006, 'params': 304204, 'time_iter': 0.18199, 'accuracy': 0.9135, 'f1': 0.91277, 'auc': 0.98594}\n",
      "val: {'epoch': 3, 'time_epoch': 3.50209, 'loss': 0.71038288, 'lr': 0, 'params': 304204, 'time_iter': 0.07451, 'accuracy': 0.92204, 'f1': 0.92333, 'auc': 0.99037}\n",
      "test: {'epoch': 3, 'time_epoch': 3.51845, 'loss': 0.68369477, 'lr': 0, 'params': 304204, 'time_iter': 0.07486, 'accuracy': 0.94631, 'f1': 0.94755, 'auc': 0.99434}\n",
      "> Epoch 3: took 75.0s (avg 77.4s) | Best so far: epoch 3\ttrain_loss: 0.8917 train_accuracy: 0.9135\tval_loss: 0.7104 val_accuracy: 0.9220\ttest_loss: 0.6837 test_accuracy: 0.9463\n",
      "train: {'epoch': 4, 'time_epoch': 65.64143, 'eta': 3085.42052, 'eta_hours': 0.85706, 'loss': 0.59142674, 'lr': 0.0008, 'params': 304204, 'time_iter': 0.17598, 'accuracy': 0.92509, 'f1': 0.92487, 'auc': 0.9907}\n",
      "val: {'epoch': 4, 'time_epoch': 3.52258, 'loss': 0.48938366, 'lr': 0, 'params': 304204, 'time_iter': 0.07495, 'accuracy': 0.92339, 'f1': 0.92527, 'auc': 0.99353}\n",
      "test: {'epoch': 4, 'time_epoch': 3.86161, 'loss': 0.50053204, 'lr': 0, 'params': 304204, 'time_iter': 0.08216, 'accuracy': 0.91409, 'f1': 0.91889, 'auc': 0.99324}\n",
      "> Epoch 4: took 73.1s (avg 76.5s) | Best so far: epoch 4\ttrain_loss: 0.5914 train_accuracy: 0.9251\tval_loss: 0.4894 val_accuracy: 0.9234\ttest_loss: 0.5005 test_accuracy: 0.9141\n",
      "train: {'epoch': 5, 'time_epoch': 80.51095, 'eta': 3104.46, 'eta_hours': 0.86235, 'loss': 0.39349792, 'lr': 0.001, 'params': 304204, 'time_iter': 0.21585, 'accuracy': 0.94054, 'f1': 0.94041, 'auc': 0.99111}\n",
      "val: {'epoch': 5, 'time_epoch': 4.62981, 'loss': 0.35021956, 'lr': 0, 'params': 304204, 'time_iter': 0.09851, 'accuracy': 0.9328, 'f1': 0.93334, 'auc': 0.99485}\n",
      "test: {'epoch': 5, 'time_epoch': 4.76893, 'loss': 0.31461957, 'lr': 0, 'params': 304204, 'time_iter': 0.10147, 'accuracy': 0.94631, 'f1': 0.94577, 'auc': 0.99379}\n",
      "> Epoch 5: took 90.1s (avg 78.8s) | Best so far: epoch 5\ttrain_loss: 0.3935 train_accuracy: 0.9405\tval_loss: 0.3502 val_accuracy: 0.9328\ttest_loss: 0.3146 test_accuracy: 0.9463\n",
      "train: {'epoch': 6, 'time_epoch': 67.05437, 'eta': 3012.39463, 'eta_hours': 0.83678, 'loss': 0.28418766, 'lr': 0.00099878, 'params': 304204, 'time_iter': 0.17977, 'accuracy': 0.94726, 'f1': 0.94715, 'auc': 0.9941}\n",
      "val: {'epoch': 6, 'time_epoch': 3.90016, 'loss': 0.34888544, 'lr': 0, 'params': 304204, 'time_iter': 0.08298, 'accuracy': 0.91129, 'f1': 0.91012, 'auc': 0.99332}\n",
      "test: {'epoch': 6, 'time_epoch': 3.8399, 'loss': 0.36453374, 'lr': 0, 'params': 304204, 'time_iter': 0.0817, 'accuracy': 0.90067, 'f1': 0.89815, 'auc': 0.99463}\n",
      "> Epoch 6: took 74.9s (avg 78.2s) | Best so far: epoch 5\ttrain_loss: 0.3935 train_accuracy: 0.9405\tval_loss: 0.3502 val_accuracy: 0.9328\ttest_loss: 0.3146 test_accuracy: 0.9463\n",
      "train: {'epoch': 7, 'time_epoch': 75.32821, 'eta': 2970.01965, 'eta_hours': 0.82501, 'loss': 0.21634244, 'lr': 0.00099513, 'params': 304204, 'time_iter': 0.20195, 'accuracy': 0.95549, 'f1': 0.9555, 'auc': 0.99642}\n",
      "val: {'epoch': 7, 'time_epoch': 4.68203, 'loss': 0.19886109, 'lr': 0, 'params': 304204, 'time_iter': 0.09962, 'accuracy': 0.96102, 'f1': 0.96209, 'auc': 0.9971}\n",
      "test: {'epoch': 7, 'time_epoch': 4.77306, 'loss': 0.16782297, 'lr': 0, 'params': 304204, 'time_iter': 0.10155, 'accuracy': 0.9745, 'f1': 0.9742, 'auc': 0.99713}\n",
      "> Epoch 7: took 84.9s (avg 79.1s) | Best so far: epoch 7\ttrain_loss: 0.2163 train_accuracy: 0.9555\tval_loss: 0.1989 val_accuracy: 0.9610\ttest_loss: 0.1678 test_accuracy: 0.9745\n",
      "train: {'epoch': 8, 'time_epoch': 76.25641, 'eta': 2924.55022, 'eta_hours': 0.81238, 'loss': 0.16227918, 'lr': 0.00098907, 'params': 304204, 'time_iter': 0.20444, 'accuracy': 0.96758, 'f1': 0.96753, 'auc': 0.99736}\n",
      "val: {'epoch': 8, 'time_epoch': 4.94089, 'loss': 0.25414606, 'lr': 0, 'params': 304204, 'time_iter': 0.10513, 'accuracy': 0.93952, 'f1': 0.94176, 'auc': 0.99428}\n",
      "test: {'epoch': 8, 'time_epoch': 4.69669, 'loss': 0.18078155, 'lr': 0, 'params': 304204, 'time_iter': 0.09993, 'accuracy': 0.96242, 'f1': 0.96257, 'auc': 0.99676}\n",
      "> Epoch 8: took 86.1s (avg 79.9s) | Best so far: epoch 7\ttrain_loss: 0.2163 train_accuracy: 0.9555\tval_loss: 0.1989 val_accuracy: 0.9610\ttest_loss: 0.1678 test_accuracy: 0.9745\n",
      "train: {'epoch': 9, 'time_epoch': 68.21429, 'eta': 2840.75489, 'eta_hours': 0.7891, 'loss': 0.14061939, 'lr': 0.00098063, 'params': 304204, 'time_iter': 0.18288, 'accuracy': 0.96977, 'f1': 0.96979, 'auc': 0.99779}\n",
      "val: {'epoch': 9, 'time_epoch': 3.92556, 'loss': 0.1938836, 'lr': 0, 'params': 304204, 'time_iter': 0.08352, 'accuracy': 0.95565, 'f1': 0.95734, 'auc': 0.99645}\n",
      "test: {'epoch': 9, 'time_epoch': 4.31735, 'loss': 0.21501267, 'lr': 0, 'params': 304204, 'time_iter': 0.09186, 'accuracy': 0.94765, 'f1': 0.94904, 'auc': 0.99657}\n",
      "> Epoch 9: took 76.6s (avg 79.5s) | Best so far: epoch 7\ttrain_loss: 0.2163 train_accuracy: 0.9555\tval_loss: 0.1989 val_accuracy: 0.9610\ttest_loss: 0.1678 test_accuracy: 0.9745\n",
      "train: {'epoch': 10, 'time_epoch': 79.92248, 'eta': 2801.30337, 'eta_hours': 0.77814, 'loss': 0.11005325, 'lr': 0.00096985, 'params': 304204, 'time_iter': 0.21427, 'accuracy': 0.97615, 'f1': 0.97614, 'auc': 0.99847}\n",
      "val: {'epoch': 10, 'time_epoch': 4.57414, 'loss': 0.15366691, 'lr': 0, 'params': 304204, 'time_iter': 0.09732, 'accuracy': 0.96371, 'f1': 0.96445, 'auc': 0.99629}\n",
      "test: {'epoch': 10, 'time_epoch': 4.69974, 'loss': 0.1351354, 'lr': 0, 'params': 304204, 'time_iter': 0.09999, 'accuracy': 0.96913, 'f1': 0.96909, 'auc': 0.99865}\n",
      "> Epoch 10: took 89.3s (avg 80.4s) | Best so far: epoch 10\ttrain_loss: 0.1101 train_accuracy: 0.9761\tval_loss: 0.1537 val_accuracy: 0.9637\ttest_loss: 0.1351 test_accuracy: 0.9691\n",
      "train: {'epoch': 11, 'time_epoch': 74.1455, 'eta': 2736.8129, 'eta_hours': 0.76023, 'loss': 0.09024049, 'lr': 0.00095677, 'params': 304204, 'time_iter': 0.19878, 'accuracy': 0.97985, 'f1': 0.97984, 'auc': 0.99906}\n",
      "val: {'epoch': 11, 'time_epoch': 5.0339, 'loss': 0.19159186, 'lr': 0, 'params': 304204, 'time_iter': 0.1071, 'accuracy': 0.95565, 'f1': 0.95702, 'auc': 0.9952}\n",
      "test: {'epoch': 11, 'time_epoch': 5.1014, 'loss': 0.16566381, 'lr': 0, 'params': 304204, 'time_iter': 0.10854, 'accuracy': 0.96376, 'f1': 0.96197, 'auc': 0.99778}\n",
      "> Epoch 11: took 84.4s (avg 80.8s) | Best so far: epoch 10\ttrain_loss: 0.1101 train_accuracy: 0.9761\tval_loss: 0.1537 val_accuracy: 0.9637\ttest_loss: 0.1351 test_accuracy: 0.9691\n",
      "train: {'epoch': 12, 'time_epoch': 66.69701, 'eta': 2649.63749, 'eta_hours': 0.73601, 'loss': 0.07637656, 'lr': 0.00094147, 'params': 304204, 'time_iter': 0.17881, 'accuracy': 0.98421, 'f1': 0.9842, 'auc': 0.99915}\n",
      "val: {'epoch': 12, 'time_epoch': 3.89316, 'loss': 0.15874334, 'lr': 0, 'params': 304204, 'time_iter': 0.08283, 'accuracy': 0.96237, 'f1': 0.96365, 'auc': 0.99822}\n",
      "test: {'epoch': 12, 'time_epoch': 3.87332, 'loss': 0.1599287, 'lr': 0, 'params': 304204, 'time_iter': 0.08241, 'accuracy': 0.96107, 'f1': 0.96154, 'auc': 0.99701}\n",
      "> Epoch 12: took 74.6s (avg 80.3s) | Best so far: epoch 10\ttrain_loss: 0.1101 train_accuracy: 0.9761\tval_loss: 0.1537 val_accuracy: 0.9637\ttest_loss: 0.1351 test_accuracy: 0.9691\n",
      "train: {'epoch': 13, 'time_epoch': 75.71249, 'eta': 2588.57025, 'eta_hours': 0.71905, 'loss': 0.07416625, 'lr': 0.00092402, 'params': 304204, 'time_iter': 0.20298, 'accuracy': 0.98304, 'f1': 0.98307, 'auc': 0.99915}\n",
      "val: {'epoch': 13, 'time_epoch': 4.56186, 'loss': 0.30129071, 'lr': 0, 'params': 304204, 'time_iter': 0.09706, 'accuracy': 0.92876, 'f1': 0.932, 'auc': 0.99431}\n",
      "test: {'epoch': 13, 'time_epoch': 4.66667, 'loss': 0.2529047, 'lr': 0, 'params': 304204, 'time_iter': 0.09929, 'accuracy': 0.93154, 'f1': 0.93245, 'auc': 0.99687}\n",
      "> Epoch 13: took 85.1s (avg 80.6s) | Best so far: epoch 10\ttrain_loss: 0.1101 train_accuracy: 0.9761\tval_loss: 0.1537 val_accuracy: 0.9637\ttest_loss: 0.1351 test_accuracy: 0.9691\n",
      "train: {'epoch': 14, 'time_epoch': 80.96969, 'eta': 2537.81711, 'eta_hours': 0.70495, 'loss': 0.05924108, 'lr': 0.00090451, 'params': 304204, 'time_iter': 0.21708, 'accuracy': 0.9864, 'f1': 0.98639, 'auc': 0.99921}\n",
      "val: {'epoch': 14, 'time_epoch': 4.57043, 'loss': 0.14918053, 'lr': 0, 'params': 304204, 'time_iter': 0.09724, 'accuracy': 0.96774, 'f1': 0.96904, 'auc': 0.99842}\n",
      "test: {'epoch': 14, 'time_epoch': 3.56207, 'loss': 0.151933, 'lr': 0, 'params': 304204, 'time_iter': 0.07579, 'accuracy': 0.9651, 'f1': 0.96589, 'auc': 0.99875}\n",
      "> Epoch 14: took 89.2s (avg 81.2s) | Best so far: epoch 14\ttrain_loss: 0.0592 train_accuracy: 0.9864\tval_loss: 0.1492 val_accuracy: 0.9677\ttest_loss: 0.1519 test_accuracy: 0.9651\n",
      "train: {'epoch': 15, 'time_epoch': 67.2469, 'eta': 2454.12595, 'eta_hours': 0.6817, 'loss': 0.04917513, 'lr': 0.00088302, 'params': 304204, 'time_iter': 0.18029, 'accuracy': 0.98841, 'f1': 0.98837, 'auc': 0.99964}\n",
      "val: {'epoch': 15, 'time_epoch': 4.42238, 'loss': 0.13264238, 'lr': 0, 'params': 304204, 'time_iter': 0.09409, 'accuracy': 0.96909, 'f1': 0.96951, 'auc': 0.99718}\n",
      "test: {'epoch': 15, 'time_epoch': 4.18012, 'loss': 0.12492741, 'lr': 0, 'params': 304204, 'time_iter': 0.08894, 'accuracy': 0.96779, 'f1': 0.9679, 'auc': 0.99866}\n",
      "> Epoch 15: took 76.0s (avg 80.9s) | Best so far: epoch 15\ttrain_loss: 0.0492 train_accuracy: 0.9884\tval_loss: 0.1326 val_accuracy: 0.9691\ttest_loss: 0.1249 test_accuracy: 0.9678\n",
      "train: {'epoch': 16, 'time_epoch': 81.77954, 'eta': 2400.57984, 'eta_hours': 0.66683, 'loss': 0.04879918, 'lr': 0.00085967, 'params': 304204, 'time_iter': 0.21925, 'accuracy': 0.98875, 'f1': 0.98876, 'auc': 0.99972}\n",
      "val: {'epoch': 16, 'time_epoch': 4.551, 'loss': 0.19753704, 'lr': 0, 'params': 304204, 'time_iter': 0.09683, 'accuracy': 0.95565, 'f1': 0.95665, 'auc': 0.99671}\n",
      "test: {'epoch': 16, 'time_epoch': 4.84257, 'loss': 0.17177707, 'lr': 0, 'params': 304204, 'time_iter': 0.10303, 'accuracy': 0.95973, 'f1': 0.95856, 'auc': 0.99865}\n",
      "> Epoch 16: took 91.3s (avg 81.5s) | Best so far: epoch 15\ttrain_loss: 0.0492 train_accuracy: 0.9884\tval_loss: 0.1326 val_accuracy: 0.9691\ttest_loss: 0.1249 test_accuracy: 0.9678\n",
      "train: {'epoch': 17, 'time_epoch': 77.70175, 'eta': 2336.64727, 'eta_hours': 0.64907, 'loss': 0.03972036, 'lr': 0.00083457, 'params': 304204, 'time_iter': 0.20832, 'accuracy': 0.99026, 'f1': 0.9902, 'auc': 0.99938}\n",
      "val: {'epoch': 17, 'time_epoch': 3.92717, 'loss': 0.21504169, 'lr': 0, 'params': 304204, 'time_iter': 0.08356, 'accuracy': 0.9543, 'f1': 0.95513, 'auc': 0.99735}\n",
      "test: {'epoch': 17, 'time_epoch': 3.77601, 'loss': 0.19447823, 'lr': 0, 'params': 304204, 'time_iter': 0.08034, 'accuracy': 0.96242, 'f1': 0.9627, 'auc': 0.99365}\n",
      "> Epoch 17: took 85.5s (avg 81.7s) | Best so far: epoch 15\ttrain_loss: 0.0492 train_accuracy: 0.9884\tval_loss: 0.1326 val_accuracy: 0.9691\ttest_loss: 0.1249 test_accuracy: 0.9678\n",
      "train: {'epoch': 18, 'time_epoch': 72.2212, 'eta': 2262.32336, 'eta_hours': 0.62842, 'loss': 0.02836598, 'lr': 0.00080783, 'params': 304204, 'time_iter': 0.19362, 'accuracy': 0.99311, 'f1': 0.9931, 'auc': 0.9999}\n",
      "val: {'epoch': 18, 'time_epoch': 4.78374, 'loss': 0.1917695, 'lr': 0, 'params': 304204, 'time_iter': 0.10178, 'accuracy': 0.95565, 'f1': 0.95706, 'auc': 0.99657}\n",
      "test: {'epoch': 18, 'time_epoch': 4.5748, 'loss': 0.1782034, 'lr': 0, 'params': 304204, 'time_iter': 0.09734, 'accuracy': 0.96107, 'f1': 0.96133, 'auc': 0.99673}\n",
      "> Epoch 18: took 81.7s (avg 81.7s) | Best so far: epoch 15\ttrain_loss: 0.0492 train_accuracy: 0.9884\tval_loss: 0.1326 val_accuracy: 0.9691\ttest_loss: 0.1249 test_accuracy: 0.9678\n",
      "train: {'epoch': 19, 'time_epoch': 80.5858, 'eta': 2200.75663, 'eta_hours': 0.61132, 'loss': 0.04438483, 'lr': 0.0007796, 'params': 304204, 'time_iter': 0.21605, 'accuracy': 0.99009, 'f1': 0.99011, 'auc': 0.99953}\n",
      "val: {'epoch': 19, 'time_epoch': 3.61438, 'loss': 0.20214826, 'lr': 0, 'params': 304204, 'time_iter': 0.0769, 'accuracy': 0.96102, 'f1': 0.96191, 'auc': 0.99499}\n",
      "test: {'epoch': 19, 'time_epoch': 3.53673, 'loss': 0.15376559, 'lr': 0, 'params': 304204, 'time_iter': 0.07525, 'accuracy': 0.96644, 'f1': 0.96521, 'auc': 0.999}\n",
      "> Epoch 19: took 87.8s (avg 82.0s) | Best so far: epoch 15\ttrain_loss: 0.0492 train_accuracy: 0.9884\tval_loss: 0.1326 val_accuracy: 0.9691\ttest_loss: 0.1249 test_accuracy: 0.9678\n",
      "train: {'epoch': 20, 'time_epoch': 74.54596, 'eta': 2129.03783, 'eta_hours': 0.5914, 'loss': 0.0256984, 'lr': 0.00075, 'params': 304204, 'time_iter': 0.19986, 'accuracy': 0.99379, 'f1': 0.99381, 'auc': 0.99982}\n",
      "val: {'epoch': 20, 'time_epoch': 3.72864, 'loss': 0.14424527, 'lr': 0, 'params': 304204, 'time_iter': 0.07933, 'accuracy': 0.96909, 'f1': 0.97007, 'auc': 0.99868}\n",
      "test: {'epoch': 20, 'time_epoch': 3.8762, 'loss': 0.13414559, 'lr': 0, 'params': 304204, 'time_iter': 0.08247, 'accuracy': 0.97315, 'f1': 0.97225, 'auc': 0.99901}\n",
      "> Epoch 20: took 82.3s (avg 82.0s) | Best so far: epoch 15\ttrain_loss: 0.0492 train_accuracy: 0.9884\tval_loss: 0.1326 val_accuracy: 0.9691\ttest_loss: 0.1249 test_accuracy: 0.9678\n",
      "train: {'epoch': 21, 'time_epoch': 68.98537, 'eta': 2049.98489, 'eta_hours': 0.56944, 'loss': 0.02393397, 'lr': 0.00071919, 'params': 304204, 'time_iter': 0.18495, 'accuracy': 0.99446, 'f1': 0.99443, 'auc': 0.99991}\n",
      "val: {'epoch': 21, 'time_epoch': 4.29671, 'loss': 0.22615528, 'lr': 0, 'params': 304204, 'time_iter': 0.09142, 'accuracy': 0.95565, 'f1': 0.95649, 'auc': 0.9952}\n",
      "test: {'epoch': 21, 'time_epoch': 4.54174, 'loss': 0.16419974, 'lr': 0, 'params': 304204, 'time_iter': 0.09663, 'accuracy': 0.95839, 'f1': 0.95809, 'auc': 0.99887}\n",
      "> Epoch 21: took 78.0s (avg 81.8s) | Best so far: epoch 15\ttrain_loss: 0.0492 train_accuracy: 0.9884\tval_loss: 0.1326 val_accuracy: 0.9691\ttest_loss: 0.1249 test_accuracy: 0.9678\n",
      "train: {'epoch': 22, 'time_epoch': 81.3663, 'eta': 1986.34154, 'eta_hours': 0.55176, 'loss': 0.01919226, 'lr': 0.0006873, 'params': 304204, 'time_iter': 0.21814, 'accuracy': 0.99547, 'f1': 0.99546, 'auc': 0.99992}\n",
      "val: {'epoch': 22, 'time_epoch': 4.7528, 'loss': 0.18333284, 'lr': 0, 'params': 304204, 'time_iter': 0.10112, 'accuracy': 0.96371, 'f1': 0.96444, 'auc': 0.99714}\n",
      "test: {'epoch': 22, 'time_epoch': 4.83038, 'loss': 0.16383025, 'lr': 0, 'params': 304204, 'time_iter': 0.10277, 'accuracy': 0.9651, 'f1': 0.96494, 'auc': 0.99884}\n",
      "> Epoch 22: took 91.1s (avg 82.2s) | Best so far: epoch 15\ttrain_loss: 0.0492 train_accuracy: 0.9884\tval_loss: 0.1326 val_accuracy: 0.9691\ttest_loss: 0.1249 test_accuracy: 0.9678\n",
      "train: {'epoch': 23, 'time_epoch': 73.53934, 'eta': 1912.74207, 'eta_hours': 0.53132, 'loss': 0.01846633, 'lr': 0.00065451, 'params': 304204, 'time_iter': 0.19716, 'accuracy': 0.99479, 'f1': 0.99479, 'auc': 0.99997}\n",
      "val: {'epoch': 23, 'time_epoch': 3.65988, 'loss': 0.11784554, 'lr': 0, 'params': 304204, 'time_iter': 0.07787, 'accuracy': 0.97715, 'f1': 0.97758, 'auc': 0.99856}\n",
      "test: {'epoch': 23, 'time_epoch': 3.60823, 'loss': 0.12836469, 'lr': 0, 'params': 304204, 'time_iter': 0.07677, 'accuracy': 0.97852, 'f1': 0.97822, 'auc': 0.99935}\n",
      "> Epoch 23: took 80.9s (avg 82.2s) | Best so far: epoch 23\ttrain_loss: 0.0185 train_accuracy: 0.9948\tval_loss: 0.1178 val_accuracy: 0.9771\ttest_loss: 0.1284 test_accuracy: 0.9785\n",
      "train: {'epoch': 24, 'time_epoch': 69.1259, 'eta': 1834.73396, 'eta_hours': 0.50965, 'loss': 0.00890917, 'lr': 0.00062096, 'params': 304204, 'time_iter': 0.18532, 'accuracy': 0.99782, 'f1': 0.99782, 'auc': 0.99999}\n",
      "val: {'epoch': 24, 'time_epoch': 4.51905, 'loss': 0.10984247, 'lr': 0, 'params': 304204, 'time_iter': 0.09615, 'accuracy': 0.97581, 'f1': 0.97646, 'auc': 0.99804}\n",
      "test: {'epoch': 24, 'time_epoch': 4.3249, 'loss': 0.13089781, 'lr': 0, 'params': 304204, 'time_iter': 0.09202, 'accuracy': 0.97584, 'f1': 0.97508, 'auc': 0.99916}\n",
      "> Epoch 24: took 78.1s (avg 82.0s) | Best so far: epoch 23\ttrain_loss: 0.0185 train_accuracy: 0.9948\tval_loss: 0.1178 val_accuracy: 0.9771\ttest_loss: 0.1284 test_accuracy: 0.9785\n",
      "train: {'epoch': 25, 'time_epoch': 80.20065, 'eta': 1767.63195, 'eta_hours': 0.49101, 'loss': 0.01056055, 'lr': 0.00058682, 'params': 304204, 'time_iter': 0.21502, 'accuracy': 0.99714, 'f1': 0.99715, 'auc': 0.99996}\n",
      "val: {'epoch': 25, 'time_epoch': 4.47706, 'loss': 0.17386788, 'lr': 0, 'params': 304204, 'time_iter': 0.09526, 'accuracy': 0.9664, 'f1': 0.9673, 'auc': 0.99733}\n",
      "test: {'epoch': 25, 'time_epoch': 4.96349, 'loss': 0.18107216, 'lr': 0, 'params': 304204, 'time_iter': 0.10561, 'accuracy': 0.96376, 'f1': 0.96309, 'auc': 0.99891}\n",
      "> Epoch 25: took 89.8s (avg 82.3s) | Best so far: epoch 23\ttrain_loss: 0.0185 train_accuracy: 0.9948\tval_loss: 0.1178 val_accuracy: 0.9771\ttest_loss: 0.1284 test_accuracy: 0.9785\n",
      "train: {'epoch': 26, 'time_epoch': 80.75064, 'eta': 1700.02819, 'eta_hours': 0.47223, 'loss': 0.00906025, 'lr': 0.00055226, 'params': 304204, 'time_iter': 0.21649, 'accuracy': 0.99782, 'f1': 0.99782, 'auc': 0.99999}\n",
      "val: {'epoch': 26, 'time_epoch': 4.07527, 'loss': 0.16948747, 'lr': 0, 'params': 304204, 'time_iter': 0.08671, 'accuracy': 0.9664, 'f1': 0.96762, 'auc': 0.99823}\n",
      "test: {'epoch': 26, 'time_epoch': 3.65563, 'loss': 0.16908276, 'lr': 0, 'params': 304204, 'time_iter': 0.07778, 'accuracy': 0.96644, 'f1': 0.96619, 'auc': 0.99795}\n",
      "> Epoch 26: took 88.6s (avg 82.6s) | Best so far: epoch 23\ttrain_loss: 0.0185 train_accuracy: 0.9948\tval_loss: 0.1178 val_accuracy: 0.9771\ttest_loss: 0.1284 test_accuracy: 0.9785\n",
      "train: {'epoch': 27, 'time_epoch': 68.35438, 'eta': 1621.74544, 'eta_hours': 0.45048, 'loss': 0.01300843, 'lr': 0.00051745, 'params': 304204, 'time_iter': 0.18326, 'accuracy': 0.99698, 'f1': 0.99699, 'auc': 0.99993}\n",
      "val: {'epoch': 27, 'time_epoch': 4.03753, 'loss': 0.18171555, 'lr': 0, 'params': 304204, 'time_iter': 0.0859, 'accuracy': 0.96505, 'f1': 0.96549, 'auc': 0.99808}\n",
      "test: {'epoch': 27, 'time_epoch': 3.94484, 'loss': 0.16818164, 'lr': 0, 'params': 304204, 'time_iter': 0.08393, 'accuracy': 0.96779, 'f1': 0.96731, 'auc': 0.99865}\n",
      "> Epoch 27: took 76.5s (avg 82.3s) | Best so far: epoch 23\ttrain_loss: 0.0185 train_accuracy: 0.9948\tval_loss: 0.1178 val_accuracy: 0.9771\ttest_loss: 0.1284 test_accuracy: 0.9785\n",
      "train: {'epoch': 28, 'time_epoch': 74.89998, 'eta': 1548.88731, 'eta_hours': 0.43025, 'loss': 0.01075112, 'lr': 0.00048255, 'params': 304204, 'time_iter': 0.2008, 'accuracy': 0.99748, 'f1': 0.99748, 'auc': 0.99996}\n",
      "val: {'epoch': 28, 'time_epoch': 4.74708, 'loss': 0.16308625, 'lr': 0, 'params': 304204, 'time_iter': 0.101, 'accuracy': 0.97177, 'f1': 0.97246, 'auc': 0.99672}\n",
      "test: {'epoch': 28, 'time_epoch': 4.58729, 'loss': 0.1729744, 'lr': 0, 'params': 304204, 'time_iter': 0.0976, 'accuracy': 0.97047, 'f1': 0.96874, 'auc': 0.99811}\n",
      "> Epoch 28: took 84.4s (avg 82.4s) | Best so far: epoch 23\ttrain_loss: 0.0185 train_accuracy: 0.9948\tval_loss: 0.1178 val_accuracy: 0.9771\ttest_loss: 0.1284 test_accuracy: 0.9785\n",
      "train: {'epoch': 29, 'time_epoch': 81.53589, 'eta': 1480.31701, 'eta_hours': 0.4112, 'loss': 0.00704413, 'lr': 0.00044774, 'params': 304204, 'time_iter': 0.21859, 'accuracy': 0.99832, 'f1': 0.99833, 'auc': 1.0}\n",
      "val: {'epoch': 29, 'time_epoch': 4.85846, 'loss': 0.1758167, 'lr': 0, 'params': 304204, 'time_iter': 0.10337, 'accuracy': 0.9664, 'f1': 0.96775, 'auc': 0.99612}\n",
      "test: {'epoch': 29, 'time_epoch': 4.11256, 'loss': 0.16556774, 'lr': 0, 'params': 304204, 'time_iter': 0.0875, 'accuracy': 0.96779, 'f1': 0.96605, 'auc': 0.99859}\n",
      "> Epoch 29: took 90.6s (avg 82.7s) | Best so far: epoch 23\ttrain_loss: 0.0185 train_accuracy: 0.9948\tval_loss: 0.1178 val_accuracy: 0.9771\ttest_loss: 0.1284 test_accuracy: 0.9785\n",
      "train: {'epoch': 30, 'time_epoch': 66.85334, 'eta': 1401.91123, 'eta_hours': 0.38942, 'loss': 0.00537128, 'lr': 0.00041318, 'params': 304204, 'time_iter': 0.17923, 'accuracy': 0.99899, 'f1': 0.999, 'auc': 1.0}\n",
      "val: {'epoch': 30, 'time_epoch': 3.80863, 'loss': 0.1814098, 'lr': 0, 'params': 304204, 'time_iter': 0.08103, 'accuracy': 0.97177, 'f1': 0.97255, 'auc': 0.99608}\n",
      "test: {'epoch': 30, 'time_epoch': 4.05953, 'loss': 0.13562514, 'lr': 0, 'params': 304204, 'time_iter': 0.08637, 'accuracy': 0.97315, 'f1': 0.97276, 'auc': 0.99914}\n",
      "> Epoch 30: took 74.8s (avg 82.4s) | Best so far: epoch 23\ttrain_loss: 0.0185 train_accuracy: 0.9948\tval_loss: 0.1178 val_accuracy: 0.9771\ttest_loss: 0.1284 test_accuracy: 0.9785\n",
      "train: {'epoch': 31, 'time_epoch': 76.3121, 'eta': 1329.54804, 'eta_hours': 0.36932, 'loss': 0.00185305, 'lr': 0.00037904, 'params': 304204, 'time_iter': 0.20459, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "val: {'epoch': 31, 'time_epoch': 5.16439, 'loss': 0.12753294, 'lr': 0, 'params': 304204, 'time_iter': 0.10988, 'accuracy': 0.97984, 'f1': 0.98016, 'auc': 0.99859}\n",
      "test: {'epoch': 31, 'time_epoch': 4.8243, 'loss': 0.10785618, 'lr': 0, 'params': 304204, 'time_iter': 0.10264, 'accuracy': 0.97718, 'f1': 0.9769, 'auc': 0.99932}\n",
      "> Epoch 31: took 86.5s (avg 82.6s) | Best so far: epoch 31\ttrain_loss: 0.0019 train_accuracy: 0.9997\tval_loss: 0.1275 val_accuracy: 0.9798\ttest_loss: 0.1079 test_accuracy: 0.9772\n",
      "train: {'epoch': 32, 'time_epoch': 79.19716, 'eta': 1258.43176, 'eta_hours': 0.34956, 'loss': 0.00522256, 'lr': 0.00034549, 'params': 304204, 'time_iter': 0.21232, 'accuracy': 0.99916, 'f1': 0.99917, 'auc': 0.99998}\n",
      "val: {'epoch': 32, 'time_epoch': 3.5765, 'loss': 0.17128579, 'lr': 0, 'params': 304204, 'time_iter': 0.0761, 'accuracy': 0.9664, 'f1': 0.96722, 'auc': 0.99825}\n",
      "test: {'epoch': 32, 'time_epoch': 3.57722, 'loss': 0.14296591, 'lr': 0, 'params': 304204, 'time_iter': 0.07611, 'accuracy': 0.96644, 'f1': 0.96696, 'auc': 0.99913}\n",
      "> Epoch 32: took 86.4s (avg 82.7s) | Best so far: epoch 31\ttrain_loss: 0.0019 train_accuracy: 0.9997\tval_loss: 0.1275 val_accuracy: 0.9798\ttest_loss: 0.1079 test_accuracy: 0.9772\n",
      "train: {'epoch': 33, 'time_epoch': 78.13296, 'eta': 1186.33933, 'eta_hours': 0.32954, 'loss': 0.00151927, 'lr': 0.0003127, 'params': 304204, 'time_iter': 0.20947, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 33, 'time_epoch': 3.78084, 'loss': 0.12518009, 'lr': 0, 'params': 304204, 'time_iter': 0.08044, 'accuracy': 0.98118, 'f1': 0.98164, 'auc': 0.99851}\n",
      "test: {'epoch': 33, 'time_epoch': 3.44013, 'loss': 0.14645588, 'lr': 0, 'params': 304204, 'time_iter': 0.07319, 'accuracy': 0.97315, 'f1': 0.97316, 'auc': 0.99931}\n",
      "> Epoch 33: took 85.5s (avg 82.8s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 34, 'time_epoch': 67.88241, 'eta': 1109.50863, 'eta_hours': 0.3082, 'loss': 0.00343161, 'lr': 0.00028081, 'params': 304204, 'time_iter': 0.18199, 'accuracy': 0.99933, 'f1': 0.99933, 'auc': 1.0}\n",
      "val: {'epoch': 34, 'time_epoch': 3.96717, 'loss': 0.15755472, 'lr': 0, 'params': 304204, 'time_iter': 0.08441, 'accuracy': 0.96909, 'f1': 0.97004, 'auc': 0.99903}\n",
      "test: {'epoch': 34, 'time_epoch': 4.34688, 'loss': 0.22549318, 'lr': 0, 'params': 304204, 'time_iter': 0.09249, 'accuracy': 0.96242, 'f1': 0.96269, 'auc': 0.99908}\n",
      "> Epoch 34: took 76.3s (avg 82.6s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 35, 'time_epoch': 79.43557, 'eta': 1037.66796, 'eta_hours': 0.28824, 'loss': 0.00340161, 'lr': 0.00025, 'params': 304204, 'time_iter': 0.21296, 'accuracy': 0.99933, 'f1': 0.99931, 'auc': 0.99995}\n",
      "val: {'epoch': 35, 'time_epoch': 4.82428, 'loss': 0.18308919, 'lr': 0, 'params': 304204, 'time_iter': 0.10264, 'accuracy': 0.97043, 'f1': 0.97117, 'auc': 0.99795}\n",
      "test: {'epoch': 35, 'time_epoch': 4.63081, 'loss': 0.144326, 'lr': 0, 'params': 304204, 'time_iter': 0.09853, 'accuracy': 0.97584, 'f1': 0.97569, 'auc': 0.99908}\n",
      "> Epoch 35: took 89.0s (avg 82.7s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 36, 'time_epoch': 80.28291, 'eta': 965.71447, 'eta_hours': 0.26825, 'loss': 0.00324505, 'lr': 0.0002204, 'params': 304204, 'time_iter': 0.21524, 'accuracy': 0.99882, 'f1': 0.99882, 'auc': 1.0}\n",
      "val: {'epoch': 36, 'time_epoch': 3.74063, 'loss': 0.1235005, 'lr': 0, 'params': 304204, 'time_iter': 0.07959, 'accuracy': 0.97715, 'f1': 0.97769, 'auc': 0.99923}\n",
      "test: {'epoch': 36, 'time_epoch': 3.90869, 'loss': 0.19079126, 'lr': 0, 'params': 304204, 'time_iter': 0.08316, 'accuracy': 0.9651, 'f1': 0.96499, 'auc': 0.9988}\n",
      "> Epoch 36: took 88.0s (avg 82.9s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 37, 'time_epoch': 66.56376, 'eta': 888.99023, 'eta_hours': 0.24694, 'loss': 0.00209094, 'lr': 0.00019217, 'params': 304204, 'time_iter': 0.17846, 'accuracy': 0.9995, 'f1': 0.99948, 'auc': 1.0}\n",
      "val: {'epoch': 37, 'time_epoch': 4.30088, 'loss': 0.1281917, 'lr': 0, 'params': 304204, 'time_iter': 0.09151, 'accuracy': 0.97446, 'f1': 0.97519, 'auc': 0.99917}\n",
      "test: {'epoch': 37, 'time_epoch': 4.67306, 'loss': 0.18503854, 'lr': 0, 'params': 304204, 'time_iter': 0.09943, 'accuracy': 0.97181, 'f1': 0.97176, 'auc': 0.99841}\n",
      "> Epoch 37: took 75.7s (avg 82.7s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 38, 'time_epoch': 80.97654, 'eta': 816.85218, 'eta_hours': 0.2269, 'loss': 0.00075917, 'lr': 0.00016543, 'params': 304204, 'time_iter': 0.2171, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 38, 'time_epoch': 5.01427, 'loss': 0.1218387, 'lr': 0, 'params': 304204, 'time_iter': 0.10669, 'accuracy': 0.97849, 'f1': 0.97901, 'auc': 0.99848}\n",
      "test: {'epoch': 38, 'time_epoch': 4.76764, 'loss': 0.17684211, 'lr': 0, 'params': 304204, 'time_iter': 0.10144, 'accuracy': 0.97315, 'f1': 0.97267, 'auc': 0.99916}\n",
      "> Epoch 38: took 90.9s (avg 82.9s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 39, 'time_epoch': 73.46914, 'eta': 742.39535, 'eta_hours': 0.20622, 'loss': 0.00065638, 'lr': 0.00014033, 'params': 304204, 'time_iter': 0.19697, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 39, 'time_epoch': 3.73162, 'loss': 0.12915321, 'lr': 0, 'params': 304204, 'time_iter': 0.0794, 'accuracy': 0.97849, 'f1': 0.97885, 'auc': 0.99954}\n",
      "test: {'epoch': 39, 'time_epoch': 3.78088, 'loss': 0.16052204, 'lr': 0, 'params': 304204, 'time_iter': 0.08044, 'accuracy': 0.9745, 'f1': 0.97397, 'auc': 0.99924}\n",
      "> Epoch 39: took 81.1s (avg 82.9s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 40, 'time_epoch': 71.25915, 'eta': 667.50158, 'eta_hours': 0.18542, 'loss': 0.00059963, 'lr': 0.00011698, 'params': 304204, 'time_iter': 0.19104, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 40, 'time_epoch': 4.93731, 'loss': 0.13116683, 'lr': 0, 'params': 304204, 'time_iter': 0.10505, 'accuracy': 0.97581, 'f1': 0.97642, 'auc': 0.99913}\n",
      "test: {'epoch': 40, 'time_epoch': 5.17225, 'loss': 0.16010926, 'lr': 0, 'params': 304204, 'time_iter': 0.11005, 'accuracy': 0.97315, 'f1': 0.97286, 'auc': 0.99917}\n",
      "> Epoch 40: took 81.6s (avg 82.8s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 41, 'time_epoch': 81.02521, 'eta': 594.6411, 'eta_hours': 0.16518, 'loss': 0.00057103, 'lr': 9.549e-05, 'params': 304204, 'time_iter': 0.21723, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 41, 'time_epoch': 4.72644, 'loss': 0.12896796, 'lr': 0, 'params': 304204, 'time_iter': 0.10056, 'accuracy': 0.97984, 'f1': 0.98023, 'auc': 0.9996}\n",
      "test: {'epoch': 41, 'time_epoch': 4.79254, 'loss': 0.16523788, 'lr': 0, 'params': 304204, 'time_iter': 0.10197, 'accuracy': 0.97181, 'f1': 0.97093, 'auc': 0.99931}\n",
      "> Epoch 41: took 90.7s (avg 83.0s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 42, 'time_epoch': 75.41418, 'eta': 520.48743, 'eta_hours': 0.14458, 'loss': 0.0006253, 'lr': 7.598e-05, 'params': 304204, 'time_iter': 0.20218, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 42, 'time_epoch': 4.60956, 'loss': 0.14065393, 'lr': 0, 'params': 304204, 'time_iter': 0.09808, 'accuracy': 0.97849, 'f1': 0.97893, 'auc': 0.99949}\n",
      "test: {'epoch': 42, 'time_epoch': 4.25615, 'loss': 0.18176943, 'lr': 0, 'params': 304204, 'time_iter': 0.09056, 'accuracy': 0.97047, 'f1': 0.96984, 'auc': 0.99931}\n",
      "> Epoch 42: took 84.4s (avg 83.1s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 43, 'time_epoch': 66.6146, 'eta': 445.07653, 'eta_hours': 0.12363, 'loss': 0.00054909, 'lr': 5.853e-05, 'params': 304204, 'time_iter': 0.17859, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 43, 'time_epoch': 4.02628, 'loss': 0.13752089, 'lr': 0, 'params': 304204, 'time_iter': 0.08567, 'accuracy': 0.97849, 'f1': 0.979, 'auc': 0.99957}\n",
      "test: {'epoch': 43, 'time_epoch': 3.89241, 'loss': 0.16884131, 'lr': 0, 'params': 304204, 'time_iter': 0.08282, 'accuracy': 0.97181, 'f1': 0.97154, 'auc': 0.99946}\n",
      "> Epoch 43: took 74.6s (avg 82.9s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 44, 'time_epoch': 74.80384, 'eta': 370.96649, 'eta_hours': 0.10305, 'loss': 0.00051107, 'lr': 4.323e-05, 'params': 304204, 'time_iter': 0.20055, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 44, 'time_epoch': 4.89379, 'loss': 0.14936607, 'lr': 0, 'params': 304204, 'time_iter': 0.10412, 'accuracy': 0.97849, 'f1': 0.9791, 'auc': 0.99952}\n",
      "test: {'epoch': 44, 'time_epoch': 4.64437, 'loss': 0.17924268, 'lr': 0, 'params': 304204, 'time_iter': 0.09882, 'accuracy': 0.9745, 'f1': 0.97394, 'auc': 0.99939}\n",
      "> Epoch 44: took 84.5s (avg 82.9s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 45, 'time_epoch': 82.38228, 'eta': 297.48528, 'eta_hours': 0.08263, 'loss': 0.00188855, 'lr': 3.015e-05, 'params': 304204, 'time_iter': 0.22086, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 45, 'time_epoch': 4.82755, 'loss': 0.13305107, 'lr': 0, 'params': 304204, 'time_iter': 0.10271, 'accuracy': 0.97849, 'f1': 0.97902, 'auc': 0.99941}\n",
      "test: {'epoch': 45, 'time_epoch': 4.39192, 'loss': 0.16886768, 'lr': 0, 'params': 304204, 'time_iter': 0.09345, 'accuracy': 0.97047, 'f1': 0.96972, 'auc': 0.99925}\n",
      "> Epoch 45: took 91.7s (avg 83.1s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 46, 'time_epoch': 64.38743, 'eta': 222.47669, 'eta_hours': 0.0618, 'loss': 0.0004829, 'lr': 1.937e-05, 'params': 304204, 'time_iter': 0.17262, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 46, 'time_epoch': 3.51078, 'loss': 0.13218164, 'lr': 0, 'params': 304204, 'time_iter': 0.0747, 'accuracy': 0.98118, 'f1': 0.98163, 'auc': 0.99953}\n",
      "test: {'epoch': 46, 'time_epoch': 3.60575, 'loss': 0.17019684, 'lr': 0, 'params': 304204, 'time_iter': 0.07672, 'accuracy': 0.9745, 'f1': 0.97371, 'auc': 0.9994}\n",
      "> Epoch 46: took 71.6s (avg 82.8s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 47, 'time_epoch': 68.20723, 'eta': 148.06981, 'eta_hours': 0.04113, 'loss': 0.00048209, 'lr': 1.093e-05, 'params': 304204, 'time_iter': 0.18286, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 47, 'time_epoch': 3.92841, 'loss': 0.13869559, 'lr': 0, 'params': 304204, 'time_iter': 0.08358, 'accuracy': 0.97984, 'f1': 0.98033, 'auc': 0.99958}\n",
      "test: {'epoch': 47, 'time_epoch': 3.78188, 'loss': 0.17895976, 'lr': 0, 'params': 304204, 'time_iter': 0.08047, 'accuracy': 0.97181, 'f1': 0.97102, 'auc': 0.99943}\n",
      "> Epoch 47: took 76.0s (avg 82.7s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 48, 'time_epoch': 72.42327, 'eta': 74.00201, 'eta_hours': 0.02056, 'loss': 0.0004721, 'lr': 4.87e-06, 'params': 304204, 'time_iter': 0.19416, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 48, 'time_epoch': 4.02887, 'loss': 0.13142832, 'lr': 0, 'params': 304204, 'time_iter': 0.08572, 'accuracy': 0.97984, 'f1': 0.98026, 'auc': 0.99957}\n",
      "test: {'epoch': 48, 'time_epoch': 3.71125, 'loss': 0.17463545, 'lr': 0, 'params': 304204, 'time_iter': 0.07896, 'accuracy': 0.97181, 'f1': 0.9712, 'auc': 0.99944}\n",
      "> Epoch 48: took 80.3s (avg 82.7s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "train: {'epoch': 49, 'time_epoch': 72.9795, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.0004704, 'lr': 1.22e-06, 'params': 304204, 'time_iter': 0.19566, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 49, 'time_epoch': 4.05576, 'loss': 0.11995738, 'lr': 0, 'params': 304204, 'time_iter': 0.08629, 'accuracy': 0.98118, 'f1': 0.98163, 'auc': 0.99962}\n",
      "test: {'epoch': 49, 'time_epoch': 3.80559, 'loss': 0.16930226, 'lr': 0, 'params': 304204, 'time_iter': 0.08097, 'accuracy': 0.97181, 'f1': 0.97148, 'auc': 0.99952}\n",
      "> Epoch 49: took 81.0s (avg 82.6s) | Best so far: epoch 33\ttrain_loss: 0.0015 train_accuracy: 0.9998\tval_loss: 0.1252 val_accuracy: 0.9812\ttest_loss: 0.1465 test_accuracy: 0.9731\n",
      "Avg time per epoch: 82.62s\n",
      "Total train loop time: 1.15h\n",
      "Task done, results saved in results\\neural-Act\\0\n",
      "33\n",
      "{'epoch': 33, 'time_epoch': 3.44013, 'loss': 0.14645588, 'lr': 0, 'params': 304204, 'time_iter': 0.07319, 'accuracy': 0.97315, 'f1': 0.97316, 'auc': 0.99931}\n",
      "{'epoch': 33, 'time_epoch': 78.13296, 'eta': 1186.33933, 'eta_hours': 0.32954, 'loss': 0.00151927, 'lr': 0.0003127, 'params': 304204, 'time_iter': 0.20947, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "{'epoch': 33, 'time_epoch': 3.78084, 'loss': 0.12518009, 'lr': 0, 'params': 304204, 'time_iter': 0.08044, 'accuracy': 0.98118, 'f1': 0.98164, 'auc': 0.99851}\n",
      "Results aggregated across runs saved in results\\neural-Act\\agg\n",
      "[*] All done: 2024-02-26 00:18:55.249262\n"
     ]
    }
   ],
   "source": [
    "#Activity  - Using CustomGCN+Exphormer\n",
    "%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0559ac34-fa95-4819-90c9-620c785c71c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-27 00:22:52.477420\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n",
      "  num classes: 7\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [05:43<00:00, 21.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:05:47.07\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [01:50<00:00, 67.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:55.24\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=400, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 5\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 45\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 197319\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 40.17852, 'eta': 1767.85492, 'eta_hours': 0.49107, 'loss': 1.95123484, 'lr': 0.0, 'params': 197319, 'time_iter': 0.10772, 'accuracy': 0.14041, 'f1': 0.06112, 'auc': 0.48172}\n",
      "...computing epoch stats took: 0.16s\n",
      "val: {'epoch': 0, 'time_epoch': 2.8618, 'loss': 1.95121404, 'lr': 0, 'params': 197319, 'time_iter': 0.06089, 'accuracy': 0.15591, 'f1': 0.07634, 'auc': 0.48345}\n",
      "...computing epoch stats took: 0.04s\n",
      "test: {'epoch': 0, 'time_epoch': 2.64398, 'loss': 1.9596483, 'lr': 0, 'params': 197319, 'time_iter': 0.05625, 'accuracy': 0.10738, 'f1': 0.05234, 'auc': 0.487}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 45.9s (avg 45.9s) | Best so far: epoch 0\ttrain_loss: 1.9512 train_accuracy: 0.1404\tval_loss: 1.9512 val_accuracy: 0.1559\ttest_loss: 1.9596 test_accuracy: 0.1074\n",
      "train: {'epoch': 1, 'time_epoch': 36.59286, 'eta': 1650.58468, 'eta_hours': 0.4585, 'loss': 1.71581416, 'lr': 0.0002, 'params': 197319, 'time_iter': 0.0981, 'accuracy': 0.60464, 'f1': 0.60904, 'auc': 0.88569}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 1, 'time_epoch': 2.09258, 'loss': 1.53910363, 'lr': 0, 'params': 197319, 'time_iter': 0.04452, 'accuracy': 0.79167, 'f1': 0.79139, 'auc': 0.96296}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 2.17666, 'loss': 1.53522589, 'lr': 0, 'params': 197319, 'time_iter': 0.04631, 'accuracy': 0.78523, 'f1': 0.78404, 'auc': 0.96614}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 1: took 40.9s (avg 43.4s) | Best so far: epoch 1\ttrain_loss: 1.7158 train_accuracy: 0.6046\tval_loss: 1.5391 val_accuracy: 0.7917\ttest_loss: 1.5352 test_accuracy: 0.7852\n",
      "train: {'epoch': 2, 'time_epoch': 36.4032, 'eta': 1584.44418, 'eta_hours': 0.44012, 'loss': 1.32074643, 'lr': 0.0004, 'params': 197319, 'time_iter': 0.0976, 'accuracy': 0.85472, 'f1': 0.85315, 'auc': 0.97352}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 2, 'time_epoch': 2.2078, 'loss': 1.12528753, 'lr': 0, 'params': 197319, 'time_iter': 0.04697, 'accuracy': 0.89651, 'f1': 0.90062, 'auc': 0.9856}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 2, 'time_epoch': 2.25522, 'loss': 1.13745467, 'lr': 0, 'params': 197319, 'time_iter': 0.04798, 'accuracy': 0.88859, 'f1': 0.8866, 'auc': 0.98259}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 2: took 41.0s (avg 42.6s) | Best so far: epoch 2\ttrain_loss: 1.3207 train_accuracy: 0.8547\tval_loss: 1.1253 val_accuracy: 0.8965\ttest_loss: 1.1375 test_accuracy: 0.8886\n",
      "train: {'epoch': 3, 'time_epoch': 36.212, 'eta': 1531.21248, 'eta_hours': 0.42534, 'loss': 0.92206345, 'lr': 0.0006, 'params': 197319, 'time_iter': 0.09708, 'accuracy': 0.91132, 'f1': 0.91092, 'auc': 0.98508}\n",
      "val: {'epoch': 3, 'time_epoch': 2.22264, 'loss': 0.91076549, 'lr': 0, 'params': 197319, 'time_iter': 0.04729, 'accuracy': 0.81183, 'f1': 0.82114, 'auc': 0.96767}\n",
      "test: {'epoch': 3, 'time_epoch': 2.26092, 'loss': 0.88463058, 'lr': 0, 'params': 197319, 'time_iter': 0.0481, 'accuracy': 0.83624, 'f1': 0.84049, 'auc': 0.974}\n",
      "> Epoch 3: took 40.8s (avg 42.1s) | Best so far: epoch 2\ttrain_loss: 1.3207 train_accuracy: 0.8547\tval_loss: 1.1253 val_accuracy: 0.8965\ttest_loss: 1.1375 test_accuracy: 0.8886\n",
      "train: {'epoch': 4, 'time_epoch': 35.93635, 'eta': 1482.58343, 'eta_hours': 0.41183, 'loss': 0.63006854, 'lr': 0.0008, 'params': 197319, 'time_iter': 0.09634, 'accuracy': 0.91518, 'f1': 0.91495, 'auc': 0.98724}\n",
      "val: {'epoch': 4, 'time_epoch': 2.3145, 'loss': 0.52799477, 'lr': 0, 'params': 197319, 'time_iter': 0.04924, 'accuracy': 0.91935, 'f1': 0.92242, 'auc': 0.98889}\n",
      "test: {'epoch': 4, 'time_epoch': 2.22261, 'loss': 0.53264366, 'lr': 0, 'params': 197319, 'time_iter': 0.04729, 'accuracy': 0.91678, 'f1': 0.91782, 'auc': 0.98814}\n",
      "> Epoch 4: took 40.5s (avg 41.8s) | Best so far: epoch 4\ttrain_loss: 0.6301 train_accuracy: 0.9152\tval_loss: 0.5280 val_accuracy: 0.9194\ttest_loss: 0.5326 test_accuracy: 0.9168\n",
      "train: {'epoch': 5, 'time_epoch': 39.01895, 'eta': 1458.22219, 'eta_hours': 0.40506, 'loss': 0.45427331, 'lr': 0.001, 'params': 197319, 'time_iter': 0.10461, 'accuracy': 0.91938, 'f1': 0.91917, 'auc': 0.98895}\n",
      "val: {'epoch': 5, 'time_epoch': 2.29548, 'loss': 0.4688565, 'lr': 0, 'params': 197319, 'time_iter': 0.04884, 'accuracy': 0.89247, 'f1': 0.8914, 'auc': 0.98832}\n",
      "test: {'epoch': 5, 'time_epoch': 2.2719, 'loss': 0.47837026, 'lr': 0, 'params': 197319, 'time_iter': 0.04834, 'accuracy': 0.88993, 'f1': 0.88801, 'auc': 0.98449}\n",
      "> Epoch 5: took 43.7s (avg 42.1s) | Best so far: epoch 4\ttrain_loss: 0.6301 train_accuracy: 0.9152\tval_loss: 0.5280 val_accuracy: 0.9194\ttest_loss: 0.5326 test_accuracy: 0.9168\n",
      "train: {'epoch': 6, 'time_epoch': 41.86464, 'eta': 1445.12111, 'eta_hours': 0.40142, 'loss': 0.32205267, 'lr': 0.00099846, 'params': 197319, 'time_iter': 0.11224, 'accuracy': 0.94004, 'f1': 0.93992, 'auc': 0.99241}\n",
      "val: {'epoch': 6, 'time_epoch': 2.36438, 'loss': 0.37279956, 'lr': 0, 'params': 197319, 'time_iter': 0.05031, 'accuracy': 0.9086, 'f1': 0.90992, 'auc': 0.99283}\n",
      "test: {'epoch': 6, 'time_epoch': 2.42188, 'loss': 0.2976467, 'lr': 0, 'params': 197319, 'time_iter': 0.05153, 'accuracy': 0.9396, 'f1': 0.93537, 'auc': 0.99319}\n",
      "> Epoch 6: took 46.7s (avg 42.8s) | Best so far: epoch 4\ttrain_loss: 0.6301 train_accuracy: 0.9152\tval_loss: 0.5280 val_accuracy: 0.9194\ttest_loss: 0.5326 test_accuracy: 0.9168\n",
      "train: {'epoch': 7, 'time_epoch': 39.36545, 'eta': 1413.27038, 'eta_hours': 0.39258, 'loss': 0.24778078, 'lr': 0.00099384, 'params': 197319, 'time_iter': 0.10554, 'accuracy': 0.95129, 'f1': 0.95117, 'auc': 0.99484}\n",
      "val: {'epoch': 7, 'time_epoch': 2.32839, 'loss': 0.30833374, 'lr': 0, 'params': 197319, 'time_iter': 0.04954, 'accuracy': 0.92608, 'f1': 0.92566, 'auc': 0.99425}\n",
      "test: {'epoch': 7, 'time_epoch': 2.42361, 'loss': 0.31910889, 'lr': 0, 'params': 197319, 'time_iter': 0.05157, 'accuracy': 0.91946, 'f1': 0.916, 'auc': 0.99508}\n",
      "> Epoch 7: took 44.2s (avg 43.0s) | Best so far: epoch 7\ttrain_loss: 0.2478 train_accuracy: 0.9513\tval_loss: 0.3083 val_accuracy: 0.9261\ttest_loss: 0.3191 test_accuracy: 0.9195\n",
      "train: {'epoch': 8, 'time_epoch': 41.21884, 'eta': 1387.16327, 'eta_hours': 0.38532, 'loss': 0.19760082, 'lr': 0.00098618, 'params': 197319, 'time_iter': 0.11051, 'accuracy': 0.95868, 'f1': 0.95862, 'auc': 0.9954}\n",
      "val: {'epoch': 8, 'time_epoch': 2.87801, 'loss': 0.24437709, 'lr': 0, 'params': 197319, 'time_iter': 0.06123, 'accuracy': 0.94489, 'f1': 0.94605, 'auc': 0.99331}\n",
      "test: {'epoch': 8, 'time_epoch': 3.56105, 'loss': 0.23504838, 'lr': 0, 'params': 197319, 'time_iter': 0.07577, 'accuracy': 0.94362, 'f1': 0.94388, 'auc': 0.99414}\n",
      "> Epoch 8: took 47.7s (avg 43.5s) | Best so far: epoch 8\ttrain_loss: 0.1976 train_accuracy: 0.9587\tval_loss: 0.2444 val_accuracy: 0.9449\ttest_loss: 0.2350 test_accuracy: 0.9436\n",
      "train: {'epoch': 9, 'time_epoch': 37.75348, 'eta': 1345.90502, 'eta_hours': 0.37386, 'loss': 0.16544021, 'lr': 0.00097553, 'params': 197319, 'time_iter': 0.10122, 'accuracy': 0.96305, 'f1': 0.96304, 'auc': 0.99628}\n",
      "val: {'epoch': 9, 'time_epoch': 2.33771, 'loss': 0.17202189, 'lr': 0, 'params': 197319, 'time_iter': 0.04974, 'accuracy': 0.96102, 'f1': 0.96207, 'auc': 0.99654}\n",
      "test: {'epoch': 9, 'time_epoch': 2.27744, 'loss': 0.17932504, 'lr': 0, 'params': 197319, 'time_iter': 0.04846, 'accuracy': 0.95973, 'f1': 0.95997, 'auc': 0.99778}\n",
      "> Epoch 9: took 42.5s (avg 43.4s) | Best so far: epoch 9\ttrain_loss: 0.1654 train_accuracy: 0.9630\tval_loss: 0.1720 val_accuracy: 0.9610\ttest_loss: 0.1793 test_accuracy: 0.9597\n",
      "train: {'epoch': 10, 'time_epoch': 37.00994, 'eta': 1302.98582, 'eta_hours': 0.36194, 'loss': 0.14690928, 'lr': 0.00096194, 'params': 197319, 'time_iter': 0.09922, 'accuracy': 0.96775, 'f1': 0.96769, 'auc': 0.99706}\n",
      "val: {'epoch': 10, 'time_epoch': 2.28706, 'loss': 0.23680344, 'lr': 0, 'params': 197319, 'time_iter': 0.04866, 'accuracy': 0.9422, 'f1': 0.94379, 'auc': 0.9952}\n",
      "test: {'epoch': 10, 'time_epoch': 2.27756, 'loss': 0.21770807, 'lr': 0, 'params': 197319, 'time_iter': 0.04846, 'accuracy': 0.94497, 'f1': 0.94379, 'auc': 0.99447}\n",
      "> Epoch 10: took 41.7s (avg 43.2s) | Best so far: epoch 9\ttrain_loss: 0.1654 train_accuracy: 0.9630\tval_loss: 0.1720 val_accuracy: 0.9610\ttest_loss: 0.1793 test_accuracy: 0.9597\n",
      "train: {'epoch': 11, 'time_epoch': 38.4634, 'eta': 1265.0485, 'eta_hours': 0.3514, 'loss': 0.1183494, 'lr': 0.0009455, 'params': 197319, 'time_iter': 0.10312, 'accuracy': 0.97497, 'f1': 0.97493, 'auc': 0.99755}\n",
      "val: {'epoch': 11, 'time_epoch': 2.42953, 'loss': 0.2966565, 'lr': 0, 'params': 197319, 'time_iter': 0.05169, 'accuracy': 0.92473, 'f1': 0.9268, 'auc': 0.9918}\n",
      "test: {'epoch': 11, 'time_epoch': 3.41133, 'loss': 0.32389884, 'lr': 0, 'params': 197319, 'time_iter': 0.07258, 'accuracy': 0.92617, 'f1': 0.92932, 'auc': 0.99233}\n",
      "> Epoch 11: took 44.4s (avg 43.3s) | Best so far: epoch 9\ttrain_loss: 0.1654 train_accuracy: 0.9630\tval_loss: 0.1720 val_accuracy: 0.9610\ttest_loss: 0.1793 test_accuracy: 0.9597\n",
      "train: {'epoch': 12, 'time_epoch': 42.46791, 'eta': 1236.88749, 'eta_hours': 0.34358, 'loss': 0.11838712, 'lr': 0.00092632, 'params': 197319, 'time_iter': 0.11385, 'accuracy': 0.97212, 'f1': 0.97211, 'auc': 0.99732}\n",
      "val: {'epoch': 12, 'time_epoch': 2.27416, 'loss': 0.15294973, 'lr': 0, 'params': 197319, 'time_iter': 0.04839, 'accuracy': 0.9664, 'f1': 0.96705, 'auc': 0.99691}\n",
      "test: {'epoch': 12, 'time_epoch': 2.64808, 'loss': 0.18146493, 'lr': 0, 'params': 197319, 'time_iter': 0.05634, 'accuracy': 0.96107, 'f1': 0.96092, 'auc': 0.99412}\n",
      "> Epoch 12: took 47.5s (avg 43.7s) | Best so far: epoch 12\ttrain_loss: 0.1184 train_accuracy: 0.9721\tval_loss: 0.1529 val_accuracy: 0.9664\ttest_loss: 0.1815 test_accuracy: 0.9611\n",
      "train: {'epoch': 13, 'time_epoch': 41.64222, 'eta': 1204.85434, 'eta_hours': 0.33468, 'loss': 0.090518, 'lr': 0.00090451, 'params': 197319, 'time_iter': 0.11164, 'accuracy': 0.97632, 'f1': 0.97629, 'auc': 0.99856}\n",
      "val: {'epoch': 13, 'time_epoch': 2.40394, 'loss': 0.17352228, 'lr': 0, 'params': 197319, 'time_iter': 0.05115, 'accuracy': 0.95565, 'f1': 0.95675, 'auc': 0.99761}\n",
      "test: {'epoch': 13, 'time_epoch': 2.24498, 'loss': 0.17638808, 'lr': 0, 'params': 197319, 'time_iter': 0.04777, 'accuracy': 0.9557, 'f1': 0.95599, 'auc': 0.99881}\n",
      "> Epoch 13: took 46.4s (avg 43.9s) | Best so far: epoch 12\ttrain_loss: 0.1184 train_accuracy: 0.9721\tval_loss: 0.1529 val_accuracy: 0.9664\ttest_loss: 0.1815 test_accuracy: 0.9611\n",
      "train: {'epoch': 14, 'time_epoch': 38.16893, 'eta': 1164.59339, 'eta_hours': 0.3235, 'loss': 0.09149952, 'lr': 0.0008802, 'params': 197319, 'time_iter': 0.10233, 'accuracy': 0.97901, 'f1': 0.97901, 'auc': 0.99847}\n",
      "val: {'epoch': 14, 'time_epoch': 2.41409, 'loss': 0.23706504, 'lr': 0, 'params': 197319, 'time_iter': 0.05136, 'accuracy': 0.93683, 'f1': 0.93834, 'auc': 0.99557}\n",
      "test: {'epoch': 14, 'time_epoch': 2.17708, 'loss': 0.17956547, 'lr': 0, 'params': 197319, 'time_iter': 0.04632, 'accuracy': 0.95705, 'f1': 0.95461, 'auc': 0.9956}\n",
      "> Epoch 14: took 42.9s (avg 43.8s) | Best so far: epoch 12\ttrain_loss: 0.1184 train_accuracy: 0.9721\tval_loss: 0.1529 val_accuracy: 0.9664\ttest_loss: 0.1815 test_accuracy: 0.9611\n",
      "train: {'epoch': 15, 'time_epoch': 42.52653, 'eta': 1132.49209, 'eta_hours': 0.31458, 'loss': 0.07606866, 'lr': 0.00085355, 'params': 197319, 'time_iter': 0.11401, 'accuracy': 0.98253, 'f1': 0.98256, 'auc': 0.9991}\n",
      "val: {'epoch': 15, 'time_epoch': 4.15391, 'loss': 0.30942761, 'lr': 0, 'params': 197319, 'time_iter': 0.08838, 'accuracy': 0.92742, 'f1': 0.92724, 'auc': 0.99482}\n",
      "test: {'epoch': 15, 'time_epoch': 2.40774, 'loss': 0.28569841, 'lr': 0, 'params': 197319, 'time_iter': 0.05123, 'accuracy': 0.93557, 'f1': 0.9331, 'auc': 0.99422}\n",
      "> Epoch 15: took 49.2s (avg 44.1s) | Best so far: epoch 12\ttrain_loss: 0.1184 train_accuracy: 0.9721\tval_loss: 0.1529 val_accuracy: 0.9664\ttest_loss: 0.1815 test_accuracy: 0.9611\n",
      "train: {'epoch': 16, 'time_epoch': 42.94402, 'eta': 1099.85193, 'eta_hours': 0.30551, 'loss': 0.07235771, 'lr': 0.00082472, 'params': 197319, 'time_iter': 0.11513, 'accuracy': 0.98236, 'f1': 0.98237, 'auc': 0.99917}\n",
      "val: {'epoch': 16, 'time_epoch': 2.38395, 'loss': 0.185877, 'lr': 0, 'params': 197319, 'time_iter': 0.05072, 'accuracy': 0.95699, 'f1': 0.95829, 'auc': 0.99622}\n",
      "test: {'epoch': 16, 'time_epoch': 2.39007, 'loss': 0.22102177, 'lr': 0, 'params': 197319, 'time_iter': 0.05085, 'accuracy': 0.94631, 'f1': 0.94727, 'auc': 0.99499}\n",
      "> Epoch 16: took 47.8s (avg 44.3s) | Best so far: epoch 12\ttrain_loss: 0.1184 train_accuracy: 0.9721\tval_loss: 0.1529 val_accuracy: 0.9664\ttest_loss: 0.1815 test_accuracy: 0.9611\n",
      "train: {'epoch': 17, 'time_epoch': 38.66197, 'eta': 1059.64382, 'eta_hours': 0.29435, 'loss': 0.06005352, 'lr': 0.00079389, 'params': 197319, 'time_iter': 0.10365, 'accuracy': 0.98539, 'f1': 0.9854, 'auc': 0.99943}\n",
      "val: {'epoch': 17, 'time_epoch': 3.04068, 'loss': 0.15852963, 'lr': 0, 'params': 197319, 'time_iter': 0.0647, 'accuracy': 0.95968, 'f1': 0.96053, 'auc': 0.99623}\n",
      "test: {'epoch': 17, 'time_epoch': 2.28186, 'loss': 0.14645728, 'lr': 0, 'params': 197319, 'time_iter': 0.04855, 'accuracy': 0.96644, 'f1': 0.96544, 'auc': 0.99689}\n",
      "> Epoch 17: took 44.1s (avg 44.3s) | Best so far: epoch 12\ttrain_loss: 0.1184 train_accuracy: 0.9721\tval_loss: 0.1529 val_accuracy: 0.9664\ttest_loss: 0.1815 test_accuracy: 0.9611\n",
      "train: {'epoch': 18, 'time_epoch': 43.18819, 'eta': 1025.79224, 'eta_hours': 0.28494, 'loss': 0.05368351, 'lr': 0.00076125, 'params': 197319, 'time_iter': 0.11579, 'accuracy': 0.98808, 'f1': 0.98812, 'auc': 0.99909}\n",
      "val: {'epoch': 18, 'time_epoch': 3.48212, 'loss': 0.17825133, 'lr': 0, 'params': 197319, 'time_iter': 0.07409, 'accuracy': 0.96505, 'f1': 0.96616, 'auc': 0.99545}\n",
      "test: {'epoch': 18, 'time_epoch': 2.4168, 'loss': 0.21913058, 'lr': 0, 'params': 197319, 'time_iter': 0.05142, 'accuracy': 0.95168, 'f1': 0.95243, 'auc': 0.99397}\n",
      "> Epoch 18: took 49.2s (avg 44.6s) | Best so far: epoch 12\ttrain_loss: 0.1184 train_accuracy: 0.9721\tval_loss: 0.1529 val_accuracy: 0.9664\ttest_loss: 0.1815 test_accuracy: 0.9611\n",
      "train: {'epoch': 19, 'time_epoch': 37.60728, 'eta': 984.03086, 'eta_hours': 0.27334, 'loss': 0.04207766, 'lr': 0.000727, 'params': 197319, 'time_iter': 0.10082, 'accuracy': 0.98959, 'f1': 0.98958, 'auc': 0.99964}\n",
      "val: {'epoch': 19, 'time_epoch': 2.31139, 'loss': 0.18339016, 'lr': 0, 'params': 197319, 'time_iter': 0.04918, 'accuracy': 0.96102, 'f1': 0.96164, 'auc': 0.99647}\n",
      "test: {'epoch': 19, 'time_epoch': 2.2048, 'loss': 0.19597687, 'lr': 0, 'params': 197319, 'time_iter': 0.04691, 'accuracy': 0.9557, 'f1': 0.95524, 'auc': 0.99773}\n",
      "> Epoch 19: took 42.2s (avg 44.5s) | Best so far: epoch 12\ttrain_loss: 0.1184 train_accuracy: 0.9721\tval_loss: 0.1529 val_accuracy: 0.9664\ttest_loss: 0.1815 test_accuracy: 0.9611\n",
      "train: {'epoch': 20, 'time_epoch': 38.20921, 'eta': 943.35303, 'eta_hours': 0.26204, 'loss': 0.0345998, 'lr': 0.00069134, 'params': 197319, 'time_iter': 0.10244, 'accuracy': 0.99261, 'f1': 0.9926, 'auc': 0.99975}\n",
      "val: {'epoch': 20, 'time_epoch': 2.1505, 'loss': 0.26519182, 'lr': 0, 'params': 197319, 'time_iter': 0.04576, 'accuracy': 0.94624, 'f1': 0.94642, 'auc': 0.99484}\n",
      "test: {'epoch': 20, 'time_epoch': 2.2525, 'loss': 0.25376327, 'lr': 0, 'params': 197319, 'time_iter': 0.04793, 'accuracy': 0.94228, 'f1': 0.94045, 'auc': 0.99673}\n",
      "> Epoch 20: took 42.7s (avg 44.4s) | Best so far: epoch 12\ttrain_loss: 0.1184 train_accuracy: 0.9721\tval_loss: 0.1529 val_accuracy: 0.9664\ttest_loss: 0.1815 test_accuracy: 0.9611\n",
      "train: {'epoch': 21, 'time_epoch': 42.35812, 'eta': 907.23711, 'eta_hours': 0.25201, 'loss': 0.0323837, 'lr': 0.00065451, 'params': 197319, 'time_iter': 0.11356, 'accuracy': 0.99261, 'f1': 0.99257, 'auc': 0.9998}\n",
      "val: {'epoch': 21, 'time_epoch': 3.2938, 'loss': 0.18371542, 'lr': 0, 'params': 197319, 'time_iter': 0.07008, 'accuracy': 0.95968, 'f1': 0.96064, 'auc': 0.99748}\n",
      "test: {'epoch': 21, 'time_epoch': 2.28406, 'loss': 0.15051234, 'lr': 0, 'params': 197319, 'time_iter': 0.0486, 'accuracy': 0.96779, 'f1': 0.96757, 'auc': 0.99814}\n",
      "> Epoch 21: took 48.1s (avg 44.5s) | Best so far: epoch 12\ttrain_loss: 0.1184 train_accuracy: 0.9721\tval_loss: 0.1529 val_accuracy: 0.9664\ttest_loss: 0.1815 test_accuracy: 0.9611\n",
      "train: {'epoch': 22, 'time_epoch': 42.76769, 'eta': 870.97015, 'eta_hours': 0.24194, 'loss': 0.02453143, 'lr': 0.00061672, 'params': 197319, 'time_iter': 0.11466, 'accuracy': 0.99446, 'f1': 0.99448, 'auc': 0.99988}\n",
      "val: {'epoch': 22, 'time_epoch': 3.2255, 'loss': 0.16685373, 'lr': 0, 'params': 197319, 'time_iter': 0.06863, 'accuracy': 0.96505, 'f1': 0.9657, 'auc': 0.99605}\n",
      "test: {'epoch': 22, 'time_epoch': 2.95395, 'loss': 0.18738858, 'lr': 0, 'params': 197319, 'time_iter': 0.06285, 'accuracy': 0.96242, 'f1': 0.9617, 'auc': 0.99762}\n",
      "> Epoch 22: took 49.0s (avg 44.7s) | Best so far: epoch 12\ttrain_loss: 0.1184 train_accuracy: 0.9721\tval_loss: 0.1529 val_accuracy: 0.9664\ttest_loss: 0.1815 test_accuracy: 0.9611\n",
      "train: {'epoch': 23, 'time_epoch': 37.22068, 'eta': 829.30784, 'eta_hours': 0.23036, 'loss': 0.01846248, 'lr': 0.00057822, 'params': 197319, 'time_iter': 0.09979, 'accuracy': 0.99597, 'f1': 0.99598, 'auc': 0.99995}\n",
      "val: {'epoch': 23, 'time_epoch': 2.367, 'loss': 0.16958924, 'lr': 0, 'params': 197319, 'time_iter': 0.05036, 'accuracy': 0.96774, 'f1': 0.96878, 'auc': 0.99858}\n",
      "test: {'epoch': 23, 'time_epoch': 2.20934, 'loss': 0.18122045, 'lr': 0, 'params': 197319, 'time_iter': 0.04701, 'accuracy': 0.9651, 'f1': 0.96505, 'auc': 0.99688}\n",
      "> Epoch 23: took 41.9s (avg 44.6s) | Best so far: epoch 23\ttrain_loss: 0.0185 train_accuracy: 0.9960\tval_loss: 0.1696 val_accuracy: 0.9677\ttest_loss: 0.1812 test_accuracy: 0.9651\n",
      "train: {'epoch': 24, 'time_epoch': 38.50818, 'eta': 789.03086, 'eta_hours': 0.21918, 'loss': 0.01839932, 'lr': 0.00053923, 'params': 197319, 'time_iter': 0.10324, 'accuracy': 0.9953, 'f1': 0.99527, 'auc': 0.99997}\n",
      "val: {'epoch': 24, 'time_epoch': 2.30571, 'loss': 0.22456652, 'lr': 0, 'params': 197319, 'time_iter': 0.04906, 'accuracy': 0.95968, 'f1': 0.9601, 'auc': 0.99588}\n",
      "test: {'epoch': 24, 'time_epoch': 2.21601, 'loss': 0.18752592, 'lr': 0, 'params': 197319, 'time_iter': 0.04715, 'accuracy': 0.96644, 'f1': 0.96693, 'auc': 0.99615}\n",
      "> Epoch 24: took 43.1s (avg 44.6s) | Best so far: epoch 23\ttrain_loss: 0.0185 train_accuracy: 0.9960\tval_loss: 0.1696 val_accuracy: 0.9677\ttest_loss: 0.1812 test_accuracy: 0.9651\n",
      "train: {'epoch': 25, 'time_epoch': 42.28469, 'eta': 751.64969, 'eta_hours': 0.20879, 'loss': 0.02074308, 'lr': 0.0005, 'params': 197319, 'time_iter': 0.11336, 'accuracy': 0.99446, 'f1': 0.99447, 'auc': 0.99996}\n",
      "val: {'epoch': 25, 'time_epoch': 3.72222, 'loss': 0.20565781, 'lr': 0, 'params': 197319, 'time_iter': 0.0792, 'accuracy': 0.96237, 'f1': 0.96324, 'auc': 0.99826}\n",
      "test: {'epoch': 25, 'time_epoch': 2.35637, 'loss': 0.19509757, 'lr': 0, 'params': 197319, 'time_iter': 0.05014, 'accuracy': 0.96376, 'f1': 0.96256, 'auc': 0.9959}\n",
      "> Epoch 25: took 48.5s (avg 44.7s) | Best so far: epoch 23\ttrain_loss: 0.0185 train_accuracy: 0.9960\tval_loss: 0.1696 val_accuracy: 0.9677\ttest_loss: 0.1812 test_accuracy: 0.9651\n",
      "train: {'epoch': 26, 'time_epoch': 43.97039, 'eta': 715.0291, 'eta_hours': 0.19862, 'loss': 0.01160037, 'lr': 0.00046077, 'params': 197319, 'time_iter': 0.11788, 'accuracy': 0.99765, 'f1': 0.99765, 'auc': 0.99996}\n",
      "val: {'epoch': 26, 'time_epoch': 2.78732, 'loss': 0.12710982, 'lr': 0, 'params': 197319, 'time_iter': 0.0593, 'accuracy': 0.97446, 'f1': 0.97504, 'auc': 0.99729}\n",
      "test: {'epoch': 26, 'time_epoch': 2.36322, 'loss': 0.18010114, 'lr': 0, 'params': 197319, 'time_iter': 0.05028, 'accuracy': 0.96376, 'f1': 0.96356, 'auc': 0.99751}\n",
      "> Epoch 26: took 49.2s (avg 44.9s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 27, 'time_epoch': 37.74259, 'eta': 674.10236, 'eta_hours': 0.18725, 'loss': 0.01191284, 'lr': 0.00042178, 'params': 197319, 'time_iter': 0.10119, 'accuracy': 0.99765, 'f1': 0.99766, 'auc': 0.99996}\n",
      "val: {'epoch': 27, 'time_epoch': 2.6487, 'loss': 0.15014671, 'lr': 0, 'params': 197319, 'time_iter': 0.05636, 'accuracy': 0.96909, 'f1': 0.96979, 'auc': 0.99774}\n",
      "test: {'epoch': 27, 'time_epoch': 2.9378, 'loss': 0.19800872, 'lr': 0, 'params': 197319, 'time_iter': 0.06251, 'accuracy': 0.9651, 'f1': 0.96443, 'auc': 0.99616}\n",
      "> Epoch 27: took 43.4s (avg 44.8s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 28, 'time_epoch': 42.92462, 'eta': 636.25426, 'eta_hours': 0.17674, 'loss': 0.01003139, 'lr': 0.00038328, 'params': 197319, 'time_iter': 0.11508, 'accuracy': 0.99765, 'f1': 0.99762, 'auc': 0.99999}\n",
      "val: {'epoch': 28, 'time_epoch': 2.30687, 'loss': 0.18263571, 'lr': 0, 'params': 197319, 'time_iter': 0.04908, 'accuracy': 0.96774, 'f1': 0.96859, 'auc': 0.99658}\n",
      "test: {'epoch': 28, 'time_epoch': 3.30388, 'loss': 0.18825937, 'lr': 0, 'params': 197319, 'time_iter': 0.0703, 'accuracy': 0.96376, 'f1': 0.9635, 'auc': 0.99685}\n",
      "> Epoch 28: took 48.6s (avg 45.0s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 29, 'time_epoch': 42.81939, 'eta': 598.01512, 'eta_hours': 0.16612, 'loss': 0.00514499, 'lr': 0.00034549, 'params': 197319, 'time_iter': 0.1148, 'accuracy': 0.99899, 'f1': 0.999, 'auc': 1.0}\n",
      "val: {'epoch': 29, 'time_epoch': 2.30826, 'loss': 0.16369201, 'lr': 0, 'params': 197319, 'time_iter': 0.04911, 'accuracy': 0.96774, 'f1': 0.96877, 'auc': 0.99817}\n",
      "test: {'epoch': 29, 'time_epoch': 2.55421, 'loss': 0.20245973, 'lr': 0, 'params': 197319, 'time_iter': 0.05434, 'accuracy': 0.96376, 'f1': 0.96244, 'auc': 0.99666}\n",
      "> Epoch 29: took 47.8s (avg 45.1s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 30, 'time_epoch': 39.54916, 'eta': 558.0036, 'eta_hours': 0.155, 'loss': 0.00445131, 'lr': 0.00030866, 'params': 197319, 'time_iter': 0.10603, 'accuracy': 0.9995, 'f1': 0.9995, 'auc': 1.0}\n",
      "val: {'epoch': 30, 'time_epoch': 2.71518, 'loss': 0.1784736, 'lr': 0, 'params': 197319, 'time_iter': 0.05777, 'accuracy': 0.96909, 'f1': 0.96993, 'auc': 0.99751}\n",
      "test: {'epoch': 30, 'time_epoch': 3.17189, 'loss': 0.16939607, 'lr': 0, 'params': 197319, 'time_iter': 0.06749, 'accuracy': 0.97181, 'f1': 0.97148, 'auc': 0.99735}\n",
      "> Epoch 30: took 45.5s (avg 45.1s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 31, 'time_epoch': 43.50128, 'eta': 519.62653, 'eta_hours': 0.14434, 'loss': 0.00332511, 'lr': 0.000273, 'params': 197319, 'time_iter': 0.11663, 'accuracy': 0.99933, 'f1': 0.99934, 'auc': 1.0}\n",
      "val: {'epoch': 31, 'time_epoch': 2.34693, 'loss': 0.18072011, 'lr': 0, 'params': 197319, 'time_iter': 0.04993, 'accuracy': 0.97043, 'f1': 0.97119, 'auc': 0.99703}\n",
      "test: {'epoch': 31, 'time_epoch': 3.45192, 'loss': 0.18269916, 'lr': 0, 'params': 197319, 'time_iter': 0.07345, 'accuracy': 0.96913, 'f1': 0.96918, 'auc': 0.99526}\n",
      "> Epoch 31: took 49.4s (avg 45.2s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 32, 'time_epoch': 41.83838, 'eta': 480.3342, 'eta_hours': 0.13343, 'loss': 0.00508207, 'lr': 0.00023875, 'params': 197319, 'time_iter': 0.11217, 'accuracy': 0.99882, 'f1': 0.99883, 'auc': 1.0}\n",
      "val: {'epoch': 32, 'time_epoch': 2.25849, 'loss': 0.16089666, 'lr': 0, 'params': 197319, 'time_iter': 0.04805, 'accuracy': 0.97312, 'f1': 0.97388, 'auc': 0.99711}\n",
      "test: {'epoch': 32, 'time_epoch': 2.33914, 'loss': 0.20382914, 'lr': 0, 'params': 197319, 'time_iter': 0.04977, 'accuracy': 0.96644, 'f1': 0.96559, 'auc': 0.99647}\n",
      "> Epoch 32: took 46.5s (avg 45.2s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 33, 'time_epoch': 40.92841, 'eta': 440.59771, 'eta_hours': 0.12239, 'loss': 0.00321842, 'lr': 0.00020611, 'params': 197319, 'time_iter': 0.10973, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "val: {'epoch': 33, 'time_epoch': 4.14542, 'loss': 0.1691311, 'lr': 0, 'params': 197319, 'time_iter': 0.0882, 'accuracy': 0.97043, 'f1': 0.97125, 'auc': 0.99798}\n",
      "test: {'epoch': 33, 'time_epoch': 2.53457, 'loss': 0.1879574, 'lr': 0, 'params': 197319, 'time_iter': 0.05393, 'accuracy': 0.97047, 'f1': 0.96927, 'auc': 0.99656}\n",
      "> Epoch 33: took 47.7s (avg 45.3s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 34, 'time_epoch': 37.3992, 'eta': 399.78476, 'eta_hours': 0.11105, 'loss': 0.00118829, 'lr': 0.00017528, 'params': 197319, 'time_iter': 0.10027, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 34, 'time_epoch': 2.2882, 'loss': 0.17489955, 'lr': 0, 'params': 197319, 'time_iter': 0.04869, 'accuracy': 0.96774, 'f1': 0.96861, 'auc': 0.997}\n",
      "test: {'epoch': 34, 'time_epoch': 2.18975, 'loss': 0.21113419, 'lr': 0, 'params': 197319, 'time_iter': 0.04659, 'accuracy': 0.96644, 'f1': 0.96545, 'auc': 0.99654}\n",
      "> Epoch 34: took 42.0s (avg 45.2s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 35, 'time_epoch': 37.0159, 'eta': 359.06564, 'eta_hours': 0.09974, 'loss': 0.00118055, 'lr': 0.00014645, 'params': 197319, 'time_iter': 0.09924, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 35, 'time_epoch': 2.22949, 'loss': 0.22710416, 'lr': 0, 'params': 197319, 'time_iter': 0.04744, 'accuracy': 0.96237, 'f1': 0.96356, 'auc': 0.99753}\n",
      "test: {'epoch': 35, 'time_epoch': 2.17066, 'loss': 0.2015787, 'lr': 0, 'params': 197319, 'time_iter': 0.04618, 'accuracy': 0.96913, 'f1': 0.96861, 'auc': 0.99715}\n",
      "> Epoch 35: took 41.5s (avg 45.1s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 36, 'time_epoch': 38.46127, 'eta': 318.85921, 'eta_hours': 0.08857, 'loss': 0.00141022, 'lr': 0.0001198, 'params': 197319, 'time_iter': 0.10311, 'accuracy': 0.99983, 'f1': 0.99984, 'auc': 1.0}\n",
      "val: {'epoch': 36, 'time_epoch': 2.20878, 'loss': 0.21364048, 'lr': 0, 'params': 197319, 'time_iter': 0.047, 'accuracy': 0.96237, 'f1': 0.96361, 'auc': 0.99789}\n",
      "test: {'epoch': 36, 'time_epoch': 2.65164, 'loss': 0.19131158, 'lr': 0, 'params': 197319, 'time_iter': 0.05642, 'accuracy': 0.96779, 'f1': 0.96702, 'auc': 0.99752}\n",
      "> Epoch 36: took 43.4s (avg 45.1s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 37, 'time_epoch': 42.76401, 'eta': 279.53723, 'eta_hours': 0.07765, 'loss': 0.00092596, 'lr': 9.549e-05, 'params': 197319, 'time_iter': 0.11465, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 37, 'time_epoch': 2.56706, 'loss': 0.20263798, 'lr': 0, 'params': 197319, 'time_iter': 0.05462, 'accuracy': 0.96774, 'f1': 0.96865, 'auc': 0.99754}\n",
      "test: {'epoch': 37, 'time_epoch': 2.3043, 'loss': 0.19312371, 'lr': 0, 'params': 197319, 'time_iter': 0.04903, 'accuracy': 0.97047, 'f1': 0.96928, 'auc': 0.99703}\n",
      "> Epoch 37: took 47.7s (avg 45.1s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 38, 'time_epoch': 44.00953, 'eta': 240.23037, 'eta_hours': 0.06673, 'loss': 0.00086659, 'lr': 7.368e-05, 'params': 197319, 'time_iter': 0.11799, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 38, 'time_epoch': 3.43142, 'loss': 0.2016937, 'lr': 0, 'params': 197319, 'time_iter': 0.07301, 'accuracy': 0.96505, 'f1': 0.9661, 'auc': 0.99787}\n",
      "test: {'epoch': 38, 'time_epoch': 2.26132, 'loss': 0.19821755, 'lr': 0, 'params': 197319, 'time_iter': 0.04811, 'accuracy': 0.97047, 'f1': 0.96951, 'auc': 0.99729}\n",
      "> Epoch 38: took 49.8s (avg 45.3s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 39, 'time_epoch': 36.95007, 'eta': 199.80593, 'eta_hours': 0.0555, 'loss': 0.00085929, 'lr': 5.45e-05, 'params': 197319, 'time_iter': 0.09906, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 39, 'time_epoch': 2.27134, 'loss': 0.20100861, 'lr': 0, 'params': 197319, 'time_iter': 0.04833, 'accuracy': 0.9664, 'f1': 0.96719, 'auc': 0.99772}\n",
      "test: {'epoch': 39, 'time_epoch': 2.19239, 'loss': 0.20170679, 'lr': 0, 'params': 197319, 'time_iter': 0.04665, 'accuracy': 0.96913, 'f1': 0.96795, 'auc': 0.99698}\n",
      "> Epoch 39: took 41.5s (avg 45.2s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 40, 'time_epoch': 38.00371, 'eta': 159.65377, 'eta_hours': 0.04435, 'loss': 0.00181991, 'lr': 3.806e-05, 'params': 197319, 'time_iter': 0.10189, 'accuracy': 0.99983, 'f1': 0.99984, 'auc': 1.0}\n",
      "val: {'epoch': 40, 'time_epoch': 2.24434, 'loss': 0.19987166, 'lr': 0, 'params': 197319, 'time_iter': 0.04775, 'accuracy': 0.96505, 'f1': 0.96587, 'auc': 0.99786}\n",
      "test: {'epoch': 40, 'time_epoch': 2.24381, 'loss': 0.19563186, 'lr': 0, 'params': 197319, 'time_iter': 0.04774, 'accuracy': 0.97047, 'f1': 0.9695, 'auc': 0.99683}\n",
      "> Epoch 40: took 42.6s (avg 45.1s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 41, 'time_epoch': 38.71268, 'eta': 119.65456, 'eta_hours': 0.03324, 'loss': 0.00243532, 'lr': 2.447e-05, 'params': 197319, 'time_iter': 0.10379, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "val: {'epoch': 41, 'time_epoch': 2.28791, 'loss': 0.19219594, 'lr': 0, 'params': 197319, 'time_iter': 0.04868, 'accuracy': 0.96774, 'f1': 0.96856, 'auc': 0.99758}\n",
      "test: {'epoch': 41, 'time_epoch': 2.84047, 'loss': 0.19262046, 'lr': 0, 'params': 197319, 'time_iter': 0.06044, 'accuracy': 0.97181, 'f1': 0.9707, 'auc': 0.99745}\n",
      "> Epoch 41: took 43.9s (avg 45.1s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 42, 'time_epoch': 43.40083, 'eta': 79.93324, 'eta_hours': 0.0222, 'loss': 0.00076709, 'lr': 1.382e-05, 'params': 197319, 'time_iter': 0.11636, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 42, 'time_epoch': 2.20022, 'loss': 0.1777685, 'lr': 0, 'params': 197319, 'time_iter': 0.04681, 'accuracy': 0.97177, 'f1': 0.97245, 'auc': 0.99767}\n",
      "test: {'epoch': 42, 'time_epoch': 2.66402, 'loss': 0.18966535, 'lr': 0, 'params': 197319, 'time_iter': 0.05668, 'accuracy': 0.97315, 'f1': 0.972, 'auc': 0.9975}\n",
      "> Epoch 42: took 48.3s (avg 45.2s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 43, 'time_epoch': 43.43227, 'eta': 40.04538, 'eta_hours': 0.01112, 'loss': 0.00075668, 'lr': 6.16e-06, 'params': 197319, 'time_iter': 0.11644, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 43, 'time_epoch': 2.55169, 'loss': 0.18257416, 'lr': 0, 'params': 197319, 'time_iter': 0.05429, 'accuracy': 0.96909, 'f1': 0.96988, 'auc': 0.99749}\n",
      "test: {'epoch': 43, 'time_epoch': 2.29911, 'loss': 0.2018983, 'lr': 0, 'params': 197319, 'time_iter': 0.04892, 'accuracy': 0.97181, 'f1': 0.97094, 'auc': 0.99711}\n",
      "> Epoch 43: took 48.4s (avg 45.2s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "train: {'epoch': 44, 'time_epoch': 38.55557, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.0007522, 'lr': 1.54e-06, 'params': 197319, 'time_iter': 0.10337, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 44, 'time_epoch': 2.26035, 'loss': 0.18383223, 'lr': 0, 'params': 197319, 'time_iter': 0.04809, 'accuracy': 0.9664, 'f1': 0.96712, 'auc': 0.99753}\n",
      "test: {'epoch': 44, 'time_epoch': 2.35864, 'loss': 0.2033009, 'lr': 0, 'params': 197319, 'time_iter': 0.05018, 'accuracy': 0.97315, 'f1': 0.97192, 'auc': 0.99689}\n",
      "> Epoch 44: took 43.3s (avg 45.2s) | Best so far: epoch 26\ttrain_loss: 0.0116 train_accuracy: 0.9977\tval_loss: 0.1271 val_accuracy: 0.9745\ttest_loss: 0.1801 test_accuracy: 0.9638\n",
      "Avg time per epoch: 45.18s\n",
      "Total train loop time: 0.56h\n",
      "Task done, results saved in results\\neural-Act\\0\n",
      "26\n",
      "{'epoch': 26, 'time_epoch': 2.36322, 'loss': 0.18010114, 'lr': 0, 'params': 197319, 'time_iter': 0.05028, 'accuracy': 0.96376, 'f1': 0.96356, 'auc': 0.99751}\n",
      "{'epoch': 26, 'time_epoch': 43.97039, 'eta': 715.0291, 'eta_hours': 0.19862, 'loss': 0.01160037, 'lr': 0.00046077, 'params': 197319, 'time_iter': 0.11788, 'accuracy': 0.99765, 'f1': 0.99765, 'auc': 0.99996}\n",
      "{'epoch': 26, 'time_epoch': 2.78732, 'loss': 0.12710982, 'lr': 0, 'params': 197319, 'time_iter': 0.0593, 'accuracy': 0.97446, 'f1': 0.97504, 'auc': 0.99729}\n",
      "Results aggregated across runs saved in results\\neural-Act\\agg\n",
      "[*] All done: 2024-02-27 01:04:39.400401\n"
     ]
    }
   ],
   "source": [
    "#Activity  - Using Exphormer\n",
    "%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97711f53-5869-4276-9a43-f62fd88680cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-01 19:02:45.597161\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 7\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [03:23<00:00, 36.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:03:36.88\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [00:48<00:00, 152.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:01.59\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=400, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 5\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 75\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 197319\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 33.42729, 'eta': 2473.61928, 'eta_hours': 0.68712, 'loss': 1.95124155, 'lr': 0.0, 'params': 197319, 'time_iter': 0.08962, 'accuracy': 0.14024, 'f1': 0.06091, 'auc': 0.48164}\n",
      "...computing epoch stats took: 0.11s\n",
      "val: {'epoch': 0, 'time_epoch': 2.13339, 'loss': 1.9512409, 'lr': 0, 'params': 197319, 'time_iter': 0.04539, 'accuracy': 0.15591, 'f1': 0.07635, 'auc': 0.4834}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 0, 'time_epoch': 2.02918, 'loss': 1.95966097, 'lr': 0, 'params': 197319, 'time_iter': 0.04317, 'accuracy': 0.10872, 'f1': 0.05464, 'auc': 0.48699}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 0: took 37.8s (avg 37.8s) | Best so far: epoch 0\ttrain_loss: 1.9512 train_accuracy: 0.1402\tval_loss: 1.9512 val_accuracy: 0.1559\ttest_loss: 1.9597 test_accuracy: 0.1087\n",
      "train: {'epoch': 1, 'time_epoch': 32.12253, 'eta': 2392.56831, 'eta_hours': 0.6646, 'loss': 1.71633635, 'lr': 0.0002, 'params': 197319, 'time_iter': 0.08612, 'accuracy': 0.60363, 'f1': 0.60838, 'auc': 0.88489}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 1, 'time_epoch': 1.94903, 'loss': 1.53896675, 'lr': 0, 'params': 197319, 'time_iter': 0.04147, 'accuracy': 0.79301, 'f1': 0.79248, 'auc': 0.96373}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 1.97248, 'loss': 1.53619821, 'lr': 0, 'params': 197319, 'time_iter': 0.04197, 'accuracy': 0.78658, 'f1': 0.78535, 'auc': 0.96648}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 36.1s (avg 36.9s) | Best so far: epoch 1\ttrain_loss: 1.7163 train_accuracy: 0.6036\tval_loss: 1.5390 val_accuracy: 0.7930\ttest_loss: 1.5362 test_accuracy: 0.7866\n",
      "train: {'epoch': 2, 'time_epoch': 31.62536, 'eta': 2332.20434, 'eta_hours': 0.64783, 'loss': 1.32152392, 'lr': 0.0004, 'params': 197319, 'time_iter': 0.08479, 'accuracy': 0.85287, 'f1': 0.85146, 'auc': 0.9732}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 1.95054, 'loss': 1.14371541, 'lr': 0, 'params': 197319, 'time_iter': 0.0415, 'accuracy': 0.89247, 'f1': 0.89697, 'auc': 0.98474}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 1.94219, 'loss': 1.15464553, 'lr': 0, 'params': 197319, 'time_iter': 0.04132, 'accuracy': 0.87248, 'f1': 0.87631, 'auc': 0.98196}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 35.6s (avg 36.5s) | Best so far: epoch 2\ttrain_loss: 1.3215 train_accuracy: 0.8529\tval_loss: 1.1437 val_accuracy: 0.8925\ttest_loss: 1.1546 test_accuracy: 0.8725\n",
      "train: {'epoch': 3, 'time_epoch': 31.7302, 'eta': 2288.07055, 'eta_hours': 0.63558, 'loss': 0.92222149, 'lr': 0.0006, 'params': 197319, 'time_iter': 0.08507, 'accuracy': 0.91233, 'f1': 0.91185, 'auc': 0.9861}\n",
      "val: {'epoch': 3, 'time_epoch': 1.97607, 'loss': 0.88845115, 'lr': 0, 'params': 197319, 'time_iter': 0.04204, 'accuracy': 0.83468, 'f1': 0.83815, 'auc': 0.97561}\n",
      "test: {'epoch': 3, 'time_epoch': 1.96417, 'loss': 0.88693575, 'lr': 0, 'params': 197319, 'time_iter': 0.04179, 'accuracy': 0.84161, 'f1': 0.84342, 'auc': 0.97711}\n",
      "> Epoch 3: took 35.7s (avg 36.3s) | Best so far: epoch 2\ttrain_loss: 1.3215 train_accuracy: 0.8529\tval_loss: 1.1437 val_accuracy: 0.8925\ttest_loss: 1.1546 test_accuracy: 0.8725\n",
      "train: {'epoch': 4, 'time_epoch': 32.9986, 'eta': 2266.65571, 'eta_hours': 0.62963, 'loss': 0.62885702, 'lr': 0.0008, 'params': 197319, 'time_iter': 0.08847, 'accuracy': 0.91821, 'f1': 0.91781, 'auc': 0.98712}\n",
      "val: {'epoch': 4, 'time_epoch': 2.15025, 'loss': 0.55291424, 'lr': 0, 'params': 197319, 'time_iter': 0.04575, 'accuracy': 0.90726, 'f1': 0.91072, 'auc': 0.98835}\n",
      "test: {'epoch': 4, 'time_epoch': 2.11961, 'loss': 0.57147557, 'lr': 0, 'params': 197319, 'time_iter': 0.0451, 'accuracy': 0.88993, 'f1': 0.89575, 'auc': 0.98611}\n",
      "> Epoch 4: took 37.3s (avg 36.5s) | Best so far: epoch 4\ttrain_loss: 0.6289 train_accuracy: 0.9182\tval_loss: 0.5529 val_accuracy: 0.9073\ttest_loss: 0.5715 test_accuracy: 0.8899\n",
      "train: {'epoch': 5, 'time_epoch': 32.80629, 'eta': 2239.1681, 'eta_hours': 0.62199, 'loss': 0.45631044, 'lr': 0.001, 'params': 197319, 'time_iter': 0.08795, 'accuracy': 0.91821, 'f1': 0.91794, 'auc': 0.98876}\n",
      "val: {'epoch': 5, 'time_epoch': 2.01129, 'loss': 0.43341901, 'lr': 0, 'params': 197319, 'time_iter': 0.04279, 'accuracy': 0.90726, 'f1': 0.90999, 'auc': 0.98904}\n",
      "test: {'epoch': 5, 'time_epoch': 2.065, 'loss': 0.45612613, 'lr': 0, 'params': 197319, 'time_iter': 0.04394, 'accuracy': 0.8953, 'f1': 0.8965, 'auc': 0.99072}\n",
      "> Epoch 5: took 36.9s (avg 36.6s) | Best so far: epoch 4\ttrain_loss: 0.6289 train_accuracy: 0.9182\tval_loss: 0.5529 val_accuracy: 0.9073\ttest_loss: 0.5715 test_accuracy: 0.8899\n",
      "train: {'epoch': 6, 'time_epoch': 33.08209, 'eta': 2212.84002, 'eta_hours': 0.61468, 'loss': 0.30801465, 'lr': 0.0009995, 'params': 197319, 'time_iter': 0.08869, 'accuracy': 0.94575, 'f1': 0.94558, 'auc': 0.99289}\n",
      "val: {'epoch': 6, 'time_epoch': 2.03927, 'loss': 0.28598459, 'lr': 0, 'params': 197319, 'time_iter': 0.04339, 'accuracy': 0.93414, 'f1': 0.93568, 'auc': 0.99607}\n",
      "test: {'epoch': 6, 'time_epoch': 2.05551, 'loss': 0.27215159, 'lr': 0, 'params': 197319, 'time_iter': 0.04373, 'accuracy': 0.94228, 'f1': 0.93999, 'auc': 0.99442}\n",
      "> Epoch 6: took 37.2s (avg 36.7s) | Best so far: epoch 6\ttrain_loss: 0.3080 train_accuracy: 0.9457\tval_loss: 0.2860 val_accuracy: 0.9341\ttest_loss: 0.2722 test_accuracy: 0.9423\n",
      "train: {'epoch': 7, 'time_epoch': 33.86012, 'eta': 2191.3395, 'eta_hours': 0.60871, 'loss': 0.24832502, 'lr': 0.00099799, 'params': 197319, 'time_iter': 0.09078, 'accuracy': 0.95045, 'f1': 0.95041, 'auc': 0.99434}\n",
      "val: {'epoch': 7, 'time_epoch': 2.05703, 'loss': 0.3147707, 'lr': 0, 'params': 197319, 'time_iter': 0.04377, 'accuracy': 0.9328, 'f1': 0.93555, 'auc': 0.98374}\n",
      "test: {'epoch': 7, 'time_epoch': 2.07397, 'loss': 0.27929952, 'lr': 0, 'params': 197319, 'time_iter': 0.04413, 'accuracy': 0.9396, 'f1': 0.94076, 'auc': 0.98994}\n",
      "> Epoch 7: took 38.0s (avg 36.8s) | Best so far: epoch 6\ttrain_loss: 0.3080 train_accuracy: 0.9457\tval_loss: 0.2860 val_accuracy: 0.9341\ttest_loss: 0.2722 test_accuracy: 0.9423\n",
      "train: {'epoch': 8, 'time_epoch': 33.08536, 'eta': 2161.41083, 'eta_hours': 0.60039, 'loss': 0.19865019, 'lr': 0.00099547, 'params': 197319, 'time_iter': 0.0887, 'accuracy': 0.95818, 'f1': 0.95804, 'auc': 0.99559}\n",
      "val: {'epoch': 8, 'time_epoch': 2.07521, 'loss': 0.21587881, 'lr': 0, 'params': 197319, 'time_iter': 0.04415, 'accuracy': 0.95027, 'f1': 0.9517, 'auc': 0.99305}\n",
      "test: {'epoch': 8, 'time_epoch': 2.12539, 'loss': 0.19152688, 'lr': 0, 'params': 197319, 'time_iter': 0.04522, 'accuracy': 0.96107, 'f1': 0.96025, 'auc': 0.99537}\n",
      "> Epoch 8: took 37.3s (avg 36.9s) | Best so far: epoch 8\ttrain_loss: 0.1987 train_accuracy: 0.9582\tval_loss: 0.2159 val_accuracy: 0.9503\ttest_loss: 0.1915 test_accuracy: 0.9611\n",
      "train: {'epoch': 9, 'time_epoch': 33.36727, 'eta': 2132.68322, 'eta_hours': 0.59241, 'loss': 0.15587991, 'lr': 0.00099196, 'params': 197319, 'time_iter': 0.08946, 'accuracy': 0.96691, 'f1': 0.96681, 'auc': 0.99755}\n",
      "val: {'epoch': 9, 'time_epoch': 2.07307, 'loss': 0.27467659, 'lr': 0, 'params': 197319, 'time_iter': 0.04411, 'accuracy': 0.93145, 'f1': 0.93325, 'auc': 0.99202}\n",
      "test: {'epoch': 9, 'time_epoch': 2.04182, 'loss': 0.2460314, 'lr': 0, 'params': 197319, 'time_iter': 0.04344, 'accuracy': 0.93691, 'f1': 0.93645, 'auc': 0.99324}\n",
      "> Epoch 9: took 37.5s (avg 36.9s) | Best so far: epoch 8\ttrain_loss: 0.1987 train_accuracy: 0.9582\tval_loss: 0.2159 val_accuracy: 0.9503\ttest_loss: 0.1915 test_accuracy: 0.9611\n",
      "train: {'epoch': 10, 'time_epoch': 33.42622, 'eta': 2103.45503, 'eta_hours': 0.58429, 'loss': 0.14246196, 'lr': 0.00098746, 'params': 197319, 'time_iter': 0.08961, 'accuracy': 0.96809, 'f1': 0.96799, 'auc': 0.99708}\n",
      "val: {'epoch': 10, 'time_epoch': 2.01252, 'loss': 0.25208728, 'lr': 0, 'params': 197319, 'time_iter': 0.04282, 'accuracy': 0.94086, 'f1': 0.942, 'auc': 0.99408}\n",
      "test: {'epoch': 10, 'time_epoch': 2.05001, 'loss': 0.20739647, 'lr': 0, 'params': 197319, 'time_iter': 0.04362, 'accuracy': 0.95436, 'f1': 0.95339, 'auc': 0.99667}\n",
      "> Epoch 10: took 37.5s (avg 37.0s) | Best so far: epoch 8\ttrain_loss: 0.1987 train_accuracy: 0.9582\tval_loss: 0.2159 val_accuracy: 0.9503\ttest_loss: 0.1915 test_accuracy: 0.9611\n",
      "train: {'epoch': 11, 'time_epoch': 33.05875, 'eta': 2071.59792, 'eta_hours': 0.57544, 'loss': 0.11671324, 'lr': 0.00098198, 'params': 197319, 'time_iter': 0.08863, 'accuracy': 0.97397, 'f1': 0.97393, 'auc': 0.99827}\n",
      "val: {'epoch': 11, 'time_epoch': 2.10923, 'loss': 0.23556946, 'lr': 0, 'params': 197319, 'time_iter': 0.04488, 'accuracy': 0.93817, 'f1': 0.94049, 'auc': 0.99456}\n",
      "test: {'epoch': 11, 'time_epoch': 2.0133, 'loss': 0.19279303, 'lr': 0, 'params': 197319, 'time_iter': 0.04284, 'accuracy': 0.94631, 'f1': 0.9478, 'auc': 0.99719}\n",
      "> Epoch 11: took 37.2s (avg 37.0s) | Best so far: epoch 8\ttrain_loss: 0.1987 train_accuracy: 0.9582\tval_loss: 0.2159 val_accuracy: 0.9503\ttest_loss: 0.1915 test_accuracy: 0.9611\n",
      "train: {'epoch': 12, 'time_epoch': 32.86299, 'eta': 2038.62234, 'eta_hours': 0.56628, 'loss': 0.10992334, 'lr': 0.00097553, 'params': 197319, 'time_iter': 0.0881, 'accuracy': 0.97363, 'f1': 0.97369, 'auc': 0.99818}\n",
      "val: {'epoch': 12, 'time_epoch': 2.00951, 'loss': 0.15687027, 'lr': 0, 'params': 197319, 'time_iter': 0.04276, 'accuracy': 0.95968, 'f1': 0.96079, 'auc': 0.99818}\n",
      "test: {'epoch': 12, 'time_epoch': 2.02484, 'loss': 0.15243207, 'lr': 0, 'params': 197319, 'time_iter': 0.04308, 'accuracy': 0.95973, 'f1': 0.9584, 'auc': 0.99721}\n",
      "> Epoch 12: took 36.9s (avg 37.0s) | Best so far: epoch 12\ttrain_loss: 0.1099 train_accuracy: 0.9736\tval_loss: 0.1569 val_accuracy: 0.9597\ttest_loss: 0.1524 test_accuracy: 0.9597\n",
      "train: {'epoch': 13, 'time_epoch': 33.1433, 'eta': 2006.88419, 'eta_hours': 0.55747, 'loss': 0.09418341, 'lr': 0.00096812, 'params': 197319, 'time_iter': 0.08886, 'accuracy': 0.97665, 'f1': 0.97662, 'auc': 0.99849}\n",
      "val: {'epoch': 13, 'time_epoch': 1.98945, 'loss': 0.21962706, 'lr': 0, 'params': 197319, 'time_iter': 0.04233, 'accuracy': 0.94489, 'f1': 0.94551, 'auc': 0.99514}\n",
      "test: {'epoch': 13, 'time_epoch': 2.05072, 'loss': 0.18930305, 'lr': 0, 'params': 197319, 'time_iter': 0.04363, 'accuracy': 0.95168, 'f1': 0.95176, 'auc': 0.99759}\n",
      "> Epoch 13: took 37.2s (avg 37.0s) | Best so far: epoch 12\ttrain_loss: 0.1099 train_accuracy: 0.9736\tval_loss: 0.1569 val_accuracy: 0.9597\ttest_loss: 0.1524 test_accuracy: 0.9597\n",
      "train: {'epoch': 14, 'time_epoch': 33.35595, 'eta': 1975.8093, 'eta_hours': 0.54884, 'loss': 0.08472804, 'lr': 0.00095976, 'params': 197319, 'time_iter': 0.08943, 'accuracy': 0.97968, 'f1': 0.97961, 'auc': 0.99893}\n",
      "val: {'epoch': 14, 'time_epoch': 2.15974, 'loss': 0.17210519, 'lr': 0, 'params': 197319, 'time_iter': 0.04595, 'accuracy': 0.95833, 'f1': 0.95872, 'auc': 0.99575}\n",
      "test: {'epoch': 14, 'time_epoch': 2.06476, 'loss': 0.21429383, 'lr': 0, 'params': 197319, 'time_iter': 0.04393, 'accuracy': 0.95034, 'f1': 0.95008, 'auc': 0.99504}\n",
      "> Epoch 14: took 37.6s (avg 37.1s) | Best so far: epoch 12\ttrain_loss: 0.1099 train_accuracy: 0.9736\tval_loss: 0.1569 val_accuracy: 0.9597\ttest_loss: 0.1524 test_accuracy: 0.9597\n",
      "train: {'epoch': 15, 'time_epoch': 32.93557, 'eta': 1942.89911, 'eta_hours': 0.53969, 'loss': 0.0800317, 'lr': 0.00095048, 'params': 197319, 'time_iter': 0.0883, 'accuracy': 0.97951, 'f1': 0.97954, 'auc': 0.99883}\n",
      "val: {'epoch': 15, 'time_epoch': 2.06219, 'loss': 0.25063599, 'lr': 0, 'params': 197319, 'time_iter': 0.04388, 'accuracy': 0.93817, 'f1': 0.93939, 'auc': 0.99439}\n",
      "test: {'epoch': 15, 'time_epoch': 2.08782, 'loss': 0.26935036, 'lr': 0, 'params': 197319, 'time_iter': 0.04442, 'accuracy': 0.93557, 'f1': 0.93576, 'auc': 0.99609}\n",
      "> Epoch 15: took 37.1s (avg 37.1s) | Best so far: epoch 12\ttrain_loss: 0.1099 train_accuracy: 0.9736\tval_loss: 0.1569 val_accuracy: 0.9597\ttest_loss: 0.1524 test_accuracy: 0.9597\n",
      "train: {'epoch': 16, 'time_epoch': 33.05965, 'eta': 1910.40928, 'eta_hours': 0.53067, 'loss': 0.07384142, 'lr': 0.0009403, 'params': 197319, 'time_iter': 0.08863, 'accuracy': 0.98337, 'f1': 0.98341, 'auc': 0.99863}\n",
      "val: {'epoch': 16, 'time_epoch': 2.06834, 'loss': 0.19459953, 'lr': 0, 'params': 197319, 'time_iter': 0.04401, 'accuracy': 0.95027, 'f1': 0.9511, 'auc': 0.99573}\n",
      "test: {'epoch': 16, 'time_epoch': 2.06317, 'loss': 0.20234105, 'lr': 0, 'params': 197319, 'time_iter': 0.0439, 'accuracy': 0.95302, 'f1': 0.95333, 'auc': 0.9973}\n",
      "> Epoch 16: took 37.2s (avg 37.1s) | Best so far: epoch 12\ttrain_loss: 0.1099 train_accuracy: 0.9736\tval_loss: 0.1569 val_accuracy: 0.9597\ttest_loss: 0.1524 test_accuracy: 0.9597\n",
      "train: {'epoch': 17, 'time_epoch': 33.95923, 'eta': 1880.70479, 'eta_hours': 0.52242, 'loss': 0.06665773, 'lr': 0.00092922, 'params': 197319, 'time_iter': 0.09104, 'accuracy': 0.9822, 'f1': 0.98214, 'auc': 0.99939}\n",
      "val: {'epoch': 17, 'time_epoch': 2.17553, 'loss': 0.21192233, 'lr': 0, 'params': 197319, 'time_iter': 0.04629, 'accuracy': 0.94892, 'f1': 0.94993, 'auc': 0.99661}\n",
      "test: {'epoch': 17, 'time_epoch': 2.06489, 'loss': 0.17340388, 'lr': 0, 'params': 197319, 'time_iter': 0.04393, 'accuracy': 0.95839, 'f1': 0.95853, 'auc': 0.99733}\n",
      "> Epoch 17: took 38.2s (avg 37.1s) | Best so far: epoch 12\ttrain_loss: 0.1099 train_accuracy: 0.9736\tval_loss: 0.1569 val_accuracy: 0.9597\ttest_loss: 0.1524 test_accuracy: 0.9597\n",
      "train: {'epoch': 18, 'time_epoch': 33.19565, 'eta': 1848.3019, 'eta_hours': 0.51342, 'loss': 0.06143596, 'lr': 0.00091729, 'params': 197319, 'time_iter': 0.089, 'accuracy': 0.98455, 'f1': 0.98448, 'auc': 0.99943}\n",
      "val: {'epoch': 18, 'time_epoch': 2.02071, 'loss': 0.17191265, 'lr': 0, 'params': 197319, 'time_iter': 0.04299, 'accuracy': 0.96102, 'f1': 0.96177, 'auc': 0.99803}\n",
      "test: {'epoch': 18, 'time_epoch': 2.04569, 'loss': 0.23817829, 'lr': 0, 'params': 197319, 'time_iter': 0.04353, 'accuracy': 0.94765, 'f1': 0.94952, 'auc': 0.99705}\n",
      "> Epoch 18: took 37.3s (avg 37.2s) | Best so far: epoch 18\ttrain_loss: 0.0614 train_accuracy: 0.9846\tval_loss: 0.1719 val_accuracy: 0.9610\ttest_loss: 0.2382 test_accuracy: 0.9476\n",
      "train: {'epoch': 19, 'time_epoch': 33.02169, 'eta': 1815.34132, 'eta_hours': 0.50426, 'loss': 0.06465354, 'lr': 0.00090451, 'params': 197319, 'time_iter': 0.08853, 'accuracy': 0.98438, 'f1': 0.98438, 'auc': 0.99938}\n",
      "val: {'epoch': 19, 'time_epoch': 2.03261, 'loss': 0.18141315, 'lr': 0, 'params': 197319, 'time_iter': 0.04325, 'accuracy': 0.95968, 'f1': 0.96055, 'auc': 0.99689}\n",
      "test: {'epoch': 19, 'time_epoch': 2.05999, 'loss': 0.18663256, 'lr': 0, 'params': 197319, 'time_iter': 0.04383, 'accuracy': 0.95705, 'f1': 0.95771, 'auc': 0.99767}\n",
      "> Epoch 19: took 37.2s (avg 37.2s) | Best so far: epoch 18\ttrain_loss: 0.0614 train_accuracy: 0.9846\tval_loss: 0.1719 val_accuracy: 0.9610\ttest_loss: 0.2382 test_accuracy: 0.9476\n",
      "train: {'epoch': 20, 'time_epoch': 33.41787, 'eta': 1783.39368, 'eta_hours': 0.49539, 'loss': 0.05469502, 'lr': 0.00089092, 'params': 197319, 'time_iter': 0.08959, 'accuracy': 0.98572, 'f1': 0.98569, 'auc': 0.99951}\n",
      "val: {'epoch': 20, 'time_epoch': 2.11096, 'loss': 0.27493734, 'lr': 0, 'params': 197319, 'time_iter': 0.04491, 'accuracy': 0.94355, 'f1': 0.94563, 'auc': 0.99581}\n",
      "test: {'epoch': 20, 'time_epoch': 2.03322, 'loss': 0.19238315, 'lr': 0, 'params': 197319, 'time_iter': 0.04326, 'accuracy': 0.95302, 'f1': 0.95103, 'auc': 0.99818}\n",
      "> Epoch 20: took 37.6s (avg 37.2s) | Best so far: epoch 18\ttrain_loss: 0.0614 train_accuracy: 0.9846\tval_loss: 0.1719 val_accuracy: 0.9610\ttest_loss: 0.2382 test_accuracy: 0.9476\n",
      "train: {'epoch': 21, 'time_epoch': 32.85705, 'eta': 1749.96131, 'eta_hours': 0.4861, 'loss': 0.04016694, 'lr': 0.00087654, 'params': 197319, 'time_iter': 0.08809, 'accuracy': 0.99026, 'f1': 0.99026, 'auc': 0.99941}\n",
      "val: {'epoch': 21, 'time_epoch': 1.99949, 'loss': 0.26517269, 'lr': 0, 'params': 197319, 'time_iter': 0.04254, 'accuracy': 0.93952, 'f1': 0.94115, 'auc': 0.99665}\n",
      "test: {'epoch': 21, 'time_epoch': 2.06471, 'loss': 0.26953623, 'lr': 0, 'params': 197319, 'time_iter': 0.04393, 'accuracy': 0.93826, 'f1': 0.9348, 'auc': 0.99692}\n",
      "> Epoch 21: took 37.0s (avg 37.2s) | Best so far: epoch 18\ttrain_loss: 0.0614 train_accuracy: 0.9846\tval_loss: 0.1719 val_accuracy: 0.9610\ttest_loss: 0.2382 test_accuracy: 0.9476\n",
      "train: {'epoch': 22, 'time_epoch': 32.75328, 'eta': 1716.34437, 'eta_hours': 0.47676, 'loss': 0.04533089, 'lr': 0.0008614, 'params': 197319, 'time_iter': 0.08781, 'accuracy': 0.98925, 'f1': 0.98925, 'auc': 0.99946}\n",
      "val: {'epoch': 22, 'time_epoch': 2.00248, 'loss': 0.20682175, 'lr': 0, 'params': 197319, 'time_iter': 0.04261, 'accuracy': 0.94892, 'f1': 0.95037, 'auc': 0.99809}\n",
      "test: {'epoch': 22, 'time_epoch': 2.01535, 'loss': 0.1960502, 'lr': 0, 'params': 197319, 'time_iter': 0.04288, 'accuracy': 0.95973, 'f1': 0.95949, 'auc': 0.99635}\n",
      "> Epoch 22: took 36.8s (avg 37.2s) | Best so far: epoch 18\ttrain_loss: 0.0614 train_accuracy: 0.9846\tval_loss: 0.1719 val_accuracy: 0.9610\ttest_loss: 0.2382 test_accuracy: 0.9476\n",
      "train: {'epoch': 23, 'time_epoch': 33.43817, 'eta': 1684.25479, 'eta_hours': 0.46785, 'loss': 0.03205988, 'lr': 0.00084553, 'params': 197319, 'time_iter': 0.08965, 'accuracy': 0.99211, 'f1': 0.9921, 'auc': 0.99962}\n",
      "val: {'epoch': 23, 'time_epoch': 2.16988, 'loss': 0.20698497, 'lr': 0, 'params': 197319, 'time_iter': 0.04617, 'accuracy': 0.95565, 'f1': 0.95659, 'auc': 0.99758}\n",
      "test: {'epoch': 23, 'time_epoch': 2.13714, 'loss': 0.21083338, 'lr': 0, 'params': 197319, 'time_iter': 0.04547, 'accuracy': 0.95839, 'f1': 0.95774, 'auc': 0.99644}\n",
      "> Epoch 23: took 37.8s (avg 37.2s) | Best so far: epoch 18\ttrain_loss: 0.0614 train_accuracy: 0.9846\tval_loss: 0.1719 val_accuracy: 0.9610\ttest_loss: 0.2382 test_accuracy: 0.9476\n",
      "train: {'epoch': 24, 'time_epoch': 33.15429, 'eta': 1651.48956, 'eta_hours': 0.45875, 'loss': 0.03016293, 'lr': 0.00082897, 'params': 197319, 'time_iter': 0.08889, 'accuracy': 0.99345, 'f1': 0.99344, 'auc': 0.99981}\n",
      "val: {'epoch': 24, 'time_epoch': 2.00636, 'loss': 0.27071489, 'lr': 0, 'params': 197319, 'time_iter': 0.04269, 'accuracy': 0.9422, 'f1': 0.94281, 'auc': 0.99391}\n",
      "test: {'epoch': 24, 'time_epoch': 2.01801, 'loss': 0.22095408, 'lr': 0, 'params': 197319, 'time_iter': 0.04294, 'accuracy': 0.95302, 'f1': 0.95219, 'auc': 0.99523}\n",
      "> Epoch 24: took 37.2s (avg 37.2s) | Best so far: epoch 18\ttrain_loss: 0.0614 train_accuracy: 0.9846\tval_loss: 0.1719 val_accuracy: 0.9610\ttest_loss: 0.2382 test_accuracy: 0.9476\n",
      "train: {'epoch': 25, 'time_epoch': 32.90367, 'eta': 1618.22208, 'eta_hours': 0.44951, 'loss': 0.04202566, 'lr': 0.00081174, 'params': 197319, 'time_iter': 0.08821, 'accuracy': 0.98975, 'f1': 0.98977, 'auc': 0.99935}\n",
      "val: {'epoch': 25, 'time_epoch': 2.02393, 'loss': 0.18731539, 'lr': 0, 'params': 197319, 'time_iter': 0.04306, 'accuracy': 0.96237, 'f1': 0.96335, 'auc': 0.99655}\n",
      "test: {'epoch': 25, 'time_epoch': 2.03997, 'loss': 0.19224564, 'lr': 0, 'params': 197319, 'time_iter': 0.0434, 'accuracy': 0.96242, 'f1': 0.96151, 'auc': 0.99769}\n",
      "> Epoch 25: took 37.0s (avg 37.2s) | Best so far: epoch 25\ttrain_loss: 0.0420 train_accuracy: 0.9898\tval_loss: 0.1873 val_accuracy: 0.9624\ttest_loss: 0.1922 test_accuracy: 0.9624\n",
      "train: {'epoch': 26, 'time_epoch': 33.61376, 'eta': 1586.24393, 'eta_hours': 0.44062, 'loss': 0.04726935, 'lr': 0.00079389, 'params': 197319, 'time_iter': 0.09012, 'accuracy': 0.98724, 'f1': 0.9872, 'auc': 0.99972}\n",
      "val: {'epoch': 26, 'time_epoch': 2.11542, 'loss': 0.17003009, 'lr': 0, 'params': 197319, 'time_iter': 0.04501, 'accuracy': 0.96237, 'f1': 0.96331, 'auc': 0.99772}\n",
      "test: {'epoch': 26, 'time_epoch': 2.09819, 'loss': 0.1588821, 'lr': 0, 'params': 197319, 'time_iter': 0.04464, 'accuracy': 0.96913, 'f1': 0.96857, 'auc': 0.99877}\n",
      "> Epoch 26: took 37.9s (avg 37.2s) | Best so far: epoch 25\ttrain_loss: 0.0420 train_accuracy: 0.9898\tval_loss: 0.1873 val_accuracy: 0.9624\ttest_loss: 0.1922 test_accuracy: 0.9624\n",
      "train: {'epoch': 27, 'time_epoch': 33.2845, 'eta': 1553.59627, 'eta_hours': 0.43155, 'loss': 0.04149279, 'lr': 0.00077545, 'params': 197319, 'time_iter': 0.08923, 'accuracy': 0.98942, 'f1': 0.98939, 'auc': 0.99958}\n",
      "val: {'epoch': 27, 'time_epoch': 2.0211, 'loss': 0.19698557, 'lr': 0, 'params': 197319, 'time_iter': 0.043, 'accuracy': 0.96102, 'f1': 0.96198, 'auc': 0.99659}\n",
      "test: {'epoch': 27, 'time_epoch': 2.08739, 'loss': 0.17404862, 'lr': 0, 'params': 197319, 'time_iter': 0.04441, 'accuracy': 0.96779, 'f1': 0.96721, 'auc': 0.99738}\n",
      "> Epoch 27: took 37.4s (avg 37.2s) | Best so far: epoch 25\ttrain_loss: 0.0420 train_accuracy: 0.9898\tval_loss: 0.1873 val_accuracy: 0.9624\ttest_loss: 0.1922 test_accuracy: 0.9624\n",
      "train: {'epoch': 28, 'time_epoch': 33.01832, 'eta': 1520.48247, 'eta_hours': 0.42236, 'loss': 0.02515579, 'lr': 0.00075645, 'params': 197319, 'time_iter': 0.08852, 'accuracy': 0.99412, 'f1': 0.99414, 'auc': 0.99988}\n",
      "val: {'epoch': 28, 'time_epoch': 2.00839, 'loss': 0.16779821, 'lr': 0, 'params': 197319, 'time_iter': 0.04273, 'accuracy': 0.96909, 'f1': 0.9702, 'auc': 0.99688}\n",
      "test: {'epoch': 28, 'time_epoch': 2.02369, 'loss': 0.22423735, 'lr': 0, 'params': 197319, 'time_iter': 0.04306, 'accuracy': 0.95705, 'f1': 0.95622, 'auc': 0.99729}\n",
      "> Epoch 28: took 37.1s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 29, 'time_epoch': 33.36644, 'eta': 1487.89721, 'eta_hours': 0.4133, 'loss': 0.01796555, 'lr': 0.00073693, 'params': 197319, 'time_iter': 0.08945, 'accuracy': 0.99446, 'f1': 0.99444, 'auc': 0.99998}\n",
      "val: {'epoch': 29, 'time_epoch': 2.14904, 'loss': 0.18583522, 'lr': 0, 'params': 197319, 'time_iter': 0.04572, 'accuracy': 0.96102, 'f1': 0.96196, 'auc': 0.99743}\n",
      "test: {'epoch': 29, 'time_epoch': 2.08605, 'loss': 0.19473374, 'lr': 0, 'params': 197319, 'time_iter': 0.04438, 'accuracy': 0.96242, 'f1': 0.96226, 'auc': 0.99693}\n",
      "> Epoch 29: took 37.6s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 30, 'time_epoch': 33.14977, 'eta': 1454.95403, 'eta_hours': 0.40415, 'loss': 0.01823418, 'lr': 0.00071694, 'params': 197319, 'time_iter': 0.08887, 'accuracy': 0.99496, 'f1': 0.99496, 'auc': 0.99984}\n",
      "val: {'epoch': 30, 'time_epoch': 1.99199, 'loss': 0.23079715, 'lr': 0, 'params': 197319, 'time_iter': 0.04238, 'accuracy': 0.96102, 'f1': 0.9623, 'auc': 0.99647}\n",
      "test: {'epoch': 30, 'time_epoch': 2.06993, 'loss': 0.20673073, 'lr': 0, 'params': 197319, 'time_iter': 0.04404, 'accuracy': 0.95705, 'f1': 0.95613, 'auc': 0.99736}\n",
      "> Epoch 30: took 37.3s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 31, 'time_epoch': 32.85325, 'eta': 1421.59948, 'eta_hours': 0.39489, 'loss': 0.01380989, 'lr': 0.00069651, 'params': 197319, 'time_iter': 0.08808, 'accuracy': 0.99681, 'f1': 0.99682, 'auc': 0.99996}\n",
      "val: {'epoch': 31, 'time_epoch': 2.04112, 'loss': 0.27022359, 'lr': 0, 'params': 197319, 'time_iter': 0.04343, 'accuracy': 0.95296, 'f1': 0.9544, 'auc': 0.99761}\n",
      "test: {'epoch': 31, 'time_epoch': 2.01599, 'loss': 0.25416808, 'lr': 0, 'params': 197319, 'time_iter': 0.04289, 'accuracy': 0.95034, 'f1': 0.9512, 'auc': 0.99789}\n",
      "> Epoch 31: took 37.0s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 32, 'time_epoch': 32.90653, 'eta': 1388.34313, 'eta_hours': 0.38565, 'loss': 0.02200788, 'lr': 0.00067569, 'params': 197319, 'time_iter': 0.08822, 'accuracy': 0.99496, 'f1': 0.99494, 'auc': 0.99981}\n",
      "val: {'epoch': 32, 'time_epoch': 2.12902, 'loss': 0.2843122, 'lr': 0, 'params': 197319, 'time_iter': 0.0453, 'accuracy': 0.94758, 'f1': 0.95025, 'auc': 0.9945}\n",
      "test: {'epoch': 32, 'time_epoch': 2.09648, 'loss': 0.21571887, 'lr': 0, 'params': 197319, 'time_iter': 0.04461, 'accuracy': 0.9557, 'f1': 0.95375, 'auc': 0.99627}\n",
      "> Epoch 32: took 37.2s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 33, 'time_epoch': 33.43219, 'eta': 1355.74123, 'eta_hours': 0.37659, 'loss': 0.02637631, 'lr': 0.00065451, 'params': 197319, 'time_iter': 0.08963, 'accuracy': 0.99412, 'f1': 0.99414, 'auc': 0.9998}\n",
      "val: {'epoch': 33, 'time_epoch': 2.03812, 'loss': 0.22790879, 'lr': 0, 'params': 197319, 'time_iter': 0.04336, 'accuracy': 0.95699, 'f1': 0.95812, 'auc': 0.99669}\n",
      "test: {'epoch': 33, 'time_epoch': 2.09434, 'loss': 0.16817622, 'lr': 0, 'params': 197319, 'time_iter': 0.04456, 'accuracy': 0.97047, 'f1': 0.96978, 'auc': 0.99609}\n",
      "> Epoch 33: took 37.6s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 34, 'time_epoch': 33.06294, 'eta': 1322.66989, 'eta_hours': 0.36741, 'loss': 0.00607396, 'lr': 0.00063302, 'params': 197319, 'time_iter': 0.08864, 'accuracy': 0.99798, 'f1': 0.99796, 'auc': 1.0}\n",
      "val: {'epoch': 34, 'time_epoch': 2.01509, 'loss': 0.19930045, 'lr': 0, 'params': 197319, 'time_iter': 0.04287, 'accuracy': 0.96505, 'f1': 0.96583, 'auc': 0.99779}\n",
      "test: {'epoch': 34, 'time_epoch': 2.02195, 'loss': 0.21594585, 'lr': 0, 'params': 197319, 'time_iter': 0.04302, 'accuracy': 0.96242, 'f1': 0.96143, 'auc': 0.99693}\n",
      "> Epoch 34: took 37.1s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 35, 'time_epoch': 33.08717, 'eta': 1289.62527, 'eta_hours': 0.35823, 'loss': 0.01088075, 'lr': 0.00061126, 'params': 197319, 'time_iter': 0.08871, 'accuracy': 0.99681, 'f1': 0.99682, 'auc': 0.99991}\n",
      "val: {'epoch': 35, 'time_epoch': 2.12923, 'loss': 0.22372977, 'lr': 0, 'params': 197319, 'time_iter': 0.0453, 'accuracy': 0.96237, 'f1': 0.96373, 'auc': 0.99704}\n",
      "test: {'epoch': 35, 'time_epoch': 2.07875, 'loss': 0.19597257, 'lr': 0, 'params': 197319, 'time_iter': 0.04423, 'accuracy': 0.9651, 'f1': 0.96395, 'auc': 0.99824}\n",
      "> Epoch 35: took 37.3s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 36, 'time_epoch': 33.77672, 'eta': 1257.28653, 'eta_hours': 0.34925, 'loss': 0.00920405, 'lr': 0.00058928, 'params': 197319, 'time_iter': 0.09055, 'accuracy': 0.99765, 'f1': 0.99764, 'auc': 0.99996}\n",
      "val: {'epoch': 36, 'time_epoch': 2.05475, 'loss': 0.22728746, 'lr': 0, 'params': 197319, 'time_iter': 0.04372, 'accuracy': 0.95968, 'f1': 0.96069, 'auc': 0.9976}\n",
      "test: {'epoch': 36, 'time_epoch': 2.06533, 'loss': 0.27474871, 'lr': 0, 'params': 197319, 'time_iter': 0.04394, 'accuracy': 0.95168, 'f1': 0.95143, 'auc': 0.99489}\n",
      "> Epoch 36: took 37.9s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 37, 'time_epoch': 33.27274, 'eta': 1224.38139, 'eta_hours': 0.34011, 'loss': 0.0181734, 'lr': 0.00056712, 'params': 197319, 'time_iter': 0.0892, 'accuracy': 0.99597, 'f1': 0.99596, 'auc': 0.99981}\n",
      "val: {'epoch': 37, 'time_epoch': 2.01858, 'loss': 0.29553538, 'lr': 0, 'params': 197319, 'time_iter': 0.04295, 'accuracy': 0.94758, 'f1': 0.94908, 'auc': 0.99363}\n",
      "test: {'epoch': 37, 'time_epoch': 2.02151, 'loss': 0.20727098, 'lr': 0, 'params': 197319, 'time_iter': 0.04301, 'accuracy': 0.96107, 'f1': 0.96041, 'auc': 0.99565}\n",
      "> Epoch 37: took 37.4s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 38, 'time_epoch': 33.05574, 'eta': 1191.2571, 'eta_hours': 0.3309, 'loss': 0.02206396, 'lr': 0.00054482, 'params': 197319, 'time_iter': 0.08862, 'accuracy': 0.99496, 'f1': 0.99499, 'auc': 0.99979}\n",
      "val: {'epoch': 38, 'time_epoch': 2.09362, 'loss': 0.21817762, 'lr': 0, 'params': 197319, 'time_iter': 0.04455, 'accuracy': 0.96237, 'f1': 0.96347, 'auc': 0.99581}\n",
      "test: {'epoch': 38, 'time_epoch': 2.07718, 'loss': 0.18616451, 'lr': 0, 'params': 197319, 'time_iter': 0.0442, 'accuracy': 0.96376, 'f1': 0.96369, 'auc': 0.99669}\n",
      "> Epoch 38: took 37.3s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 39, 'time_epoch': 33.33932, 'eta': 1158.38436, 'eta_hours': 0.32177, 'loss': 0.01625374, 'lr': 0.00052243, 'params': 197319, 'time_iter': 0.08938, 'accuracy': 0.99496, 'f1': 0.99494, 'auc': 0.99999}\n",
      "val: {'epoch': 39, 'time_epoch': 2.01827, 'loss': 0.28969163, 'lr': 0, 'params': 197319, 'time_iter': 0.04294, 'accuracy': 0.95027, 'f1': 0.95237, 'auc': 0.99265}\n",
      "test: {'epoch': 39, 'time_epoch': 2.0699, 'loss': 0.23269868, 'lr': 0, 'params': 197319, 'time_iter': 0.04404, 'accuracy': 0.96376, 'f1': 0.96208, 'auc': 0.99546}\n",
      "> Epoch 39: took 37.5s (avg 37.3s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 40, 'time_epoch': 33.01846, 'eta': 1125.22279, 'eta_hours': 0.31256, 'loss': 0.0086013, 'lr': 0.0005, 'params': 197319, 'time_iter': 0.08852, 'accuracy': 0.99815, 'f1': 0.99815, 'auc': 1.0}\n",
      "val: {'epoch': 40, 'time_epoch': 2.00257, 'loss': 0.22491064, 'lr': 0, 'params': 197319, 'time_iter': 0.04261, 'accuracy': 0.96237, 'f1': 0.96327, 'auc': 0.99586}\n",
      "test: {'epoch': 40, 'time_epoch': 2.00559, 'loss': 0.20463273, 'lr': 0, 'params': 197319, 'time_iter': 0.04267, 'accuracy': 0.96376, 'f1': 0.96281, 'auc': 0.99811}\n",
      "> Epoch 40: took 37.1s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 41, 'time_epoch': 32.77577, 'eta': 1091.87734, 'eta_hours': 0.3033, 'loss': 0.00953295, 'lr': 0.00047757, 'params': 197319, 'time_iter': 0.08787, 'accuracy': 0.99782, 'f1': 0.99781, 'auc': 0.99999}\n",
      "val: {'epoch': 41, 'time_epoch': 2.07128, 'loss': 0.26343739, 'lr': 0, 'params': 197319, 'time_iter': 0.04407, 'accuracy': 0.95833, 'f1': 0.9595, 'auc': 0.99517}\n",
      "test: {'epoch': 41, 'time_epoch': 2.05602, 'loss': 0.24024072, 'lr': 0, 'params': 197319, 'time_iter': 0.04375, 'accuracy': 0.96107, 'f1': 0.95999, 'auc': 0.99719}\n",
      "> Epoch 41: took 36.9s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 42, 'time_epoch': 33.21966, 'eta': 1058.88873, 'eta_hours': 0.29414, 'loss': 0.02484736, 'lr': 0.00045518, 'params': 197319, 'time_iter': 0.08906, 'accuracy': 0.99496, 'f1': 0.99494, 'auc': 0.99983}\n",
      "val: {'epoch': 42, 'time_epoch': 2.02049, 'loss': 0.17833934, 'lr': 0, 'params': 197319, 'time_iter': 0.04299, 'accuracy': 0.96909, 'f1': 0.96979, 'auc': 0.99728}\n",
      "test: {'epoch': 42, 'time_epoch': 2.04042, 'loss': 0.20379228, 'lr': 0, 'params': 197319, 'time_iter': 0.04341, 'accuracy': 0.96376, 'f1': 0.96296, 'auc': 0.99829}\n",
      "> Epoch 42: took 37.3s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 43, 'time_epoch': 33.39637, 'eta': 1026.01412, 'eta_hours': 0.285, 'loss': 0.00558044, 'lr': 0.00043288, 'params': 197319, 'time_iter': 0.08953, 'accuracy': 0.99866, 'f1': 0.99866, 'auc': 1.0}\n",
      "val: {'epoch': 43, 'time_epoch': 2.04371, 'loss': 0.24565999, 'lr': 0, 'params': 197319, 'time_iter': 0.04348, 'accuracy': 0.96102, 'f1': 0.96197, 'auc': 0.99704}\n",
      "test: {'epoch': 43, 'time_epoch': 2.05241, 'loss': 0.18665031, 'lr': 0, 'params': 197319, 'time_iter': 0.04367, 'accuracy': 0.97047, 'f1': 0.96976, 'auc': 0.99859}\n",
      "> Epoch 43: took 37.5s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 44, 'time_epoch': 32.90535, 'eta': 992.78897, 'eta_hours': 0.27577, 'loss': 0.00601148, 'lr': 0.00041072, 'params': 197319, 'time_iter': 0.08822, 'accuracy': 0.99815, 'f1': 0.99817, 'auc': 1.0}\n",
      "val: {'epoch': 44, 'time_epoch': 2.10372, 'loss': 0.21800428, 'lr': 0, 'params': 197319, 'time_iter': 0.04476, 'accuracy': 0.96371, 'f1': 0.96481, 'auc': 0.99629}\n",
      "test: {'epoch': 44, 'time_epoch': 2.08231, 'loss': 0.16424634, 'lr': 0, 'params': 197319, 'time_iter': 0.0443, 'accuracy': 0.96913, 'f1': 0.96902, 'auc': 0.99872}\n",
      "> Epoch 44: took 37.1s (avg 37.2s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 45, 'time_epoch': 33.32799, 'eta': 959.84417, 'eta_hours': 0.26662, 'loss': 0.00423571, 'lr': 0.00038874, 'params': 197319, 'time_iter': 0.08935, 'accuracy': 0.99866, 'f1': 0.99867, 'auc': 1.0}\n",
      "val: {'epoch': 45, 'time_epoch': 2.06, 'loss': 0.20200564, 'lr': 0, 'params': 197319, 'time_iter': 0.04383, 'accuracy': 0.96774, 'f1': 0.96858, 'auc': 0.99723}\n",
      "test: {'epoch': 45, 'time_epoch': 2.04741, 'loss': 0.18059984, 'lr': 0, 'params': 197319, 'time_iter': 0.04356, 'accuracy': 0.97315, 'f1': 0.9731, 'auc': 0.9972}\n",
      "> Epoch 45: took 37.5s (avg 37.3s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 46, 'time_epoch': 33.55155, 'eta': 927.01625, 'eta_hours': 0.2575, 'loss': 0.00420381, 'lr': 0.00036698, 'params': 197319, 'time_iter': 0.08995, 'accuracy': 0.99916, 'f1': 0.99915, 'auc': 0.99999}\n",
      "val: {'epoch': 46, 'time_epoch': 2.04924, 'loss': 0.24263159, 'lr': 0, 'params': 197319, 'time_iter': 0.0436, 'accuracy': 0.96371, 'f1': 0.9647, 'auc': 0.99664}\n",
      "test: {'epoch': 46, 'time_epoch': 2.0555, 'loss': 0.21195401, 'lr': 0, 'params': 197319, 'time_iter': 0.04373, 'accuracy': 0.96644, 'f1': 0.96523, 'auc': 0.99862}\n",
      "> Epoch 46: took 37.7s (avg 37.3s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 47, 'time_epoch': 33.06017, 'eta': 893.88178, 'eta_hours': 0.2483, 'loss': 0.00539956, 'lr': 0.00034549, 'params': 197319, 'time_iter': 0.08863, 'accuracy': 0.99899, 'f1': 0.99899, 'auc': 0.99994}\n",
      "val: {'epoch': 47, 'time_epoch': 2.15211, 'loss': 0.22929847, 'lr': 0, 'params': 197319, 'time_iter': 0.04579, 'accuracy': 0.9664, 'f1': 0.96739, 'auc': 0.99621}\n",
      "test: {'epoch': 47, 'time_epoch': 2.06421, 'loss': 0.18324366, 'lr': 0, 'params': 197319, 'time_iter': 0.04392, 'accuracy': 0.96913, 'f1': 0.9683, 'auc': 0.99838}\n",
      "> Epoch 47: took 37.3s (avg 37.3s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 48, 'time_epoch': 33.18034, 'eta': 860.81411, 'eta_hours': 0.23912, 'loss': 0.00410678, 'lr': 0.00032431, 'params': 197319, 'time_iter': 0.08896, 'accuracy': 0.99916, 'f1': 0.99918, 'auc': 0.99989}\n",
      "val: {'epoch': 48, 'time_epoch': 2.02469, 'loss': 0.29340678, 'lr': 0, 'params': 197319, 'time_iter': 0.04308, 'accuracy': 0.95833, 'f1': 0.95925, 'auc': 0.99558}\n",
      "test: {'epoch': 48, 'time_epoch': 2.04575, 'loss': 0.26858312, 'lr': 0, 'params': 197319, 'time_iter': 0.04353, 'accuracy': 0.95973, 'f1': 0.96001, 'auc': 0.99602}\n",
      "> Epoch 48: took 37.3s (avg 37.3s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 49, 'time_epoch': 33.30004, 'eta': 827.80178, 'eta_hours': 0.22994, 'loss': 0.00491344, 'lr': 0.00030349, 'params': 197319, 'time_iter': 0.08928, 'accuracy': 0.99849, 'f1': 0.9985, 'auc': 1.0}\n",
      "val: {'epoch': 49, 'time_epoch': 2.01897, 'loss': 0.25724458, 'lr': 0, 'params': 197319, 'time_iter': 0.04296, 'accuracy': 0.96505, 'f1': 0.96613, 'auc': 0.99627}\n",
      "test: {'epoch': 49, 'time_epoch': 2.03243, 'loss': 0.17704287, 'lr': 0, 'params': 197319, 'time_iter': 0.04324, 'accuracy': 0.97047, 'f1': 0.96963, 'auc': 0.99788}\n",
      "> Epoch 49: took 37.4s (avg 37.3s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 50, 'time_epoch': 32.99791, 'eta': 794.63598, 'eta_hours': 0.22073, 'loss': 0.00039198, 'lr': 0.00028306, 'params': 197319, 'time_iter': 0.08847, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 50, 'time_epoch': 2.1511, 'loss': 0.25336212, 'lr': 0, 'params': 197319, 'time_iter': 0.04577, 'accuracy': 0.96371, 'f1': 0.96478, 'auc': 0.99612}\n",
      "test: {'epoch': 50, 'time_epoch': 2.07012, 'loss': 0.18833275, 'lr': 0, 'params': 197319, 'time_iter': 0.04405, 'accuracy': 0.96644, 'f1': 0.96585, 'auc': 0.99802}\n",
      "> Epoch 50: took 37.3s (avg 37.3s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 51, 'time_epoch': 32.83826, 'eta': 761.40603, 'eta_hours': 0.2115, 'loss': 0.0016609, 'lr': 0.00026307, 'params': 197319, 'time_iter': 0.08804, 'accuracy': 0.99983, 'f1': 0.99982, 'auc': 1.0}\n",
      "val: {'epoch': 51, 'time_epoch': 1.98526, 'loss': 0.25753057, 'lr': 0, 'params': 197319, 'time_iter': 0.04224, 'accuracy': 0.96371, 'f1': 0.96497, 'auc': 0.99574}\n",
      "test: {'epoch': 51, 'time_epoch': 2.01588, 'loss': 0.18607751, 'lr': 0, 'params': 197319, 'time_iter': 0.04289, 'accuracy': 0.97047, 'f1': 0.96951, 'auc': 0.99835}\n",
      "> Epoch 51: took 36.9s (avg 37.3s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 52, 'time_epoch': 33.58376, 'eta': 728.50031, 'eta_hours': 0.20236, 'loss': 0.00319861, 'lr': 0.00024355, 'params': 197319, 'time_iter': 0.09004, 'accuracy': 0.99916, 'f1': 0.99915, 'auc': 1.0}\n",
      "val: {'epoch': 52, 'time_epoch': 2.13292, 'loss': 0.22180922, 'lr': 0, 'params': 197319, 'time_iter': 0.04538, 'accuracy': 0.9664, 'f1': 0.96713, 'auc': 0.99589}\n",
      "test: {'epoch': 52, 'time_epoch': 2.0948, 'loss': 0.2218026, 'lr': 0, 'params': 197319, 'time_iter': 0.04457, 'accuracy': 0.96644, 'f1': 0.96642, 'auc': 0.99744}\n",
      "> Epoch 52: took 37.9s (avg 37.3s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 53, 'time_epoch': 33.07425, 'eta': 695.37134, 'eta_hours': 0.19316, 'loss': 0.00081273, 'lr': 0.00022455, 'params': 197319, 'time_iter': 0.08867, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 53, 'time_epoch': 2.08601, 'loss': 0.26409346, 'lr': 0, 'params': 197319, 'time_iter': 0.04438, 'accuracy': 0.96237, 'f1': 0.96343, 'auc': 0.99583}\n",
      "test: {'epoch': 53, 'time_epoch': 2.07442, 'loss': 0.21828015, 'lr': 0, 'params': 197319, 'time_iter': 0.04414, 'accuracy': 0.97047, 'f1': 0.97006, 'auc': 0.99779}\n",
      "> Epoch 53: took 37.3s (avg 37.3s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 54, 'time_epoch': 32.97128, 'eta': 662.20691, 'eta_hours': 0.18395, 'loss': 0.00158572, 'lr': 0.00020611, 'params': 197319, 'time_iter': 0.08839, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 54, 'time_epoch': 2.02215, 'loss': 0.23879935, 'lr': 0, 'params': 197319, 'time_iter': 0.04302, 'accuracy': 0.96371, 'f1': 0.96473, 'auc': 0.99589}\n",
      "test: {'epoch': 54, 'time_epoch': 2.03976, 'loss': 0.19163369, 'lr': 0, 'params': 197319, 'time_iter': 0.0434, 'accuracy': 0.97181, 'f1': 0.97104, 'auc': 0.99829}\n",
      "> Epoch 54: took 37.1s (avg 37.3s) | Best so far: epoch 28\ttrain_loss: 0.0252 train_accuracy: 0.9941\tval_loss: 0.1678 val_accuracy: 0.9691\ttest_loss: 0.2242 test_accuracy: 0.9570\n",
      "train: {'epoch': 55, 'time_epoch': 33.52213, 'eta': 629.23628, 'eta_hours': 0.17479, 'loss': 0.00029352, 'lr': 0.00018826, 'params': 197319, 'time_iter': 0.08987, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 55, 'time_epoch': 2.00884, 'loss': 0.21796846, 'lr': 0, 'params': 197319, 'time_iter': 0.04274, 'accuracy': 0.97043, 'f1': 0.9712, 'auc': 0.99711}\n",
      "test: {'epoch': 55, 'time_epoch': 2.06676, 'loss': 0.20201741, 'lr': 0, 'params': 197319, 'time_iter': 0.04397, 'accuracy': 0.97181, 'f1': 0.97159, 'auc': 0.99828}\n",
      "> Epoch 55: took 37.6s (avg 37.3s) | Best so far: epoch 55\ttrain_loss: 0.0003 train_accuracy: 1.0000\tval_loss: 0.2180 val_accuracy: 0.9704\ttest_loss: 0.2020 test_accuracy: 0.9718\n",
      "train: {'epoch': 56, 'time_epoch': 33.2485, 'eta': 596.15989, 'eta_hours': 0.1656, 'loss': 0.00132549, 'lr': 0.00017103, 'params': 197319, 'time_iter': 0.08914, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 56, 'time_epoch': 2.12231, 'loss': 0.22239005, 'lr': 0, 'params': 197319, 'time_iter': 0.04516, 'accuracy': 0.9664, 'f1': 0.96746, 'auc': 0.99711}\n",
      "test: {'epoch': 56, 'time_epoch': 2.07232, 'loss': 0.16866598, 'lr': 0, 'params': 197319, 'time_iter': 0.04409, 'accuracy': 0.97718, 'f1': 0.97657, 'auc': 0.99842}\n",
      "> Epoch 56: took 37.5s (avg 37.3s) | Best so far: epoch 55\ttrain_loss: 0.0003 train_accuracy: 1.0000\tval_loss: 0.2180 val_accuracy: 0.9704\ttest_loss: 0.2020 test_accuracy: 0.9718\n",
      "train: {'epoch': 57, 'time_epoch': 33.06254, 'eta': 563.02305, 'eta_hours': 0.1564, 'loss': 0.00359248, 'lr': 0.00015447, 'params': 197319, 'time_iter': 0.08864, 'accuracy': 0.99916, 'f1': 0.99916, 'auc': 1.0}\n",
      "val: {'epoch': 57, 'time_epoch': 1.99963, 'loss': 0.2808855, 'lr': 0, 'params': 197319, 'time_iter': 0.04255, 'accuracy': 0.95833, 'f1': 0.95973, 'auc': 0.99421}\n",
      "test: {'epoch': 57, 'time_epoch': 2.06185, 'loss': 0.24351563, 'lr': 0, 'params': 197319, 'time_iter': 0.04387, 'accuracy': 0.9651, 'f1': 0.96466, 'auc': 0.9977}\n",
      "> Epoch 57: took 37.2s (avg 37.3s) | Best so far: epoch 55\ttrain_loss: 0.0003 train_accuracy: 1.0000\tval_loss: 0.2180 val_accuracy: 0.9704\ttest_loss: 0.2020 test_accuracy: 0.9718\n",
      "train: {'epoch': 58, 'time_epoch': 33.31957, 'eta': 529.95844, 'eta_hours': 0.14721, 'loss': 0.00165143, 'lr': 0.0001386, 'params': 197319, 'time_iter': 0.08933, 'accuracy': 0.99966, 'f1': 0.99966, 'auc': 1.0}\n",
      "val: {'epoch': 58, 'time_epoch': 2.03286, 'loss': 0.26124594, 'lr': 0, 'params': 197319, 'time_iter': 0.04325, 'accuracy': 0.96505, 'f1': 0.96603, 'auc': 0.997}\n",
      "test: {'epoch': 58, 'time_epoch': 2.0424, 'loss': 0.22585332, 'lr': 0, 'params': 197319, 'time_iter': 0.04346, 'accuracy': 0.96644, 'f1': 0.96532, 'auc': 0.99836}\n",
      "> Epoch 58: took 37.4s (avg 37.3s) | Best so far: epoch 55\ttrain_loss: 0.0003 train_accuracy: 1.0000\tval_loss: 0.2180 val_accuracy: 0.9704\ttest_loss: 0.2020 test_accuracy: 0.9718\n",
      "train: {'epoch': 59, 'time_epoch': 33.16375, 'eta': 496.84638, 'eta_hours': 0.13801, 'loss': 0.00154098, 'lr': 0.00012346, 'params': 197319, 'time_iter': 0.08891, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 59, 'time_epoch': 2.11049, 'loss': 0.27506225, 'lr': 0, 'params': 197319, 'time_iter': 0.0449, 'accuracy': 0.95833, 'f1': 0.95982, 'auc': 0.99707}\n",
      "test: {'epoch': 59, 'time_epoch': 2.04808, 'loss': 0.23788028, 'lr': 0, 'params': 197319, 'time_iter': 0.04358, 'accuracy': 0.9651, 'f1': 0.96372, 'auc': 0.99847}\n",
      "> Epoch 59: took 37.4s (avg 37.3s) | Best so far: epoch 55\ttrain_loss: 0.0003 train_accuracy: 1.0000\tval_loss: 0.2180 val_accuracy: 0.9704\ttest_loss: 0.2020 test_accuracy: 0.9718\n",
      "train: {'epoch': 60, 'time_epoch': 32.78804, 'eta': 463.64639, 'eta_hours': 0.12879, 'loss': 0.00108688, 'lr': 0.00010908, 'params': 197319, 'time_iter': 0.0879, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 60, 'time_epoch': 1.98131, 'loss': 0.17411131, 'lr': 0, 'params': 197319, 'time_iter': 0.04216, 'accuracy': 0.97446, 'f1': 0.97545, 'auc': 0.99788}\n",
      "test: {'epoch': 60, 'time_epoch': 2.01336, 'loss': 0.21962566, 'lr': 0, 'params': 197319, 'time_iter': 0.04284, 'accuracy': 0.96913, 'f1': 0.96858, 'auc': 0.99786}\n",
      "> Epoch 60: took 36.8s (avg 37.3s) | Best so far: epoch 60\ttrain_loss: 0.0011 train_accuracy: 0.9998\tval_loss: 0.1741 val_accuracy: 0.9745\ttest_loss: 0.2196 test_accuracy: 0.9691\n",
      "train: {'epoch': 61, 'time_epoch': 33.11618, 'eta': 430.52849, 'eta_hours': 0.11959, 'loss': 0.00023594, 'lr': 9.549e-05, 'params': 197319, 'time_iter': 0.08878, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 61, 'time_epoch': 2.03195, 'loss': 0.1940743, 'lr': 0, 'params': 197319, 'time_iter': 0.04323, 'accuracy': 0.97177, 'f1': 0.97276, 'auc': 0.99748}\n",
      "test: {'epoch': 61, 'time_epoch': 2.0564, 'loss': 0.21293782, 'lr': 0, 'params': 197319, 'time_iter': 0.04375, 'accuracy': 0.96779, 'f1': 0.9674, 'auc': 0.99843}\n",
      "> Epoch 61: took 37.3s (avg 37.3s) | Best so far: epoch 60\ttrain_loss: 0.0011 train_accuracy: 0.9998\tval_loss: 0.1741 val_accuracy: 0.9745\ttest_loss: 0.2196 test_accuracy: 0.9691\n",
      "train: {'epoch': 62, 'time_epoch': 33.65343, 'eta': 397.51298, 'eta_hours': 0.11042, 'loss': 0.00020219, 'lr': 8.271e-05, 'params': 197319, 'time_iter': 0.09022, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 62, 'time_epoch': 2.13707, 'loss': 0.18512361, 'lr': 0, 'params': 197319, 'time_iter': 0.04547, 'accuracy': 0.97312, 'f1': 0.97409, 'auc': 0.99757}\n",
      "test: {'epoch': 62, 'time_epoch': 2.08823, 'loss': 0.20940487, 'lr': 0, 'params': 197319, 'time_iter': 0.04443, 'accuracy': 0.97047, 'f1': 0.96988, 'auc': 0.9985}\n",
      "> Epoch 62: took 37.9s (avg 37.3s) | Best so far: epoch 60\ttrain_loss: 0.0011 train_accuracy: 0.9998\tval_loss: 0.1741 val_accuracy: 0.9745\ttest_loss: 0.2196 test_accuracy: 0.9691\n",
      "train: {'epoch': 63, 'time_epoch': 33.04358, 'eta': 364.37272, 'eta_hours': 0.10121, 'loss': 0.0001971, 'lr': 7.078e-05, 'params': 197319, 'time_iter': 0.08859, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 63, 'time_epoch': 2.01305, 'loss': 0.19912504, 'lr': 0, 'params': 197319, 'time_iter': 0.04283, 'accuracy': 0.97177, 'f1': 0.97279, 'auc': 0.99746}\n",
      "test: {'epoch': 63, 'time_epoch': 2.02937, 'loss': 0.22316005, 'lr': 0, 'params': 197319, 'time_iter': 0.04318, 'accuracy': 0.96913, 'f1': 0.96816, 'auc': 0.9982}\n",
      "> Epoch 63: took 37.1s (avg 37.3s) | Best so far: epoch 60\ttrain_loss: 0.0011 train_accuracy: 0.9998\tval_loss: 0.1741 val_accuracy: 0.9745\ttest_loss: 0.2196 test_accuracy: 0.9691\n",
      "train: {'epoch': 64, 'time_epoch': 33.2828, 'eta': 331.27224, 'eta_hours': 0.09202, 'loss': 0.00019028, 'lr': 5.97e-05, 'params': 197319, 'time_iter': 0.08923, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 64, 'time_epoch': 2.02219, 'loss': 0.19818542, 'lr': 0, 'params': 197319, 'time_iter': 0.04303, 'accuracy': 0.97043, 'f1': 0.9715, 'auc': 0.99777}\n",
      "test: {'epoch': 64, 'time_epoch': 2.05697, 'loss': 0.21712622, 'lr': 0, 'params': 197319, 'time_iter': 0.04377, 'accuracy': 0.97047, 'f1': 0.96988, 'auc': 0.99829}\n",
      "> Epoch 64: took 37.4s (avg 37.3s) | Best so far: epoch 60\ttrain_loss: 0.0011 train_accuracy: 0.9998\tval_loss: 0.1741 val_accuracy: 0.9745\ttest_loss: 0.2196 test_accuracy: 0.9691\n",
      "train: {'epoch': 65, 'time_epoch': 33.63161, 'eta': 298.21379, 'eta_hours': 0.08284, 'loss': 0.00225698, 'lr': 4.952e-05, 'params': 197319, 'time_iter': 0.09017, 'accuracy': 0.99966, 'f1': 0.99966, 'auc': 0.99997}\n",
      "val: {'epoch': 65, 'time_epoch': 2.10444, 'loss': 0.1623736, 'lr': 0, 'params': 197319, 'time_iter': 0.04478, 'accuracy': 0.97849, 'f1': 0.97906, 'auc': 0.99696}\n",
      "test: {'epoch': 65, 'time_epoch': 2.07668, 'loss': 0.21103228, 'lr': 0, 'params': 197319, 'time_iter': 0.04418, 'accuracy': 0.96913, 'f1': 0.96857, 'auc': 0.99811}\n",
      "> Epoch 65: took 37.9s (avg 37.3s) | Best so far: epoch 65\ttrain_loss: 0.0023 train_accuracy: 0.9997\tval_loss: 0.1624 val_accuracy: 0.9785\ttest_loss: 0.2110 test_accuracy: 0.9691\n",
      "train: {'epoch': 66, 'time_epoch': 33.11307, 'eta': 265.07633, 'eta_hours': 0.07363, 'loss': 0.00033002, 'lr': 4.024e-05, 'params': 197319, 'time_iter': 0.08877, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 66, 'time_epoch': 2.03197, 'loss': 0.18915219, 'lr': 0, 'params': 197319, 'time_iter': 0.04323, 'accuracy': 0.97446, 'f1': 0.97541, 'auc': 0.99752}\n",
      "test: {'epoch': 66, 'time_epoch': 2.04093, 'loss': 0.24223557, 'lr': 0, 'params': 197319, 'time_iter': 0.04342, 'accuracy': 0.9651, 'f1': 0.96414, 'auc': 0.99859}\n",
      "> Epoch 66: took 37.2s (avg 37.3s) | Best so far: epoch 65\ttrain_loss: 0.0023 train_accuracy: 0.9997\tval_loss: 0.1624 val_accuracy: 0.9785\ttest_loss: 0.2110 test_accuracy: 0.9691\n",
      "train: {'epoch': 67, 'time_epoch': 33.12155, 'eta': 231.94045, 'eta_hours': 0.06443, 'loss': 0.00017611, 'lr': 3.188e-05, 'params': 197319, 'time_iter': 0.0888, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 67, 'time_epoch': 2.07521, 'loss': 0.18733786, 'lr': 0, 'params': 197319, 'time_iter': 0.04415, 'accuracy': 0.97715, 'f1': 0.97791, 'auc': 0.99757}\n",
      "test: {'epoch': 67, 'time_epoch': 2.06026, 'loss': 0.23440291, 'lr': 0, 'params': 197319, 'time_iter': 0.04384, 'accuracy': 0.9651, 'f1': 0.96414, 'auc': 0.99874}\n",
      "> Epoch 67: took 37.3s (avg 37.3s) | Best so far: epoch 65\ttrain_loss: 0.0023 train_accuracy: 0.9997\tval_loss: 0.1624 val_accuracy: 0.9785\ttest_loss: 0.2110 test_accuracy: 0.9691\n",
      "train: {'epoch': 68, 'time_epoch': 33.48868, 'eta': 198.83691, 'eta_hours': 0.05523, 'loss': 0.00017523, 'lr': 2.447e-05, 'params': 197319, 'time_iter': 0.08978, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 68, 'time_epoch': 2.06425, 'loss': 0.19842298, 'lr': 0, 'params': 197319, 'time_iter': 0.04392, 'accuracy': 0.97312, 'f1': 0.97422, 'auc': 0.99737}\n",
      "test: {'epoch': 68, 'time_epoch': 2.10336, 'loss': 0.24722266, 'lr': 0, 'params': 197319, 'time_iter': 0.04475, 'accuracy': 0.9651, 'f1': 0.96413, 'auc': 0.99881}\n",
      "> Epoch 68: took 37.7s (avg 37.3s) | Best so far: epoch 65\ttrain_loss: 0.0023 train_accuracy: 0.9997\tval_loss: 0.1624 val_accuracy: 0.9785\ttest_loss: 0.2110 test_accuracy: 0.9691\n",
      "train: {'epoch': 69, 'time_epoch': 33.08008, 'eta': 165.69318, 'eta_hours': 0.04603, 'loss': 0.00017324, 'lr': 1.802e-05, 'params': 197319, 'time_iter': 0.08869, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 69, 'time_epoch': 1.98951, 'loss': 0.18984736, 'lr': 0, 'params': 197319, 'time_iter': 0.04233, 'accuracy': 0.97446, 'f1': 0.97542, 'auc': 0.99772}\n",
      "test: {'epoch': 69, 'time_epoch': 1.99059, 'loss': 0.23521645, 'lr': 0, 'params': 197319, 'time_iter': 0.04235, 'accuracy': 0.96644, 'f1': 0.96532, 'auc': 0.9986}\n",
      "> Epoch 69: took 37.1s (avg 37.3s) | Best so far: epoch 65\ttrain_loss: 0.0023 train_accuracy: 0.9997\tval_loss: 0.1624 val_accuracy: 0.9785\ttest_loss: 0.2110 test_accuracy: 0.9691\n",
      "train: {'epoch': 70, 'time_epoch': 32.8209, 'eta': 132.53664, 'eta_hours': 0.03682, 'loss': 0.00174029, 'lr': 1.254e-05, 'params': 197319, 'time_iter': 0.08799, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 70, 'time_epoch': 2.01391, 'loss': 0.1713623, 'lr': 0, 'params': 197319, 'time_iter': 0.04285, 'accuracy': 0.97581, 'f1': 0.97662, 'auc': 0.99731}\n",
      "test: {'epoch': 70, 'time_epoch': 2.02631, 'loss': 0.22425396, 'lr': 0, 'params': 197319, 'time_iter': 0.04311, 'accuracy': 0.96644, 'f1': 0.96532, 'auc': 0.99854}\n",
      "> Epoch 70: took 36.9s (avg 37.3s) | Best so far: epoch 65\ttrain_loss: 0.0023 train_accuracy: 0.9997\tval_loss: 0.1624 val_accuracy: 0.9785\ttest_loss: 0.2110 test_accuracy: 0.9691\n",
      "train: {'epoch': 71, 'time_epoch': 33.38729, 'eta': 99.41303, 'eta_hours': 0.02761, 'loss': 0.00016993, 'lr': 8.04e-06, 'params': 197319, 'time_iter': 0.08951, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 71, 'time_epoch': 2.05767, 'loss': 0.18272868, 'lr': 0, 'params': 197319, 'time_iter': 0.04378, 'accuracy': 0.97581, 'f1': 0.97672, 'auc': 0.99714}\n",
      "test: {'epoch': 71, 'time_epoch': 2.0892, 'loss': 0.23114258, 'lr': 0, 'params': 197319, 'time_iter': 0.04445, 'accuracy': 0.9651, 'f1': 0.96414, 'auc': 0.99846}\n",
      "> Epoch 71: took 37.6s (avg 37.3s) | Best so far: epoch 65\ttrain_loss: 0.0023 train_accuracy: 0.9997\tval_loss: 0.1624 val_accuracy: 0.9785\ttest_loss: 0.2110 test_accuracy: 0.9691\n",
      "train: {'epoch': 72, 'time_epoch': 33.37214, 'eta': 66.28178, 'eta_hours': 0.01841, 'loss': 0.00017394, 'lr': 4.53e-06, 'params': 197319, 'time_iter': 0.08947, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 72, 'time_epoch': 2.05418, 'loss': 0.18134877, 'lr': 0, 'params': 197319, 'time_iter': 0.04371, 'accuracy': 0.97715, 'f1': 0.97792, 'auc': 0.99727}\n",
      "test: {'epoch': 72, 'time_epoch': 2.04123, 'loss': 0.23097085, 'lr': 0, 'params': 197319, 'time_iter': 0.04343, 'accuracy': 0.96779, 'f1': 0.96691, 'auc': 0.99839}\n",
      "> Epoch 72: took 37.5s (avg 37.3s) | Best so far: epoch 65\ttrain_loss: 0.0023 train_accuracy: 0.9997\tval_loss: 0.1624 val_accuracy: 0.9785\ttest_loss: 0.2110 test_accuracy: 0.9691\n",
      "train: {'epoch': 73, 'time_epoch': 33.03863, 'eta': 33.13951, 'eta_hours': 0.00921, 'loss': 0.00020453, 'lr': 2.01e-06, 'params': 197319, 'time_iter': 0.08858, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 73, 'time_epoch': 2.06457, 'loss': 0.19850492, 'lr': 0, 'params': 197319, 'time_iter': 0.04393, 'accuracy': 0.97446, 'f1': 0.97521, 'auc': 0.99722}\n",
      "test: {'epoch': 73, 'time_epoch': 2.04424, 'loss': 0.23622309, 'lr': 0, 'params': 197319, 'time_iter': 0.04349, 'accuracy': 0.96779, 'f1': 0.96691, 'auc': 0.99875}\n",
      "> Epoch 73: took 37.2s (avg 37.3s) | Best so far: epoch 65\ttrain_loss: 0.0023 train_accuracy: 0.9997\tval_loss: 0.1624 val_accuracy: 0.9785\ttest_loss: 0.2110 test_accuracy: 0.9691\n",
      "train: {'epoch': 74, 'time_epoch': 33.4381, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.00017915, 'lr': 5e-07, 'params': 197319, 'time_iter': 0.08965, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 74, 'time_epoch': 2.06936, 'loss': 0.19868019, 'lr': 0, 'params': 197319, 'time_iter': 0.04403, 'accuracy': 0.97177, 'f1': 0.97283, 'auc': 0.99705}\n",
      "test: {'epoch': 74, 'time_epoch': 2.09988, 'loss': 0.23559189, 'lr': 0, 'params': 197319, 'time_iter': 0.04468, 'accuracy': 0.96644, 'f1': 0.96558, 'auc': 0.99888}\n",
      "> Epoch 74: took 37.7s (avg 37.3s) | Best so far: epoch 65\ttrain_loss: 0.0023 train_accuracy: 0.9997\tval_loss: 0.1624 val_accuracy: 0.9785\ttest_loss: 0.2110 test_accuracy: 0.9691\n",
      "Avg time per epoch: 37.30s\n",
      "Total train loop time: 0.78h\n",
      "Task done, results saved in results\\neural-Act\\0\n",
      "65\n",
      "{'epoch': 65, 'time_epoch': 2.07668, 'loss': 0.21103228, 'lr': 0, 'params': 197319, 'time_iter': 0.04418, 'accuracy': 0.96913, 'f1': 0.96857, 'auc': 0.99811}\n",
      "{'epoch': 65, 'time_epoch': 33.63161, 'eta': 298.21379, 'eta_hours': 0.08284, 'loss': 0.00225698, 'lr': 4.952e-05, 'params': 197319, 'time_iter': 0.09017, 'accuracy': 0.99966, 'f1': 0.99966, 'auc': 0.99997}\n",
      "{'epoch': 65, 'time_epoch': 2.10444, 'loss': 0.1623736, 'lr': 0, 'params': 197319, 'time_iter': 0.04478, 'accuracy': 0.97849, 'f1': 0.97906, 'auc': 0.99696}\n",
      "Results aggregated across runs saved in results\\neural-Act\\agg\n",
      "[*] All done: 2024-03-01 19:54:14.969767\n"
     ]
    }
   ],
   "source": [
    "#Activity  - Using Exphormer more layers 3->5\n",
    "%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44604f-b352-4a12-8796-302cf892ac29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ca6f4-e87e-4ddb-bfd4-e30ab5f8ac15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d3f2e2-bb9b-4bab-b7f2-a160ec1cc4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeda79f-6a1b-4537-95d4-3dd0445ee1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be7aff0f-edc8-42db-b434-500633c54b23",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9892e84f-a7ee-409f-85c9-3bfdf360be5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-27 01:12:12.218016\n",
      "[*] Loaded dataset 'HCPAge' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1065000, 1000], edge_index=[2, 48551656], y=[1065])\n",
      "  undirected: True\n",
      "  num graphs: 1065\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 3\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [04:13<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:04:16.27\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [01:17<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:19.38\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 3, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPAge\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 3\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 30\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 3\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Age\n",
      "params: 197319\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Age\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 3\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 169027\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 239.12204, 'eta': 6934.53924, 'eta_hours': 1.92626, 'loss': 1.09864181, 'lr': 0.0, 'params': 169027, 'time_iter': 4.42819, 'accuracy': 0.33803, 'f1': 0.29118, 'auc': 0.5326}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 0, 'time_epoch': 14.75073, 'loss': 1.10786427, 'lr': 0, 'params': 169027, 'time_iter': 2.10725, 'accuracy': 0.26415, 'f1': 0.22914, 'auc': 0.50424}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 0, 'time_epoch': 18.62562, 'loss': 1.09791408, 'lr': 0, 'params': 169027, 'time_iter': 2.6608, 'accuracy': 0.3271, 'f1': 0.28441, 'auc': 0.553}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 0: took 272.5s (avg 272.5s) | Best so far: epoch 0\ttrain_loss: 1.0986 train_accuracy: 0.3380\tval_loss: 1.1079 val_accuracy: 0.2641\ttest_loss: 1.0979 test_accuracy: 0.3271\n",
      "train: {'epoch': 1, 'time_epoch': 239.00414, 'eta': 6693.76655, 'eta_hours': 1.85938, 'loss': 1.07027639, 'lr': 0.00033333, 'params': 169027, 'time_iter': 4.426, 'accuracy': 0.4284, 'f1': 0.36163, 'auc': 0.5665}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 1, 'time_epoch': 14.77959, 'loss': 1.06622382, 'lr': 0, 'params': 169027, 'time_iter': 2.11137, 'accuracy': 0.38679, 'f1': 0.31385, 'auc': 0.61567}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 17.84508, 'loss': 1.08545968, 'lr': 0, 'params': 169027, 'time_iter': 2.5493, 'accuracy': 0.40187, 'f1': 0.34467, 'auc': 0.53284}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 271.7s (avg 272.1s) | Best so far: epoch 1\ttrain_loss: 1.0703 train_accuracy: 0.4284\tval_loss: 1.0662 val_accuracy: 0.3868\ttest_loss: 1.0855 test_accuracy: 0.4019\n",
      "train: {'epoch': 2, 'time_epoch': 238.56781, 'eta': 6450.24593, 'eta_hours': 1.79173, 'loss': 1.03365692, 'lr': 0.00066667, 'params': 169027, 'time_iter': 4.41792, 'accuracy': 0.48239, 'f1': 0.44047, 'auc': 0.63567}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 14.68534, 'loss': 1.08625023, 'lr': 0, 'params': 169027, 'time_iter': 2.09791, 'accuracy': 0.28302, 'f1': 0.16882, 'auc': 0.63796}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 17.83405, 'loss': 1.09520539, 'lr': 0, 'params': 169027, 'time_iter': 2.54772, 'accuracy': 0.37383, 'f1': 0.23951, 'auc': 0.57223}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 2: took 271.1s (avg 271.8s) | Best so far: epoch 1\ttrain_loss: 1.0703 train_accuracy: 0.4284\tval_loss: 1.0662 val_accuracy: 0.3868\ttest_loss: 1.0855 test_accuracy: 0.4019\n",
      "train: {'epoch': 3, 'time_epoch': 248.25434, 'eta': 6272.16418, 'eta_hours': 1.74227, 'loss': 0.98706108, 'lr': 0.001, 'params': 169027, 'time_iter': 4.5973, 'accuracy': 0.51995, 'f1': 0.50193, 'auc': 0.68818}\n",
      "val: {'epoch': 3, 'time_epoch': 14.7086, 'loss': 1.07737823, 'lr': 0, 'params': 169027, 'time_iter': 2.10123, 'accuracy': 0.30189, 'f1': 0.22658, 'auc': 0.64953}\n",
      "test: {'epoch': 3, 'time_epoch': 17.87112, 'loss': 1.11878961, 'lr': 0, 'params': 169027, 'time_iter': 2.55302, 'accuracy': 0.31776, 'f1': 0.20775, 'auc': 0.53919}\n",
      "> Epoch 3: took 280.9s (avg 274.1s) | Best so far: epoch 1\ttrain_loss: 1.0703 train_accuracy: 0.4284\tval_loss: 1.0662 val_accuracy: 0.3868\ttest_loss: 1.0855 test_accuracy: 0.4019\n",
      "train: {'epoch': 4, 'time_epoch': 154.73965, 'eta': 5598.43992, 'eta_hours': 1.55512, 'loss': 0.91137938, 'lr': 0.00099662, 'params': 169027, 'time_iter': 2.86555, 'accuracy': 0.64085, 'f1': 0.63195, 'auc': 0.77924}\n",
      "val: {'epoch': 4, 'time_epoch': 0.89192, 'loss': 1.12796195, 'lr': 0, 'params': 169027, 'time_iter': 0.12742, 'accuracy': 0.36792, 'f1': 0.27494, 'auc': 0.60447}\n",
      "test: {'epoch': 4, 'time_epoch': 0.94214, 'loss': 1.16269786, 'lr': 0, 'params': 169027, 'time_iter': 0.13459, 'accuracy': 0.34579, 'f1': 0.24803, 'auc': 0.51364}\n",
      "> Epoch 4: took 156.6s (avg 250.6s) | Best so far: epoch 1\ttrain_loss: 1.0703 train_accuracy: 0.4284\tval_loss: 1.0662 val_accuracy: 0.3868\ttest_loss: 1.0855 test_accuracy: 0.4019\n",
      "train: {'epoch': 5, 'time_epoch': 13.36375, 'eta': 4532.20692, 'eta_hours': 1.25895, 'loss': 0.83590957, 'lr': 0.00098652, 'params': 169027, 'time_iter': 0.24748, 'accuracy': 0.66315, 'f1': 0.65854, 'auc': 0.82618}\n",
      "val: {'epoch': 5, 'time_epoch': 0.88899, 'loss': 1.2240575, 'lr': 0, 'params': 169027, 'time_iter': 0.127, 'accuracy': 0.26415, 'f1': 0.1393, 'auc': 0.62691}\n",
      "test: {'epoch': 5, 'time_epoch': 0.89454, 'loss': 1.21386668, 'lr': 0, 'params': 169027, 'time_iter': 0.12779, 'accuracy': 0.3271, 'f1': 0.16432, 'auc': 0.51597}\n",
      "> Epoch 5: took 15.2s (avg 211.3s) | Best so far: epoch 1\ttrain_loss: 1.0703 train_accuracy: 0.4284\tval_loss: 1.0662 val_accuracy: 0.3868\ttest_loss: 1.0855 test_accuracy: 0.4019\n",
      "train: {'epoch': 6, 'time_epoch': 13.38746, 'eta': 3766.87164, 'eta_hours': 1.04635, 'loss': 0.77200989, 'lr': 0.00096985, 'params': 169027, 'time_iter': 0.24792, 'accuracy': 0.71596, 'f1': 0.71388, 'auc': 0.85785}\n",
      "val: {'epoch': 6, 'time_epoch': 0.92361, 'loss': 1.11394618, 'lr': 0, 'params': 169027, 'time_iter': 0.13194, 'accuracy': 0.34906, 'f1': 0.31113, 'auc': 0.60768}\n",
      "test: {'epoch': 6, 'time_epoch': 0.88364, 'loss': 1.13680664, 'lr': 0, 'params': 169027, 'time_iter': 0.12623, 'accuracy': 0.33645, 'f1': 0.26923, 'auc': 0.58899}\n",
      "> Epoch 6: took 15.3s (avg 183.3s) | Best so far: epoch 1\ttrain_loss: 1.0703 train_accuracy: 0.4284\tval_loss: 1.0662 val_accuracy: 0.3868\ttest_loss: 1.0855 test_accuracy: 0.4019\n",
      "train: {'epoch': 7, 'time_epoch': 13.36775, 'eta': 3189.4691, 'eta_hours': 0.88596, 'loss': 0.72112364, 'lr': 0.00094682, 'params': 169027, 'time_iter': 0.24755, 'accuracy': 0.7277, 'f1': 0.72583, 'auc': 0.87002}\n",
      "val: {'epoch': 7, 'time_epoch': 0.9192, 'loss': 1.23038376, 'lr': 0, 'params': 169027, 'time_iter': 0.13131, 'accuracy': 0.33962, 'f1': 0.26119, 'auc': 0.5582}\n",
      "test: {'epoch': 7, 'time_epoch': 0.87451, 'loss': 1.22572781, 'lr': 0, 'params': 169027, 'time_iter': 0.12493, 'accuracy': 0.37383, 'f1': 0.31731, 'auc': 0.57884}\n",
      "> Epoch 7: took 15.2s (avg 162.3s) | Best so far: epoch 1\ttrain_loss: 1.0703 train_accuracy: 0.4284\tval_loss: 1.0662 val_accuracy: 0.3868\ttest_loss: 1.0855 test_accuracy: 0.4019\n",
      "train: {'epoch': 8, 'time_epoch': 13.39025, 'eta': 2737.46013, 'eta_hours': 0.76041, 'loss': 0.6381741, 'lr': 0.00091774, 'params': 169027, 'time_iter': 0.24797, 'accuracy': 0.79343, 'f1': 0.79253, 'auc': 0.90915}\n",
      "val: {'epoch': 8, 'time_epoch': 0.90193, 'loss': 1.1280179, 'lr': 0, 'params': 169027, 'time_iter': 0.12885, 'accuracy': 0.43396, 'f1': 0.43204, 'auc': 0.61908}\n",
      "test: {'epoch': 8, 'time_epoch': 0.84541, 'loss': 1.06683787, 'lr': 0, 'params': 169027, 'time_iter': 0.12077, 'accuracy': 0.50467, 'f1': 0.49482, 'auc': 0.6589}\n",
      "> Epoch 8: took 15.2s (avg 146.0s) | Best so far: epoch 8\ttrain_loss: 0.6382 train_accuracy: 0.7934\tval_loss: 1.1280 val_accuracy: 0.4340\ttest_loss: 1.0668 test_accuracy: 0.5047\n",
      "train: {'epoch': 9, 'time_epoch': 13.24256, 'eta': 2372.87953, 'eta_hours': 0.65913, 'loss': 0.59176929, 'lr': 0.00088302, 'params': 169027, 'time_iter': 0.24523, 'accuracy': 0.8169, 'f1': 0.81243, 'auc': 0.92116}\n",
      "val: {'epoch': 9, 'time_epoch': 0.90367, 'loss': 1.2919512, 'lr': 0, 'params': 169027, 'time_iter': 0.1291, 'accuracy': 0.41509, 'f1': 0.3172, 'auc': 0.57832}\n",
      "test: {'epoch': 9, 'time_epoch': 0.92363, 'loss': 1.32276879, 'lr': 0, 'params': 169027, 'time_iter': 0.13195, 'accuracy': 0.40187, 'f1': 0.30988, 'auc': 0.56934}\n",
      "> Epoch 9: took 15.1s (avg 132.9s) | Best so far: epoch 8\ttrain_loss: 0.6382 train_accuracy: 0.7934\tval_loss: 1.1280 val_accuracy: 0.4340\ttest_loss: 1.0668 test_accuracy: 0.5047\n",
      "train: {'epoch': 10, 'time_epoch': 13.24241, 'eta': 2072.1783, 'eta_hours': 0.57561, 'loss': 0.58151828, 'lr': 0.00084312, 'params': 169027, 'time_iter': 0.24523, 'accuracy': 0.80399, 'f1': 0.79928, 'auc': 0.92267}\n",
      "val: {'epoch': 10, 'time_epoch': 0.95252, 'loss': 1.28401995, 'lr': 0, 'params': 169027, 'time_iter': 0.13607, 'accuracy': 0.38679, 'f1': 0.34213, 'auc': 0.63337}\n",
      "test: {'epoch': 10, 'time_epoch': 0.88261, 'loss': 1.24903579, 'lr': 0, 'params': 169027, 'time_iter': 0.12609, 'accuracy': 0.41121, 'f1': 0.37981, 'auc': 0.63491}\n",
      "> Epoch 10: took 15.1s (avg 122.2s) | Best so far: epoch 8\ttrain_loss: 0.6382 train_accuracy: 0.7934\tval_loss: 1.1280 val_accuracy: 0.4340\ttest_loss: 1.0668 test_accuracy: 0.5047\n",
      "train: {'epoch': 11, 'time_epoch': 13.27082, 'eta': 1819.4295, 'eta_hours': 0.5054, 'loss': 0.51992162, 'lr': 0.00079858, 'params': 169027, 'time_iter': 0.24576, 'accuracy': 0.83803, 'f1': 0.83749, 'auc': 0.9354}\n",
      "val: {'epoch': 11, 'time_epoch': 0.88124, 'loss': 1.23785694, 'lr': 0, 'params': 169027, 'time_iter': 0.12589, 'accuracy': 0.4434, 'f1': 0.37731, 'auc': 0.6044}\n",
      "test: {'epoch': 11, 'time_epoch': 0.87371, 'loss': 1.21634025, 'lr': 0, 'params': 169027, 'time_iter': 0.12482, 'accuracy': 0.47664, 'f1': 0.42354, 'auc': 0.64252}\n",
      "> Epoch 11: took 15.1s (avg 113.2s) | Best so far: epoch 11\ttrain_loss: 0.5199 train_accuracy: 0.8380\tval_loss: 1.2379 val_accuracy: 0.4434\ttest_loss: 1.2163 test_accuracy: 0.4766\n",
      "train: {'epoch': 12, 'time_epoch': 12.96402, 'eta': 1603.12225, 'eta_hours': 0.44531, 'loss': 0.49541634, 'lr': 0.00075, 'params': 169027, 'time_iter': 0.24007, 'accuracy': 0.84624, 'f1': 0.84327, 'auc': 0.9441}\n",
      "val: {'epoch': 12, 'time_epoch': 0.90193, 'loss': 1.26901136, 'lr': 0, 'params': 169027, 'time_iter': 0.12885, 'accuracy': 0.45283, 'f1': 0.35732, 'auc': 0.60211}\n",
      "test: {'epoch': 12, 'time_epoch': 0.8628, 'loss': 1.25457062, 'lr': 0, 'params': 169027, 'time_iter': 0.12326, 'accuracy': 0.49533, 'f1': 0.41516, 'auc': 0.652}\n",
      "> Epoch 12: took 14.8s (avg 105.7s) | Best so far: epoch 12\ttrain_loss: 0.4954 train_accuracy: 0.8462\tval_loss: 1.2690 val_accuracy: 0.4528\ttest_loss: 1.2546 test_accuracy: 0.4953\n",
      "train: {'epoch': 13, 'time_epoch': 13.65686, 'eta': 1416.65586, 'eta_hours': 0.39352, 'loss': 0.41651914, 'lr': 0.00069804, 'params': 169027, 'time_iter': 0.2529, 'accuracy': 0.89671, 'f1': 0.8936, 'auc': 0.96059}\n",
      "val: {'epoch': 13, 'time_epoch': 1.00049, 'loss': 1.43067192, 'lr': 0, 'params': 169027, 'time_iter': 0.14293, 'accuracy': 0.39623, 'f1': 0.39047, 'auc': 0.58096}\n",
      "test: {'epoch': 13, 'time_epoch': 0.85757, 'loss': 1.38726509, 'lr': 0, 'params': 169027, 'time_iter': 0.12251, 'accuracy': 0.40187, 'f1': 0.37128, 'auc': 0.61854}\n",
      "> Epoch 13: took 15.6s (avg 99.2s) | Best so far: epoch 12\ttrain_loss: 0.4954 train_accuracy: 0.8462\tval_loss: 1.2690 val_accuracy: 0.4528\ttest_loss: 1.2546 test_accuracy: 0.4953\n",
      "train: {'epoch': 14, 'time_epoch': 13.6091, 'eta': 1253.18298, 'eta_hours': 0.34811, 'loss': 0.41029354, 'lr': 0.0006434, 'params': 169027, 'time_iter': 0.25202, 'accuracy': 0.8838, 'f1': 0.88008, 'auc': 0.96246}\n",
      "val: {'epoch': 14, 'time_epoch': 0.89353, 'loss': 1.33520303, 'lr': 0, 'params': 169027, 'time_iter': 0.12765, 'accuracy': 0.43396, 'f1': 0.44392, 'auc': 0.59304}\n",
      "test: {'epoch': 14, 'time_epoch': 0.87583, 'loss': 1.23081761, 'lr': 0, 'params': 169027, 'time_iter': 0.12512, 'accuracy': 0.48598, 'f1': 0.46168, 'auc': 0.65835}\n",
      "> Epoch 14: took 15.4s (avg 93.6s) | Best so far: epoch 12\ttrain_loss: 0.4954 train_accuracy: 0.8462\tval_loss: 1.2690 val_accuracy: 0.4528\ttest_loss: 1.2546 test_accuracy: 0.4953\n",
      "train: {'epoch': 15, 'time_epoch': 13.66191, 'eta': 1108.48928, 'eta_hours': 0.30791, 'loss': 0.41405452, 'lr': 0.00058682, 'params': 169027, 'time_iter': 0.253, 'accuracy': 0.87911, 'f1': 0.87194, 'auc': 0.95852}\n",
      "val: {'epoch': 15, 'time_epoch': 0.89542, 'loss': 1.47744066, 'lr': 0, 'params': 169027, 'time_iter': 0.12792, 'accuracy': 0.33962, 'f1': 0.33844, 'auc': 0.58393}\n",
      "test: {'epoch': 15, 'time_epoch': 0.7857, 'loss': 1.25562696, 'lr': 0, 'params': 169027, 'time_iter': 0.11224, 'accuracy': 0.45794, 'f1': 0.44827, 'auc': 0.65275}\n",
      "> Epoch 15: took 15.4s (avg 88.8s) | Best so far: epoch 12\ttrain_loss: 0.4954 train_accuracy: 0.8462\tval_loss: 1.2690 val_accuracy: 0.4528\ttest_loss: 1.2546 test_accuracy: 0.4953\n",
      "train: {'epoch': 16, 'time_epoch': 13.24291, 'eta': 978.89067, 'eta_hours': 0.27191, 'loss': 0.32245899, 'lr': 0.00052907, 'params': 169027, 'time_iter': 0.24524, 'accuracy': 0.91784, 'f1': 0.91264, 'auc': 0.97748}\n",
      "val: {'epoch': 16, 'time_epoch': 0.87112, 'loss': 1.34214979, 'lr': 0, 'params': 169027, 'time_iter': 0.12445, 'accuracy': 0.4717, 'f1': 0.46731, 'auc': 0.60047}\n",
      "test: {'epoch': 16, 'time_epoch': 0.82864, 'loss': 1.28459675, 'lr': 0, 'params': 169027, 'time_iter': 0.11838, 'accuracy': 0.46729, 'f1': 0.46189, 'auc': 0.65365}\n",
      "> Epoch 16: took 15.0s (avg 84.4s) | Best so far: epoch 16\ttrain_loss: 0.3225 train_accuracy: 0.9178\tval_loss: 1.3421 val_accuracy: 0.4717\ttest_loss: 1.2846 test_accuracy: 0.4673\n",
      "train: {'epoch': 17, 'time_epoch': 13.66133, 'eta': 862.49942, 'eta_hours': 0.23958, 'loss': 0.31552621, 'lr': 0.00047093, 'params': 169027, 'time_iter': 0.25299, 'accuracy': 0.92136, 'f1': 0.91814, 'auc': 0.97763}\n",
      "val: {'epoch': 17, 'time_epoch': 0.87349, 'loss': 1.4752413, 'lr': 0, 'params': 169027, 'time_iter': 0.12478, 'accuracy': 0.39623, 'f1': 0.40334, 'auc': 0.59713}\n",
      "test: {'epoch': 17, 'time_epoch': 0.82915, 'loss': 1.4035321, 'lr': 0, 'params': 169027, 'time_iter': 0.11845, 'accuracy': 0.42991, 'f1': 0.42961, 'auc': 0.62954}\n",
      "> Epoch 17: took 15.4s (avg 80.6s) | Best so far: epoch 16\ttrain_loss: 0.3225 train_accuracy: 0.9178\tval_loss: 1.3421 val_accuracy: 0.4717\ttest_loss: 1.2846 test_accuracy: 0.4673\n",
      "train: {'epoch': 18, 'time_epoch': 13.50151, 'eta': 756.82932, 'eta_hours': 0.21023, 'loss': 0.30935326, 'lr': 0.00041318, 'params': 169027, 'time_iter': 0.25003, 'accuracy': 0.92371, 'f1': 0.91913, 'auc': 0.97887}\n",
      "val: {'epoch': 18, 'time_epoch': 0.90151, 'loss': 1.20787936, 'lr': 0, 'params': 169027, 'time_iter': 0.12879, 'accuracy': 0.54717, 'f1': 0.48899, 'auc': 0.65367}\n",
      "test: {'epoch': 18, 'time_epoch': 0.883, 'loss': 1.40889763, 'lr': 0, 'params': 169027, 'time_iter': 0.12614, 'accuracy': 0.48598, 'f1': 0.3994, 'auc': 0.63051}\n",
      "> Epoch 18: took 15.3s (avg 77.2s) | Best so far: epoch 18\ttrain_loss: 0.3094 train_accuracy: 0.9237\tval_loss: 1.2079 val_accuracy: 0.5472\ttest_loss: 1.4089 test_accuracy: 0.4860\n",
      "train: {'epoch': 19, 'time_epoch': 13.42409, 'eta': 660.33737, 'eta_hours': 0.18343, 'loss': 0.2587229, 'lr': 0.0003566, 'params': 169027, 'time_iter': 0.24859, 'accuracy': 0.94249, 'f1': 0.94093, 'auc': 0.9855}\n",
      "val: {'epoch': 19, 'time_epoch': 0.91302, 'loss': 1.47902211, 'lr': 0, 'params': 169027, 'time_iter': 0.13043, 'accuracy': 0.43396, 'f1': 0.43348, 'auc': 0.57314}\n",
      "test: {'epoch': 19, 'time_epoch': 0.88596, 'loss': 1.35774929, 'lr': 0, 'params': 169027, 'time_iter': 0.12657, 'accuracy': 0.48598, 'f1': 0.45946, 'auc': 0.64078}\n",
      "> Epoch 19: took 15.3s (avg 74.1s) | Best so far: epoch 18\ttrain_loss: 0.3094 train_accuracy: 0.9237\tval_loss: 1.2079 val_accuracy: 0.5472\ttest_loss: 1.4089 test_accuracy: 0.4860\n",
      "train: {'epoch': 20, 'time_epoch': 13.44306, 'eta': 571.76477, 'eta_hours': 0.15882, 'loss': 0.22267794, 'lr': 0.00030196, 'params': 169027, 'time_iter': 0.24895, 'accuracy': 0.95775, 'f1': 0.95619, 'auc': 0.98833}\n",
      "val: {'epoch': 20, 'time_epoch': 0.93978, 'loss': 1.51467884, 'lr': 0, 'params': 169027, 'time_iter': 0.13425, 'accuracy': 0.43396, 'f1': 0.42496, 'auc': 0.59232}\n",
      "test: {'epoch': 20, 'time_epoch': 0.90295, 'loss': 1.35157062, 'lr': 0, 'params': 169027, 'time_iter': 0.12899, 'accuracy': 0.51402, 'f1': 0.48711, 'auc': 0.64876}\n",
      "> Epoch 20: took 15.3s (avg 71.3s) | Best so far: epoch 18\ttrain_loss: 0.3094 train_accuracy: 0.9237\tval_loss: 1.2079 val_accuracy: 0.5472\ttest_loss: 1.4089 test_accuracy: 0.4860\n",
      "train: {'epoch': 21, 'time_epoch': 13.47846, 'eta': 490.035, 'eta_hours': 0.13612, 'loss': 0.21927175, 'lr': 0.00025, 'params': 169027, 'time_iter': 0.2496, 'accuracy': 0.95892, 'f1': 0.95483, 'auc': 0.98736}\n",
      "val: {'epoch': 21, 'time_epoch': 0.86472, 'loss': 1.47293445, 'lr': 0, 'params': 169027, 'time_iter': 0.12353, 'accuracy': 0.46226, 'f1': 0.43413, 'auc': 0.5887}\n",
      "test: {'epoch': 21, 'time_epoch': 0.89698, 'loss': 1.34385217, 'lr': 0, 'params': 169027, 'time_iter': 0.12814, 'accuracy': 0.54206, 'f1': 0.50339, 'auc': 0.68372}\n",
      "> Epoch 21: took 15.3s (avg 68.7s) | Best so far: epoch 18\ttrain_loss: 0.3094 train_accuracy: 0.9237\tval_loss: 1.2079 val_accuracy: 0.5472\ttest_loss: 1.4089 test_accuracy: 0.4860\n",
      "train: {'epoch': 22, 'time_epoch': 13.38594, 'eta': 414.21197, 'eta_hours': 0.11506, 'loss': 0.21046083, 'lr': 0.00020142, 'params': 169027, 'time_iter': 0.24789, 'accuracy': 0.96009, 'f1': 0.95525, 'auc': 0.99006}\n",
      "val: {'epoch': 22, 'time_epoch': 0.90737, 'loss': 1.5304686, 'lr': 0, 'params': 169027, 'time_iter': 0.12962, 'accuracy': 0.41509, 'f1': 0.4071, 'auc': 0.60678}\n",
      "test: {'epoch': 22, 'time_epoch': 0.86691, 'loss': 1.33116693, 'lr': 0, 'params': 169027, 'time_iter': 0.12384, 'accuracy': 0.49533, 'f1': 0.48058, 'auc': 0.66944}\n",
      "> Epoch 22: took 15.2s (avg 66.4s) | Best so far: epoch 18\ttrain_loss: 0.3094 train_accuracy: 0.9237\tval_loss: 1.2079 val_accuracy: 0.5472\ttest_loss: 1.4089 test_accuracy: 0.4860\n",
      "train: {'epoch': 23, 'time_epoch': 13.66305, 'eta': 343.66131, 'eta_hours': 0.09546, 'loss': 0.23155703, 'lr': 0.00015688, 'params': 169027, 'time_iter': 0.25302, 'accuracy': 0.94718, 'f1': 0.94469, 'auc': 0.98511}\n",
      "val: {'epoch': 23, 'time_epoch': 0.90836, 'loss': 1.59626784, 'lr': 0, 'params': 169027, 'time_iter': 0.12977, 'accuracy': 0.41509, 'f1': 0.41802, 'auc': 0.58075}\n",
      "test: {'epoch': 23, 'time_epoch': 0.92932, 'loss': 1.38320732, 'lr': 0, 'params': 169027, 'time_iter': 0.13276, 'accuracy': 0.50467, 'f1': 0.48206, 'auc': 0.65342}\n",
      "> Epoch 23: took 15.5s (avg 64.3s) | Best so far: epoch 18\ttrain_loss: 0.3094 train_accuracy: 0.9237\tval_loss: 1.2079 val_accuracy: 0.5472\ttest_loss: 1.4089 test_accuracy: 0.4860\n",
      "train: {'epoch': 24, 'time_epoch': 13.51733, 'eta': 277.63252, 'eta_hours': 0.07712, 'loss': 0.18874846, 'lr': 0.00011698, 'params': 169027, 'time_iter': 0.25032, 'accuracy': 0.96714, 'f1': 0.9655, 'auc': 0.99153}\n",
      "val: {'epoch': 24, 'time_epoch': 0.93924, 'loss': 1.5206774, 'lr': 0, 'params': 169027, 'time_iter': 0.13418, 'accuracy': 0.48113, 'f1': 0.47909, 'auc': 0.59085}\n",
      "test: {'epoch': 24, 'time_epoch': 0.90013, 'loss': 1.31743169, 'lr': 0, 'params': 169027, 'time_iter': 0.12859, 'accuracy': 0.52336, 'f1': 0.50971, 'auc': 0.68235}\n",
      "> Epoch 24: took 15.4s (avg 62.3s) | Best so far: epoch 18\ttrain_loss: 0.3094 train_accuracy: 0.9237\tval_loss: 1.2079 val_accuracy: 0.5472\ttest_loss: 1.4089 test_accuracy: 0.4860\n",
      "train: {'epoch': 25, 'time_epoch': 13.58954, 'eta': 215.65417, 'eta_hours': 0.0599, 'loss': 0.17083172, 'lr': 8.226e-05, 'params': 169027, 'time_iter': 0.25166, 'accuracy': 0.97887, 'f1': 0.97737, 'auc': 0.99237}\n",
      "val: {'epoch': 25, 'time_epoch': 0.88762, 'loss': 1.51268321, 'lr': 0, 'params': 169027, 'time_iter': 0.1268, 'accuracy': 0.48113, 'f1': 0.47161, 'auc': 0.58901}\n",
      "test: {'epoch': 25, 'time_epoch': 0.91672, 'loss': 1.36050883, 'lr': 0, 'params': 169027, 'time_iter': 0.13096, 'accuracy': 0.52336, 'f1': 0.50606, 'auc': 0.68567}\n",
      "> Epoch 25: took 15.4s (avg 60.5s) | Best so far: epoch 18\ttrain_loss: 0.3094 train_accuracy: 0.9237\tval_loss: 1.2079 val_accuracy: 0.5472\ttest_loss: 1.4089 test_accuracy: 0.4860\n",
      "train: {'epoch': 26, 'time_epoch': 13.60147, 'eta': 157.26151, 'eta_hours': 0.04368, 'loss': 0.17138505, 'lr': 5.318e-05, 'params': 169027, 'time_iter': 0.25188, 'accuracy': 0.97418, 'f1': 0.97205, 'auc': 0.99413}\n",
      "val: {'epoch': 26, 'time_epoch': 0.88602, 'loss': 1.49865846, 'lr': 0, 'params': 169027, 'time_iter': 0.12657, 'accuracy': 0.49057, 'f1': 0.48334, 'auc': 0.58421}\n",
      "test: {'epoch': 26, 'time_epoch': 0.87918, 'loss': 1.38615093, 'lr': 0, 'params': 169027, 'time_iter': 0.1256, 'accuracy': 0.51402, 'f1': 0.47661, 'auc': 0.68649}\n",
      "> Epoch 26: took 15.4s (avg 58.8s) | Best so far: epoch 18\ttrain_loss: 0.3094 train_accuracy: 0.9237\tval_loss: 1.2079 val_accuracy: 0.5472\ttest_loss: 1.4089 test_accuracy: 0.4860\n",
      "train: {'epoch': 27, 'time_epoch': 13.45906, 'eta': 102.05805, 'eta_hours': 0.02835, 'loss': 0.16173479, 'lr': 3.015e-05, 'params': 169027, 'time_iter': 0.24924, 'accuracy': 0.98005, 'f1': 0.97808, 'auc': 0.99459}\n",
      "val: {'epoch': 27, 'time_epoch': 0.90821, 'loss': 1.55802492, 'lr': 0, 'params': 169027, 'time_iter': 0.12974, 'accuracy': 0.45283, 'f1': 0.44951, 'auc': 0.58599}\n",
      "test: {'epoch': 27, 'time_epoch': 0.89185, 'loss': 1.36996249, 'lr': 0, 'params': 169027, 'time_iter': 0.12741, 'accuracy': 0.50467, 'f1': 0.49795, 'auc': 0.67222}\n",
      "> Epoch 27: took 15.3s (avg 57.3s) | Best so far: epoch 18\ttrain_loss: 0.3094 train_accuracy: 0.9237\tval_loss: 1.2079 val_accuracy: 0.5472\ttest_loss: 1.4089 test_accuracy: 0.4860\n",
      "train: {'epoch': 28, 'time_epoch': 13.45647, 'eta': 49.73342, 'eta_hours': 0.01381, 'loss': 0.18965274, 'lr': 1.348e-05, 'params': 169027, 'time_iter': 0.24919, 'accuracy': 0.96714, 'f1': 0.96391, 'auc': 0.99145}\n",
      "val: {'epoch': 28, 'time_epoch': 0.8914, 'loss': 1.49054466, 'lr': 0, 'params': 169027, 'time_iter': 0.12734, 'accuracy': 0.48113, 'f1': 0.46913, 'auc': 0.5976}\n",
      "test: {'epoch': 28, 'time_epoch': 0.92164, 'loss': 1.38767388, 'lr': 0, 'params': 169027, 'time_iter': 0.13166, 'accuracy': 0.52336, 'f1': 0.50127, 'auc': 0.68676}\n",
      "> Epoch 28: took 15.3s (avg 55.8s) | Best so far: epoch 18\ttrain_loss: 0.3094 train_accuracy: 0.9237\tval_loss: 1.2079 val_accuracy: 0.5472\ttest_loss: 1.4089 test_accuracy: 0.4860\n",
      "train: {'epoch': 29, 'time_epoch': 13.44337, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.16275728, 'lr': 3.38e-06, 'params': 169027, 'time_iter': 0.24895, 'accuracy': 0.97653, 'f1': 0.97411, 'auc': 0.99368}\n",
      "val: {'epoch': 29, 'time_epoch': 0.87904, 'loss': 1.51278668, 'lr': 0, 'params': 169027, 'time_iter': 0.12558, 'accuracy': 0.4717, 'f1': 0.46249, 'auc': 0.59293}\n",
      "test: {'epoch': 29, 'time_epoch': 0.91306, 'loss': 1.3641673, 'lr': 0, 'params': 169027, 'time_iter': 0.13044, 'accuracy': 0.51402, 'f1': 0.49228, 'auc': 0.6776}\n",
      "> Epoch 29: took 15.3s (avg 54.5s) | Best so far: epoch 18\ttrain_loss: 0.3094 train_accuracy: 0.9237\tval_loss: 1.2079 val_accuracy: 0.5472\ttest_loss: 1.4089 test_accuracy: 0.4860\n",
      "Avg time per epoch: 54.49s\n",
      "Total train loop time: 0.45h\n",
      "Task done, results saved in results\\neural-Age\\0\n",
      "18\n",
      "{'epoch': 18, 'time_epoch': 0.883, 'loss': 1.40889763, 'lr': 0, 'params': 169027, 'time_iter': 0.12614, 'accuracy': 0.48598, 'f1': 0.3994, 'auc': 0.63051}\n",
      "{'epoch': 18, 'time_epoch': 13.50151, 'eta': 756.82932, 'eta_hours': 0.21023, 'loss': 0.30935326, 'lr': 0.00041318, 'params': 169027, 'time_iter': 0.25003, 'accuracy': 0.92371, 'f1': 0.91913, 'auc': 0.97887}\n",
      "{'epoch': 18, 'time_epoch': 0.90151, 'loss': 1.20787936, 'lr': 0, 'params': 169027, 'time_iter': 0.12879, 'accuracy': 0.54717, 'f1': 0.48899, 'auc': 0.65367}\n",
      "Results aggregated across runs saved in results\\neural-Age\\agg\n",
      "[*] All done: 2024-02-27 01:45:09.018286\n"
     ]
    }
   ],
   "source": [
    "#Age using Exphormer\n",
    "%run main.py --cfg configs/Exphormer/neural-Age.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3edffbe-5232-4301-934e-a64f1a9c3ebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-28 00:14:08.983151\n",
      "[*] Loaded dataset 'HCPAge' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1065000, 1000], edge_index=[2, 48551656], y=[1065])\n",
      "  undirected: True\n",
      "  num graphs: 1065\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 3\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [04:19<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:04:25.66\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [01:22<00:00, 12.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:24.43\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 3, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPAge\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.3\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 3\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 50\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 3\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Age\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Age\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 3\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 169027\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 120.12904, 'eta': 5886.32276, 'eta_hours': 1.63509, 'loss': 1.0991891, 'lr': 0.0, 'params': 169027, 'time_iter': 2.22461, 'accuracy': 0.3392, 'f1': 0.29539, 'auc': 0.52983}\n",
      "...computing epoch stats took: 0.14s\n",
      "val: {'epoch': 0, 'time_epoch': 0.9085, 'loss': 1.10799156, 'lr': 0, 'params': 169027, 'time_iter': 0.12979, 'accuracy': 0.26415, 'f1': 0.22947, 'auc': 0.50479}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 0, 'time_epoch': 0.90934, 'loss': 1.0981158, 'lr': 0, 'params': 169027, 'time_iter': 0.12991, 'accuracy': 0.33645, 'f1': 0.28456, 'auc': 0.55476}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 122.1s (avg 122.1s) | Best so far: epoch 0\ttrain_loss: 1.0992 train_accuracy: 0.3392\tval_loss: 1.1080 val_accuracy: 0.2641\ttest_loss: 1.0981 test_accuracy: 0.3365\n",
      "train: {'epoch': 1, 'time_epoch': 115.81348, 'eta': 5662.62027, 'eta_hours': 1.57295, 'loss': 1.07019505, 'lr': 0.00033333, 'params': 169027, 'time_iter': 2.14469, 'accuracy': 0.42019, 'f1': 0.34869, 'auc': 0.56223}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 1, 'time_epoch': 0.8818, 'loss': 1.07136814, 'lr': 0, 'params': 169027, 'time_iter': 0.12597, 'accuracy': 0.36792, 'f1': 0.27606, 'auc': 0.57748}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 0.90448, 'loss': 1.09028017, 'lr': 0, 'params': 169027, 'time_iter': 0.12921, 'accuracy': 0.40187, 'f1': 0.30902, 'auc': 0.5153}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 117.7s (avg 119.9s) | Best so far: epoch 1\ttrain_loss: 1.0702 train_accuracy: 0.4202\tval_loss: 1.0714 val_accuracy: 0.3679\ttest_loss: 1.0903 test_accuracy: 0.4019\n",
      "train: {'epoch': 2, 'time_epoch': 123.15837, 'eta': 5625.91379, 'eta_hours': 1.56275, 'loss': 1.03621072, 'lr': 0.00066667, 'params': 169027, 'time_iter': 2.28071, 'accuracy': 0.45423, 'f1': 0.38439, 'auc': 0.6223}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 0.85544, 'loss': 1.08754709, 'lr': 0, 'params': 169027, 'time_iter': 0.12221, 'accuracy': 0.28302, 'f1': 0.1674, 'auc': 0.6317}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 0.86557, 'loss': 1.09960292, 'lr': 0, 'params': 169027, 'time_iter': 0.12365, 'accuracy': 0.33645, 'f1': 0.18148, 'auc': 0.55532}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 124.9s (avg 121.6s) | Best so far: epoch 1\ttrain_loss: 1.0702 train_accuracy: 0.4202\tval_loss: 1.0714 val_accuracy: 0.3679\ttest_loss: 1.0903 test_accuracy: 0.4019\n",
      "train: {'epoch': 3, 'time_epoch': 133.54441, 'eta': 5665.42088, 'eta_hours': 1.57373, 'loss': 0.99507243, 'lr': 0.001, 'params': 169027, 'time_iter': 2.47304, 'accuracy': 0.50939, 'f1': 0.46258, 'auc': 0.6789}\n",
      "val: {'epoch': 3, 'time_epoch': 1.15351, 'loss': 1.12777032, 'lr': 0, 'params': 169027, 'time_iter': 0.16479, 'accuracy': 0.27358, 'f1': 0.15293, 'auc': 0.56883}\n",
      "test: {'epoch': 3, 'time_epoch': 1.26248, 'loss': 1.13814687, 'lr': 0, 'params': 169027, 'time_iter': 0.18035, 'accuracy': 0.3271, 'f1': 0.16432, 'auc': 0.48221}\n",
      "> Epoch 3: took 136.1s (avg 125.2s) | Best so far: epoch 1\ttrain_loss: 1.0702 train_accuracy: 0.4202\tval_loss: 1.0714 val_accuracy: 0.3679\ttest_loss: 1.0903 test_accuracy: 0.4019\n",
      "train: {'epoch': 4, 'time_epoch': 150.75733, 'eta': 5790.6236, 'eta_hours': 1.60851, 'loss': 0.92770995, 'lr': 0.00099888, 'params': 169027, 'time_iter': 2.7918, 'accuracy': 0.60798, 'f1': 0.58517, 'auc': 0.75981}\n",
      "val: {'epoch': 4, 'time_epoch': 0.87488, 'loss': 1.11825959, 'lr': 0, 'params': 169027, 'time_iter': 0.12498, 'accuracy': 0.36792, 'f1': 0.2739, 'auc': 0.58772}\n",
      "test: {'epoch': 4, 'time_epoch': 0.90244, 'loss': 1.09652944, 'lr': 0, 'params': 169027, 'time_iter': 0.12892, 'accuracy': 0.42991, 'f1': 0.32901, 'auc': 0.62771}\n",
      "> Epoch 4: took 152.6s (avg 130.7s) | Best so far: epoch 1\ttrain_loss: 1.0702 train_accuracy: 0.4202\tval_loss: 1.0714 val_accuracy: 0.3679\ttest_loss: 1.0903 test_accuracy: 0.4019\n",
      "train: {'epoch': 5, 'time_epoch': 119.54065, 'eta': 5594.9173, 'eta_hours': 1.55414, 'loss': 0.86408507, 'lr': 0.00099554, 'params': 169027, 'time_iter': 2.21372, 'accuracy': 0.64319, 'f1': 0.63873, 'auc': 0.7958}\n",
      "val: {'epoch': 5, 'time_epoch': 0.86685, 'loss': 1.05888558, 'lr': 0, 'params': 169027, 'time_iter': 0.12384, 'accuracy': 0.40566, 'f1': 0.38807, 'auc': 0.63266}\n",
      "test: {'epoch': 5, 'time_epoch': 0.87175, 'loss': 1.04442535, 'lr': 0, 'params': 169027, 'time_iter': 0.12454, 'accuracy': 0.46729, 'f1': 0.46311, 'auc': 0.64505}\n",
      "> Epoch 5: took 121.3s (avg 129.1s) | Best so far: epoch 5\ttrain_loss: 0.8641 train_accuracy: 0.6432\tval_loss: 1.0589 val_accuracy: 0.4057\ttest_loss: 1.0444 test_accuracy: 0.4673\n",
      "train: {'epoch': 6, 'time_epoch': 122.52556, 'eta': 5439.30851, 'eta_hours': 1.51092, 'loss': 0.79420248, 'lr': 0.00098998, 'params': 169027, 'time_iter': 2.26899, 'accuracy': 0.71244, 'f1': 0.69983, 'auc': 0.8448}\n",
      "val: {'epoch': 6, 'time_epoch': 0.88443, 'loss': 1.18976836, 'lr': 0, 'params': 169027, 'time_iter': 0.12635, 'accuracy': 0.31132, 'f1': 0.25369, 'auc': 0.64967}\n",
      "test: {'epoch': 6, 'time_epoch': 0.87356, 'loss': 1.16412875, 'lr': 0, 'params': 169027, 'time_iter': 0.12479, 'accuracy': 0.39252, 'f1': 0.30968, 'auc': 0.5296}\n",
      "> Epoch 6: took 124.3s (avg 128.4s) | Best so far: epoch 5\ttrain_loss: 0.8641 train_accuracy: 0.6432\tval_loss: 1.0589 val_accuracy: 0.4057\ttest_loss: 1.0444 test_accuracy: 0.4673\n",
      "train: {'epoch': 7, 'time_epoch': 122.25339, 'eta': 5290.54165, 'eta_hours': 1.46959, 'loss': 0.73185983, 'lr': 0.00098223, 'params': 169027, 'time_iter': 2.26395, 'accuracy': 0.74413, 'f1': 0.74032, 'auc': 0.8636}\n",
      "val: {'epoch': 7, 'time_epoch': 0.9024, 'loss': 1.3337558, 'lr': 0, 'params': 169027, 'time_iter': 0.12891, 'accuracy': 0.28302, 'f1': 0.16611, 'auc': 0.5692}\n",
      "test: {'epoch': 7, 'time_epoch': 0.90412, 'loss': 1.33386965, 'lr': 0, 'params': 169027, 'time_iter': 0.12916, 'accuracy': 0.3271, 'f1': 0.17756, 'auc': 0.53264}\n",
      "> Epoch 7: took 124.1s (avg 127.9s) | Best so far: epoch 5\ttrain_loss: 0.8641 train_accuracy: 0.6432\tval_loss: 1.0589 val_accuracy: 0.4057\ttest_loss: 1.0444 test_accuracy: 0.4673\n",
      "train: {'epoch': 8, 'time_epoch': 126.22018, 'eta': 5165.7376, 'eta_hours': 1.43493, 'loss': 0.6886028, 'lr': 0.00097233, 'params': 169027, 'time_iter': 2.33741, 'accuracy': 0.75117, 'f1': 0.74516, 'auc': 0.88918}\n",
      "val: {'epoch': 8, 'time_epoch': 0.87737, 'loss': 1.20579095, 'lr': 0, 'params': 169027, 'time_iter': 0.12534, 'accuracy': 0.39623, 'f1': 0.3004, 'auc': 0.59504}\n",
      "test: {'epoch': 8, 'time_epoch': 0.8484, 'loss': 1.1944861, 'lr': 0, 'params': 169027, 'time_iter': 0.1212, 'accuracy': 0.40187, 'f1': 0.35549, 'auc': 0.57951}\n",
      "> Epoch 8: took 128.0s (avg 127.9s) | Best so far: epoch 5\ttrain_loss: 0.8641 train_accuracy: 0.6432\tval_loss: 1.0589 val_accuracy: 0.4057\ttest_loss: 1.0444 test_accuracy: 0.4673\n",
      "train: {'epoch': 9, 'time_epoch': 118.38562, 'eta': 5009.31207, 'eta_hours': 1.39148, 'loss': 0.62873818, 'lr': 0.00096032, 'params': 169027, 'time_iter': 2.19233, 'accuracy': 0.78521, 'f1': 0.78183, 'auc': 0.90115}\n",
      "val: {'epoch': 9, 'time_epoch': 0.86223, 'loss': 1.14298471, 'lr': 0, 'params': 169027, 'time_iter': 0.12318, 'accuracy': 0.41509, 'f1': 0.41559, 'auc': 0.66213}\n",
      "test: {'epoch': 9, 'time_epoch': 0.89576, 'loss': 1.14767586, 'lr': 0, 'params': 169027, 'time_iter': 0.12797, 'accuracy': 0.4486, 'f1': 0.44797, 'auc': 0.61113}\n",
      "> Epoch 9: took 120.2s (avg 127.1s) | Best so far: epoch 9\ttrain_loss: 0.6287 train_accuracy: 0.7852\tval_loss: 1.1430 val_accuracy: 0.4151\ttest_loss: 1.1477 test_accuracy: 0.4486\n",
      "train: {'epoch': 10, 'time_epoch': 115.3592, 'eta': 4849.07286, 'eta_hours': 1.34696, 'loss': 0.5789384, 'lr': 0.00094626, 'params': 169027, 'time_iter': 2.13628, 'accuracy': 0.81573, 'f1': 0.81294, 'auc': 0.91808}\n",
      "val: {'epoch': 10, 'time_epoch': 0.87289, 'loss': 1.16021806, 'lr': 0, 'params': 169027, 'time_iter': 0.1247, 'accuracy': 0.5283, 'f1': 0.38256, 'auc': 0.58584}\n",
      "test: {'epoch': 10, 'time_epoch': 0.84191, 'loss': 1.28669188, 'lr': 0, 'params': 169027, 'time_iter': 0.12027, 'accuracy': 0.43925, 'f1': 0.29132, 'auc': 0.62064}\n",
      "> Epoch 10: took 117.1s (avg 126.2s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 11, 'time_epoch': 117.58246, 'eta': 4703.35399, 'eta_hours': 1.30649, 'loss': 0.55576642, 'lr': 0.0009302, 'params': 169027, 'time_iter': 2.17745, 'accuracy': 0.82864, 'f1': 0.82598, 'auc': 0.91838}\n",
      "val: {'epoch': 11, 'time_epoch': 0.86928, 'loss': 1.14293566, 'lr': 0, 'params': 169027, 'time_iter': 0.12418, 'accuracy': 0.5, 'f1': 0.46508, 'auc': 0.67539}\n",
      "test: {'epoch': 11, 'time_epoch': 0.83787, 'loss': 1.28680027, 'lr': 0, 'params': 169027, 'time_iter': 0.1197, 'accuracy': 0.43925, 'f1': 0.39392, 'auc': 0.62171}\n",
      "> Epoch 11: took 119.3s (avg 125.6s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 12, 'time_epoch': 127.99442, 'eta': 4591.59781, 'eta_hours': 1.27544, 'loss': 0.52001123, 'lr': 0.00091222, 'params': 169027, 'time_iter': 2.37027, 'accuracy': 0.83333, 'f1': 0.82792, 'auc': 0.93267}\n",
      "val: {'epoch': 12, 'time_epoch': 0.89565, 'loss': 1.21969943, 'lr': 0, 'params': 169027, 'time_iter': 0.12795, 'accuracy': 0.43396, 'f1': 0.43547, 'auc': 0.63769}\n",
      "test: {'epoch': 12, 'time_epoch': 0.87275, 'loss': 1.20269846, 'lr': 0, 'params': 169027, 'time_iter': 0.12468, 'accuracy': 0.45794, 'f1': 0.45832, 'auc': 0.64256}\n",
      "> Epoch 12: took 129.8s (avg 126.0s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 13, 'time_epoch': 126.38804, 'eta': 4473.39121, 'eta_hours': 1.24261, 'loss': 0.52384136, 'lr': 0.0008924, 'params': 169027, 'time_iter': 2.34052, 'accuracy': 0.82746, 'f1': 0.81769, 'auc': 0.92659}\n",
      "val: {'epoch': 13, 'time_epoch': 0.8574, 'loss': 1.28195477, 'lr': 0, 'params': 169027, 'time_iter': 0.12249, 'accuracy': 0.43396, 'f1': 0.34206, 'auc': 0.6228}\n",
      "test: {'epoch': 13, 'time_epoch': 0.83654, 'loss': 1.30063878, 'lr': 0, 'params': 169027, 'time_iter': 0.11951, 'accuracy': 0.4486, 'f1': 0.35311, 'auc': 0.646}\n",
      "> Epoch 13: took 128.1s (avg 126.1s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 14, 'time_epoch': 124.63781, 'eta': 4350.00987, 'eta_hours': 1.20834, 'loss': 0.46071067, 'lr': 0.00087083, 'params': 169027, 'time_iter': 2.30811, 'accuracy': 0.85915, 'f1': 0.85736, 'auc': 0.93725}\n",
      "val: {'epoch': 14, 'time_epoch': 0.87974, 'loss': 1.32257502, 'lr': 0, 'params': 169027, 'time_iter': 0.12568, 'accuracy': 0.4434, 'f1': 0.38046, 'auc': 0.58934}\n",
      "test: {'epoch': 14, 'time_epoch': 0.88371, 'loss': 1.29896618, 'lr': 0, 'params': 169027, 'time_iter': 0.12624, 'accuracy': 0.47664, 'f1': 0.40515, 'auc': 0.66342}\n",
      "> Epoch 14: took 126.4s (avg 126.1s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 15, 'time_epoch': 121.39724, 'eta': 4219.58526, 'eta_hours': 1.17211, 'loss': 0.45096481, 'lr': 0.0008476, 'params': 169027, 'time_iter': 2.2481, 'accuracy': 0.85915, 'f1': 0.85689, 'auc': 0.94245}\n",
      "val: {'epoch': 15, 'time_epoch': 0.87817, 'loss': 1.42584174, 'lr': 0, 'params': 169027, 'time_iter': 0.12545, 'accuracy': 0.35849, 'f1': 0.33664, 'auc': 0.63884}\n",
      "test: {'epoch': 15, 'time_epoch': 0.88478, 'loss': 1.44603221, 'lr': 0, 'params': 169027, 'time_iter': 0.1264, 'accuracy': 0.34579, 'f1': 0.29117, 'auc': 0.59425}\n",
      "> Epoch 15: took 123.2s (avg 126.0s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 16, 'time_epoch': 123.76662, 'eta': 4094.82209, 'eta_hours': 1.13745, 'loss': 0.40556751, 'lr': 0.00082281, 'params': 169027, 'time_iter': 2.29197, 'accuracy': 0.88028, 'f1': 0.87905, 'auc': 0.95086}\n",
      "val: {'epoch': 16, 'time_epoch': 0.80082, 'loss': 1.58753177, 'lr': 0, 'params': 169027, 'time_iter': 0.1144, 'accuracy': 0.33962, 'f1': 0.30734, 'auc': 0.54655}\n",
      "test: {'epoch': 16, 'time_epoch': 0.85931, 'loss': 1.40569138, 'lr': 0, 'params': 169027, 'time_iter': 0.12276, 'accuracy': 0.42991, 'f1': 0.38873, 'auc': 0.60044}\n",
      "> Epoch 16: took 125.5s (avg 125.9s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 17, 'time_epoch': 120.87721, 'eta': 3965.03291, 'eta_hours': 1.1014, 'loss': 0.3832477, 'lr': 0.00079659, 'params': 169027, 'time_iter': 2.23847, 'accuracy': 0.8838, 'f1': 0.87983, 'auc': 0.95827}\n",
      "val: {'epoch': 17, 'time_epoch': 0.83356, 'loss': 1.23811594, 'lr': 0, 'params': 169027, 'time_iter': 0.11908, 'accuracy': 0.50943, 'f1': 0.46647, 'auc': 0.66475}\n",
      "test: {'epoch': 17, 'time_epoch': 0.86057, 'loss': 1.4596435, 'lr': 0, 'params': 169027, 'time_iter': 0.12294, 'accuracy': 0.45794, 'f1': 0.4019, 'auc': 0.6251}\n",
      "> Epoch 17: took 122.6s (avg 125.7s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 18, 'time_epoch': 119.3239, 'eta': 3833.64749, 'eta_hours': 1.0649, 'loss': 0.35902721, 'lr': 0.00076904, 'params': 169027, 'time_iter': 2.2097, 'accuracy': 0.89319, 'f1': 0.89087, 'auc': 0.9608}\n",
      "val: {'epoch': 18, 'time_epoch': 0.66869, 'loss': 1.25160302, 'lr': 0, 'params': 169027, 'time_iter': 0.09553, 'accuracy': 0.46226, 'f1': 0.44632, 'auc': 0.65725}\n",
      "test: {'epoch': 18, 'time_epoch': 0.65567, 'loss': 1.48154621, 'lr': 0, 'params': 169027, 'time_iter': 0.09367, 'accuracy': 0.42991, 'f1': 0.39945, 'auc': 0.61743}\n",
      "> Epoch 18: took 120.7s (avg 125.5s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 19, 'time_epoch': 197.80599, 'eta': 3821.19136, 'eta_hours': 1.06144, 'loss': 0.31054256, 'lr': 0.00074029, 'params': 169027, 'time_iter': 3.66307, 'accuracy': 0.92136, 'f1': 0.92015, 'auc': 0.97007}\n",
      "val: {'epoch': 19, 'time_epoch': 1.20139, 'loss': 1.3652262, 'lr': 0, 'params': 169027, 'time_iter': 0.17163, 'accuracy': 0.43396, 'f1': 0.43529, 'auc': 0.64036}\n",
      "test: {'epoch': 19, 'time_epoch': 1.65426, 'loss': 1.44819566, 'lr': 0, 'params': 169027, 'time_iter': 0.23632, 'accuracy': 0.46729, 'f1': 0.44807, 'auc': 0.61972}\n",
      "> Epoch 19: took 200.7s (avg 129.2s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 20, 'time_epoch': 184.89949, 'eta': 3773.25959, 'eta_hours': 1.04813, 'loss': 0.30319881, 'lr': 0.00071047, 'params': 169027, 'time_iter': 3.42406, 'accuracy': 0.92019, 'f1': 0.91627, 'auc': 0.97261}\n",
      "val: {'epoch': 20, 'time_epoch': 1.00093, 'loss': 1.40468937, 'lr': 0, 'params': 169027, 'time_iter': 0.14299, 'accuracy': 0.4717, 'f1': 0.44082, 'auc': 0.63132}\n",
      "test: {'epoch': 20, 'time_epoch': 1.19212, 'loss': 1.43307081, 'lr': 0, 'params': 169027, 'time_iter': 0.1703, 'accuracy': 0.47664, 'f1': 0.45736, 'auc': 0.64519}\n",
      "> Epoch 20: took 187.1s (avg 132.0s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 21, 'time_epoch': 176.81736, 'eta': 3702.58987, 'eta_hours': 1.0285, 'loss': 0.29011174, 'lr': 0.0006797, 'params': 169027, 'time_iter': 3.2744, 'accuracy': 0.91667, 'f1': 0.91333, 'auc': 0.97307}\n",
      "val: {'epoch': 21, 'time_epoch': 0.99443, 'loss': 1.50823437, 'lr': 0, 'params': 169027, 'time_iter': 0.14206, 'accuracy': 0.43396, 'f1': 0.44017, 'auc': 0.62503}\n",
      "test: {'epoch': 21, 'time_epoch': 1.20519, 'loss': 1.45741705, 'lr': 0, 'params': 169027, 'time_iter': 0.17217, 'accuracy': 0.4486, 'f1': 0.44115, 'auc': 0.64174}\n",
      "> Epoch 21: took 179.0s (avg 134.1s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 22, 'time_epoch': 172.01204, 'eta': 3617.04889, 'eta_hours': 1.00474, 'loss': 0.27484767, 'lr': 0.00064814, 'params': 169027, 'time_iter': 3.18541, 'accuracy': 0.92254, 'f1': 0.91699, 'auc': 0.97862}\n",
      "val: {'epoch': 22, 'time_epoch': 1.23499, 'loss': 1.45386279, 'lr': 0, 'params': 169027, 'time_iter': 0.17643, 'accuracy': 0.48113, 'f1': 0.46556, 'auc': 0.63635}\n",
      "test: {'epoch': 22, 'time_epoch': 1.29162, 'loss': 1.43610539, 'lr': 0, 'params': 169027, 'time_iter': 0.18452, 'accuracy': 0.50467, 'f1': 0.48338, 'auc': 0.65951}\n",
      "> Epoch 22: took 174.6s (avg 135.9s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 23, 'time_epoch': 180.89201, 'eta': 3533.92195, 'eta_hours': 0.98164, 'loss': 0.28443751, 'lr': 0.00061591, 'params': 169027, 'time_iter': 3.34985, 'accuracy': 0.92371, 'f1': 0.92134, 'auc': 0.97095}\n",
      "val: {'epoch': 23, 'time_epoch': 1.00287, 'loss': 1.6406598, 'lr': 0, 'params': 169027, 'time_iter': 0.14327, 'accuracy': 0.45283, 'f1': 0.34803, 'auc': 0.58778}\n",
      "test: {'epoch': 23, 'time_epoch': 1.09424, 'loss': 1.75770934, 'lr': 0, 'params': 169027, 'time_iter': 0.15632, 'accuracy': 0.42991, 'f1': 0.35052, 'auc': 0.59262}\n",
      "> Epoch 23: took 183.0s (avg 137.9s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 24, 'time_epoch': 178.29001, 'eta': 3440.37181, 'eta_hours': 0.95566, 'loss': 0.23458919, 'lr': 0.00058316, 'params': 169027, 'time_iter': 3.30167, 'accuracy': 0.94014, 'f1': 0.93888, 'auc': 0.98076}\n",
      "val: {'epoch': 24, 'time_epoch': 0.87011, 'loss': 1.61154463, 'lr': 0, 'params': 169027, 'time_iter': 0.1243, 'accuracy': 0.43396, 'f1': 0.42845, 'auc': 0.60473}\n",
      "test: {'epoch': 24, 'time_epoch': 1.19016, 'loss': 1.64070868, 'lr': 0, 'params': 169027, 'time_iter': 0.17002, 'accuracy': 0.45794, 'f1': 0.45328, 'auc': 0.59696}\n",
      "> Epoch 24: took 180.4s (avg 139.6s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 25, 'time_epoch': 170.89141, 'eta': 3333.47375, 'eta_hours': 0.92596, 'loss': 0.25030744, 'lr': 0.00055005, 'params': 169027, 'time_iter': 3.16466, 'accuracy': 0.93427, 'f1': 0.92807, 'auc': 0.97904}\n",
      "val: {'epoch': 25, 'time_epoch': 0.99191, 'loss': 1.73687082, 'lr': 0, 'params': 169027, 'time_iter': 0.1417, 'accuracy': 0.42453, 'f1': 0.39782, 'auc': 0.58187}\n",
      "test: {'epoch': 25, 'time_epoch': 1.27206, 'loss': 1.73971241, 'lr': 0, 'params': 169027, 'time_iter': 0.18172, 'accuracy': 0.42991, 'f1': 0.38686, 'auc': 0.60778}\n",
      "> Epoch 25: took 173.2s (avg 140.8s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 26, 'time_epoch': 183.79011, 'eta': 3232.82322, 'eta_hours': 0.89801, 'loss': 0.21620715, 'lr': 0.00051671, 'params': 169027, 'time_iter': 3.40352, 'accuracy': 0.94366, 'f1': 0.93964, 'auc': 0.98332}\n",
      "val: {'epoch': 26, 'time_epoch': 0.98935, 'loss': 1.71677341, 'lr': 0, 'params': 169027, 'time_iter': 0.14134, 'accuracy': 0.4434, 'f1': 0.37411, 'auc': 0.59008}\n",
      "test: {'epoch': 26, 'time_epoch': 1.17317, 'loss': 1.80318367, 'lr': 0, 'params': 169027, 'time_iter': 0.1676, 'accuracy': 0.42056, 'f1': 0.35633, 'auc': 0.61291}\n",
      "> Epoch 26: took 186.0s (avg 142.5s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 27, 'time_epoch': 183.64691, 'eta': 3126.12162, 'eta_hours': 0.86837, 'loss': 0.19850377, 'lr': 0.00048329, 'params': 169027, 'time_iter': 3.40087, 'accuracy': 0.95305, 'f1': 0.95153, 'auc': 0.98333}\n",
      "val: {'epoch': 27, 'time_epoch': 1.02326, 'loss': 1.75932196, 'lr': 0, 'params': 169027, 'time_iter': 0.14618, 'accuracy': 0.4434, 'f1': 0.40009, 'auc': 0.6041}\n",
      "test: {'epoch': 27, 'time_epoch': 1.12021, 'loss': 1.83273163, 'lr': 0, 'params': 169027, 'time_iter': 0.16003, 'accuracy': 0.43925, 'f1': 0.40133, 'auc': 0.6426}\n",
      "> Epoch 27: took 185.8s (avg 144.1s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n",
      "train: {'epoch': 28, 'time_epoch': 185.31625, 'eta': 3015.32229, 'eta_hours': 0.83759, 'loss': 0.23781662, 'lr': 0.00044995, 'params': 169027, 'time_iter': 3.43178, 'accuracy': 0.93427, 'f1': 0.9287, 'auc': 0.98008}\n",
      "val: {'epoch': 28, 'time_epoch': 0.9827, 'loss': 1.7353865, 'lr': 0, 'params': 169027, 'time_iter': 0.14039, 'accuracy': 0.4717, 'f1': 0.36273, 'auc': 0.60056}\n",
      "test: {'epoch': 28, 'time_epoch': 1.14537, 'loss': 1.89939618, 'lr': 0, 'params': 169027, 'time_iter': 0.16362, 'accuracy': 0.4486, 'f1': 0.34862, 'auc': 0.60328}\n",
      "> Epoch 28: took 187.5s (avg 145.6s) | Best so far: epoch 10\ttrain_loss: 0.5789 train_accuracy: 0.8157\tval_loss: 1.1602 val_accuracy: 0.5283\ttest_loss: 1.2867 test_accuracy: 0.4392\n"
     ]
    }
   ],
   "source": [
    "#Age using Exphormer dropout 0.3\n",
    "%run main.py --cfg configs/Exphormer/neural-Age.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78479d12-b3c2-4896-b142-6d912a0b2067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-01 15:48:52.356661\n",
      "[*] Loaded dataset 'HCPAge' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1065000, 1000], edge_index=[2, 48551656], y=[1065])\n",
      "  undirected: True\n",
      "  num graphs: 1065\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 3\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [01:51<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:52.47\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [01:20<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:22.45\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 3, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPAge\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.3\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.3\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 3\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 50\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 3\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Age\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Age\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 3\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 169027\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 526.63702, 'eta': 25805.2141, 'eta_hours': 7.16812, 'loss': 1.09918134, 'lr': 0.0, 'params': 169027, 'time_iter': 9.75254, 'accuracy': 0.33803, 'f1': 0.29354, 'auc': 0.52984}\n",
      "...computing epoch stats took: 0.19s\n",
      "val: {'epoch': 0, 'time_epoch': 1.30024, 'loss': 1.10791513, 'lr': 0, 'params': 169027, 'time_iter': 0.18575, 'accuracy': 0.26415, 'f1': 0.22947, 'auc': 0.50471}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 0, 'time_epoch': 1.32714, 'loss': 1.09808046, 'lr': 0, 'params': 169027, 'time_iter': 0.18959, 'accuracy': 0.34579, 'f1': 0.29645, 'auc': 0.55444}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 529.5s (avg 529.5s) | Best so far: epoch 0\ttrain_loss: 1.0992 train_accuracy: 0.3380\tval_loss: 1.1079 val_accuracy: 0.2641\ttest_loss: 1.0981 test_accuracy: 0.3458\n",
      "train: {'epoch': 1, 'time_epoch': 519.06259, 'eta': 25096.79082, 'eta_hours': 6.97133, 'loss': 1.07011076, 'lr': 0.00033333, 'params': 169027, 'time_iter': 9.61227, 'accuracy': 0.42254, 'f1': 0.34831, 'auc': 0.56303}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 1, 'time_epoch': 1.24382, 'loss': 1.06873533, 'lr': 0, 'params': 169027, 'time_iter': 0.17769, 'accuracy': 0.34906, 'f1': 0.2633, 'auc': 0.58698}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 1.21542, 'loss': 1.08850192, 'lr': 0, 'params': 169027, 'time_iter': 0.17363, 'accuracy': 0.40187, 'f1': 0.30959, 'auc': 0.52442}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 521.6s (avg 525.5s) | Best so far: epoch 1\ttrain_loss: 1.0701 train_accuracy: 0.4225\tval_loss: 1.0687 val_accuracy: 0.3491\ttest_loss: 1.0885 test_accuracy: 0.4019\n",
      "train: {'epoch': 2, 'time_epoch': 545.72904, 'eta': 24932.38233, 'eta_hours': 6.92566, 'loss': 1.03502889, 'lr': 0.00066667, 'params': 169027, 'time_iter': 10.10609, 'accuracy': 0.4554, 'f1': 0.38933, 'auc': 0.6249}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 1.1581, 'loss': 1.0851483, 'lr': 0, 'params': 169027, 'time_iter': 0.16544, 'accuracy': 0.29245, 'f1': 0.17979, 'auc': 0.63063}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 2, 'time_epoch': 1.21388, 'loss': 1.09948446, 'lr': 0, 'params': 169027, 'time_iter': 0.17341, 'accuracy': 0.38318, 'f1': 0.25256, 'auc': 0.55169}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 548.2s (avg 533.1s) | Best so far: epoch 1\ttrain_loss: 1.0701 train_accuracy: 0.4225\tval_loss: 1.0687 val_accuracy: 0.3491\ttest_loss: 1.0885 test_accuracy: 0.4019\n",
      "train: {'epoch': 3, 'time_epoch': 565.15529, 'eta': 24800.71538, 'eta_hours': 6.88909, 'loss': 0.98817833, 'lr': 0.001, 'params': 169027, 'time_iter': 10.46584, 'accuracy': 0.51995, 'f1': 0.46267, 'auc': 0.69167}\n",
      "val: {'epoch': 3, 'time_epoch': 0.94547, 'loss': 1.12123038, 'lr': 0, 'params': 169027, 'time_iter': 0.13507, 'accuracy': 0.29245, 'f1': 0.1793, 'auc': 0.56294}\n",
      "test: {'epoch': 3, 'time_epoch': 0.96765, 'loss': 1.1396837, 'lr': 0, 'params': 169027, 'time_iter': 0.13824, 'accuracy': 0.30841, 'f1': 0.15714, 'auc': 0.49524}\n",
      "> Epoch 3: took 567.1s (avg 541.6s) | Best so far: epoch 1\ttrain_loss: 1.0701 train_accuracy: 0.4225\tval_loss: 1.0687 val_accuracy: 0.3491\ttest_loss: 1.0885 test_accuracy: 0.4019\n",
      "train: {'epoch': 4, 'time_epoch': 565.21308, 'eta': 24496.17324, 'eta_hours': 6.80449, 'loss': 0.92281286, 'lr': 0.00099888, 'params': 169027, 'time_iter': 10.46691, 'accuracy': 0.60915, 'f1': 0.59575, 'auc': 0.76511}\n",
      "val: {'epoch': 4, 'time_epoch': 0.96547, 'loss': 1.06205823, 'lr': 0, 'params': 169027, 'time_iter': 0.13792, 'accuracy': 0.49057, 'f1': 0.37161, 'auc': 0.62947}\n",
      "test: {'epoch': 4, 'time_epoch': 1.0026, 'loss': 1.08577372, 'lr': 0, 'params': 169027, 'time_iter': 0.14323, 'accuracy': 0.48598, 'f1': 0.36039, 'auc': 0.63005}\n",
      "> Epoch 4: took 567.2s (avg 546.7s) | Best so far: epoch 4\ttrain_loss: 0.9228 train_accuracy: 0.6091\tval_loss: 1.0621 val_accuracy: 0.4906\ttest_loss: 1.0858 test_accuracy: 0.4860\n",
      "train: {'epoch': 5, 'time_epoch': 521.54152, 'eta': 23784.48269, 'eta_hours': 6.6068, 'loss': 0.86361296, 'lr': 0.00099554, 'params': 169027, 'time_iter': 9.65818, 'accuracy': 0.63967, 'f1': 0.63078, 'auc': 0.78695}\n",
      "val: {'epoch': 5, 'time_epoch': 0.96435, 'loss': 0.99711861, 'lr': 0, 'params': 169027, 'time_iter': 0.13776, 'accuracy': 0.48113, 'f1': 0.40261, 'auc': 0.64345}\n",
      "test: {'epoch': 5, 'time_epoch': 0.96052, 'loss': 1.09502883, 'lr': 0, 'params': 169027, 'time_iter': 0.13722, 'accuracy': 0.42056, 'f1': 0.33741, 'auc': 0.59835}\n",
      "> Epoch 5: took 523.5s (avg 542.8s) | Best so far: epoch 4\ttrain_loss: 0.9228 train_accuracy: 0.6091\tval_loss: 1.0621 val_accuracy: 0.4906\ttest_loss: 1.0858 test_accuracy: 0.4860\n",
      "train: {'epoch': 6, 'time_epoch': 527.07254, 'eta': 23161.09669, 'eta_hours': 6.43364, 'loss': 0.79409807, 'lr': 0.00098998, 'params': 169027, 'time_iter': 9.7606, 'accuracy': 0.68897, 'f1': 0.68911, 'auc': 0.83915}\n",
      "val: {'epoch': 6, 'time_epoch': 0.94073, 'loss': 1.14687517, 'lr': 0, 'params': 169027, 'time_iter': 0.13439, 'accuracy': 0.34906, 'f1': 0.31843, 'auc': 0.62788}\n",
      "test: {'epoch': 6, 'time_epoch': 0.94218, 'loss': 1.12799015, 'lr': 0, 'params': 169027, 'time_iter': 0.1346, 'accuracy': 0.38318, 'f1': 0.31052, 'auc': 0.57821}\n",
      "> Epoch 6: took 529.0s (avg 540.9s) | Best so far: epoch 4\ttrain_loss: 0.9228 train_accuracy: 0.6091\tval_loss: 1.0621 val_accuracy: 0.4906\ttest_loss: 1.0858 test_accuracy: 0.4860\n",
      "train: {'epoch': 7, 'time_epoch': 546.95147, 'eta': 22666.15343, 'eta_hours': 6.29615, 'loss': 0.74591707, 'lr': 0.00098223, 'params': 169027, 'time_iter': 10.12873, 'accuracy': 0.71479, 'f1': 0.71019, 'auc': 0.85397}\n",
      "val: {'epoch': 7, 'time_epoch': 0.94265, 'loss': 1.17788593, 'lr': 0, 'params': 169027, 'time_iter': 0.13466, 'accuracy': 0.36792, 'f1': 0.35372, 'auc': 0.57851}\n",
      "test: {'epoch': 7, 'time_epoch': 0.94412, 'loss': 1.19391415, 'lr': 0, 'params': 169027, 'time_iter': 0.13487, 'accuracy': 0.34579, 'f1': 0.3205, 'auc': 0.59535}\n",
      "> Epoch 7: took 548.9s (avg 541.9s) | Best so far: epoch 4\ttrain_loss: 0.9228 train_accuracy: 0.6091\tval_loss: 1.0621 val_accuracy: 0.4906\ttest_loss: 1.0858 test_accuracy: 0.4860\n",
      "train: {'epoch': 8, 'time_epoch': 567.34346, 'eta': 22252.54964, 'eta_hours': 6.18126, 'loss': 0.68620206, 'lr': 0.00097233, 'params': 169027, 'time_iter': 10.50636, 'accuracy': 0.75587, 'f1': 0.75271, 'auc': 0.88587}\n",
      "val: {'epoch': 8, 'time_epoch': 0.94146, 'loss': 1.10287276, 'lr': 0, 'params': 169027, 'time_iter': 0.13449, 'accuracy': 0.43396, 'f1': 0.31407, 'auc': 0.61937}\n",
      "test: {'epoch': 8, 'time_epoch': 0.96338, 'loss': 1.13532732, 'lr': 0, 'params': 169027, 'time_iter': 0.13763, 'accuracy': 0.47664, 'f1': 0.35344, 'auc': 0.65111}\n",
      "> Epoch 8: took 569.3s (avg 544.9s) | Best so far: epoch 4\ttrain_loss: 0.9228 train_accuracy: 0.6091\tval_loss: 1.0621 val_accuracy: 0.4906\ttest_loss: 1.0858 test_accuracy: 0.4860\n",
      "train: {'epoch': 9, 'time_epoch': 529.00147, 'eta': 21654.82994, 'eta_hours': 6.01523, 'loss': 0.64581416, 'lr': 0.00096032, 'params': 169027, 'time_iter': 9.79632, 'accuracy': 0.77347, 'f1': 0.77009, 'auc': 0.89618}\n",
      "val: {'epoch': 9, 'time_epoch': 0.95849, 'loss': 1.11969074, 'lr': 0, 'params': 169027, 'time_iter': 0.13693, 'accuracy': 0.50943, 'f1': 0.35445, 'auc': 0.64419}\n",
      "test: {'epoch': 9, 'time_epoch': 0.9559, 'loss': 1.24861736, 'lr': 0, 'params': 169027, 'time_iter': 0.13656, 'accuracy': 0.46729, 'f1': 0.31738, 'auc': 0.59931}\n",
      "> Epoch 9: took 530.9s (avg 543.5s) | Best so far: epoch 9\ttrain_loss: 0.6458 train_accuracy: 0.7735\tval_loss: 1.1197 val_accuracy: 0.5094\ttest_loss: 1.2486 test_accuracy: 0.4673\n",
      "train: {'epoch': 10, 'time_epoch': 502.51288, 'eta': 20975.69038, 'eta_hours': 5.82658, 'loss': 0.60877121, 'lr': 0.00094626, 'params': 169027, 'time_iter': 9.30579, 'accuracy': 0.78873, 'f1': 0.78699, 'auc': 0.90846}\n",
      "val: {'epoch': 10, 'time_epoch': 0.97088, 'loss': 1.1698866, 'lr': 0, 'params': 169027, 'time_iter': 0.1387, 'accuracy': 0.50943, 'f1': 0.28904, 'auc': 0.64583}\n",
      "test: {'epoch': 10, 'time_epoch': 0.97053, 'loss': 1.33179411, 'lr': 0, 'params': 169027, 'time_iter': 0.13865, 'accuracy': 0.40187, 'f1': 0.20771, 'auc': 0.65261}\n",
      "> Epoch 10: took 504.5s (avg 540.0s) | Best so far: epoch 9\ttrain_loss: 0.6458 train_accuracy: 0.7735\tval_loss: 1.1197 val_accuracy: 0.5094\ttest_loss: 1.2486 test_accuracy: 0.4673\n",
      "train: {'epoch': 11, 'time_epoch': 529.79084, 'eta': 20412.3688, 'eta_hours': 5.6701, 'loss': 0.57028612, 'lr': 0.0009302, 'params': 169027, 'time_iter': 9.81094, 'accuracy': 0.81221, 'f1': 0.81112, 'auc': 0.91775}\n",
      "val: {'epoch': 11, 'time_epoch': 0.96774, 'loss': 1.38479949, 'lr': 0, 'params': 169027, 'time_iter': 0.13825, 'accuracy': 0.35849, 'f1': 0.26931, 'auc': 0.59634}\n",
      "test: {'epoch': 11, 'time_epoch': 0.97057, 'loss': 1.39509594, 'lr': 0, 'params': 169027, 'time_iter': 0.13865, 'accuracy': 0.37383, 'f1': 0.30263, 'auc': 0.53281}\n",
      "> Epoch 11: took 531.8s (avg 539.3s) | Best so far: epoch 9\ttrain_loss: 0.6458 train_accuracy: 0.7735\tval_loss: 1.1197 val_accuracy: 0.5094\ttest_loss: 1.2486 test_accuracy: 0.4673\n",
      "train: {'epoch': 12, 'time_epoch': 565.1773, 'eta': 19954.92113, 'eta_hours': 5.54303, 'loss': 0.55103798, 'lr': 0.00091222, 'params': 169027, 'time_iter': 10.46625, 'accuracy': 0.82277, 'f1': 0.82108, 'auc': 0.92496}\n",
      "val: {'epoch': 12, 'time_epoch': 0.95701, 'loss': 1.36052973, 'lr': 0, 'params': 169027, 'time_iter': 0.13672, 'accuracy': 0.34906, 'f1': 0.29864, 'auc': 0.60245}\n",
      "test: {'epoch': 12, 'time_epoch': 0.96244, 'loss': 1.35794782, 'lr': 0, 'params': 169027, 'time_iter': 0.13749, 'accuracy': 0.42991, 'f1': 0.33191, 'auc': 0.57817}\n",
      "> Epoch 12: took 567.1s (avg 541.4s) | Best so far: epoch 9\ttrain_loss: 0.6458 train_accuracy: 0.7735\tval_loss: 1.1197 val_accuracy: 0.5094\ttest_loss: 1.2486 test_accuracy: 0.4673\n",
      "train: {'epoch': 13, 'time_epoch': 556.83106, 'eta': 19460.62174, 'eta_hours': 5.40573, 'loss': 0.49141761, 'lr': 0.0008924, 'params': 169027, 'time_iter': 10.31169, 'accuracy': 0.84859, 'f1': 0.84249, 'auc': 0.94288}\n",
      "val: {'epoch': 13, 'time_epoch': 0.96532, 'loss': 1.26612994, 'lr': 0, 'params': 169027, 'time_iter': 0.1379, 'accuracy': 0.45283, 'f1': 0.33644, 'auc': 0.62447}\n",
      "test: {'epoch': 13, 'time_epoch': 0.94858, 'loss': 1.36394099, 'lr': 0, 'params': 169027, 'time_iter': 0.13551, 'accuracy': 0.43925, 'f1': 0.30513, 'auc': 0.60747}\n",
      "> Epoch 13: took 558.8s (avg 542.7s) | Best so far: epoch 9\ttrain_loss: 0.6458 train_accuracy: 0.7735\tval_loss: 1.1197 val_accuracy: 0.5094\ttest_loss: 1.2486 test_accuracy: 0.4673\n",
      "train: {'epoch': 14, 'time_epoch': 561.18004, 'eta': 18968.1324, 'eta_hours': 5.26893, 'loss': 0.47349192, 'lr': 0.00087083, 'params': 169027, 'time_iter': 10.39222, 'accuracy': 0.84977, 'f1': 0.84264, 'auc': 0.94215}\n",
      "val: {'epoch': 14, 'time_epoch': 0.94989, 'loss': 1.3408666, 'lr': 0, 'params': 169027, 'time_iter': 0.1357, 'accuracy': 0.36792, 'f1': 0.3355, 'auc': 0.63254}\n",
      "test: {'epoch': 14, 'time_epoch': 0.96077, 'loss': 1.40458775, 'lr': 0, 'params': 169027, 'time_iter': 0.13725, 'accuracy': 0.34579, 'f1': 0.28914, 'auc': 0.58023}\n",
      "> Epoch 14: took 563.1s (avg 544.0s) | Best so far: epoch 9\ttrain_loss: 0.6458 train_accuracy: 0.7735\tval_loss: 1.1197 val_accuracy: 0.5094\ttest_loss: 1.2486 test_accuracy: 0.4673\n",
      "train: {'epoch': 15, 'time_epoch': 548.82766, 'eta': 18440.80794, 'eta_hours': 5.12245, 'loss': 0.44663818, 'lr': 0.0008476, 'params': 169027, 'time_iter': 10.16348, 'accuracy': 0.8615, 'f1': 0.85828, 'auc': 0.94672}\n",
      "val: {'epoch': 15, 'time_epoch': 0.95495, 'loss': 1.25267859, 'lr': 0, 'params': 169027, 'time_iter': 0.13642, 'accuracy': 0.49057, 'f1': 0.47385, 'auc': 0.63801}\n",
      "test: {'epoch': 15, 'time_epoch': 0.94832, 'loss': 1.27569881, 'lr': 0, 'params': 169027, 'time_iter': 0.13547, 'accuracy': 0.49533, 'f1': 0.46896, 'auc': 0.6347}\n",
      "> Epoch 15: took 550.8s (avg 544.4s) | Best so far: epoch 9\ttrain_loss: 0.6458 train_accuracy: 0.7735\tval_loss: 1.1197 val_accuracy: 0.5094\ttest_loss: 1.2486 test_accuracy: 0.4673\n",
      "train: {'epoch': 16, 'time_epoch': 538.37273, 'eta': 17890.65881, 'eta_hours': 4.96963, 'loss': 0.37493686, 'lr': 0.00082281, 'params': 169027, 'time_iter': 9.96987, 'accuracy': 0.89789, 'f1': 0.89672, 'auc': 0.96281}\n",
      "val: {'epoch': 16, 'time_epoch': 0.94795, 'loss': 1.40596734, 'lr': 0, 'params': 169027, 'time_iter': 0.13542, 'accuracy': 0.42453, 'f1': 0.43068, 'auc': 0.59984}\n",
      "test: {'epoch': 16, 'time_epoch': 0.94698, 'loss': 1.42855414, 'lr': 0, 'params': 169027, 'time_iter': 0.13528, 'accuracy': 0.39252, 'f1': 0.39306, 'auc': 0.58604}\n",
      "> Epoch 16: took 540.3s (avg 544.2s) | Best so far: epoch 9\ttrain_loss: 0.6458 train_accuracy: 0.7735\tval_loss: 1.1197 val_accuracy: 0.5094\ttest_loss: 1.2486 test_accuracy: 0.4673\n",
      "train: {'epoch': 17, 'time_epoch': 541.7391, 'eta': 17347.80283, 'eta_hours': 4.81883, 'loss': 0.35422139, 'lr': 0.00079659, 'params': 169027, 'time_iter': 10.03221, 'accuracy': 0.89789, 'f1': 0.89759, 'auc': 0.96702}\n",
      "val: {'epoch': 17, 'time_epoch': 0.96994, 'loss': 1.67288832, 'lr': 0, 'params': 169027, 'time_iter': 0.13856, 'accuracy': 0.33019, 'f1': 0.28546, 'auc': 0.56625}\n",
      "test: {'epoch': 17, 'time_epoch': 0.96427, 'loss': 1.60791062, 'lr': 0, 'params': 169027, 'time_iter': 0.13775, 'accuracy': 0.38318, 'f1': 0.32554, 'auc': 0.50847}\n",
      "> Epoch 17: took 543.7s (avg 544.2s) | Best so far: epoch 9\ttrain_loss: 0.6458 train_accuracy: 0.7735\tval_loss: 1.1197 val_accuracy: 0.5094\ttest_loss: 1.2486 test_accuracy: 0.4673\n",
      "train: {'epoch': 18, 'time_epoch': 535.77372, 'eta': 16795.33143, 'eta_hours': 4.66537, 'loss': 0.37788231, 'lr': 0.00076904, 'params': 169027, 'time_iter': 9.92174, 'accuracy': 0.8838, 'f1': 0.88195, 'auc': 0.95953}\n",
      "val: {'epoch': 18, 'time_epoch': 0.94239, 'loss': 1.50573329, 'lr': 0, 'params': 169027, 'time_iter': 0.13463, 'accuracy': 0.36792, 'f1': 0.36342, 'auc': 0.60488}\n",
      "test: {'epoch': 18, 'time_epoch': 0.94716, 'loss': 1.41194566, 'lr': 0, 'params': 169027, 'time_iter': 0.13531, 'accuracy': 0.42056, 'f1': 0.42358, 'auc': 0.58326}\n",
      "> Epoch 18: took 537.7s (avg 543.8s) | Best so far: epoch 9\ttrain_loss: 0.6458 train_accuracy: 0.7735\tval_loss: 1.1197 val_accuracy: 0.5094\ttest_loss: 1.2486 test_accuracy: 0.4673\n",
      "train: {'epoch': 19, 'time_epoch': 534.56046, 'eta': 16242.7099, 'eta_hours': 4.51186, 'loss': 0.30606751, 'lr': 0.00074029, 'params': 169027, 'time_iter': 9.89927, 'accuracy': 0.91784, 'f1': 0.91874, 'auc': 0.97686}\n",
      "val: {'epoch': 19, 'time_epoch': 0.95166, 'loss': 1.60623539, 'lr': 0, 'params': 169027, 'time_iter': 0.13595, 'accuracy': 0.32075, 'f1': 0.31631, 'auc': 0.59804}\n",
      "test: {'epoch': 19, 'time_epoch': 0.95993, 'loss': 1.57577441, 'lr': 0, 'params': 169027, 'time_iter': 0.13713, 'accuracy': 0.36449, 'f1': 0.33517, 'auc': 0.55961}\n",
      "> Epoch 19: took 536.5s (avg 543.5s) | Best so far: epoch 9\ttrain_loss: 0.6458 train_accuracy: 0.7735\tval_loss: 1.1197 val_accuracy: 0.5094\ttest_loss: 1.2486 test_accuracy: 0.4673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Age using Exphormer dropout 0.3 attention droupout 0.3\n",
    "%run main.py --cfg configs/Exphormer/neural-Age.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a4f81e-d81a-436f-a190-e71c7aafee0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-01 21:11:56.349118\n",
      "[*] Loaded dataset 'HCPAge' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1065000, 1000], edge_index=[2, 48551656], y=[1065])\n",
      "  undirected: True\n",
      "  num graphs: 1065\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 3\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [02:44<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:02:49.89\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [01:38<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:40.98\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 3, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPAge\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 2\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 50\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 3\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Age\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Age\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 3\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 135811\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 18.78929, 'eta': 920.67507, 'eta_hours': 0.25574, 'loss': 1.10820259, 'lr': 0.0, 'params': 135811, 'time_iter': 0.34795, 'accuracy': 0.35563, 'f1': 0.18323, 'auc': 0.51437}\n",
      "...computing epoch stats took: 0.17s\n",
      "val: {'epoch': 0, 'time_epoch': 1.32772, 'loss': 1.12436036, 'lr': 0, 'params': 135811, 'time_iter': 0.18967, 'accuracy': 0.25472, 'f1': 0.13534, 'auc': 0.51612}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 0, 'time_epoch': 1.2412, 'loss': 1.11294939, 'lr': 0, 'params': 135811, 'time_iter': 0.17731, 'accuracy': 0.31776, 'f1': 0.16307, 'auc': 0.49185}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 0: took 21.6s (avg 21.6s) | Best so far: epoch 0\ttrain_loss: 1.1082 train_accuracy: 0.3556\tval_loss: 1.1244 val_accuracy: 0.2547\ttest_loss: 1.1129 test_accuracy: 0.3178\n",
      "train: {'epoch': 1, 'time_epoch': 16.20526, 'eta': 839.86921, 'eta_hours': 0.2333, 'loss': 1.08026227, 'lr': 0.00033333, 'params': 135811, 'time_iter': 0.3001, 'accuracy': 0.37441, 'f1': 0.24114, 'auc': 0.54847}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 1, 'time_epoch': 1.39642, 'loss': 1.08595834, 'lr': 0, 'params': 135811, 'time_iter': 0.19949, 'accuracy': 0.25472, 'f1': 0.13534, 'auc': 0.57898}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 1.22806, 'loss': 1.09641878, 'lr': 0, 'params': 135811, 'time_iter': 0.17544, 'accuracy': 0.31776, 'f1': 0.1736, 'auc': 0.51617}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 18.9s (avg 20.2s) | Best so far: epoch 0\ttrain_loss: 1.1082 train_accuracy: 0.3556\tval_loss: 1.1244 val_accuracy: 0.2547\ttest_loss: 1.1129 test_accuracy: 0.3178\n",
      "train: {'epoch': 2, 'time_epoch': 16.77459, 'eta': 811.04981, 'eta_hours': 0.22529, 'loss': 1.04290865, 'lr': 0.00066667, 'params': 135811, 'time_iter': 0.31064, 'accuracy': 0.48239, 'f1': 0.40036, 'auc': 0.61918}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 2, 'time_epoch': 1.21428, 'loss': 1.04585089, 'lr': 0, 'params': 135811, 'time_iter': 0.17347, 'accuracy': 0.45283, 'f1': 0.44118, 'auc': 0.61717}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 1.16413, 'loss': 1.08332474, 'lr': 0, 'params': 135811, 'time_iter': 0.1663, 'accuracy': 0.43925, 'f1': 0.4185, 'auc': 0.54779}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 19.2s (avg 19.9s) | Best so far: epoch 2\ttrain_loss: 1.0429 train_accuracy: 0.4824\tval_loss: 1.0459 val_accuracy: 0.4528\ttest_loss: 1.0833 test_accuracy: 0.4392\n",
      "train: {'epoch': 3, 'time_epoch': 18.58148, 'eta': 809.03214, 'eta_hours': 0.22473, 'loss': 0.99433622, 'lr': 0.001, 'params': 135811, 'time_iter': 0.3441, 'accuracy': 0.52817, 'f1': 0.48247, 'auc': 0.70584}\n",
      "val: {'epoch': 3, 'time_epoch': 1.38384, 'loss': 1.05575309, 'lr': 0, 'params': 135811, 'time_iter': 0.19769, 'accuracy': 0.46226, 'f1': 0.42336, 'auc': 0.67218}\n",
      "test: {'epoch': 3, 'time_epoch': 1.18603, 'loss': 1.09796797, 'lr': 0, 'params': 135811, 'time_iter': 0.16943, 'accuracy': 0.30841, 'f1': 0.25674, 'auc': 0.59572}\n",
      "> Epoch 3: took 21.2s (avg 20.2s) | Best so far: epoch 3\ttrain_loss: 0.9943 train_accuracy: 0.5282\tval_loss: 1.0558 val_accuracy: 0.4623\ttest_loss: 1.0980 test_accuracy: 0.3084\n",
      "train: {'epoch': 4, 'time_epoch': 17.97706, 'eta': 794.94912, 'eta_hours': 0.22082, 'loss': 0.93049854, 'lr': 0.00099888, 'params': 135811, 'time_iter': 0.33291, 'accuracy': 0.59272, 'f1': 0.58656, 'auc': 0.76126}\n",
      "val: {'epoch': 4, 'time_epoch': 1.20427, 'loss': 1.0845747, 'lr': 0, 'params': 135811, 'time_iter': 0.17204, 'accuracy': 0.33019, 'f1': 0.28934, 'auc': 0.67897}\n",
      "test: {'epoch': 4, 'time_epoch': 1.21407, 'loss': 1.09343245, 'lr': 0, 'params': 135811, 'time_iter': 0.17344, 'accuracy': 0.38318, 'f1': 0.30343, 'auc': 0.60292}\n",
      "> Epoch 4: took 20.4s (avg 20.2s) | Best so far: epoch 3\ttrain_loss: 0.9943 train_accuracy: 0.5282\tval_loss: 1.0558 val_accuracy: 0.4623\ttest_loss: 1.0980 test_accuracy: 0.3084\n",
      "train: {'epoch': 5, 'time_epoch': 16.37538, 'eta': 767.82244, 'eta_hours': 0.21328, 'loss': 0.84247648, 'lr': 0.00099554, 'params': 135811, 'time_iter': 0.30325, 'accuracy': 0.66667, 'f1': 0.65835, 'auc': 0.81979}\n",
      "val: {'epoch': 5, 'time_epoch': 1.20711, 'loss': 1.06808655, 'lr': 0, 'params': 135811, 'time_iter': 0.17244, 'accuracy': 0.5, 'f1': 0.30486, 'auc': 0.61867}\n",
      "test: {'epoch': 5, 'time_epoch': 1.18382, 'loss': 1.1393889, 'lr': 0, 'params': 135811, 'time_iter': 0.16912, 'accuracy': 0.43925, 'f1': 0.28551, 'auc': 0.60506}\n",
      "> Epoch 5: took 18.8s (avg 20.0s) | Best so far: epoch 5\ttrain_loss: 0.8425 train_accuracy: 0.6667\tval_loss: 1.0681 val_accuracy: 0.5000\ttest_loss: 1.1394 test_accuracy: 0.4392\n",
      "train: {'epoch': 6, 'time_epoch': 17.12419, 'eta': 748.36741, 'eta_hours': 0.20788, 'loss': 0.76550493, 'lr': 0.00098998, 'params': 135811, 'time_iter': 0.31711, 'accuracy': 0.71244, 'f1': 0.70637, 'auc': 0.86485}\n",
      "val: {'epoch': 6, 'time_epoch': 1.21117, 'loss': 1.12088962, 'lr': 0, 'params': 135811, 'time_iter': 0.17302, 'accuracy': 0.36792, 'f1': 0.32751, 'auc': 0.62613}\n",
      "test: {'epoch': 6, 'time_epoch': 1.20036, 'loss': 1.14455142, 'lr': 0, 'params': 135811, 'time_iter': 0.17148, 'accuracy': 0.31776, 'f1': 0.25145, 'auc': 0.62056}\n",
      "> Epoch 6: took 19.6s (avg 19.9s) | Best so far: epoch 5\ttrain_loss: 0.8425 train_accuracy: 0.6667\tval_loss: 1.0681 val_accuracy: 0.5000\ttest_loss: 1.1394 test_accuracy: 0.4392\n",
      "train: {'epoch': 7, 'time_epoch': 16.32647, 'eta': 725.30705, 'eta_hours': 0.20147, 'loss': 0.71411654, 'lr': 0.00098223, 'params': 135811, 'time_iter': 0.30234, 'accuracy': 0.75469, 'f1': 0.74559, 'auc': 0.87916}\n",
      "val: {'epoch': 7, 'time_epoch': 1.2049, 'loss': 1.10137816, 'lr': 0, 'params': 135811, 'time_iter': 0.17213, 'accuracy': 0.4434, 'f1': 0.31901, 'auc': 0.65001}\n",
      "test: {'epoch': 7, 'time_epoch': 1.22177, 'loss': 1.17663617, 'lr': 0, 'params': 135811, 'time_iter': 0.17454, 'accuracy': 0.42056, 'f1': 0.28545, 'auc': 0.61837}\n",
      "> Epoch 7: took 18.8s (avg 19.8s) | Best so far: epoch 5\ttrain_loss: 0.8425 train_accuracy: 0.6667\tval_loss: 1.0681 val_accuracy: 0.5000\ttest_loss: 1.1394 test_accuracy: 0.4392\n",
      "train: {'epoch': 8, 'time_epoch': 16.57554, 'eta': 704.87776, 'eta_hours': 0.1958, 'loss': 0.65233763, 'lr': 0.00097233, 'params': 135811, 'time_iter': 0.30695, 'accuracy': 0.77934, 'f1': 0.77598, 'auc': 0.89692}\n",
      "val: {'epoch': 8, 'time_epoch': 1.15247, 'loss': 1.12036913, 'lr': 0, 'params': 135811, 'time_iter': 0.16464, 'accuracy': 0.48113, 'f1': 0.311, 'auc': 0.61355}\n",
      "test: {'epoch': 8, 'time_epoch': 1.2132, 'loss': 1.1850422, 'lr': 0, 'params': 135811, 'time_iter': 0.17331, 'accuracy': 0.43925, 'f1': 0.2884, 'auc': 0.61757}\n",
      "> Epoch 8: took 19.0s (avg 19.7s) | Best so far: epoch 5\ttrain_loss: 0.8425 train_accuracy: 0.6667\tval_loss: 1.0681 val_accuracy: 0.5000\ttest_loss: 1.1394 test_accuracy: 0.4392\n",
      "train: {'epoch': 9, 'time_epoch': 18.24454, 'eta': 691.8952, 'eta_hours': 0.19219, 'loss': 0.61180803, 'lr': 0.00096032, 'params': 135811, 'time_iter': 0.33786, 'accuracy': 0.79577, 'f1': 0.79352, 'auc': 0.90698}\n",
      "val: {'epoch': 9, 'time_epoch': 1.0329, 'loss': 1.18895038, 'lr': 0, 'params': 135811, 'time_iter': 0.14756, 'accuracy': 0.46226, 'f1': 0.2836, 'auc': 0.61467}\n",
      "test: {'epoch': 9, 'time_epoch': 1.26605, 'loss': 1.26390444, 'lr': 0, 'params': 135811, 'time_iter': 0.18086, 'accuracy': 0.43925, 'f1': 0.27575, 'auc': 0.63998}\n",
      "> Epoch 9: took 20.6s (avg 19.8s) | Best so far: epoch 5\ttrain_loss: 0.8425 train_accuracy: 0.6667\tval_loss: 1.0681 val_accuracy: 0.5000\ttest_loss: 1.1394 test_accuracy: 0.4392\n",
      "train: {'epoch': 10, 'time_epoch': 30.8526, 'eta': 722.65725, 'eta_hours': 0.20074, 'loss': 0.59289697, 'lr': 0.00094626, 'params': 135811, 'time_iter': 0.57134, 'accuracy': 0.7993, 'f1': 0.79876, 'auc': 0.90811}\n",
      "val: {'epoch': 10, 'time_epoch': 1.21883, 'loss': 1.37399363, 'lr': 0, 'params': 135811, 'time_iter': 0.17412, 'accuracy': 0.32075, 'f1': 0.24212, 'auc': 0.63462}\n",
      "test: {'epoch': 10, 'time_epoch': 1.21714, 'loss': 1.36009103, 'lr': 0, 'params': 135811, 'time_iter': 0.17388, 'accuracy': 0.38318, 'f1': 0.29601, 'auc': 0.55101}\n",
      "> Epoch 10: took 33.3s (avg 21.0s) | Best so far: epoch 5\ttrain_loss: 0.8425 train_accuracy: 0.6667\tval_loss: 1.0681 val_accuracy: 0.5000\ttest_loss: 1.1394 test_accuracy: 0.4392\n",
      "train: {'epoch': 11, 'time_epoch': 19.1478, 'eta': 706.08497, 'eta_hours': 0.19613, 'loss': 0.51495427, 'lr': 0.0009302, 'params': 135811, 'time_iter': 0.35459, 'accuracy': 0.84272, 'f1': 0.84082, 'auc': 0.93848}\n",
      "val: {'epoch': 11, 'time_epoch': 1.19408, 'loss': 1.53136712, 'lr': 0, 'params': 135811, 'time_iter': 0.17058, 'accuracy': 0.33962, 'f1': 0.29088, 'auc': 0.57241}\n",
      "test: {'epoch': 11, 'time_epoch': 1.18915, 'loss': 1.5370031, 'lr': 0, 'params': 135811, 'time_iter': 0.16988, 'accuracy': 0.31776, 'f1': 0.25356, 'auc': 0.51698}\n",
      "> Epoch 11: took 21.6s (avg 21.1s) | Best so far: epoch 5\ttrain_loss: 0.8425 train_accuracy: 0.6667\tval_loss: 1.0681 val_accuracy: 0.5000\ttest_loss: 1.1394 test_accuracy: 0.4392\n",
      "train: {'epoch': 12, 'time_epoch': 17.13234, 'eta': 683.38016, 'eta_hours': 0.18983, 'loss': 0.53116333, 'lr': 0.00091222, 'params': 135811, 'time_iter': 0.31727, 'accuracy': 0.81808, 'f1': 0.81756, 'auc': 0.93222}\n",
      "val: {'epoch': 12, 'time_epoch': 1.4059, 'loss': 1.13318741, 'lr': 0, 'params': 135811, 'time_iter': 0.20084, 'accuracy': 0.42453, 'f1': 0.38469, 'auc': 0.67465}\n",
      "test: {'epoch': 12, 'time_epoch': 1.18723, 'loss': 1.36213652, 'lr': 0, 'params': 135811, 'time_iter': 0.1696, 'accuracy': 0.28972, 'f1': 0.22959, 'auc': 0.61032}\n",
      "> Epoch 12: took 19.8s (avg 21.0s) | Best so far: epoch 5\ttrain_loss: 0.8425 train_accuracy: 0.6667\tval_loss: 1.0681 val_accuracy: 0.5000\ttest_loss: 1.1394 test_accuracy: 0.4392\n",
      "train: {'epoch': 13, 'time_epoch': 29.60855, 'eta': 693.55311, 'eta_hours': 0.19265, 'loss': 0.45851067, 'lr': 0.0008924, 'params': 135811, 'time_iter': 0.54831, 'accuracy': 0.85915, 'f1': 0.85382, 'auc': 0.95389}\n",
      "val: {'epoch': 13, 'time_epoch': 1.36672, 'loss': 1.42103215, 'lr': 0, 'params': 135811, 'time_iter': 0.19525, 'accuracy': 0.37736, 'f1': 0.34959, 'auc': 0.61987}\n",
      "test: {'epoch': 13, 'time_epoch': 1.18424, 'loss': 1.40665327, 'lr': 0, 'params': 135811, 'time_iter': 0.16918, 'accuracy': 0.35514, 'f1': 0.30159, 'auc': 0.56987}\n",
      "> Epoch 13: took 32.2s (avg 21.8s) | Best so far: epoch 5\ttrain_loss: 0.8425 train_accuracy: 0.6667\tval_loss: 1.0681 val_accuracy: 0.5000\ttest_loss: 1.1394 test_accuracy: 0.4392\n",
      "train: {'epoch': 14, 'time_epoch': 18.36702, 'eta': 672.19161, 'eta_hours': 0.18672, 'loss': 0.4287495, 'lr': 0.00087083, 'params': 135811, 'time_iter': 0.34013, 'accuracy': 0.87324, 'f1': 0.86818, 'auc': 0.94767}\n",
      "val: {'epoch': 14, 'time_epoch': 1.20471, 'loss': 1.18169801, 'lr': 0, 'params': 135811, 'time_iter': 0.1721, 'accuracy': 0.5, 'f1': 0.47858, 'auc': 0.68888}\n",
      "test: {'epoch': 14, 'time_epoch': 1.19412, 'loss': 1.29665245, 'lr': 0, 'params': 135811, 'time_iter': 0.17059, 'accuracy': 0.4486, 'f1': 0.41642, 'auc': 0.63695}\n",
      "> Epoch 14: took 20.8s (avg 21.7s) | Best so far: epoch 5\ttrain_loss: 0.8425 train_accuracy: 0.6667\tval_loss: 1.0681 val_accuracy: 0.5000\ttest_loss: 1.1394 test_accuracy: 0.4392\n",
      "train: {'epoch': 15, 'time_epoch': 17.82427, 'eta': 650.05107, 'eta_hours': 0.18057, 'loss': 0.4021364, 'lr': 0.0008476, 'params': 135811, 'time_iter': 0.33008, 'accuracy': 0.88498, 'f1': 0.88323, 'auc': 0.95465}\n",
      "val: {'epoch': 15, 'time_epoch': 1.19658, 'loss': 1.46525209, 'lr': 0, 'params': 135811, 'time_iter': 0.17094, 'accuracy': 0.42453, 'f1': 0.41713, 'auc': 0.6353}\n",
      "test: {'epoch': 15, 'time_epoch': 1.21567, 'loss': 1.4442802, 'lr': 0, 'params': 135811, 'time_iter': 0.17367, 'accuracy': 0.43925, 'f1': 0.43501, 'auc': 0.58572}\n",
      "> Epoch 15: took 20.3s (avg 21.6s) | Best so far: epoch 5\ttrain_loss: 0.8425 train_accuracy: 0.6667\tval_loss: 1.0681 val_accuracy: 0.5000\ttest_loss: 1.1394 test_accuracy: 0.4392\n",
      "train: {'epoch': 16, 'time_epoch': 17.85999, 'eta': 628.48767, 'eta_hours': 0.17458, 'loss': 0.40427172, 'lr': 0.00082281, 'params': 135811, 'time_iter': 0.33074, 'accuracy': 0.86854, 'f1': 0.86215, 'auc': 0.96242}\n",
      "val: {'epoch': 16, 'time_epoch': 1.21245, 'loss': 1.17702629, 'lr': 0, 'params': 135811, 'time_iter': 0.17321, 'accuracy': 0.5283, 'f1': 0.43947, 'auc': 0.68444}\n",
      "test: {'epoch': 16, 'time_epoch': 1.20622, 'loss': 1.33963114, 'lr': 0, 'params': 135811, 'time_iter': 0.17232, 'accuracy': 0.49533, 'f1': 0.41422, 'auc': 0.67236}\n",
      "> Epoch 16: took 20.3s (avg 21.5s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 17, 'time_epoch': 17.18083, 'eta': 606.12836, 'eta_hours': 0.16837, 'loss': 0.3285453, 'lr': 0.00079659, 'params': 135811, 'time_iter': 0.31816, 'accuracy': 0.9108, 'f1': 0.90879, 'auc': 0.9707}\n",
      "val: {'epoch': 17, 'time_epoch': 1.23948, 'loss': 1.48280255, 'lr': 0, 'params': 135811, 'time_iter': 0.17707, 'accuracy': 0.46226, 'f1': 0.33526, 'auc': 0.62654}\n",
      "test: {'epoch': 17, 'time_epoch': 1.21548, 'loss': 1.50610454, 'lr': 0, 'params': 135811, 'time_iter': 0.17364, 'accuracy': 0.46729, 'f1': 0.36474, 'auc': 0.62502}\n",
      "> Epoch 17: took 19.7s (avg 21.4s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 18, 'time_epoch': 16.91192, 'eta': 583.87541, 'eta_hours': 0.16219, 'loss': 0.32893519, 'lr': 0.00076904, 'params': 135811, 'time_iter': 0.31318, 'accuracy': 0.90845, 'f1': 0.9062, 'auc': 0.97415}\n",
      "val: {'epoch': 18, 'time_epoch': 1.19292, 'loss': 1.90757133, 'lr': 0, 'params': 135811, 'time_iter': 0.17042, 'accuracy': 0.33962, 'f1': 0.29602, 'auc': 0.58165}\n",
      "test: {'epoch': 18, 'time_epoch': 1.2037, 'loss': 1.8197795, 'lr': 0, 'params': 135811, 'time_iter': 0.17196, 'accuracy': 0.39252, 'f1': 0.35751, 'auc': 0.52938}\n",
      "> Epoch 18: took 19.3s (avg 21.3s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 19, 'time_epoch': 15.76416, 'eta': 560.43492, 'eta_hours': 0.15568, 'loss': 0.32198432, 'lr': 0.00074029, 'params': 135811, 'time_iter': 0.29193, 'accuracy': 0.9061, 'f1': 0.90533, 'auc': 0.97311}\n",
      "val: {'epoch': 19, 'time_epoch': 1.30702, 'loss': 1.99363287, 'lr': 0, 'params': 135811, 'time_iter': 0.18672, 'accuracy': 0.33962, 'f1': 0.25679, 'auc': 0.64764}\n",
      "test: {'epoch': 19, 'time_epoch': 1.24226, 'loss': 1.90862777, 'lr': 0, 'params': 135811, 'time_iter': 0.17747, 'accuracy': 0.39252, 'f1': 0.31672, 'auc': 0.49914}\n",
      "> Epoch 19: took 18.4s (avg 21.2s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 20, 'time_epoch': 16.44048, 'eta': 538.65948, 'eta_hours': 0.14963, 'loss': 0.2924889, 'lr': 0.00071047, 'params': 135811, 'time_iter': 0.30445, 'accuracy': 0.91784, 'f1': 0.91733, 'auc': 0.97176}\n",
      "val: {'epoch': 20, 'time_epoch': 1.20502, 'loss': 1.58302111, 'lr': 0, 'params': 135811, 'time_iter': 0.17215, 'accuracy': 0.42453, 'f1': 0.42408, 'auc': 0.65229}\n",
      "test: {'epoch': 20, 'time_epoch': 1.20164, 'loss': 1.6234823, 'lr': 0, 'params': 135811, 'time_iter': 0.17166, 'accuracy': 0.41121, 'f1': 0.40651, 'auc': 0.58347}\n",
      "> Epoch 20: took 18.9s (avg 21.1s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 21, 'time_epoch': 16.71549, 'eta': 517.71905, 'eta_hours': 0.14381, 'loss': 0.24413559, 'lr': 0.0006797, 'params': 135811, 'time_iter': 0.30955, 'accuracy': 0.94249, 'f1': 0.93916, 'auc': 0.97898}\n",
      "val: {'epoch': 21, 'time_epoch': 1.2716, 'loss': 1.57797986, 'lr': 0, 'params': 135811, 'time_iter': 0.18166, 'accuracy': 0.40566, 'f1': 0.40767, 'auc': 0.65514}\n",
      "test: {'epoch': 21, 'time_epoch': 1.28141, 'loss': 1.58507888, 'lr': 0, 'params': 135811, 'time_iter': 0.18306, 'accuracy': 0.41121, 'f1': 0.40896, 'auc': 0.63536}\n",
      "> Epoch 21: took 19.3s (avg 21.0s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 22, 'time_epoch': 18.00837, 'eta': 498.66373, 'eta_hours': 0.13852, 'loss': 0.27892646, 'lr': 0.00064814, 'params': 135811, 'time_iter': 0.33349, 'accuracy': 0.92958, 'f1': 0.92697, 'auc': 0.9731}\n",
      "val: {'epoch': 22, 'time_epoch': 1.2008, 'loss': 1.573867, 'lr': 0, 'params': 135811, 'time_iter': 0.17154, 'accuracy': 0.46226, 'f1': 0.45657, 'auc': 0.64315}\n",
      "test: {'epoch': 22, 'time_epoch': 1.19747, 'loss': 1.50205862, 'lr': 0, 'params': 135811, 'time_iter': 0.17107, 'accuracy': 0.51402, 'f1': 0.49869, 'auc': 0.64227}\n",
      "> Epoch 22: took 20.4s (avg 21.0s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 23, 'time_epoch': 19.77361, 'eta': 481.608, 'eta_hours': 0.13378, 'loss': 0.24273359, 'lr': 0.00061591, 'params': 135811, 'time_iter': 0.36618, 'accuracy': 0.93779, 'f1': 0.93405, 'auc': 0.98028}\n",
      "val: {'epoch': 23, 'time_epoch': 1.20248, 'loss': 1.66660029, 'lr': 0, 'params': 135811, 'time_iter': 0.17178, 'accuracy': 0.48113, 'f1': 0.41367, 'auc': 0.63237}\n",
      "test: {'epoch': 23, 'time_epoch': 1.19641, 'loss': 1.74856829, 'lr': 0, 'params': 135811, 'time_iter': 0.17092, 'accuracy': 0.4486, 'f1': 0.39841, 'auc': 0.60371}\n",
      "> Epoch 23: took 22.2s (avg 21.0s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 24, 'time_epoch': 16.35092, 'eta': 460.91215, 'eta_hours': 0.12803, 'loss': 0.23603409, 'lr': 0.00058316, 'params': 135811, 'time_iter': 0.30279, 'accuracy': 0.93779, 'f1': 0.93579, 'auc': 0.97812}\n",
      "val: {'epoch': 24, 'time_epoch': 1.34775, 'loss': 1.87079295, 'lr': 0, 'params': 135811, 'time_iter': 0.19254, 'accuracy': 0.37736, 'f1': 0.32208, 'auc': 0.63636}\n",
      "test: {'epoch': 24, 'time_epoch': 1.17871, 'loss': 1.84010796, 'lr': 0, 'params': 135811, 'time_iter': 0.16839, 'accuracy': 0.42056, 'f1': 0.37795, 'auc': 0.59632}\n",
      "> Epoch 24: took 18.9s (avg 20.9s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 25, 'time_epoch': 17.23352, 'eta': 441.36523, 'eta_hours': 0.1226, 'loss': 0.22912835, 'lr': 0.00055005, 'params': 135811, 'time_iter': 0.31914, 'accuracy': 0.94131, 'f1': 0.93887, 'auc': 0.97755}\n",
      "val: {'epoch': 25, 'time_epoch': 1.26334, 'loss': 1.65484284, 'lr': 0, 'params': 135811, 'time_iter': 0.18048, 'accuracy': 0.5, 'f1': 0.44387, 'auc': 0.621}\n",
      "test: {'epoch': 25, 'time_epoch': 1.2144, 'loss': 1.67626674, 'lr': 0, 'params': 135811, 'time_iter': 0.17349, 'accuracy': 0.48598, 'f1': 0.45337, 'auc': 0.63128}\n",
      "> Epoch 25: took 19.7s (avg 20.9s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 26, 'time_epoch': 18.61982, 'eta': 423.1706, 'eta_hours': 0.11755, 'loss': 0.17631099, 'lr': 0.00051671, 'params': 135811, 'time_iter': 0.34481, 'accuracy': 0.95775, 'f1': 0.95376, 'auc': 0.98816}\n",
      "val: {'epoch': 26, 'time_epoch': 1.21395, 'loss': 1.88535324, 'lr': 0, 'params': 135811, 'time_iter': 0.17342, 'accuracy': 0.36792, 'f1': 0.36901, 'auc': 0.61284}\n",
      "test: {'epoch': 26, 'time_epoch': 1.21991, 'loss': 1.7823933, 'lr': 0, 'params': 135811, 'time_iter': 0.17427, 'accuracy': 0.39252, 'f1': 0.38679, 'auc': 0.58332}\n",
      "> Epoch 26: took 21.1s (avg 20.9s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 27, 'time_epoch': 17.78803, 'eta': 404.29205, 'eta_hours': 0.1123, 'loss': 0.18924406, 'lr': 0.00048329, 'params': 135811, 'time_iter': 0.32941, 'accuracy': 0.9554, 'f1': 0.95584, 'auc': 0.98528}\n",
      "val: {'epoch': 27, 'time_epoch': 1.20124, 'loss': 1.61588073, 'lr': 0, 'params': 135811, 'time_iter': 0.17161, 'accuracy': 0.51887, 'f1': 0.49063, 'auc': 0.65736}\n",
      "test: {'epoch': 27, 'time_epoch': 1.20488, 'loss': 1.68054557, 'lr': 0, 'params': 135811, 'time_iter': 0.17213, 'accuracy': 0.50467, 'f1': 0.45684, 'auc': 0.63512}\n",
      "> Epoch 27: took 20.2s (avg 20.9s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 28, 'time_epoch': 19.04146, 'eta': 386.39637, 'eta_hours': 0.10733, 'loss': 0.15683061, 'lr': 0.00044995, 'params': 135811, 'time_iter': 0.35262, 'accuracy': 0.96244, 'f1': 0.9622, 'auc': 0.98937}\n",
      "val: {'epoch': 28, 'time_epoch': 1.18588, 'loss': 1.88106441, 'lr': 0, 'params': 135811, 'time_iter': 0.16941, 'accuracy': 0.38679, 'f1': 0.38761, 'auc': 0.61774}\n",
      "test: {'epoch': 28, 'time_epoch': 1.19958, 'loss': 1.69508146, 'lr': 0, 'params': 135811, 'time_iter': 0.17137, 'accuracy': 0.47664, 'f1': 0.4708, 'auc': 0.62292}\n",
      "> Epoch 28: took 21.5s (avg 20.9s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 29, 'time_epoch': 17.10866, 'eta': 367.13576, 'eta_hours': 0.10198, 'loss': 0.16877601, 'lr': 0.00041684, 'params': 135811, 'time_iter': 0.31683, 'accuracy': 0.96362, 'f1': 0.96274, 'auc': 0.98543}\n",
      "val: {'epoch': 29, 'time_epoch': 1.04358, 'loss': 1.74256114, 'lr': 0, 'params': 135811, 'time_iter': 0.14908, 'accuracy': 0.46226, 'f1': 0.46261, 'auc': 0.63815}\n",
      "test: {'epoch': 29, 'time_epoch': 1.11855, 'loss': 1.71261011, 'lr': 0, 'params': 135811, 'time_iter': 0.15979, 'accuracy': 0.45794, 'f1': 0.45821, 'auc': 0.60428}\n",
      "> Epoch 29: took 19.3s (avg 20.8s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 30, 'time_epoch': 30.64913, 'eta': 356.31299, 'eta_hours': 0.09898, 'loss': 0.12908259, 'lr': 0.00038409, 'params': 135811, 'time_iter': 0.56758, 'accuracy': 0.97418, 'f1': 0.97512, 'auc': 0.99101}\n",
      "val: {'epoch': 30, 'time_epoch': 1.19902, 'loss': 1.67075563, 'lr': 0, 'params': 135811, 'time_iter': 0.17129, 'accuracy': 0.48113, 'f1': 0.43105, 'auc': 0.63162}\n",
      "test: {'epoch': 30, 'time_epoch': 1.26474, 'loss': 1.81819876, 'lr': 0, 'params': 135811, 'time_iter': 0.18068, 'accuracy': 0.39252, 'f1': 0.32432, 'auc': 0.61534}\n",
      "> Epoch 30: took 33.1s (avg 21.2s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 31, 'time_epoch': 18.42932, 'eta': 337.37742, 'eta_hours': 0.09372, 'loss': 0.16199091, 'lr': 0.00035186, 'params': 135811, 'time_iter': 0.34128, 'accuracy': 0.95892, 'f1': 0.9569, 'auc': 0.98614}\n",
      "val: {'epoch': 31, 'time_epoch': 1.18102, 'loss': 1.84559306, 'lr': 0, 'params': 135811, 'time_iter': 0.16872, 'accuracy': 0.4434, 'f1': 0.43746, 'auc': 0.61533}\n",
      "test: {'epoch': 31, 'time_epoch': 1.18864, 'loss': 1.72357625, 'lr': 0, 'params': 135811, 'time_iter': 0.16981, 'accuracy': 0.49533, 'f1': 0.48735, 'auc': 0.62499}\n",
      "> Epoch 31: took 20.8s (avg 21.2s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 32, 'time_epoch': 31.63773, 'eta': 325.27688, 'eta_hours': 0.09035, 'loss': 0.15024768, 'lr': 0.0003203, 'params': 135811, 'time_iter': 0.58588, 'accuracy': 0.97066, 'f1': 0.97164, 'auc': 0.9897}\n",
      "val: {'epoch': 32, 'time_epoch': 1.21632, 'loss': 1.89548761, 'lr': 0, 'params': 135811, 'time_iter': 0.17376, 'accuracy': 0.39623, 'f1': 0.39379, 'auc': 0.61408}\n",
      "test: {'epoch': 32, 'time_epoch': 1.20251, 'loss': 1.67831439, 'lr': 0, 'params': 135811, 'time_iter': 0.17179, 'accuracy': 0.4486, 'f1': 0.44702, 'auc': 0.62584}\n",
      "> Epoch 32: took 34.1s (avg 21.6s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 33, 'time_epoch': 18.52566, 'eta': 305.8567, 'eta_hours': 0.08496, 'loss': 0.1532894, 'lr': 0.00028953, 'params': 135811, 'time_iter': 0.34307, 'accuracy': 0.96596, 'f1': 0.965, 'auc': 0.9891}\n",
      "val: {'epoch': 33, 'time_epoch': 1.20048, 'loss': 1.83229625, 'lr': 0, 'params': 135811, 'time_iter': 0.1715, 'accuracy': 0.48113, 'f1': 0.45812, 'auc': 0.63431}\n",
      "test: {'epoch': 33, 'time_epoch': 1.21858, 'loss': 1.75753123, 'lr': 0, 'params': 135811, 'time_iter': 0.17408, 'accuracy': 0.47664, 'f1': 0.43583, 'auc': 0.65294}\n",
      "> Epoch 33: took 21.0s (avg 21.6s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 34, 'time_epoch': 19.14264, 'eta': 286.75205, 'eta_hours': 0.07965, 'loss': 0.12034643, 'lr': 0.00025971, 'params': 135811, 'time_iter': 0.35449, 'accuracy': 0.97653, 'f1': 0.97495, 'auc': 0.99274}\n",
      "val: {'epoch': 34, 'time_epoch': 1.20851, 'loss': 1.90206904, 'lr': 0, 'params': 135811, 'time_iter': 0.17264, 'accuracy': 0.4717, 'f1': 0.45802, 'auc': 0.61016}\n",
      "test: {'epoch': 34, 'time_epoch': 1.18697, 'loss': 1.69485224, 'lr': 0, 'params': 135811, 'time_iter': 0.16957, 'accuracy': 0.48598, 'f1': 0.46898, 'auc': 0.65038}\n",
      "> Epoch 34: took 21.6s (avg 21.6s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 35, 'time_epoch': 17.82945, 'eta': 267.13461, 'eta_hours': 0.0742, 'loss': 0.10389866, 'lr': 0.00023096, 'params': 135811, 'time_iter': 0.33017, 'accuracy': 0.98474, 'f1': 0.98444, 'auc': 0.9948}\n",
      "val: {'epoch': 35, 'time_epoch': 1.20827, 'loss': 1.89355026, 'lr': 0, 'params': 135811, 'time_iter': 0.17261, 'accuracy': 0.46226, 'f1': 0.44779, 'auc': 0.62013}\n",
      "test: {'epoch': 35, 'time_epoch': 1.2065, 'loss': 1.70000501, 'lr': 0, 'params': 135811, 'time_iter': 0.17236, 'accuracy': 0.48598, 'f1': 0.4651, 'auc': 0.66084}\n",
      "> Epoch 35: took 20.3s (avg 21.6s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 36, 'time_epoch': 17.90818, 'eta': 247.64148, 'eta_hours': 0.06879, 'loss': 0.13255644, 'lr': 0.00020341, 'params': 135811, 'time_iter': 0.33163, 'accuracy': 0.97066, 'f1': 0.97055, 'auc': 0.99094}\n",
      "val: {'epoch': 36, 'time_epoch': 1.35125, 'loss': 1.84155564, 'lr': 0, 'params': 135811, 'time_iter': 0.19304, 'accuracy': 0.5, 'f1': 0.48757, 'auc': 0.6182}\n",
      "test: {'epoch': 36, 'time_epoch': 1.06139, 'loss': 1.79225141, 'lr': 0, 'params': 135811, 'time_iter': 0.15163, 'accuracy': 0.47664, 'f1': 0.44797, 'auc': 0.64758}\n",
      "> Epoch 36: took 20.4s (avg 21.5s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 37, 'time_epoch': 17.35932, 'eta': 228.05844, 'eta_hours': 0.06335, 'loss': 0.11704531, 'lr': 0.00017719, 'params': 135811, 'time_iter': 0.32147, 'accuracy': 0.9777, 'f1': 0.97528, 'auc': 0.99226}\n",
      "val: {'epoch': 37, 'time_epoch': 1.36203, 'loss': 1.8388615, 'lr': 0, 'params': 135811, 'time_iter': 0.19458, 'accuracy': 0.5, 'f1': 0.47899, 'auc': 0.61392}\n",
      "test: {'epoch': 37, 'time_epoch': 1.24662, 'loss': 1.80720525, 'lr': 0, 'params': 135811, 'time_iter': 0.17809, 'accuracy': 0.48598, 'f1': 0.45513, 'auc': 0.6565}\n",
      "> Epoch 37: took 20.0s (avg 21.5s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 38, 'time_epoch': 30.17409, 'eta': 212.20387, 'eta_hours': 0.05895, 'loss': 0.111952, 'lr': 0.0001524, 'params': 135811, 'time_iter': 0.55878, 'accuracy': 0.9777, 'f1': 0.97565, 'auc': 0.99331}\n",
      "val: {'epoch': 38, 'time_epoch': 1.42034, 'loss': 2.06056807, 'lr': 0, 'params': 135811, 'time_iter': 0.20291, 'accuracy': 0.43396, 'f1': 0.43189, 'auc': 0.60896}\n",
      "test: {'epoch': 38, 'time_epoch': 1.1985, 'loss': 1.78099653, 'lr': 0, 'params': 135811, 'time_iter': 0.17121, 'accuracy': 0.50467, 'f1': 0.50335, 'auc': 0.63807}\n",
      "> Epoch 38: took 32.8s (avg 21.8s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 39, 'time_epoch': 16.33065, 'eta': 192.17245, 'eta_hours': 0.05338, 'loss': 0.13583296, 'lr': 0.00012917, 'params': 135811, 'time_iter': 0.30242, 'accuracy': 0.96714, 'f1': 0.96682, 'auc': 0.99345}\n",
      "val: {'epoch': 39, 'time_epoch': 1.20999, 'loss': 1.80154944, 'lr': 0, 'params': 135811, 'time_iter': 0.17286, 'accuracy': 0.5, 'f1': 0.47998, 'auc': 0.62762}\n",
      "test: {'epoch': 39, 'time_epoch': 1.19716, 'loss': 1.73234551, 'lr': 0, 'params': 135811, 'time_iter': 0.17102, 'accuracy': 0.47664, 'f1': 0.44423, 'auc': 0.65703}\n",
      "> Epoch 39: took 18.8s (avg 21.7s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 40, 'time_epoch': 17.68176, 'eta': 172.61815, 'eta_hours': 0.04795, 'loss': 0.10067897, 'lr': 0.0001076, 'params': 135811, 'time_iter': 0.32744, 'accuracy': 0.98474, 'f1': 0.98444, 'auc': 0.99391}\n",
      "val: {'epoch': 40, 'time_epoch': 1.20383, 'loss': 1.90219111, 'lr': 0, 'params': 135811, 'time_iter': 0.17198, 'accuracy': 0.4717, 'f1': 0.45473, 'auc': 0.61061}\n",
      "test: {'epoch': 40, 'time_epoch': 1.19372, 'loss': 1.80788492, 'lr': 0, 'params': 135811, 'time_iter': 0.17053, 'accuracy': 0.48598, 'f1': 0.46365, 'auc': 0.65278}\n",
      "> Epoch 40: took 20.1s (avg 21.7s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 41, 'time_epoch': 17.19995, 'eta': 153.06124, 'eta_hours': 0.04252, 'loss': 0.09300839, 'lr': 8.778e-05, 'params': 135811, 'time_iter': 0.31852, 'accuracy': 0.98592, 'f1': 0.98511, 'auc': 0.99404}\n",
      "val: {'epoch': 41, 'time_epoch': 1.21391, 'loss': 1.87541344, 'lr': 0, 'params': 135811, 'time_iter': 0.17342, 'accuracy': 0.49057, 'f1': 0.47626, 'auc': 0.6201}\n",
      "test: {'epoch': 41, 'time_epoch': 1.22496, 'loss': 1.72426365, 'lr': 0, 'params': 135811, 'time_iter': 0.17499, 'accuracy': 0.50467, 'f1': 0.48477, 'auc': 0.6545}\n",
      "> Epoch 41: took 19.7s (avg 21.6s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 42, 'time_epoch': 31.88882, 'eta': 136.00517, 'eta_hours': 0.03778, 'loss': 0.1071964, 'lr': 6.98e-05, 'params': 135811, 'time_iter': 0.59053, 'accuracy': 0.98005, 'f1': 0.9781, 'auc': 0.99162}\n",
      "val: {'epoch': 42, 'time_epoch': 5.51918, 'loss': 1.97232352, 'lr': 0, 'params': 135811, 'time_iter': 0.78845, 'accuracy': 0.46226, 'f1': 0.45178, 'auc': 0.60914}\n",
      "test: {'epoch': 42, 'time_epoch': 5.26527, 'loss': 1.72390123, 'lr': 0, 'params': 135811, 'time_iter': 0.75218, 'accuracy': 0.52336, 'f1': 0.51453, 'auc': 0.65858}\n",
      "> Epoch 42: took 42.7s (avg 22.1s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 43, 'time_epoch': 119.94166, 'eta': 130.28209, 'eta_hours': 0.03619, 'loss': 0.09789911, 'lr': 5.374e-05, 'params': 135811, 'time_iter': 2.22114, 'accuracy': 0.98474, 'f1': 0.9843, 'auc': 0.99388}\n",
      "val: {'epoch': 43, 'time_epoch': 2.76752, 'loss': 1.96879005, 'lr': 0, 'params': 135811, 'time_iter': 0.39536, 'accuracy': 0.45283, 'f1': 0.43954, 'auc': 0.60972}\n",
      "test: {'epoch': 43, 'time_epoch': 5.40338, 'loss': 1.7402027, 'lr': 0, 'params': 135811, 'time_iter': 0.77191, 'accuracy': 0.53271, 'f1': 0.52376, 'auc': 0.65361}\n",
      "> Epoch 43: took 128.2s (avg 24.5s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 44, 'time_epoch': 68.98966, 'eta': 113.8213, 'eta_hours': 0.03162, 'loss': 0.10597667, 'lr': 3.968e-05, 'params': 135811, 'time_iter': 1.27759, 'accuracy': 0.98005, 'f1': 0.97889, 'auc': 0.99378}\n",
      "val: {'epoch': 44, 'time_epoch': 5.57798, 'loss': 1.84450629, 'lr': 0, 'params': 135811, 'time_iter': 0.79685, 'accuracy': 0.5, 'f1': 0.47369, 'auc': 0.61888}\n",
      "test: {'epoch': 44, 'time_epoch': 5.15106, 'loss': 1.72705976, 'lr': 0, 'params': 135811, 'time_iter': 0.73587, 'accuracy': 0.47664, 'f1': 0.45874, 'auc': 0.65468}\n",
      "> Epoch 44: took 79.8s (avg 25.7s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 45, 'time_epoch': 108.60276, 'eta': 98.52125, 'eta_hours': 0.02737, 'loss': 0.09420236, 'lr': 2.767e-05, 'params': 135811, 'time_iter': 2.01116, 'accuracy': 0.98474, 'f1': 0.98364, 'auc': 0.99442}\n",
      "val: {'epoch': 45, 'time_epoch': 5.71936, 'loss': 1.88368881, 'lr': 0, 'params': 135811, 'time_iter': 0.81705, 'accuracy': 0.49057, 'f1': 0.47266, 'auc': 0.61251}\n",
      "test: {'epoch': 45, 'time_epoch': 5.0941, 'loss': 1.74481212, 'lr': 0, 'params': 135811, 'time_iter': 0.72773, 'accuracy': 0.50467, 'f1': 0.48903, 'auc': 0.65363}\n",
      "> Epoch 45: took 119.5s (avg 27.8s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 46, 'time_epoch': 120.36158, 'eta': 80.00145, 'eta_hours': 0.02222, 'loss': 0.08444305, 'lr': 1.777e-05, 'params': 135811, 'time_iter': 2.22892, 'accuracy': 0.98826, 'f1': 0.98753, 'auc': 0.99431}\n",
      "val: {'epoch': 46, 'time_epoch': 5.13928, 'loss': 1.99371538, 'lr': 0, 'params': 135811, 'time_iter': 0.73418, 'accuracy': 0.45283, 'f1': 0.43954, 'auc': 0.60422}\n",
      "test: {'epoch': 46, 'time_epoch': 4.87294, 'loss': 1.79208041, 'lr': 0, 'params': 135811, 'time_iter': 0.69613, 'accuracy': 0.50467, 'f1': 0.49122, 'auc': 0.6525}\n",
      "> Epoch 46: took 130.4s (avg 30.0s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 47, 'time_epoch': 90.31848, 'eta': 55.98644, 'eta_hours': 0.01555, 'loss': 0.09857363, 'lr': 1.002e-05, 'params': 135811, 'time_iter': 1.67256, 'accuracy': 0.97887, 'f1': 0.97716, 'auc': 0.99699}\n",
      "val: {'epoch': 47, 'time_epoch': 4.86405, 'loss': 2.00187955, 'lr': 0, 'params': 135811, 'time_iter': 0.69486, 'accuracy': 0.46226, 'f1': 0.45717, 'auc': 0.6136}\n",
      "test: {'epoch': 47, 'time_epoch': 5.46193, 'loss': 1.7621335, 'lr': 0, 'params': 135811, 'time_iter': 0.78028, 'accuracy': 0.51402, 'f1': 0.50841, 'auc': 0.65039}\n",
      "> Epoch 47: took 100.7s (avg 31.4s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 48, 'time_epoch': 54.15899, 'eta': 28.52721, 'eta_hours': 0.00792, 'loss': 0.09096757, 'lr': 4.46e-06, 'params': 135811, 'time_iter': 1.00294, 'accuracy': 0.98709, 'f1': 0.98652, 'auc': 0.99547}\n",
      "val: {'epoch': 48, 'time_epoch': 4.2892, 'loss': 2.04750769, 'lr': 0, 'params': 135811, 'time_iter': 0.61274, 'accuracy': 0.42453, 'f1': 0.42419, 'auc': 0.60171}\n",
      "test: {'epoch': 48, 'time_epoch': 5.27329, 'loss': 1.86916082, 'lr': 0, 'params': 135811, 'time_iter': 0.75333, 'accuracy': 0.49533, 'f1': 0.48815, 'auc': 0.65683}\n",
      "> Epoch 48: took 63.8s (avg 32.1s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "train: {'epoch': 49, 'time_epoch': 74.93219, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.0983415, 'lr': 1.12e-06, 'params': 135811, 'time_iter': 1.38763, 'accuracy': 0.98357, 'f1': 0.983, 'auc': 0.99537}\n",
      "val: {'epoch': 49, 'time_epoch': 5.09055, 'loss': 1.95479524, 'lr': 0, 'params': 135811, 'time_iter': 0.72722, 'accuracy': 0.48113, 'f1': 0.46586, 'auc': 0.6228}\n",
      "test: {'epoch': 49, 'time_epoch': 5.41034, 'loss': 1.73451678, 'lr': 0, 'params': 135811, 'time_iter': 0.77291, 'accuracy': 0.50467, 'f1': 0.48995, 'auc': 0.65276}\n",
      "> Epoch 49: took 85.5s (avg 33.2s) | Best so far: epoch 16\ttrain_loss: 0.4043 train_accuracy: 0.8685\tval_loss: 1.1770 val_accuracy: 0.5283\ttest_loss: 1.3396 test_accuracy: 0.4953\n",
      "Avg time per epoch: 33.16s\n",
      "Total train loop time: 0.46h\n",
      "Task done, results saved in results\\neural-Age\\0\n",
      "16\n",
      "{'epoch': 16, 'time_epoch': 1.20622, 'loss': 1.33963114, 'lr': 0, 'params': 135811, 'time_iter': 0.17232, 'accuracy': 0.49533, 'f1': 0.41422, 'auc': 0.67236}\n",
      "{'epoch': 16, 'time_epoch': 17.85999, 'eta': 628.48767, 'eta_hours': 0.17458, 'loss': 0.40427172, 'lr': 0.00082281, 'params': 135811, 'time_iter': 0.33074, 'accuracy': 0.86854, 'f1': 0.86215, 'auc': 0.96242}\n",
      "{'epoch': 16, 'time_epoch': 1.21245, 'loss': 1.17702629, 'lr': 0, 'params': 135811, 'time_iter': 0.17321, 'accuracy': 0.5283, 'f1': 0.43947, 'auc': 0.68444}\n",
      "Results aggregated across runs saved in results\\neural-Age\\agg\n",
      "[*] All done: 2024-03-01 21:44:14.806756\n"
     ]
    }
   ],
   "source": [
    "#Age using Exphormer 2 layers \n",
    "%run main.py --cfg configs/Exphormer/neural-Age.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26fc7cf-e154-497c-9544-8bfba9cc95c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-01 21:48:55.679216\n",
      "[*] Loaded dataset 'HCPAge' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1065000, 1000], edge_index=[2, 48551656], y=[1065])\n",
      "  undirected: True\n",
      "  num graphs: 1065\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 3\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [01:58<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:59.39\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [01:22<00:00, 12.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:23.86\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 3, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPAge\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.3\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 2\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 60\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 3\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Age\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Age\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 3\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 135811\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 11.87143, 'eta': 700.41434, 'eta_hours': 0.19456, 'loss': 1.1078273, 'lr': 0.0, 'params': 135811, 'time_iter': 0.21984, 'accuracy': 0.35446, 'f1': 0.18241, 'auc': 0.51567}\n",
      "...computing epoch stats took: 0.07s\n",
      "val: {'epoch': 0, 'time_epoch': 0.81473, 'loss': 1.12347547, 'lr': 0, 'params': 135811, 'time_iter': 0.11639, 'accuracy': 0.25472, 'f1': 0.13534, 'auc': 0.51139}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 0, 'time_epoch': 0.83311, 'loss': 1.11263384, 'lr': 0, 'params': 135811, 'time_iter': 0.11902, 'accuracy': 0.31776, 'f1': 0.1619, 'auc': 0.49427}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 0: took 13.6s (avg 13.6s) | Best so far: epoch 0\ttrain_loss: 1.1078 train_accuracy: 0.3545\tval_loss: 1.1235 val_accuracy: 0.2547\ttest_loss: 1.1126 test_accuracy: 0.3178\n",
      "train: {'epoch': 1, 'time_epoch': 10.52391, 'eta': 649.46475, 'eta_hours': 0.18041, 'loss': 1.08022342, 'lr': 0.00033333, 'params': 135811, 'time_iter': 0.19489, 'accuracy': 0.37207, 'f1': 0.25073, 'auc': 0.54734}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 1, 'time_epoch': 0.80806, 'loss': 1.0855337, 'lr': 0, 'params': 135811, 'time_iter': 0.11544, 'accuracy': 0.26415, 'f1': 0.1393, 'auc': 0.59523}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 0.80078, 'loss': 1.09696309, 'lr': 0, 'params': 135811, 'time_iter': 0.1144, 'accuracy': 0.3271, 'f1': 0.16432, 'auc': 0.51234}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 12.2s (avg 12.9s) | Best so far: epoch 1\ttrain_loss: 1.0802 train_accuracy: 0.3721\tval_loss: 1.0855 val_accuracy: 0.2641\ttest_loss: 1.0970 test_accuracy: 0.3271\n",
      "train: {'epoch': 2, 'time_epoch': 10.77775, 'eta': 630.28873, 'eta_hours': 0.17508, 'loss': 1.04697995, 'lr': 0.00066667, 'params': 135811, 'time_iter': 0.19959, 'accuracy': 0.45305, 'f1': 0.35231, 'auc': 0.60476}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 0.80661, 'loss': 1.05828759, 'lr': 0, 'params': 135811, 'time_iter': 0.11523, 'accuracy': 0.42453, 'f1': 0.41486, 'auc': 0.60969}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 0.7968, 'loss': 1.08865723, 'lr': 0, 'params': 135811, 'time_iter': 0.11383, 'accuracy': 0.36449, 'f1': 0.35469, 'auc': 0.53069}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 12.4s (avg 12.7s) | Best so far: epoch 2\ttrain_loss: 1.0470 train_accuracy: 0.4531\tval_loss: 1.0583 val_accuracy: 0.4245\ttest_loss: 1.0887 test_accuracy: 0.3645\n",
      "train: {'epoch': 3, 'time_epoch': 11.01393, 'eta': 618.61829, 'eta_hours': 0.17184, 'loss': 1.01258203, 'lr': 0.001, 'params': 135811, 'time_iter': 0.20396, 'accuracy': 0.5, 'f1': 0.43026, 'auc': 0.66642}\n",
      "val: {'epoch': 3, 'time_epoch': 0.79439, 'loss': 1.09336075, 'lr': 0, 'params': 135811, 'time_iter': 0.11348, 'accuracy': 0.28302, 'f1': 0.18576, 'auc': 0.65687}\n",
      "test: {'epoch': 3, 'time_epoch': 0.79824, 'loss': 1.1117297, 'lr': 0, 'params': 135811, 'time_iter': 0.11403, 'accuracy': 0.27103, 'f1': 0.14646, 'auc': 0.57984}\n",
      "> Epoch 3: took 12.6s (avg 12.7s) | Best so far: epoch 2\ttrain_loss: 1.0470 train_accuracy: 0.4531\tval_loss: 1.0583 val_accuracy: 0.4245\ttest_loss: 1.0887 test_accuracy: 0.3645\n",
      "train: {'epoch': 4, 'time_epoch': 10.75929, 'eta': 604.40942, 'eta_hours': 0.16789, 'loss': 0.9494054, 'lr': 0.00099924, 'params': 135811, 'time_iter': 0.19925, 'accuracy': 0.57277, 'f1': 0.5621, 'auc': 0.74187}\n",
      "val: {'epoch': 4, 'time_epoch': 0.78279, 'loss': 1.16747988, 'lr': 0, 'params': 135811, 'time_iter': 0.11183, 'accuracy': 0.26415, 'f1': 0.1393, 'auc': 0.66231}\n",
      "test: {'epoch': 4, 'time_epoch': 0.7985, 'loss': 1.16099222, 'lr': 0, 'params': 135811, 'time_iter': 0.11407, 'accuracy': 0.3271, 'f1': 0.16432, 'auc': 0.54194}\n",
      "> Epoch 4: took 12.4s (avg 12.6s) | Best so far: epoch 2\ttrain_loss: 1.0470 train_accuracy: 0.4531\tval_loss: 1.0583 val_accuracy: 0.4245\ttest_loss: 1.0887 test_accuracy: 0.3645\n",
      "train: {'epoch': 5, 'time_epoch': 10.1829, 'eta': 586.16292, 'eta_hours': 0.16282, 'loss': 0.87613088, 'lr': 0.00099697, 'params': 135811, 'time_iter': 0.18857, 'accuracy': 0.65023, 'f1': 0.64062, 'auc': 0.79551}\n",
      "val: {'epoch': 5, 'time_epoch': 0.79397, 'loss': 1.2021741, 'lr': 0, 'params': 135811, 'time_iter': 0.11342, 'accuracy': 0.32075, 'f1': 0.23589, 'auc': 0.58106}\n",
      "test: {'epoch': 5, 'time_epoch': 0.7987, 'loss': 1.22338172, 'lr': 0, 'params': 135811, 'time_iter': 0.1141, 'accuracy': 0.30841, 'f1': 0.21103, 'auc': 0.53164}\n",
      "> Epoch 5: took 11.8s (avg 12.5s) | Best so far: epoch 2\ttrain_loss: 1.0470 train_accuracy: 0.4531\tval_loss: 1.0583 val_accuracy: 0.4245\ttest_loss: 1.0887 test_accuracy: 0.3645\n",
      "train: {'epoch': 6, 'time_epoch': 10.53327, 'eta': 572.87311, 'eta_hours': 0.15913, 'loss': 0.79673106, 'lr': 0.00099318, 'params': 135811, 'time_iter': 0.19506, 'accuracy': 0.7007, 'f1': 0.69633, 'auc': 0.84884}\n",
      "val: {'epoch': 6, 'time_epoch': 0.80052, 'loss': 1.0808249, 'lr': 0, 'params': 135811, 'time_iter': 0.11436, 'accuracy': 0.41509, 'f1': 0.36516, 'auc': 0.65115}\n",
      "test: {'epoch': 6, 'time_epoch': 0.80976, 'loss': 1.09498465, 'lr': 0, 'params': 135811, 'time_iter': 0.11568, 'accuracy': 0.4486, 'f1': 0.36499, 'auc': 0.61961}\n",
      "> Epoch 6: took 12.2s (avg 12.4s) | Best so far: epoch 2\ttrain_loss: 1.0470 train_accuracy: 0.4531\tval_loss: 1.0583 val_accuracy: 0.4245\ttest_loss: 1.0887 test_accuracy: 0.3645\n",
      "train: {'epoch': 7, 'time_epoch': 10.17883, 'eta': 557.96854, 'eta_hours': 0.15499, 'loss': 0.72570811, 'lr': 0.0009879, 'params': 135811, 'time_iter': 0.1885, 'accuracy': 0.73239, 'f1': 0.72457, 'auc': 0.87683}\n",
      "val: {'epoch': 7, 'time_epoch': 0.82738, 'loss': 1.23108293, 'lr': 0, 'params': 135811, 'time_iter': 0.1182, 'accuracy': 0.37736, 'f1': 0.28542, 'auc': 0.60203}\n",
      "test: {'epoch': 7, 'time_epoch': 0.79102, 'loss': 1.23091026, 'lr': 0, 'params': 135811, 'time_iter': 0.113, 'accuracy': 0.37383, 'f1': 0.30537, 'auc': 0.5567}\n",
      "> Epoch 7: took 11.8s (avg 12.4s) | Best so far: epoch 2\ttrain_loss: 1.0470 train_accuracy: 0.4531\tval_loss: 1.0583 val_accuracy: 0.4245\ttest_loss: 1.0887 test_accuracy: 0.3645\n",
      "train: {'epoch': 8, 'time_epoch': 10.51537, 'eta': 546.02119, 'eta_hours': 0.15167, 'loss': 0.66411295, 'lr': 0.00098113, 'params': 135811, 'time_iter': 0.19473, 'accuracy': 0.76643, 'f1': 0.75643, 'auc': 0.90321}\n",
      "val: {'epoch': 8, 'time_epoch': 0.80176, 'loss': 1.12466504, 'lr': 0, 'params': 135811, 'time_iter': 0.11454, 'accuracy': 0.4717, 'f1': 0.34255, 'auc': 0.65367}\n",
      "test: {'epoch': 8, 'time_epoch': 0.80266, 'loss': 1.2238401, 'lr': 0, 'params': 135811, 'time_iter': 0.11467, 'accuracy': 0.4486, 'f1': 0.33718, 'auc': 0.58623}\n",
      "> Epoch 8: took 12.1s (avg 12.3s) | Best so far: epoch 8\ttrain_loss: 0.6641 train_accuracy: 0.7664\tval_loss: 1.1247 val_accuracy: 0.4717\ttest_loss: 1.2238 test_accuracy: 0.4486\n",
      "train: {'epoch': 9, 'time_epoch': 11.95018, 'eta': 541.53429, 'eta_hours': 0.15043, 'loss': 0.61155476, 'lr': 0.00097291, 'params': 135811, 'time_iter': 0.2213, 'accuracy': 0.79225, 'f1': 0.79684, 'auc': 0.91057}\n",
      "val: {'epoch': 9, 'time_epoch': 0.81559, 'loss': 1.11065814, 'lr': 0, 'params': 135811, 'time_iter': 0.11651, 'accuracy': 0.46226, 'f1': 0.34317, 'auc': 0.66506}\n",
      "test: {'epoch': 9, 'time_epoch': 0.80253, 'loss': 1.24088514, 'lr': 0, 'params': 135811, 'time_iter': 0.11465, 'accuracy': 0.46729, 'f1': 0.34325, 'auc': 0.57039}\n",
      "> Epoch 9: took 13.6s (avg 12.5s) | Best so far: epoch 8\ttrain_loss: 0.6641 train_accuracy: 0.7664\tval_loss: 1.1247 val_accuracy: 0.4717\ttest_loss: 1.2238 test_accuracy: 0.4486\n",
      "train: {'epoch': 10, 'time_epoch': 22.34847, 'eta': 582.01009, 'eta_hours': 0.16167, 'loss': 0.59718015, 'lr': 0.00096325, 'params': 135811, 'time_iter': 0.41386, 'accuracy': 0.80282, 'f1': 0.80213, 'auc': 0.91104}\n",
      "val: {'epoch': 10, 'time_epoch': 0.82153, 'loss': 1.07294174, 'lr': 0, 'params': 135811, 'time_iter': 0.11736, 'accuracy': 0.51887, 'f1': 0.4422, 'auc': 0.67804}\n",
      "test: {'epoch': 10, 'time_epoch': 0.82311, 'loss': 1.21802376, 'lr': 0, 'params': 135811, 'time_iter': 0.11759, 'accuracy': 0.43925, 'f1': 0.35742, 'auc': 0.61969}\n",
      "> Epoch 10: took 24.0s (avg 13.5s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 11, 'time_epoch': 11.44606, 'eta': 568.40554, 'eta_hours': 0.15789, 'loss': 0.51611363, 'lr': 0.00095218, 'params': 135811, 'time_iter': 0.21196, 'accuracy': 0.84272, 'f1': 0.84008, 'auc': 0.93987}\n",
      "val: {'epoch': 11, 'time_epoch': 0.80265, 'loss': 1.59929639, 'lr': 0, 'params': 135811, 'time_iter': 0.11466, 'accuracy': 0.30189, 'f1': 0.22818, 'auc': 0.55907}\n",
      "test: {'epoch': 11, 'time_epoch': 0.80042, 'loss': 1.55027412, 'lr': 0, 'params': 135811, 'time_iter': 0.11435, 'accuracy': 0.30841, 'f1': 0.20707, 'auc': 0.51737}\n",
      "> Epoch 11: took 13.1s (avg 13.5s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 12, 'time_epoch': 10.60721, 'eta': 552.10032, 'eta_hours': 0.15336, 'loss': 0.53683336, 'lr': 0.00093974, 'params': 135811, 'time_iter': 0.19643, 'accuracy': 0.81573, 'f1': 0.81712, 'auc': 0.93075}\n",
      "val: {'epoch': 12, 'time_epoch': 0.8104, 'loss': 1.28833706, 'lr': 0, 'params': 135811, 'time_iter': 0.11577, 'accuracy': 0.37736, 'f1': 0.30116, 'auc': 0.64401}\n",
      "test: {'epoch': 12, 'time_epoch': 0.82764, 'loss': 1.47472418, 'lr': 0, 'params': 135811, 'time_iter': 0.11823, 'accuracy': 0.27103, 'f1': 0.16801, 'auc': 0.58067}\n",
      "> Epoch 12: took 12.3s (avg 13.4s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 13, 'time_epoch': 21.89205, 'eta': 573.68786, 'eta_hours': 0.15936, 'loss': 0.49268423, 'lr': 0.00092596, 'params': 135811, 'time_iter': 0.40541, 'accuracy': 0.83568, 'f1': 0.83048, 'auc': 0.93977}\n",
      "val: {'epoch': 13, 'time_epoch': 0.80204, 'loss': 1.33478483, 'lr': 0, 'params': 135811, 'time_iter': 0.11458, 'accuracy': 0.33962, 'f1': 0.29202, 'auc': 0.65068}\n",
      "test: {'epoch': 13, 'time_epoch': 0.80338, 'loss': 1.46899996, 'lr': 0, 'params': 135811, 'time_iter': 0.11477, 'accuracy': 0.28037, 'f1': 0.20212, 'auc': 0.60717}\n",
      "> Epoch 13: took 23.5s (avg 14.1s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 14, 'time_epoch': 11.03932, 'eta': 556.91991, 'eta_hours': 0.1547, 'loss': 0.50642533, 'lr': 0.00091089, 'params': 135811, 'time_iter': 0.20443, 'accuracy': 0.82512, 'f1': 0.81796, 'auc': 0.93225}\n",
      "val: {'epoch': 14, 'time_epoch': 0.80595, 'loss': 1.20292249, 'lr': 0, 'params': 135811, 'time_iter': 0.11514, 'accuracy': 0.46226, 'f1': 0.45828, 'auc': 0.67646}\n",
      "test: {'epoch': 14, 'time_epoch': 0.80454, 'loss': 1.2619228, 'lr': 0, 'params': 135811, 'time_iter': 0.11493, 'accuracy': 0.46729, 'f1': 0.47026, 'auc': 0.62394}\n",
      "> Epoch 14: took 12.7s (avg 14.0s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 15, 'time_epoch': 10.73682, 'eta': 540.03616, 'eta_hours': 0.15001, 'loss': 0.41723488, 'lr': 0.00089457, 'params': 135811, 'time_iter': 0.19883, 'accuracy': 0.87089, 'f1': 0.86744, 'auc': 0.95001}\n",
      "val: {'epoch': 15, 'time_epoch': 0.77864, 'loss': 1.34017681, 'lr': 0, 'params': 135811, 'time_iter': 0.11123, 'accuracy': 0.41509, 'f1': 0.41609, 'auc': 0.64773}\n",
      "test: {'epoch': 15, 'time_epoch': 0.80102, 'loss': 1.44303163, 'lr': 0, 'params': 135811, 'time_iter': 0.11443, 'accuracy': 0.39252, 'f1': 0.39089, 'auc': 0.60229}\n",
      "> Epoch 15: took 12.3s (avg 13.9s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 16, 'time_epoch': 10.72852, 'eta': 523.8546, 'eta_hours': 0.14552, 'loss': 0.38654467, 'lr': 0.00087705, 'params': 135811, 'time_iter': 0.19868, 'accuracy': 0.88498, 'f1': 0.88097, 'auc': 0.96384}\n",
      "val: {'epoch': 16, 'time_epoch': 0.79307, 'loss': 1.2440609, 'lr': 0, 'params': 135811, 'time_iter': 0.1133, 'accuracy': 0.5, 'f1': 0.40405, 'auc': 0.64598}\n",
      "test: {'epoch': 16, 'time_epoch': 0.78681, 'loss': 1.42081747, 'lr': 0, 'params': 135811, 'time_iter': 0.1124, 'accuracy': 0.46729, 'f1': 0.35517, 'auc': 0.64471}\n",
      "> Epoch 16: took 12.3s (avg 13.8s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 17, 'time_epoch': 10.54751, 'eta': 507.85657, 'eta_hours': 0.14107, 'loss': 0.33162867, 'lr': 0.00085839, 'params': 135811, 'time_iter': 0.19532, 'accuracy': 0.9061, 'f1': 0.90404, 'auc': 0.96981}\n",
      "val: {'epoch': 17, 'time_epoch': 0.81655, 'loss': 1.20761942, 'lr': 0, 'params': 135811, 'time_iter': 0.11665, 'accuracy': 0.49057, 'f1': 0.44458, 'auc': 0.6727}\n",
      "test: {'epoch': 17, 'time_epoch': 0.79382, 'loss': 1.4230726, 'lr': 0, 'params': 135811, 'time_iter': 0.1134, 'accuracy': 0.39252, 'f1': 0.31752, 'auc': 0.60074}\n",
      "> Epoch 17: took 12.2s (avg 13.7s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 18, 'time_epoch': 10.46342, 'eta': 492.25083, 'eta_hours': 0.13674, 'loss': 0.3330198, 'lr': 0.00083864, 'params': 135811, 'time_iter': 0.19377, 'accuracy': 0.89671, 'f1': 0.89748, 'auc': 0.97438}\n",
      "val: {'epoch': 18, 'time_epoch': 0.79742, 'loss': 1.48623213, 'lr': 0, 'params': 135811, 'time_iter': 0.11392, 'accuracy': 0.4717, 'f1': 0.3881, 'auc': 0.65328}\n",
      "test: {'epoch': 18, 'time_epoch': 0.80431, 'loss': 1.57993122, 'lr': 0, 'params': 135811, 'time_iter': 0.1149, 'accuracy': 0.47664, 'f1': 0.37015, 'auc': 0.60001}\n",
      "> Epoch 18: took 12.1s (avg 13.6s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 19, 'time_epoch': 10.50771, 'eta': 477.2479, 'eta_hours': 0.13257, 'loss': 0.31248829, 'lr': 0.00081786, 'params': 135811, 'time_iter': 0.19459, 'accuracy': 0.91197, 'f1': 0.91294, 'auc': 0.97064}\n",
      "val: {'epoch': 19, 'time_epoch': 0.80116, 'loss': 1.28679898, 'lr': 0, 'params': 135811, 'time_iter': 0.11445, 'accuracy': 0.51887, 'f1': 0.48791, 'auc': 0.67632}\n",
      "test: {'epoch': 19, 'time_epoch': 0.80558, 'loss': 1.35527915, 'lr': 0, 'params': 135811, 'time_iter': 0.11508, 'accuracy': 0.51402, 'f1': 0.49162, 'auc': 0.64161}\n",
      "> Epoch 19: took 12.1s (avg 13.6s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 20, 'time_epoch': 11.04401, 'eta': 463.66907, 'eta_hours': 0.1288, 'loss': 0.28984929, 'lr': 0.00079612, 'params': 135811, 'time_iter': 0.20452, 'accuracy': 0.91549, 'f1': 0.91573, 'auc': 0.97721}\n",
      "val: {'epoch': 20, 'time_epoch': 0.79774, 'loss': 1.45377157, 'lr': 0, 'params': 135811, 'time_iter': 0.11396, 'accuracy': 0.41509, 'f1': 0.39581, 'auc': 0.68027}\n",
      "test: {'epoch': 20, 'time_epoch': 0.8111, 'loss': 1.83036086, 'lr': 0, 'params': 135811, 'time_iter': 0.11587, 'accuracy': 0.28972, 'f1': 0.23408, 'auc': 0.54405}\n",
      "> Epoch 20: took 12.7s (avg 13.5s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 21, 'time_epoch': 10.50739, 'eta': 449.39379, 'eta_hours': 0.12483, 'loss': 0.25733025, 'lr': 0.00077347, 'params': 135811, 'time_iter': 0.19458, 'accuracy': 0.93427, 'f1': 0.93216, 'auc': 0.97673}\n",
      "val: {'epoch': 21, 'time_epoch': 0.80741, 'loss': 1.41675053, 'lr': 0, 'params': 135811, 'time_iter': 0.11534, 'accuracy': 0.48113, 'f1': 0.46523, 'auc': 0.65741}\n",
      "test: {'epoch': 21, 'time_epoch': 0.80432, 'loss': 1.60270743, 'lr': 0, 'params': 135811, 'time_iter': 0.1149, 'accuracy': 0.43925, 'f1': 0.3991, 'auc': 0.61046}\n",
      "> Epoch 21: took 12.1s (avg 13.5s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 22, 'time_epoch': 10.8467, 'eta': 435.99199, 'eta_hours': 0.12111, 'loss': 0.29840667, 'lr': 0.00075, 'params': 135811, 'time_iter': 0.20086, 'accuracy': 0.91315, 'f1': 0.90952, 'auc': 0.97309}\n",
      "val: {'epoch': 22, 'time_epoch': 0.78953, 'loss': 1.37388007, 'lr': 0, 'params': 135811, 'time_iter': 0.11279, 'accuracy': 0.45283, 'f1': 0.43781, 'auc': 0.68509}\n",
      "test: {'epoch': 22, 'time_epoch': 0.80491, 'loss': 1.68287707, 'lr': 0, 'params': 135811, 'time_iter': 0.11499, 'accuracy': 0.33645, 'f1': 0.30351, 'auc': 0.60713}\n",
      "> Epoch 22: took 12.5s (avg 13.4s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 23, 'time_epoch': 11.75228, 'eta': 424.1615, 'eta_hours': 0.11782, 'loss': 0.2556326, 'lr': 0.00072577, 'params': 135811, 'time_iter': 0.21763, 'accuracy': 0.93545, 'f1': 0.93359, 'auc': 0.97918}\n",
      "val: {'epoch': 23, 'time_epoch': 0.80793, 'loss': 1.4786391, 'lr': 0, 'params': 135811, 'time_iter': 0.11542, 'accuracy': 0.41509, 'f1': 0.40134, 'auc': 0.67569}\n",
      "test: {'epoch': 23, 'time_epoch': 0.80203, 'loss': 1.74494242, 'lr': 0, 'params': 135811, 'time_iter': 0.11458, 'accuracy': 0.37383, 'f1': 0.35326, 'auc': 0.63335}\n",
      "> Epoch 23: took 13.4s (avg 13.4s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 24, 'time_epoch': 10.33192, 'eta': 410.34875, 'eta_hours': 0.11399, 'loss': 0.24174806, 'lr': 0.00070085, 'params': 135811, 'time_iter': 0.19133, 'accuracy': 0.93662, 'f1': 0.93518, 'auc': 0.97658}\n",
      "val: {'epoch': 24, 'time_epoch': 0.81322, 'loss': 1.72022055, 'lr': 0, 'params': 135811, 'time_iter': 0.11617, 'accuracy': 0.38679, 'f1': 0.39087, 'auc': 0.61948}\n",
      "test: {'epoch': 24, 'time_epoch': 0.81372, 'loss': 1.70452076, 'lr': 0, 'params': 135811, 'time_iter': 0.11625, 'accuracy': 0.40187, 'f1': 0.40266, 'auc': 0.60913}\n",
      "> Epoch 24: took 12.0s (avg 13.4s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 25, 'time_epoch': 10.6092, 'eta': 397.16637, 'eta_hours': 0.11032, 'loss': 0.25792306, 'lr': 0.00067532, 'params': 135811, 'time_iter': 0.19647, 'accuracy': 0.93075, 'f1': 0.93059, 'auc': 0.97738}\n",
      "val: {'epoch': 25, 'time_epoch': 0.82368, 'loss': 1.69912453, 'lr': 0, 'params': 135811, 'time_iter': 0.11767, 'accuracy': 0.4717, 'f1': 0.42277, 'auc': 0.63299}\n",
      "test: {'epoch': 25, 'time_epoch': 0.81016, 'loss': 1.80774555, 'lr': 0, 'params': 135811, 'time_iter': 0.11574, 'accuracy': 0.43925, 'f1': 0.39652, 'auc': 0.62113}\n",
      "> Epoch 25: took 12.3s (avg 13.3s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 26, 'time_epoch': 11.26062, 'eta': 384.97076, 'eta_hours': 0.10694, 'loss': 0.18260329, 'lr': 0.00064926, 'params': 135811, 'time_iter': 0.20853, 'accuracy': 0.95305, 'f1': 0.9492, 'auc': 0.98679}\n",
      "val: {'epoch': 26, 'time_epoch': 0.81274, 'loss': 1.71411677, 'lr': 0, 'params': 135811, 'time_iter': 0.11611, 'accuracy': 0.4434, 'f1': 0.42814, 'auc': 0.61343}\n",
      "test: {'epoch': 26, 'time_epoch': 0.80588, 'loss': 1.60396123, 'lr': 0, 'params': 135811, 'time_iter': 0.11513, 'accuracy': 0.48598, 'f1': 0.46887, 'auc': 0.61805}\n",
      "> Epoch 26: took 12.9s (avg 13.3s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 27, 'time_epoch': 10.904, 'eta': 372.43437, 'eta_hours': 0.10345, 'loss': 0.19749179, 'lr': 0.00062274, 'params': 135811, 'time_iter': 0.20193, 'accuracy': 0.94718, 'f1': 0.94677, 'auc': 0.98412}\n",
      "val: {'epoch': 27, 'time_epoch': 0.84761, 'loss': 1.80608511, 'lr': 0, 'params': 135811, 'time_iter': 0.12109, 'accuracy': 0.42453, 'f1': 0.42461, 'auc': 0.63019}\n",
      "test: {'epoch': 27, 'time_epoch': 0.82074, 'loss': 1.81324382, 'lr': 0, 'params': 135811, 'time_iter': 0.11725, 'accuracy': 0.38318, 'f1': 0.3838, 'auc': 0.58194}\n",
      "> Epoch 27: took 12.6s (avg 13.3s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 28, 'time_epoch': 11.53137, 'eta': 360.6812, 'eta_hours': 0.10019, 'loss': 0.2139327, 'lr': 0.00059586, 'params': 135811, 'time_iter': 0.21354, 'accuracy': 0.94366, 'f1': 0.94564, 'auc': 0.98456}\n",
      "val: {'epoch': 28, 'time_epoch': 0.83203, 'loss': 1.86212504, 'lr': 0, 'params': 135811, 'time_iter': 0.11886, 'accuracy': 0.46226, 'f1': 0.45, 'auc': 0.60113}\n",
      "test: {'epoch': 28, 'time_epoch': 0.81595, 'loss': 1.66792351, 'lr': 0, 'params': 135811, 'time_iter': 0.11656, 'accuracy': 0.49533, 'f1': 0.47143, 'auc': 0.62734}\n",
      "> Epoch 28: took 13.2s (avg 13.3s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 29, 'time_epoch': 10.87441, 'eta': 348.28586, 'eta_hours': 0.09675, 'loss': 0.19535747, 'lr': 0.00056868, 'params': 135811, 'time_iter': 0.20138, 'accuracy': 0.94484, 'f1': 0.94528, 'auc': 0.98466}\n",
      "val: {'epoch': 29, 'time_epoch': 0.81798, 'loss': 1.66342538, 'lr': 0, 'params': 135811, 'time_iter': 0.11685, 'accuracy': 0.48113, 'f1': 0.46461, 'auc': 0.64922}\n",
      "test: {'epoch': 29, 'time_epoch': 0.81233, 'loss': 1.91007513, 'lr': 0, 'params': 135811, 'time_iter': 0.11605, 'accuracy': 0.40187, 'f1': 0.36641, 'auc': 0.58346}\n",
      "> Epoch 29: took 12.5s (avg 13.3s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 30, 'time_epoch': 22.46283, 'eta': 346.82942, 'eta_hours': 0.09634, 'loss': 0.15117889, 'lr': 0.00054129, 'params': 135811, 'time_iter': 0.41598, 'accuracy': 0.96479, 'f1': 0.96525, 'auc': 0.98991}\n",
      "val: {'epoch': 30, 'time_epoch': 0.78777, 'loss': 1.70754092, 'lr': 0, 'params': 135811, 'time_iter': 0.11254, 'accuracy': 0.46226, 'f1': 0.44449, 'auc': 0.6474}\n",
      "test: {'epoch': 30, 'time_epoch': 0.79272, 'loss': 1.78888097, 'lr': 0, 'params': 135811, 'time_iter': 0.11325, 'accuracy': 0.42056, 'f1': 0.40792, 'auc': 0.5954}\n",
      "> Epoch 30: took 24.1s (avg 13.6s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 31, 'time_epoch': 11.05289, 'eta': 334.07639, 'eta_hours': 0.0928, 'loss': 0.18138141, 'lr': 0.00051378, 'params': 135811, 'time_iter': 0.20468, 'accuracy': 0.95188, 'f1': 0.95132, 'auc': 0.9855}\n",
      "val: {'epoch': 31, 'time_epoch': 0.8093, 'loss': 1.82177306, 'lr': 0, 'params': 135811, 'time_iter': 0.11561, 'accuracy': 0.49057, 'f1': 0.4151, 'auc': 0.63291}\n",
      "test: {'epoch': 31, 'time_epoch': 0.80606, 'loss': 1.882555, 'lr': 0, 'params': 135811, 'time_iter': 0.11515, 'accuracy': 0.46729, 'f1': 0.39998, 'auc': 0.58797}\n",
      "> Epoch 31: took 12.7s (avg 13.6s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 32, 'time_epoch': 22.45221, 'eta': 330.75311, 'eta_hours': 0.09188, 'loss': 0.13666131, 'lr': 0.00048622, 'params': 135811, 'time_iter': 0.41578, 'accuracy': 0.97066, 'f1': 0.97145, 'auc': 0.99158}\n",
      "val: {'epoch': 32, 'time_epoch': 0.78609, 'loss': 1.734164, 'lr': 0, 'params': 135811, 'time_iter': 0.1123, 'accuracy': 0.50943, 'f1': 0.50794, 'auc': 0.62946}\n",
      "test: {'epoch': 32, 'time_epoch': 0.80426, 'loss': 1.80008547, 'lr': 0, 'params': 135811, 'time_iter': 0.11489, 'accuracy': 0.48598, 'f1': 0.48094, 'auc': 0.62295}\n",
      "> Epoch 32: took 24.1s (avg 13.9s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 33, 'time_epoch': 11.13566, 'eta': 317.65076, 'eta_hours': 0.08824, 'loss': 0.15064202, 'lr': 0.00045871, 'params': 135811, 'time_iter': 0.20622, 'accuracy': 0.96714, 'f1': 0.96778, 'auc': 0.98932}\n",
      "val: {'epoch': 33, 'time_epoch': 0.79779, 'loss': 1.8272092, 'lr': 0, 'params': 135811, 'time_iter': 0.11397, 'accuracy': 0.45283, 'f1': 0.44885, 'auc': 0.64266}\n",
      "test: {'epoch': 33, 'time_epoch': 0.82516, 'loss': 1.83315167, 'lr': 0, 'params': 135811, 'time_iter': 0.11788, 'accuracy': 0.42991, 'f1': 0.43133, 'auc': 0.60097}\n",
      "> Epoch 33: took 12.8s (avg 13.9s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 34, 'time_epoch': 11.40567, 'eta': 304.85366, 'eta_hours': 0.08468, 'loss': 0.11988688, 'lr': 0.00043132, 'params': 135811, 'time_iter': 0.21122, 'accuracy': 0.97418, 'f1': 0.97329, 'auc': 0.99306}\n",
      "val: {'epoch': 34, 'time_epoch': 0.79668, 'loss': 1.80138008, 'lr': 0, 'params': 135811, 'time_iter': 0.11381, 'accuracy': 0.48113, 'f1': 0.42045, 'auc': 0.63065}\n",
      "test: {'epoch': 34, 'time_epoch': 0.8061, 'loss': 1.79214857, 'lr': 0, 'params': 135811, 'time_iter': 0.11516, 'accuracy': 0.47664, 'f1': 0.41636, 'auc': 0.63341}\n",
      "> Epoch 34: took 13.0s (avg 13.8s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 35, 'time_epoch': 10.89465, 'eta': 291.79319, 'eta_hours': 0.08105, 'loss': 0.12279592, 'lr': 0.00040414, 'params': 135811, 'time_iter': 0.20175, 'accuracy': 0.97535, 'f1': 0.97655, 'auc': 0.99177}\n",
      "val: {'epoch': 35, 'time_epoch': 0.81494, 'loss': 1.82527543, 'lr': 0, 'params': 135811, 'time_iter': 0.11642, 'accuracy': 0.46226, 'f1': 0.44389, 'auc': 0.62963}\n",
      "test: {'epoch': 35, 'time_epoch': 0.81172, 'loss': 1.92654912, 'lr': 0, 'params': 135811, 'time_iter': 0.11596, 'accuracy': 0.42991, 'f1': 0.40826, 'auc': 0.61698}\n",
      "> Epoch 35: took 12.5s (avg 13.8s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 36, 'time_epoch': 11.17352, 'eta': 279.02313, 'eta_hours': 0.07751, 'loss': 0.15020602, 'lr': 0.00037726, 'params': 135811, 'time_iter': 0.20692, 'accuracy': 0.9554, 'f1': 0.95648, 'auc': 0.99217}\n",
      "val: {'epoch': 36, 'time_epoch': 0.86031, 'loss': 1.85544104, 'lr': 0, 'params': 135811, 'time_iter': 0.1229, 'accuracy': 0.4717, 'f1': 0.45588, 'auc': 0.61916}\n",
      "test: {'epoch': 36, 'time_epoch': 0.80809, 'loss': 1.89291543, 'lr': 0, 'params': 135811, 'time_iter': 0.11544, 'accuracy': 0.45794, 'f1': 0.42896, 'auc': 0.61165}\n",
      "> Epoch 36: took 12.9s (avg 13.8s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 37, 'time_epoch': 10.85819, 'eta': 266.15454, 'eta_hours': 0.07393, 'loss': 0.12112934, 'lr': 0.00035074, 'params': 135811, 'time_iter': 0.20108, 'accuracy': 0.973, 'f1': 0.97203, 'auc': 0.99448}\n",
      "val: {'epoch': 37, 'time_epoch': 0.81122, 'loss': 1.95930163, 'lr': 0, 'params': 135811, 'time_iter': 0.11589, 'accuracy': 0.46226, 'f1': 0.37841, 'auc': 0.64021}\n",
      "test: {'epoch': 37, 'time_epoch': 0.81021, 'loss': 1.93273629, 'lr': 0, 'params': 135811, 'time_iter': 0.11574, 'accuracy': 0.46729, 'f1': 0.4035, 'auc': 0.59356}\n",
      "> Epoch 37: took 12.5s (avg 13.7s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 38, 'time_epoch': 21.98978, 'eta': 259.38299, 'eta_hours': 0.07205, 'loss': 0.10892189, 'lr': 0.00032468, 'params': 135811, 'time_iter': 0.40722, 'accuracy': 0.97653, 'f1': 0.97552, 'auc': 0.99541}\n",
      "val: {'epoch': 38, 'time_epoch': 0.803, 'loss': 1.97859074, 'lr': 0, 'params': 135811, 'time_iter': 0.11471, 'accuracy': 0.4717, 'f1': 0.45938, 'auc': 0.61063}\n",
      "test: {'epoch': 38, 'time_epoch': 0.79563, 'loss': 1.84291455, 'lr': 0, 'params': 135811, 'time_iter': 0.11366, 'accuracy': 0.48598, 'f1': 0.47334, 'auc': 0.6314}\n",
      "> Epoch 38: took 23.6s (avg 14.0s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 39, 'time_epoch': 10.19691, 'eta': 245.95409, 'eta_hours': 0.06832, 'loss': 0.1327741, 'lr': 0.00029915, 'params': 135811, 'time_iter': 0.18883, 'accuracy': 0.96831, 'f1': 0.96975, 'auc': 0.99374}\n",
      "val: {'epoch': 39, 'time_epoch': 0.79637, 'loss': 1.97539117, 'lr': 0, 'params': 135811, 'time_iter': 0.11377, 'accuracy': 0.4434, 'f1': 0.41914, 'auc': 0.62319}\n",
      "test: {'epoch': 39, 'time_epoch': 0.80011, 'loss': 1.89411157, 'lr': 0, 'params': 135811, 'time_iter': 0.1143, 'accuracy': 0.4486, 'f1': 0.42029, 'auc': 0.62359}\n",
      "> Epoch 39: took 11.8s (avg 13.9s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 40, 'time_epoch': 10.73139, 'eta': 232.93053, 'eta_hours': 0.0647, 'loss': 0.0962827, 'lr': 0.00027423, 'params': 135811, 'time_iter': 0.19873, 'accuracy': 0.98005, 'f1': 0.98052, 'auc': 0.99544}\n",
      "val: {'epoch': 40, 'time_epoch': 0.78393, 'loss': 2.1136662, 'lr': 0, 'params': 135811, 'time_iter': 0.11199, 'accuracy': 0.43396, 'f1': 0.42598, 'auc': 0.59885}\n",
      "test: {'epoch': 40, 'time_epoch': 0.80844, 'loss': 1.82064995, 'lr': 0, 'params': 135811, 'time_iter': 0.11549, 'accuracy': 0.48598, 'f1': 0.4788, 'auc': 0.6311}\n",
      "> Epoch 40: took 12.3s (avg 13.9s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 41, 'time_epoch': 10.53947, 'eta': 219.93387, 'eta_hours': 0.06109, 'loss': 0.08929184, 'lr': 0.00025, 'params': 135811, 'time_iter': 0.19518, 'accuracy': 0.98357, 'f1': 0.98281, 'auc': 0.99615}\n",
      "val: {'epoch': 41, 'time_epoch': 0.79962, 'loss': 2.01600289, 'lr': 0, 'params': 135811, 'time_iter': 0.11423, 'accuracy': 0.45283, 'f1': 0.39601, 'auc': 0.63649}\n",
      "test: {'epoch': 41, 'time_epoch': 0.80515, 'loss': 1.91517304, 'lr': 0, 'params': 135811, 'time_iter': 0.11502, 'accuracy': 0.48598, 'f1': 0.45495, 'auc': 0.62237}\n",
      "> Epoch 41: took 12.2s (avg 13.9s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 42, 'time_epoch': 11.10273, 'eta': 207.27418, 'eta_hours': 0.05758, 'loss': 0.098425, 'lr': 0.00022653, 'params': 135811, 'time_iter': 0.20561, 'accuracy': 0.98122, 'f1': 0.97938, 'auc': 0.99473}\n",
      "val: {'epoch': 42, 'time_epoch': 0.80711, 'loss': 2.0791493, 'lr': 0, 'params': 135811, 'time_iter': 0.1153, 'accuracy': 0.46226, 'f1': 0.43748, 'auc': 0.61132}\n",
      "test: {'epoch': 42, 'time_epoch': 0.79439, 'loss': 1.87494555, 'lr': 0, 'params': 135811, 'time_iter': 0.11348, 'accuracy': 0.46729, 'f1': 0.44188, 'auc': 0.63692}\n",
      "> Epoch 42: took 12.7s (avg 13.8s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 43, 'time_epoch': 21.86206, 'eta': 198.59775, 'eta_hours': 0.05517, 'loss': 0.08860849, 'lr': 0.00020388, 'params': 135811, 'time_iter': 0.40485, 'accuracy': 0.98474, 'f1': 0.98379, 'auc': 0.99501}\n",
      "val: {'epoch': 43, 'time_epoch': 0.80561, 'loss': 2.14605262, 'lr': 0, 'params': 135811, 'time_iter': 0.11509, 'accuracy': 0.42453, 'f1': 0.42011, 'auc': 0.60384}\n",
      "test: {'epoch': 43, 'time_epoch': 0.79651, 'loss': 1.90438348, 'lr': 0, 'params': 135811, 'time_iter': 0.11379, 'accuracy': 0.42991, 'f1': 0.42743, 'auc': 0.63518}\n",
      "> Epoch 43: took 23.5s (avg 14.1s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 44, 'time_epoch': 10.56635, 'eta': 185.57005, 'eta_hours': 0.05155, 'loss': 0.08557678, 'lr': 0.00018214, 'params': 135811, 'time_iter': 0.19567, 'accuracy': 0.98474, 'f1': 0.98394, 'auc': 0.99547}\n",
      "val: {'epoch': 44, 'time_epoch': 0.82145, 'loss': 2.07339077, 'lr': 0, 'params': 135811, 'time_iter': 0.11735, 'accuracy': 0.43396, 'f1': 0.40368, 'auc': 0.61494}\n",
      "test: {'epoch': 44, 'time_epoch': 0.80697, 'loss': 1.94843309, 'lr': 0, 'params': 135811, 'time_iter': 0.11528, 'accuracy': 0.48598, 'f1': 0.45774, 'auc': 0.62368}\n",
      "> Epoch 44: took 12.2s (avg 14.0s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 45, 'time_epoch': 11.53383, 'eta': 172.94383, 'eta_hours': 0.04804, 'loss': 0.08457885, 'lr': 0.00016136, 'params': 135811, 'time_iter': 0.21359, 'accuracy': 0.98357, 'f1': 0.98242, 'auc': 0.99675}\n",
      "val: {'epoch': 45, 'time_epoch': 0.80078, 'loss': 2.12708779, 'lr': 0, 'params': 135811, 'time_iter': 0.1144, 'accuracy': 0.4434, 'f1': 0.42253, 'auc': 0.61386}\n",
      "test: {'epoch': 45, 'time_epoch': 0.80686, 'loss': 1.88100207, 'lr': 0, 'params': 135811, 'time_iter': 0.11527, 'accuracy': 0.48598, 'f1': 0.46014, 'auc': 0.63595}\n",
      "> Epoch 45: took 13.2s (avg 14.0s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 46, 'time_epoch': 22.45841, 'eta': 163.38577, 'eta_hours': 0.04538, 'loss': 0.06936881, 'lr': 0.00014161, 'params': 135811, 'time_iter': 0.4159, 'accuracy': 0.98826, 'f1': 0.98839, 'auc': 0.99595}\n",
      "val: {'epoch': 46, 'time_epoch': 0.79764, 'loss': 2.07547205, 'lr': 0, 'params': 135811, 'time_iter': 0.11395, 'accuracy': 0.4717, 'f1': 0.43048, 'auc': 0.60655}\n",
      "test: {'epoch': 46, 'time_epoch': 0.79578, 'loss': 1.96694699, 'lr': 0, 'params': 135811, 'time_iter': 0.11368, 'accuracy': 0.49533, 'f1': 0.46553, 'auc': 0.62809}\n",
      "> Epoch 46: took 24.1s (avg 14.2s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 47, 'time_epoch': 10.42512, 'eta': 150.28188, 'eta_hours': 0.04174, 'loss': 0.07484675, 'lr': 0.00012295, 'params': 135811, 'time_iter': 0.19306, 'accuracy': 0.98709, 'f1': 0.9861, 'auc': 0.99639}\n",
      "val: {'epoch': 47, 'time_epoch': 0.79424, 'loss': 2.19006402, 'lr': 0, 'params': 135811, 'time_iter': 0.11346, 'accuracy': 0.4434, 'f1': 0.42823, 'auc': 0.61118}\n",
      "test: {'epoch': 47, 'time_epoch': 0.79218, 'loss': 1.88604022, 'lr': 0, 'params': 135811, 'time_iter': 0.11317, 'accuracy': 0.4486, 'f1': 0.43633, 'auc': 0.63707}\n",
      "> Epoch 47: took 12.0s (avg 14.2s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 48, 'time_epoch': 10.40373, 'eta': 137.28253, 'eta_hours': 0.03813, 'loss': 0.08019666, 'lr': 0.00010543, 'params': 135811, 'time_iter': 0.19266, 'accuracy': 0.98592, 'f1': 0.98684, 'auc': 0.99623}\n",
      "val: {'epoch': 48, 'time_epoch': 0.79131, 'loss': 2.24762064, 'lr': 0, 'params': 135811, 'time_iter': 0.11304, 'accuracy': 0.40566, 'f1': 0.38366, 'auc': 0.58906}\n",
      "test: {'epoch': 48, 'time_epoch': 0.78856, 'loss': 2.02937416, 'lr': 0, 'params': 135811, 'time_iter': 0.11265, 'accuracy': 0.48598, 'f1': 0.46249, 'auc': 0.61224}\n",
      "> Epoch 48: took 12.0s (avg 14.1s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 49, 'time_epoch': 10.78307, 'eta': 124.46287, 'eta_hours': 0.03457, 'loss': 0.07302429, 'lr': 8.911e-05, 'params': 135811, 'time_iter': 0.19969, 'accuracy': 0.98826, 'f1': 0.98797, 'auc': 0.99772}\n",
      "val: {'epoch': 49, 'time_epoch': 0.79111, 'loss': 2.14650478, 'lr': 0, 'params': 135811, 'time_iter': 0.11302, 'accuracy': 0.45283, 'f1': 0.43, 'auc': 0.60887}\n",
      "test: {'epoch': 49, 'time_epoch': 0.80145, 'loss': 1.9258632, 'lr': 0, 'params': 135811, 'time_iter': 0.11449, 'accuracy': 0.48598, 'f1': 0.46496, 'auc': 0.64637}\n",
      "> Epoch 49: took 12.4s (avg 14.1s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 50, 'time_epoch': 10.466, 'eta': 111.66712, 'eta_hours': 0.03102, 'loss': 0.07147537, 'lr': 7.404e-05, 'params': 135811, 'time_iter': 0.19381, 'accuracy': 0.98944, 'f1': 0.9879, 'auc': 0.99661}\n",
      "val: {'epoch': 50, 'time_epoch': 0.81394, 'loss': 2.17481434, 'lr': 0, 'params': 135811, 'time_iter': 0.11628, 'accuracy': 0.42453, 'f1': 0.41269, 'auc': 0.61043}\n",
      "test: {'epoch': 50, 'time_epoch': 0.82745, 'loss': 1.91448515, 'lr': 0, 'params': 135811, 'time_iter': 0.11821, 'accuracy': 0.47664, 'f1': 0.46589, 'auc': 0.63852}\n",
      "> Epoch 50: took 12.1s (avg 14.0s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 51, 'time_epoch': 10.80248, 'eta': 99.01274, 'eta_hours': 0.0275, 'loss': 0.07419321, 'lr': 6.026e-05, 'params': 135811, 'time_iter': 0.20005, 'accuracy': 0.98826, 'f1': 0.98838, 'auc': 0.99555}\n",
      "val: {'epoch': 51, 'time_epoch': 0.79571, 'loss': 2.16190313, 'lr': 0, 'params': 135811, 'time_iter': 0.11367, 'accuracy': 0.4434, 'f1': 0.42253, 'auc': 0.6057}\n",
      "test: {'epoch': 51, 'time_epoch': 0.8071, 'loss': 1.93083853, 'lr': 0, 'params': 135811, 'time_iter': 0.1153, 'accuracy': 0.46729, 'f1': 0.45025, 'auc': 0.63034}\n",
      "> Epoch 51: took 12.4s (avg 14.0s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 52, 'time_epoch': 22.41409, 'eta': 87.96185, 'eta_hours': 0.02443, 'loss': 0.08245938, 'lr': 4.782e-05, 'params': 135811, 'time_iter': 0.41508, 'accuracy': 0.98592, 'f1': 0.98523, 'auc': 0.99472}\n",
      "val: {'epoch': 52, 'time_epoch': 0.81092, 'loss': 2.17032947, 'lr': 0, 'params': 135811, 'time_iter': 0.11585, 'accuracy': 0.4434, 'f1': 0.41669, 'auc': 0.59869}\n",
      "test: {'epoch': 52, 'time_epoch': 0.8042, 'loss': 1.98819725, 'lr': 0, 'params': 135811, 'time_iter': 0.11489, 'accuracy': 0.49533, 'f1': 0.46553, 'auc': 0.62544}\n",
      "> Epoch 52: took 24.1s (avg 14.2s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 53, 'time_epoch': 11.11797, 'eta': 75.23498, 'eta_hours': 0.0209, 'loss': 0.07403922, 'lr': 3.675e-05, 'params': 135811, 'time_iter': 0.20589, 'accuracy': 0.98709, 'f1': 0.98499, 'auc': 0.99732}\n",
      "val: {'epoch': 53, 'time_epoch': 0.82192, 'loss': 2.13579204, 'lr': 0, 'params': 135811, 'time_iter': 0.11742, 'accuracy': 0.45283, 'f1': 0.4352, 'auc': 0.60611}\n",
      "test: {'epoch': 53, 'time_epoch': 0.80202, 'loss': 1.96545921, 'lr': 0, 'params': 135811, 'time_iter': 0.11457, 'accuracy': 0.47664, 'f1': 0.4551, 'auc': 0.62814}\n",
      "> Epoch 53: took 12.8s (avg 14.2s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 54, 'time_epoch': 21.88213, 'eta': 63.54518, 'eta_hours': 0.01765, 'loss': 0.08432276, 'lr': 2.709e-05, 'params': 135811, 'time_iter': 0.40522, 'accuracy': 0.98357, 'f1': 0.98325, 'auc': 0.99731}\n",
      "val: {'epoch': 54, 'time_epoch': 0.83829, 'loss': 2.17312327, 'lr': 0, 'params': 135811, 'time_iter': 0.11976, 'accuracy': 0.43396, 'f1': 0.42116, 'auc': 0.60776}\n",
      "test: {'epoch': 54, 'time_epoch': 0.81756, 'loss': 1.90161592, 'lr': 0, 'params': 135811, 'time_iter': 0.11679, 'accuracy': 0.46729, 'f1': 0.45586, 'auc': 0.62833}\n",
      "> Epoch 54: took 23.6s (avg 14.3s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 55, 'time_epoch': 10.61838, 'eta': 50.68681, 'eta_hours': 0.01408, 'loss': 0.06383673, 'lr': 1.887e-05, 'params': 135811, 'time_iter': 0.19664, 'accuracy': 0.99061, 'f1': 0.99069, 'auc': 0.99714}\n",
      "val: {'epoch': 55, 'time_epoch': 0.80669, 'loss': 2.14195527, 'lr': 0, 'params': 135811, 'time_iter': 0.11524, 'accuracy': 0.43396, 'f1': 0.40989, 'auc': 0.60722}\n",
      "test: {'epoch': 55, 'time_epoch': 0.81724, 'loss': 1.97828868, 'lr': 0, 'params': 135811, 'time_iter': 0.11675, 'accuracy': 0.50467, 'f1': 0.47949, 'auc': 0.62154}\n",
      "> Epoch 55: took 12.3s (avg 14.3s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 56, 'time_epoch': 10.92679, 'eta': 37.92327, 'eta_hours': 0.01053, 'loss': 0.08719886, 'lr': 1.21e-05, 'params': 135811, 'time_iter': 0.20235, 'accuracy': 0.98357, 'f1': 0.98185, 'auc': 0.99506}\n",
      "val: {'epoch': 56, 'time_epoch': 0.82335, 'loss': 2.12814316, 'lr': 0, 'params': 135811, 'time_iter': 0.11762, 'accuracy': 0.4434, 'f1': 0.41724, 'auc': 0.60929}\n",
      "test: {'epoch': 56, 'time_epoch': 0.80924, 'loss': 1.99154589, 'lr': 0, 'params': 135811, 'time_iter': 0.11561, 'accuracy': 0.48598, 'f1': 0.45781, 'auc': 0.62338}\n",
      "> Epoch 56: took 12.6s (avg 14.3s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 57, 'time_epoch': 10.59017, 'eta': 25.21146, 'eta_hours': 0.007, 'loss': 0.07033417, 'lr': 6.82e-06, 'params': 135811, 'time_iter': 0.19611, 'accuracy': 0.99061, 'f1': 0.99079, 'auc': 0.99654}\n",
      "val: {'epoch': 57, 'time_epoch': 0.82134, 'loss': 2.1643359, 'lr': 0, 'params': 135811, 'time_iter': 0.11733, 'accuracy': 0.4434, 'f1': 0.42823, 'auc': 0.60772}\n",
      "test: {'epoch': 57, 'time_epoch': 0.81033, 'loss': 1.94919448, 'lr': 0, 'params': 135811, 'time_iter': 0.11576, 'accuracy': 0.48598, 'f1': 0.4705, 'auc': 0.63397}\n",
      "> Epoch 57: took 12.2s (avg 14.2s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 58, 'time_epoch': 10.95755, 'eta': 12.57779, 'eta_hours': 0.00349, 'loss': 0.07013791, 'lr': 3.03e-06, 'params': 135811, 'time_iter': 0.20292, 'accuracy': 0.98944, 'f1': 0.98938, 'auc': 0.99787}\n",
      "val: {'epoch': 58, 'time_epoch': 0.81023, 'loss': 2.17547094, 'lr': 0, 'params': 135811, 'time_iter': 0.11575, 'accuracy': 0.42453, 'f1': 0.41194, 'auc': 0.60689}\n",
      "test: {'epoch': 58, 'time_epoch': 0.80686, 'loss': 1.92188123, 'lr': 0, 'params': 135811, 'time_iter': 0.11527, 'accuracy': 0.49533, 'f1': 0.48171, 'auc': 0.61905}\n",
      "> Epoch 58: took 12.6s (avg 14.2s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "train: {'epoch': 59, 'time_epoch': 10.33902, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.06394249, 'lr': 7.6e-07, 'params': 135811, 'time_iter': 0.19146, 'accuracy': 0.99061, 'f1': 0.99017, 'auc': 0.99783}\n",
      "val: {'epoch': 59, 'time_epoch': 0.80873, 'loss': 2.15544044, 'lr': 0, 'params': 135811, 'time_iter': 0.11553, 'accuracy': 0.45283, 'f1': 0.4352, 'auc': 0.60699}\n",
      "test: {'epoch': 59, 'time_epoch': 0.80245, 'loss': 1.96638523, 'lr': 0, 'params': 135811, 'time_iter': 0.11464, 'accuracy': 0.45794, 'f1': 0.43578, 'auc': 0.62557}\n",
      "> Epoch 59: took 12.0s (avg 14.2s) | Best so far: epoch 10\ttrain_loss: 0.5972 train_accuracy: 0.8028\tval_loss: 1.0729 val_accuracy: 0.5189\ttest_loss: 1.2180 test_accuracy: 0.4392\n",
      "Avg time per epoch: 14.18s\n",
      "Total train loop time: 0.24h\n",
      "Task done, results saved in results\\neural-Age\\0\n",
      "10\n",
      "{'epoch': 10, 'time_epoch': 0.82311, 'loss': 1.21802376, 'lr': 0, 'params': 135811, 'time_iter': 0.11759, 'accuracy': 0.43925, 'f1': 0.35742, 'auc': 0.61969}\n",
      "{'epoch': 10, 'time_epoch': 22.34847, 'eta': 582.01009, 'eta_hours': 0.16167, 'loss': 0.59718015, 'lr': 0.00096325, 'params': 135811, 'time_iter': 0.41386, 'accuracy': 0.80282, 'f1': 0.80213, 'auc': 0.91104}\n",
      "{'epoch': 10, 'time_epoch': 0.82153, 'loss': 1.07294174, 'lr': 0, 'params': 135811, 'time_iter': 0.11736, 'accuracy': 0.51887, 'f1': 0.4422, 'auc': 0.67804}\n",
      "Results aggregated across runs saved in results\\neural-Age\\agg\n",
      "[*] All done: 2024-03-01 22:06:33.863424\n"
     ]
    }
   ],
   "source": [
    "#Age using Exphormer 2 layers 0.3 dropout and 0.1 att dropout\n",
    "%run main.py --cfg configs/Exphormer/neural-Age.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b72fe8-b884-4ea4-8c0b-709658176ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-01 22:08:38.657002\n",
      "[*] Loaded dataset 'HCPAge' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1065000, 1000], edge_index=[2, 48551656], y=[1065])\n",
      "  undirected: True\n",
      "  num graphs: 1065\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 3\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [01:53<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:54.44\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [01:21<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:23.98\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 3, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPAge\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.3\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 2\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 80\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 3\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Age\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Age\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 3\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 135811\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 11.92204, 'eta': 941.84133, 'eta_hours': 0.26162, 'loss': 1.10820434, 'lr': 0.0, 'params': 135811, 'time_iter': 0.22078, 'accuracy': 0.35446, 'f1': 0.18276, 'auc': 0.51433}\n",
      "...computing epoch stats took: 0.07s\n",
      "val: {'epoch': 0, 'time_epoch': 0.8044, 'loss': 1.12433029, 'lr': 0, 'params': 135811, 'time_iter': 0.11491, 'accuracy': 0.25472, 'f1': 0.13534, 'auc': 0.51585}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 0, 'time_epoch': 0.83174, 'loss': 1.11294811, 'lr': 0, 'params': 135811, 'time_iter': 0.11882, 'accuracy': 0.31776, 'f1': 0.16307, 'auc': 0.49186}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 0: took 13.6s (avg 13.6s) | Best so far: epoch 0\ttrain_loss: 1.1082 train_accuracy: 0.3545\tval_loss: 1.1243 val_accuracy: 0.2547\ttest_loss: 1.1129 test_accuracy: 0.3178\n",
      "train: {'epoch': 1, 'time_epoch': 10.4912, 'eta': 874.1163, 'eta_hours': 0.24281, 'loss': 1.08021156, 'lr': 0.00033333, 'params': 135811, 'time_iter': 0.19428, 'accuracy': 0.37207, 'f1': 0.2392, 'auc': 0.54902}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 1, 'time_epoch': 0.80239, 'loss': 1.08620044, 'lr': 0, 'params': 135811, 'time_iter': 0.11463, 'accuracy': 0.26415, 'f1': 0.1393, 'auc': 0.58783}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 0.79539, 'loss': 1.09657471, 'lr': 0, 'params': 135811, 'time_iter': 0.11363, 'accuracy': 0.31776, 'f1': 0.1736, 'auc': 0.51401}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 12.1s (avg 12.9s) | Best so far: epoch 1\ttrain_loss: 1.0802 train_accuracy: 0.3721\tval_loss: 1.0862 val_accuracy: 0.2641\ttest_loss: 1.0966 test_accuracy: 0.3178\n",
      "train: {'epoch': 2, 'time_epoch': 10.82856, 'eta': 853.20613, 'eta_hours': 0.237, 'loss': 1.04314808, 'lr': 0.00066667, 'params': 135811, 'time_iter': 0.20053, 'accuracy': 0.48592, 'f1': 0.40292, 'auc': 0.6116}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 0.80645, 'loss': 1.04825298, 'lr': 0, 'params': 135811, 'time_iter': 0.11521, 'accuracy': 0.45283, 'f1': 0.45476, 'auc': 0.61891}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 0.80061, 'loss': 1.08341984, 'lr': 0, 'params': 135811, 'time_iter': 0.11437, 'accuracy': 0.40187, 'f1': 0.39611, 'auc': 0.55555}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 12.5s (avg 12.7s) | Best so far: epoch 2\ttrain_loss: 1.0431 train_accuracy: 0.4859\tval_loss: 1.0483 val_accuracy: 0.4528\ttest_loss: 1.0834 test_accuracy: 0.4019\n",
      "train: {'epoch': 3, 'time_epoch': 11.10696, 'eta': 842.62641, 'eta_hours': 0.23406, 'loss': 0.99954824, 'lr': 0.001, 'params': 135811, 'time_iter': 0.20568, 'accuracy': 0.52113, 'f1': 0.47737, 'auc': 0.69221}\n",
      "val: {'epoch': 3, 'time_epoch': 0.81035, 'loss': 1.03065849, 'lr': 0, 'params': 135811, 'time_iter': 0.11576, 'accuracy': 0.4717, 'f1': 0.45614, 'auc': 0.66861}\n",
      "test: {'epoch': 3, 'time_epoch': 0.80546, 'loss': 1.080007, 'lr': 0, 'params': 135811, 'time_iter': 0.11507, 'accuracy': 0.35514, 'f1': 0.31533, 'auc': 0.59726}\n",
      "> Epoch 3: took 12.8s (avg 12.7s) | Best so far: epoch 3\ttrain_loss: 0.9995 train_accuracy: 0.5211\tval_loss: 1.0307 val_accuracy: 0.4717\ttest_loss: 1.0800 test_accuracy: 0.3551\n",
      "train: {'epoch': 4, 'time_epoch': 10.76829, 'eta': 826.75574, 'eta_hours': 0.22965, 'loss': 0.94008156, 'lr': 0.00099958, 'params': 135811, 'time_iter': 0.19941, 'accuracy': 0.58333, 'f1': 0.56629, 'auc': 0.75119}\n",
      "val: {'epoch': 4, 'time_epoch': 0.79904, 'loss': 1.125393, 'lr': 0, 'params': 135811, 'time_iter': 0.11415, 'accuracy': 0.29245, 'f1': 0.18772, 'auc': 0.66399}\n",
      "test: {'epoch': 4, 'time_epoch': 0.79751, 'loss': 1.1281752, 'lr': 0, 'params': 135811, 'time_iter': 0.11393, 'accuracy': 0.37383, 'f1': 0.26023, 'auc': 0.59747}\n",
      "> Epoch 4: took 12.4s (avg 12.7s) | Best so far: epoch 3\ttrain_loss: 0.9995 train_accuracy: 0.5211\tval_loss: 1.0307 val_accuracy: 0.4717\ttest_loss: 1.0800 test_accuracy: 0.3551\n",
      "train: {'epoch': 5, 'time_epoch': 10.19432, 'eta': 805.50688, 'eta_hours': 0.22375, 'loss': 0.82960277, 'lr': 0.00099834, 'params': 135811, 'time_iter': 0.18878, 'accuracy': 0.69601, 'f1': 0.69177, 'auc': 0.8348}\n",
      "val: {'epoch': 5, 'time_epoch': 0.80293, 'loss': 1.26819422, 'lr': 0, 'params': 135811, 'time_iter': 0.1147, 'accuracy': 0.30189, 'f1': 0.19121, 'auc': 0.60836}\n",
      "test: {'epoch': 5, 'time_epoch': 0.79414, 'loss': 1.23943028, 'lr': 0, 'params': 135811, 'time_iter': 0.11345, 'accuracy': 0.33645, 'f1': 0.19262, 'auc': 0.56115}\n",
      "> Epoch 5: took 11.8s (avg 12.5s) | Best so far: epoch 3\ttrain_loss: 0.9995 train_accuracy: 0.5211\tval_loss: 1.0307 val_accuracy: 0.4717\ttest_loss: 1.0800 test_accuracy: 0.3551\n",
      "train: {'epoch': 6, 'time_epoch': 10.48242, 'eta': 790.42097, 'eta_hours': 0.21956, 'loss': 0.75431699, 'lr': 0.00099626, 'params': 135811, 'time_iter': 0.19412, 'accuracy': 0.73357, 'f1': 0.73098, 'auc': 0.86799}\n",
      "val: {'epoch': 6, 'time_epoch': 0.79856, 'loss': 1.0209747, 'lr': 0, 'params': 135811, 'time_iter': 0.11408, 'accuracy': 0.50943, 'f1': 0.4838, 'auc': 0.6608}\n",
      "test: {'epoch': 6, 'time_epoch': 0.80437, 'loss': 1.12581249, 'lr': 0, 'params': 135811, 'time_iter': 0.11491, 'accuracy': 0.38318, 'f1': 0.31332, 'auc': 0.61015}\n",
      "> Epoch 6: took 12.1s (avg 12.5s) | Best so far: epoch 6\ttrain_loss: 0.7543 train_accuracy: 0.7336\tval_loss: 1.0210 val_accuracy: 0.5094\ttest_loss: 1.1258 test_accuracy: 0.3832\n",
      "train: {'epoch': 7, 'time_epoch': 10.16197, 'eta': 773.60185, 'eta_hours': 0.21489, 'loss': 0.70227002, 'lr': 0.00099336, 'params': 135811, 'time_iter': 0.18818, 'accuracy': 0.76878, 'f1': 0.76664, 'auc': 0.88464}\n",
      "val: {'epoch': 7, 'time_epoch': 0.79383, 'loss': 1.11526508, 'lr': 0, 'params': 135811, 'time_iter': 0.1134, 'accuracy': 0.4717, 'f1': 0.35556, 'auc': 0.64928}\n",
      "test: {'epoch': 7, 'time_epoch': 0.7962, 'loss': 1.19101006, 'lr': 0, 'params': 135811, 'time_iter': 0.11374, 'accuracy': 0.42991, 'f1': 0.28783, 'auc': 0.59073}\n",
      "> Epoch 7: took 11.8s (avg 12.4s) | Best so far: epoch 6\ttrain_loss: 0.7543 train_accuracy: 0.7336\tval_loss: 1.0210 val_accuracy: 0.5094\ttest_loss: 1.1258 test_accuracy: 0.3832\n",
      "train: {'epoch': 8, 'time_epoch': 10.48305, 'eta': 760.79503, 'eta_hours': 0.21133, 'loss': 0.67253292, 'lr': 0.00098963, 'params': 135811, 'time_iter': 0.19413, 'accuracy': 0.76526, 'f1': 0.7592, 'auc': 0.89198}\n",
      "val: {'epoch': 8, 'time_epoch': 0.79359, 'loss': 0.9760015, 'lr': 0, 'params': 135811, 'time_iter': 0.11337, 'accuracy': 0.53774, 'f1': 0.47292, 'auc': 0.69349}\n",
      "test: {'epoch': 8, 'time_epoch': 0.80422, 'loss': 1.13413043, 'lr': 0, 'params': 135811, 'time_iter': 0.11489, 'accuracy': 0.43925, 'f1': 0.34856, 'auc': 0.65442}\n",
      "> Epoch 8: took 12.1s (avg 12.4s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 9, 'time_epoch': 11.9482, 'eta': 758.70907, 'eta_hours': 0.21075, 'loss': 0.61589254, 'lr': 0.00098509, 'params': 135811, 'time_iter': 0.22126, 'accuracy': 0.79577, 'f1': 0.79601, 'auc': 0.9086}\n",
      "val: {'epoch': 9, 'time_epoch': 0.81243, 'loss': 1.14577918, 'lr': 0, 'params': 135811, 'time_iter': 0.11606, 'accuracy': 0.5, 'f1': 0.29253, 'auc': 0.66104}\n",
      "test: {'epoch': 9, 'time_epoch': 0.79594, 'loss': 1.31261244, 'lr': 0, 'params': 135811, 'time_iter': 0.11371, 'accuracy': 0.42056, 'f1': 0.2301, 'auc': 0.57428}\n",
      "> Epoch 9: took 13.6s (avg 12.5s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 10, 'time_epoch': 22.37039, 'eta': 820.20548, 'eta_hours': 0.22783, 'loss': 0.60035227, 'lr': 0.00097975, 'params': 135811, 'time_iter': 0.41427, 'accuracy': 0.80399, 'f1': 0.80162, 'auc': 0.90537}\n",
      "val: {'epoch': 10, 'time_epoch': 0.81402, 'loss': 1.15388342, 'lr': 0, 'params': 135811, 'time_iter': 0.11629, 'accuracy': 0.50943, 'f1': 0.33128, 'auc': 0.67673}\n",
      "test: {'epoch': 10, 'time_epoch': 0.81434, 'loss': 1.35387052, 'lr': 0, 'params': 135811, 'time_iter': 0.11633, 'accuracy': 0.41121, 'f1': 0.23992, 'auc': 0.60893}\n",
      "> Epoch 10: took 24.0s (avg 13.5s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 11, 'time_epoch': 11.38056, 'eta': 805.44842, 'eta_hours': 0.22374, 'loss': 0.53533872, 'lr': 0.0009736, 'params': 135811, 'time_iter': 0.21075, 'accuracy': 0.84038, 'f1': 0.83443, 'auc': 0.93215}\n",
      "val: {'epoch': 11, 'time_epoch': 0.79896, 'loss': 1.18435447, 'lr': 0, 'params': 135811, 'time_iter': 0.11414, 'accuracy': 0.38679, 'f1': 0.37324, 'auc': 0.65531}\n",
      "test: {'epoch': 11, 'time_epoch': 0.80592, 'loss': 1.29633856, 'lr': 0, 'params': 135811, 'time_iter': 0.11513, 'accuracy': 0.3271, 'f1': 0.29208, 'auc': 0.63048}\n",
      "> Epoch 11: took 13.0s (avg 13.5s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 12, 'time_epoch': 10.53491, 'eta': 786.85246, 'eta_hours': 0.21857, 'loss': 0.50351654, 'lr': 0.00096667, 'params': 135811, 'time_iter': 0.19509, 'accuracy': 0.85211, 'f1': 0.85529, 'auc': 0.93059}\n",
      "val: {'epoch': 12, 'time_epoch': 0.80972, 'loss': 1.12549017, 'lr': 0, 'params': 135811, 'time_iter': 0.11567, 'accuracy': 0.5283, 'f1': 0.47795, 'auc': 0.68589}\n",
      "test: {'epoch': 12, 'time_epoch': 0.80526, 'loss': 1.31709669, 'lr': 0, 'params': 135811, 'time_iter': 0.11504, 'accuracy': 0.45794, 'f1': 0.34557, 'auc': 0.64324}\n",
      "> Epoch 12: took 12.2s (avg 13.4s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 13, 'time_epoch': 21.92787, 'eta': 823.11777, 'eta_hours': 0.22864, 'loss': 0.48019992, 'lr': 0.00095896, 'params': 135811, 'time_iter': 0.40607, 'accuracy': 0.84038, 'f1': 0.83641, 'auc': 0.94301}\n",
      "val: {'epoch': 13, 'time_epoch': 0.83179, 'loss': 1.18006104, 'lr': 0, 'params': 135811, 'time_iter': 0.11883, 'accuracy': 0.43396, 'f1': 0.43257, 'auc': 0.67527}\n",
      "test: {'epoch': 13, 'time_epoch': 0.80753, 'loss': 1.38661623, 'lr': 0, 'params': 135811, 'time_iter': 0.11536, 'accuracy': 0.33645, 'f1': 0.31698, 'auc': 0.60209}\n",
      "> Epoch 13: took 23.6s (avg 14.1s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 14, 'time_epoch': 11.10699, 'eta': 804.73348, 'eta_hours': 0.22354, 'loss': 0.45647206, 'lr': 0.00095048, 'params': 135811, 'time_iter': 0.20568, 'accuracy': 0.85563, 'f1': 0.8536, 'auc': 0.94432}\n",
      "val: {'epoch': 14, 'time_epoch': 0.82168, 'loss': 1.33201176, 'lr': 0, 'params': 135811, 'time_iter': 0.11738, 'accuracy': 0.4717, 'f1': 0.3668, 'auc': 0.63576}\n",
      "test: {'epoch': 14, 'time_epoch': 0.82163, 'loss': 1.43575535, 'lr': 0, 'params': 135811, 'time_iter': 0.11738, 'accuracy': 0.47664, 'f1': 0.37292, 'auc': 0.58498}\n",
      "> Epoch 14: took 12.8s (avg 14.0s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 15, 'time_epoch': 10.85817, 'eta': 786.26357, 'eta_hours': 0.21841, 'loss': 0.43873645, 'lr': 0.00094126, 'params': 135811, 'time_iter': 0.20108, 'accuracy': 0.86385, 'f1': 0.86204, 'auc': 0.94639}\n",
      "val: {'epoch': 15, 'time_epoch': 0.80033, 'loss': 1.35093697, 'lr': 0, 'params': 135811, 'time_iter': 0.11433, 'accuracy': 0.39623, 'f1': 0.36379, 'auc': 0.64057}\n",
      "test: {'epoch': 15, 'time_epoch': 0.80386, 'loss': 1.53310984, 'lr': 0, 'params': 135811, 'time_iter': 0.11484, 'accuracy': 0.3271, 'f1': 0.27647, 'auc': 0.58183}\n",
      "> Epoch 15: took 12.5s (avg 13.9s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 16, 'time_epoch': 10.91017, 'eta': 768.88189, 'eta_hours': 0.21358, 'loss': 0.43635073, 'lr': 0.0009313, 'params': 135811, 'time_iter': 0.20204, 'accuracy': 0.86502, 'f1': 0.85978, 'auc': 0.94644}\n",
      "val: {'epoch': 16, 'time_epoch': 0.80578, 'loss': 1.39520918, 'lr': 0, 'params': 135811, 'time_iter': 0.11511, 'accuracy': 0.46226, 'f1': 0.3384, 'auc': 0.65847}\n",
      "test: {'epoch': 16, 'time_epoch': 0.83094, 'loss': 1.48957281, 'lr': 0, 'params': 135811, 'time_iter': 0.11871, 'accuracy': 0.43925, 'f1': 0.31727, 'auc': 0.63092}\n",
      "> Epoch 16: took 12.6s (avg 13.8s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 17, 'time_epoch': 10.72321, 'eta': 751.5753, 'eta_hours': 0.20877, 'loss': 0.37145107, 'lr': 0.00092063, 'params': 135811, 'time_iter': 0.19858, 'accuracy': 0.89085, 'f1': 0.88935, 'auc': 0.96159}\n",
      "val: {'epoch': 17, 'time_epoch': 0.80287, 'loss': 1.21771727, 'lr': 0, 'params': 135811, 'time_iter': 0.1147, 'accuracy': 0.51887, 'f1': 0.43532, 'auc': 0.66912}\n",
      "test: {'epoch': 17, 'time_epoch': 0.8065, 'loss': 1.44452732, 'lr': 0, 'params': 135811, 'time_iter': 0.11521, 'accuracy': 0.43925, 'f1': 0.33714, 'auc': 0.5818}\n",
      "> Epoch 17: took 12.4s (avg 13.8s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 18, 'time_epoch': 10.60158, 'eta': 734.5712, 'eta_hours': 0.20405, 'loss': 0.37564767, 'lr': 0.00090925, 'params': 135811, 'time_iter': 0.19633, 'accuracy': 0.88028, 'f1': 0.87641, 'auc': 0.96338}\n",
      "val: {'epoch': 18, 'time_epoch': 0.80531, 'loss': 1.34132042, 'lr': 0, 'params': 135811, 'time_iter': 0.11504, 'accuracy': 0.46226, 'f1': 0.46327, 'auc': 0.65052}\n",
      "test: {'epoch': 18, 'time_epoch': 0.81629, 'loss': 1.47633513, 'lr': 0, 'params': 135811, 'time_iter': 0.11661, 'accuracy': 0.38318, 'f1': 0.38399, 'auc': 0.60288}\n",
      "> Epoch 18: took 12.3s (avg 13.7s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 19, 'time_epoch': 10.61058, 'eta': 718.23435, 'eta_hours': 0.19951, 'loss': 0.35026904, 'lr': 0.00089719, 'params': 135811, 'time_iter': 0.19649, 'accuracy': 0.89085, 'f1': 0.89101, 'auc': 0.96692}\n",
      "val: {'epoch': 19, 'time_epoch': 0.80631, 'loss': 1.36913362, 'lr': 0, 'params': 135811, 'time_iter': 0.11519, 'accuracy': 0.46226, 'f1': 0.45457, 'auc': 0.64279}\n",
      "test: {'epoch': 19, 'time_epoch': 0.80813, 'loss': 1.40262474, 'lr': 0, 'params': 135811, 'time_iter': 0.11545, 'accuracy': 0.4486, 'f1': 0.43197, 'auc': 0.62446}\n",
      "> Epoch 19: took 12.2s (avg 13.6s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 20, 'time_epoch': 11.14526, 'eta': 703.94504, 'eta_hours': 0.19554, 'loss': 0.32401871, 'lr': 0.00088448, 'params': 135811, 'time_iter': 0.20639, 'accuracy': 0.91197, 'f1': 0.91232, 'auc': 0.96602}\n",
      "val: {'epoch': 20, 'time_epoch': 0.81187, 'loss': 1.59722561, 'lr': 0, 'params': 135811, 'time_iter': 0.11598, 'accuracy': 0.38679, 'f1': 0.38855, 'auc': 0.61752}\n",
      "test: {'epoch': 20, 'time_epoch': 0.80712, 'loss': 1.51393938, 'lr': 0, 'params': 135811, 'time_iter': 0.1153, 'accuracy': 0.4486, 'f1': 0.44758, 'auc': 0.58446}\n",
      "> Epoch 20: took 12.8s (avg 13.6s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 21, 'time_epoch': 10.66652, 'eta': 688.67941, 'eta_hours': 0.1913, 'loss': 0.29864275, 'lr': 0.00087112, 'params': 135811, 'time_iter': 0.19753, 'accuracy': 0.90962, 'f1': 0.90537, 'auc': 0.96858}\n",
      "val: {'epoch': 21, 'time_epoch': 0.81081, 'loss': 1.83246976, 'lr': 0, 'params': 135811, 'time_iter': 0.11583, 'accuracy': 0.33019, 'f1': 0.28917, 'auc': 0.61986}\n",
      "test: {'epoch': 21, 'time_epoch': 0.82153, 'loss': 1.69216195, 'lr': 0, 'params': 135811, 'time_iter': 0.11736, 'accuracy': 0.37383, 'f1': 0.31258, 'auc': 0.54637}\n",
      "> Epoch 21: took 12.3s (avg 13.5s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 22, 'time_epoch': 10.90655, 'eta': 674.40857, 'eta_hours': 0.18734, 'loss': 0.28559433, 'lr': 0.00085714, 'params': 135811, 'time_iter': 0.20197, 'accuracy': 0.91901, 'f1': 0.91856, 'auc': 0.97516}\n",
      "val: {'epoch': 22, 'time_epoch': 0.80432, 'loss': 1.7933271, 'lr': 0, 'params': 135811, 'time_iter': 0.1149, 'accuracy': 0.39623, 'f1': 0.33728, 'auc': 0.62109}\n",
      "test: {'epoch': 22, 'time_epoch': 0.80858, 'loss': 1.78541038, 'lr': 0, 'params': 135811, 'time_iter': 0.11551, 'accuracy': 0.42056, 'f1': 0.36845, 'auc': 0.57719}\n",
      "> Epoch 22: took 12.5s (avg 13.5s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 23, 'time_epoch': 11.79769, 'eta': 662.49741, 'eta_hours': 0.18403, 'loss': 0.27379356, 'lr': 0.00084257, 'params': 135811, 'time_iter': 0.21848, 'accuracy': 0.92019, 'f1': 0.9141, 'auc': 0.97621}\n",
      "val: {'epoch': 23, 'time_epoch': 0.81827, 'loss': 1.91526712, 'lr': 0, 'params': 135811, 'time_iter': 0.1169, 'accuracy': 0.40566, 'f1': 0.3281, 'auc': 0.61602}\n",
      "test: {'epoch': 23, 'time_epoch': 0.82114, 'loss': 1.98885238, 'lr': 0, 'params': 135811, 'time_iter': 0.11731, 'accuracy': 0.34579, 'f1': 0.28136, 'auc': 0.56751}\n",
      "> Epoch 23: took 13.5s (avg 13.5s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 24, 'time_epoch': 10.48612, 'eta': 647.70989, 'eta_hours': 0.17992, 'loss': 0.26872389, 'lr': 0.00082743, 'params': 135811, 'time_iter': 0.19419, 'accuracy': 0.92136, 'f1': 0.9192, 'auc': 0.97382}\n",
      "val: {'epoch': 24, 'time_epoch': 0.81563, 'loss': 2.04470567, 'lr': 0, 'params': 135811, 'time_iter': 0.11652, 'accuracy': 0.34906, 'f1': 0.30528, 'auc': 0.55887}\n",
      "test: {'epoch': 24, 'time_epoch': 0.80797, 'loss': 2.08025573, 'lr': 0, 'params': 135811, 'time_iter': 0.11542, 'accuracy': 0.36449, 'f1': 0.29093, 'auc': 0.51375}\n",
      "> Epoch 24: took 12.1s (avg 13.4s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 25, 'time_epoch': 10.65283, 'eta': 633.59949, 'eta_hours': 0.176, 'loss': 0.26957027, 'lr': 0.00081174, 'params': 135811, 'time_iter': 0.19727, 'accuracy': 0.92254, 'f1': 0.91954, 'auc': 0.97381}\n",
      "val: {'epoch': 25, 'time_epoch': 0.81686, 'loss': 2.12086636, 'lr': 0, 'params': 135811, 'time_iter': 0.11669, 'accuracy': 0.35849, 'f1': 0.28343, 'auc': 0.60855}\n",
      "test: {'epoch': 25, 'time_epoch': 0.81235, 'loss': 1.99897338, 'lr': 0, 'params': 135811, 'time_iter': 0.11605, 'accuracy': 0.39252, 'f1': 0.30628, 'auc': 0.55922}\n",
      "> Epoch 25: took 12.3s (avg 13.4s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 26, 'time_epoch': 11.26382, 'eta': 620.94455, 'eta_hours': 0.17248, 'loss': 0.21621887, 'lr': 0.00079554, 'params': 135811, 'time_iter': 0.20859, 'accuracy': 0.94718, 'f1': 0.94309, 'auc': 0.98436}\n",
      "val: {'epoch': 26, 'time_epoch': 0.80132, 'loss': 1.51532067, 'lr': 0, 'params': 135811, 'time_iter': 0.11447, 'accuracy': 0.51887, 'f1': 0.46622, 'auc': 0.64373}\n",
      "test: {'epoch': 26, 'time_epoch': 0.81303, 'loss': 1.72809954, 'lr': 0, 'params': 135811, 'time_iter': 0.11615, 'accuracy': 0.43925, 'f1': 0.37128, 'auc': 0.59757}\n",
      "> Epoch 26: took 12.9s (avg 13.4s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 27, 'time_epoch': 10.97208, 'eta': 607.84717, 'eta_hours': 0.16885, 'loss': 0.23437951, 'lr': 0.00077884, 'params': 135811, 'time_iter': 0.20319, 'accuracy': 0.93075, 'f1': 0.9281, 'auc': 0.98126}\n",
      "val: {'epoch': 27, 'time_epoch': 0.80544, 'loss': 1.47208823, 'lr': 0, 'params': 135811, 'time_iter': 0.11506, 'accuracy': 0.5, 'f1': 0.48056, 'auc': 0.67225}\n",
      "test: {'epoch': 27, 'time_epoch': 0.81757, 'loss': 1.79021653, 'lr': 0, 'params': 135811, 'time_iter': 0.1168, 'accuracy': 0.40187, 'f1': 0.38013, 'auc': 0.57564}\n",
      "> Epoch 27: took 12.6s (avg 13.3s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 28, 'time_epoch': 11.61735, 'eta': 596.03115, 'eta_hours': 0.16556, 'loss': 0.20752099, 'lr': 0.00076168, 'params': 135811, 'time_iter': 0.21514, 'accuracy': 0.94601, 'f1': 0.94356, 'auc': 0.98059}\n",
      "val: {'epoch': 28, 'time_epoch': 0.82015, 'loss': 2.29655772, 'lr': 0, 'params': 135811, 'time_iter': 0.11716, 'accuracy': 0.34906, 'f1': 0.25708, 'auc': 0.58627}\n",
      "test: {'epoch': 28, 'time_epoch': 0.85537, 'loss': 2.1709976, 'lr': 0, 'params': 135811, 'time_iter': 0.1222, 'accuracy': 0.39252, 'f1': 0.30242, 'auc': 0.53629}\n",
      "> Epoch 28: took 13.3s (avg 13.3s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 29, 'time_epoch': 10.92166, 'eta': 583.06889, 'eta_hours': 0.16196, 'loss': 0.23648628, 'lr': 0.00074409, 'params': 135811, 'time_iter': 0.20225, 'accuracy': 0.93075, 'f1': 0.93141, 'auc': 0.98071}\n",
      "val: {'epoch': 29, 'time_epoch': 0.80837, 'loss': 1.58934586, 'lr': 0, 'params': 135811, 'time_iter': 0.11548, 'accuracy': 0.5, 'f1': 0.4544, 'auc': 0.63038}\n",
      "test: {'epoch': 29, 'time_epoch': 0.81669, 'loss': 2.01184016, 'lr': 0, 'params': 135811, 'time_iter': 0.11667, 'accuracy': 0.36449, 'f1': 0.31828, 'auc': 0.56259}\n",
      "> Epoch 29: took 12.6s (avg 13.3s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 30, 'time_epoch': 22.54638, 'eta': 588.61284, 'eta_hours': 0.1635, 'loss': 0.20784082, 'lr': 0.00072609, 'params': 135811, 'time_iter': 0.41753, 'accuracy': 0.94249, 'f1': 0.94408, 'auc': 0.98402}\n",
      "val: {'epoch': 30, 'time_epoch': 0.8039, 'loss': 1.55505093, 'lr': 0, 'params': 135811, 'time_iter': 0.11484, 'accuracy': 0.53774, 'f1': 0.42462, 'auc': 0.61405}\n",
      "test: {'epoch': 30, 'time_epoch': 0.79727, 'loss': 1.85991649, 'lr': 0, 'params': 135811, 'time_iter': 0.1139, 'accuracy': 0.46729, 'f1': 0.37498, 'auc': 0.62525}\n",
      "> Epoch 30: took 24.2s (avg 13.7s) | Best so far: epoch 8\ttrain_loss: 0.6725 train_accuracy: 0.7653\tval_loss: 0.9760 val_accuracy: 0.5377\ttest_loss: 1.1341 test_accuracy: 0.4392\n",
      "train: {'epoch': 31, 'time_epoch': 11.01826, 'eta': 575.10896, 'eta_hours': 0.15975, 'loss': 0.20892315, 'lr': 0.00070771, 'params': 135811, 'time_iter': 0.20404, 'accuracy': 0.93897, 'f1': 0.93766, 'auc': 0.98462}\n",
      "val: {'epoch': 31, 'time_epoch': 0.78589, 'loss': 1.57201175, 'lr': 0, 'params': 135811, 'time_iter': 0.11227, 'accuracy': 0.54717, 'f1': 0.48025, 'auc': 0.64557}\n",
      "test: {'epoch': 31, 'time_epoch': 0.80646, 'loss': 1.96031895, 'lr': 0, 'params': 135811, 'time_iter': 0.11521, 'accuracy': 0.42991, 'f1': 0.30875, 'auc': 0.61688}\n",
      "> Epoch 31: took 12.6s (avg 13.6s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 32, 'time_epoch': 22.45733, 'eta': 578.04774, 'eta_hours': 0.16057, 'loss': 0.14863295, 'lr': 0.00068898, 'params': 135811, 'time_iter': 0.41588, 'accuracy': 0.96244, 'f1': 0.96368, 'auc': 0.99221}\n",
      "val: {'epoch': 32, 'time_epoch': 0.8349, 'loss': 1.83938644, 'lr': 0, 'params': 135811, 'time_iter': 0.11927, 'accuracy': 0.46226, 'f1': 0.45645, 'auc': 0.63613}\n",
      "test: {'epoch': 32, 'time_epoch': 0.80523, 'loss': 1.8152041, 'lr': 0, 'params': 135811, 'time_iter': 0.11503, 'accuracy': 0.4486, 'f1': 0.44493, 'auc': 0.62347}\n",
      "> Epoch 32: took 24.1s (avg 13.9s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 33, 'time_epoch': 11.08414, 'eta': 564.10537, 'eta_hours': 0.1567, 'loss': 0.16490983, 'lr': 0.00066994, 'params': 135811, 'time_iter': 0.20526, 'accuracy': 0.96244, 'f1': 0.95914, 'auc': 0.98868}\n",
      "val: {'epoch': 33, 'time_epoch': 0.79097, 'loss': 1.92128159, 'lr': 0, 'params': 135811, 'time_iter': 0.113, 'accuracy': 0.46226, 'f1': 0.45833, 'auc': 0.61542}\n",
      "test: {'epoch': 33, 'time_epoch': 0.80266, 'loss': 1.99332276, 'lr': 0, 'params': 135811, 'time_iter': 0.11467, 'accuracy': 0.42056, 'f1': 0.41056, 'auc': 0.60277}\n",
      "> Epoch 33: took 12.7s (avg 13.9s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 34, 'time_epoch': 11.37143, 'eta': 550.69569, 'eta_hours': 0.15297, 'loss': 0.1236728, 'lr': 0.00065062, 'params': 135811, 'time_iter': 0.21058, 'accuracy': 0.97418, 'f1': 0.97262, 'auc': 0.99297}\n",
      "val: {'epoch': 34, 'time_epoch': 0.79304, 'loss': 1.86073366, 'lr': 0, 'params': 135811, 'time_iter': 0.11329, 'accuracy': 0.4717, 'f1': 0.4628, 'auc': 0.65748}\n",
      "test: {'epoch': 34, 'time_epoch': 0.79773, 'loss': 1.76854817, 'lr': 0, 'params': 135811, 'time_iter': 0.11396, 'accuracy': 0.47664, 'f1': 0.46174, 'auc': 0.62647}\n",
      "> Epoch 34: took 13.0s (avg 13.9s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 35, 'time_epoch': 10.74816, 'eta': 536.63749, 'eta_hours': 0.14907, 'loss': 0.1256619, 'lr': 0.00063105, 'params': 135811, 'time_iter': 0.19904, 'accuracy': 0.96948, 'f1': 0.96887, 'auc': 0.99017}\n",
      "val: {'epoch': 35, 'time_epoch': 0.79887, 'loss': 1.7844465, 'lr': 0, 'params': 135811, 'time_iter': 0.11412, 'accuracy': 0.50943, 'f1': 0.4652, 'auc': 0.64227}\n",
      "test: {'epoch': 35, 'time_epoch': 0.81211, 'loss': 1.75544683, 'lr': 0, 'params': 135811, 'time_iter': 0.11602, 'accuracy': 0.52336, 'f1': 0.46958, 'auc': 0.65681}\n",
      "> Epoch 35: took 12.4s (avg 13.8s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 36, 'time_epoch': 11.09116, 'eta': 523.15682, 'eta_hours': 0.14532, 'loss': 0.15287792, 'lr': 0.00061126, 'params': 135811, 'time_iter': 0.20539, 'accuracy': 0.95423, 'f1': 0.95216, 'auc': 0.99005}\n",
      "val: {'epoch': 36, 'time_epoch': 0.81566, 'loss': 2.04688768, 'lr': 0, 'params': 135811, 'time_iter': 0.11652, 'accuracy': 0.43396, 'f1': 0.314, 'auc': 0.62507}\n",
      "test: {'epoch': 36, 'time_epoch': 0.80123, 'loss': 2.08823084, 'lr': 0, 'params': 135811, 'time_iter': 0.11446, 'accuracy': 0.46729, 'f1': 0.32871, 'auc': 0.59458}\n",
      "> Epoch 36: took 12.7s (avg 13.8s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 37, 'time_epoch': 10.76707, 'eta': 509.44371, 'eta_hours': 0.14151, 'loss': 0.11970638, 'lr': 0.00059128, 'params': 135811, 'time_iter': 0.19939, 'accuracy': 0.96948, 'f1': 0.96625, 'auc': 0.99052}\n",
      "val: {'epoch': 37, 'time_epoch': 0.80437, 'loss': 1.94921389, 'lr': 0, 'params': 135811, 'time_iter': 0.11491, 'accuracy': 0.48113, 'f1': 0.46849, 'auc': 0.6344}\n",
      "test: {'epoch': 37, 'time_epoch': 0.81295, 'loss': 1.79195322, 'lr': 0, 'params': 135811, 'time_iter': 0.11614, 'accuracy': 0.47664, 'f1': 0.46971, 'auc': 0.62791}\n",
      "> Epoch 37: took 12.4s (avg 13.8s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 38, 'time_epoch': 21.89905, 'eta': 507.58454, 'eta_hours': 0.141, 'loss': 0.12601412, 'lr': 0.00057116, 'params': 135811, 'time_iter': 0.40554, 'accuracy': 0.97066, 'f1': 0.96836, 'auc': 0.99283}\n",
      "val: {'epoch': 38, 'time_epoch': 0.82635, 'loss': 2.0424479, 'lr': 0, 'params': 135811, 'time_iter': 0.11805, 'accuracy': 0.43396, 'f1': 0.41777, 'auc': 0.64741}\n",
      "test: {'epoch': 38, 'time_epoch': 0.82807, 'loss': 1.9971681, 'lr': 0, 'params': 135811, 'time_iter': 0.1183, 'accuracy': 0.4486, 'f1': 0.42764, 'auc': 0.62868}\n",
      "> Epoch 38: took 23.6s (avg 14.0s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 39, 'time_epoch': 10.29776, 'eta': 493.12208, 'eta_hours': 0.13698, 'loss': 0.14062184, 'lr': 0.00055091, 'params': 135811, 'time_iter': 0.1907, 'accuracy': 0.96596, 'f1': 0.96659, 'auc': 0.98969}\n",
      "val: {'epoch': 39, 'time_epoch': 0.80965, 'loss': 1.9804964, 'lr': 0, 'params': 135811, 'time_iter': 0.11566, 'accuracy': 0.48113, 'f1': 0.45236, 'auc': 0.62293}\n",
      "test: {'epoch': 39, 'time_epoch': 0.81135, 'loss': 1.92697664, 'lr': 0, 'params': 135811, 'time_iter': 0.11591, 'accuracy': 0.50467, 'f1': 0.48232, 'auc': 0.63288}\n",
      "> Epoch 39: took 11.9s (avg 14.0s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 40, 'time_epoch': 10.87444, 'eta': 479.41132, 'eta_hours': 0.13317, 'loss': 0.11634253, 'lr': 0.00053058, 'params': 135811, 'time_iter': 0.20138, 'accuracy': 0.973, 'f1': 0.97291, 'auc': 0.99021}\n",
      "val: {'epoch': 40, 'time_epoch': 0.80735, 'loss': 2.15019509, 'lr': 0, 'params': 135811, 'time_iter': 0.11534, 'accuracy': 0.42453, 'f1': 0.41776, 'auc': 0.61436}\n",
      "test: {'epoch': 40, 'time_epoch': 0.82948, 'loss': 1.96763921, 'lr': 0, 'params': 135811, 'time_iter': 0.1185, 'accuracy': 0.47664, 'f1': 0.47172, 'auc': 0.60338}\n",
      "> Epoch 40: took 12.5s (avg 13.9s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 41, 'time_epoch': 10.67541, 'eta': 465.65555, 'eta_hours': 0.12935, 'loss': 0.11203166, 'lr': 0.0005102, 'params': 135811, 'time_iter': 0.19769, 'accuracy': 0.97418, 'f1': 0.97049, 'auc': 0.99154}\n",
      "val: {'epoch': 41, 'time_epoch': 0.806, 'loss': 2.17201108, 'lr': 0, 'params': 135811, 'time_iter': 0.11514, 'accuracy': 0.45283, 'f1': 0.40788, 'auc': 0.61133}\n",
      "test: {'epoch': 41, 'time_epoch': 0.81034, 'loss': 2.05779721, 'lr': 0, 'params': 135811, 'time_iter': 0.11576, 'accuracy': 0.47664, 'f1': 0.44565, 'auc': 0.62909}\n",
      "> Epoch 41: took 12.3s (avg 13.9s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 42, 'time_epoch': 11.19229, 'eta': 452.48781, 'eta_hours': 0.12569, 'loss': 0.11559221, 'lr': 0.0004898, 'params': 135811, 'time_iter': 0.20726, 'accuracy': 0.97183, 'f1': 0.9696, 'auc': 0.9916}\n",
      "val: {'epoch': 42, 'time_epoch': 0.83622, 'loss': 1.85544186, 'lr': 0, 'params': 135811, 'time_iter': 0.11946, 'accuracy': 0.50943, 'f1': 0.46415, 'auc': 0.66039}\n",
      "test: {'epoch': 42, 'time_epoch': 0.81524, 'loss': 1.93289033, 'lr': 0, 'params': 135811, 'time_iter': 0.11646, 'accuracy': 0.48598, 'f1': 0.42386, 'auc': 0.65902}\n",
      "> Epoch 42: took 12.9s (avg 13.9s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 43, 'time_epoch': 22.00644, 'eta': 448.25781, 'eta_hours': 0.12452, 'loss': 0.0903549, 'lr': 0.00046942, 'params': 135811, 'time_iter': 0.40753, 'accuracy': 0.98239, 'f1': 0.9798, 'auc': 0.99299}\n",
      "val: {'epoch': 43, 'time_epoch': 0.8252, 'loss': 2.11237555, 'lr': 0, 'params': 135811, 'time_iter': 0.11789, 'accuracy': 0.45283, 'f1': 0.4504, 'auc': 0.64101}\n",
      "test: {'epoch': 43, 'time_epoch': 0.80613, 'loss': 2.14399644, 'lr': 0, 'params': 135811, 'time_iter': 0.11516, 'accuracy': 0.42991, 'f1': 0.41938, 'auc': 0.60422}\n",
      "> Epoch 43: took 23.7s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 44, 'time_epoch': 10.62095, 'eta': 434.38236, 'eta_hours': 0.12066, 'loss': 0.11741586, 'lr': 0.00044909, 'params': 135811, 'time_iter': 0.19668, 'accuracy': 0.96948, 'f1': 0.96802, 'auc': 0.99311}\n",
      "val: {'epoch': 44, 'time_epoch': 0.79622, 'loss': 2.18419838, 'lr': 0, 'params': 135811, 'time_iter': 0.11375, 'accuracy': 0.45283, 'f1': 0.42745, 'auc': 0.61279}\n",
      "test: {'epoch': 44, 'time_epoch': 0.79864, 'loss': 2.09030657, 'lr': 0, 'params': 135811, 'time_iter': 0.11409, 'accuracy': 0.45794, 'f1': 0.44148, 'auc': 0.64136}\n",
      "> Epoch 44: took 12.2s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 45, 'time_epoch': 11.40139, 'eta': 421.22525, 'eta_hours': 0.11701, 'loss': 0.09844573, 'lr': 0.00042884, 'params': 135811, 'time_iter': 0.21114, 'accuracy': 0.97653, 'f1': 0.97487, 'auc': 0.99344}\n",
      "val: {'epoch': 45, 'time_epoch': 0.79386, 'loss': 2.13544414, 'lr': 0, 'params': 135811, 'time_iter': 0.11341, 'accuracy': 0.45283, 'f1': 0.43285, 'auc': 0.63113}\n",
      "test: {'epoch': 45, 'time_epoch': 0.80636, 'loss': 2.03760919, 'lr': 0, 'params': 135811, 'time_iter': 0.11519, 'accuracy': 0.45794, 'f1': 0.44917, 'auc': 0.60682}\n",
      "> Epoch 45: took 13.0s (avg 14.0s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 46, 'time_epoch': 22.42374, 'eta': 415.88196, 'eta_hours': 0.11552, 'loss': 0.07562486, 'lr': 0.00040872, 'params': 135811, 'time_iter': 0.41525, 'accuracy': 0.98592, 'f1': 0.9853, 'auc': 0.99497}\n",
      "val: {'epoch': 46, 'time_epoch': 0.80478, 'loss': 2.0683607, 'lr': 0, 'params': 135811, 'time_iter': 0.11497, 'accuracy': 0.48113, 'f1': 0.46719, 'auc': 0.63336}\n",
      "test: {'epoch': 46, 'time_epoch': 0.79479, 'loss': 2.08048213, 'lr': 0, 'params': 135811, 'time_iter': 0.11354, 'accuracy': 0.43925, 'f1': 0.43122, 'auc': 0.61891}\n",
      "> Epoch 46: took 24.0s (avg 14.2s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 47, 'time_epoch': 10.47589, 'eta': 401.86175, 'eta_hours': 0.11163, 'loss': 0.10483542, 'lr': 0.00038874, 'params': 135811, 'time_iter': 0.194, 'accuracy': 0.97887, 'f1': 0.97762, 'auc': 0.99412}\n",
      "val: {'epoch': 47, 'time_epoch': 0.79971, 'loss': 2.1947903, 'lr': 0, 'params': 135811, 'time_iter': 0.11424, 'accuracy': 0.4434, 'f1': 0.4377, 'auc': 0.62151}\n",
      "test: {'epoch': 47, 'time_epoch': 0.80121, 'loss': 2.04471831, 'lr': 0, 'params': 135811, 'time_iter': 0.11446, 'accuracy': 0.47664, 'f1': 0.47149, 'auc': 0.62532}\n",
      "> Epoch 47: took 12.1s (avg 14.2s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 48, 'time_epoch': 10.49106, 'eta': 387.9958, 'eta_hours': 0.10778, 'loss': 0.06982419, 'lr': 0.00036895, 'params': 135811, 'time_iter': 0.19428, 'accuracy': 0.98709, 'f1': 0.98681, 'auc': 0.99543}\n",
      "val: {'epoch': 48, 'time_epoch': 0.80343, 'loss': 2.15023994, 'lr': 0, 'params': 135811, 'time_iter': 0.11478, 'accuracy': 0.48113, 'f1': 0.47061, 'auc': 0.62524}\n",
      "test: {'epoch': 48, 'time_epoch': 0.79824, 'loss': 2.04344004, 'lr': 0, 'params': 135811, 'time_iter': 0.11403, 'accuracy': 0.4486, 'f1': 0.44395, 'auc': 0.6208}\n",
      "> Epoch 48: took 12.1s (avg 14.2s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 49, 'time_epoch': 10.82818, 'eta': 374.46712, 'eta_hours': 0.10402, 'loss': 0.06922003, 'lr': 0.00034938, 'params': 135811, 'time_iter': 0.20052, 'accuracy': 0.98709, 'f1': 0.98738, 'auc': 0.9968}\n",
      "val: {'epoch': 49, 'time_epoch': 0.79693, 'loss': 2.10977425, 'lr': 0, 'params': 135811, 'time_iter': 0.11385, 'accuracy': 0.45283, 'f1': 0.4299, 'auc': 0.62326}\n",
      "test: {'epoch': 49, 'time_epoch': 0.80402, 'loss': 1.99886901, 'lr': 0, 'params': 135811, 'time_iter': 0.11486, 'accuracy': 0.50467, 'f1': 0.48938, 'auc': 0.6271}\n",
      "> Epoch 49: took 12.5s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 50, 'time_epoch': 10.50396, 'eta': 360.85998, 'eta_hours': 0.10024, 'loss': 0.07439362, 'lr': 0.00033006, 'params': 135811, 'time_iter': 0.19452, 'accuracy': 0.98709, 'f1': 0.98576, 'auc': 0.99334}\n",
      "val: {'epoch': 50, 'time_epoch': 0.7945, 'loss': 2.26596736, 'lr': 0, 'params': 135811, 'time_iter': 0.1135, 'accuracy': 0.43396, 'f1': 0.39807, 'auc': 0.60382}\n",
      "test: {'epoch': 50, 'time_epoch': 0.81115, 'loss': 2.22835824, 'lr': 0, 'params': 135811, 'time_iter': 0.11588, 'accuracy': 0.4486, 'f1': 0.42725, 'auc': 0.61436}\n",
      "> Epoch 50: took 12.1s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 51, 'time_epoch': 10.92664, 'eta': 347.59979, 'eta_hours': 0.09656, 'loss': 0.08132961, 'lr': 0.00031102, 'params': 135811, 'time_iter': 0.20235, 'accuracy': 0.98357, 'f1': 0.98375, 'auc': 0.99526}\n",
      "val: {'epoch': 51, 'time_epoch': 0.78836, 'loss': 2.38360014, 'lr': 0, 'params': 135811, 'time_iter': 0.11262, 'accuracy': 0.39623, 'f1': 0.39526, 'auc': 0.61235}\n",
      "test: {'epoch': 51, 'time_epoch': 0.80028, 'loss': 2.12761484, 'lr': 0, 'params': 135811, 'time_iter': 0.11433, 'accuracy': 0.48598, 'f1': 0.48346, 'auc': 0.6124}\n",
      "> Epoch 51: took 12.5s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 52, 'time_epoch': 22.57124, 'eta': 340.35981, 'eta_hours': 0.09454, 'loss': 0.09537507, 'lr': 0.00029229, 'params': 135811, 'time_iter': 0.41799, 'accuracy': 0.98122, 'f1': 0.98024, 'auc': 0.99302}\n",
      "val: {'epoch': 52, 'time_epoch': 0.81702, 'loss': 2.23623295, 'lr': 0, 'params': 135811, 'time_iter': 0.11672, 'accuracy': 0.46226, 'f1': 0.43126, 'auc': 0.60463}\n",
      "test: {'epoch': 52, 'time_epoch': 0.81909, 'loss': 2.17845444, 'lr': 0, 'params': 135811, 'time_iter': 0.11701, 'accuracy': 0.46729, 'f1': 0.45259, 'auc': 0.62692}\n",
      "> Epoch 52: took 24.2s (avg 14.2s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 53, 'time_epoch': 11.21381, 'eta': 327.08362, 'eta_hours': 0.09086, 'loss': 0.06673719, 'lr': 0.00027391, 'params': 135811, 'time_iter': 0.20766, 'accuracy': 0.98592, 'f1': 0.98485, 'auc': 0.99719}\n",
      "val: {'epoch': 53, 'time_epoch': 0.81051, 'loss': 2.12705223, 'lr': 0, 'params': 135811, 'time_iter': 0.11579, 'accuracy': 0.46226, 'f1': 0.44707, 'auc': 0.62849}\n",
      "test: {'epoch': 53, 'time_epoch': 0.81929, 'loss': 2.04146184, 'lr': 0, 'params': 135811, 'time_iter': 0.11704, 'accuracy': 0.45794, 'f1': 0.44388, 'auc': 0.62858}\n",
      "> Epoch 53: took 12.9s (avg 14.2s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 54, 'time_epoch': 21.94094, 'eta': 318.75839, 'eta_hours': 0.08854, 'loss': 0.07361094, 'lr': 0.00025591, 'params': 135811, 'time_iter': 0.40631, 'accuracy': 0.98592, 'f1': 0.98618, 'auc': 0.99622}\n",
      "val: {'epoch': 54, 'time_epoch': 0.83233, 'loss': 2.19496124, 'lr': 0, 'params': 135811, 'time_iter': 0.1189, 'accuracy': 0.4434, 'f1': 0.42359, 'auc': 0.61529}\n",
      "test: {'epoch': 54, 'time_epoch': 0.80538, 'loss': 2.09941023, 'lr': 0, 'params': 135811, 'time_iter': 0.11505, 'accuracy': 0.48598, 'f1': 0.47321, 'auc': 0.62919}\n",
      "> Epoch 54: took 23.6s (avg 14.4s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 55, 'time_epoch': 10.48053, 'eta': 305.03528, 'eta_hours': 0.08473, 'loss': 0.07500077, 'lr': 0.00023832, 'params': 135811, 'time_iter': 0.19408, 'accuracy': 0.98592, 'f1': 0.98498, 'auc': 0.99518}\n",
      "val: {'epoch': 55, 'time_epoch': 0.80603, 'loss': 2.07937611, 'lr': 0, 'params': 135811, 'time_iter': 0.11515, 'accuracy': 0.4717, 'f1': 0.43197, 'auc': 0.63332}\n",
      "test: {'epoch': 55, 'time_epoch': 0.80422, 'loss': 2.0986543, 'lr': 0, 'params': 135811, 'time_iter': 0.11489, 'accuracy': 0.50467, 'f1': 0.48068, 'auc': 0.62448}\n",
      "> Epoch 55: took 12.1s (avg 14.4s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 56, 'time_epoch': 10.76975, 'eta': 291.54265, 'eta_hours': 0.08098, 'loss': 0.07198679, 'lr': 0.00022116, 'params': 135811, 'time_iter': 0.19944, 'accuracy': 0.98709, 'f1': 0.98537, 'auc': 0.99635}\n",
      "val: {'epoch': 56, 'time_epoch': 0.78913, 'loss': 2.19219937, 'lr': 0, 'params': 135811, 'time_iter': 0.11273, 'accuracy': 0.5, 'f1': 0.46144, 'auc': 0.61695}\n",
      "test: {'epoch': 56, 'time_epoch': 0.80199, 'loss': 2.11849128, 'lr': 0, 'params': 135811, 'time_iter': 0.11457, 'accuracy': 0.48598, 'f1': 0.46459, 'auc': 0.62886}\n",
      "> Epoch 56: took 12.4s (avg 14.3s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 57, 'time_epoch': 10.51767, 'eta': 278.04829, 'eta_hours': 0.07724, 'loss': 0.07272333, 'lr': 0.00020446, 'params': 135811, 'time_iter': 0.19477, 'accuracy': 0.98474, 'f1': 0.98423, 'auc': 0.9965}\n",
      "val: {'epoch': 57, 'time_epoch': 0.80332, 'loss': 2.16289703, 'lr': 0, 'params': 135811, 'time_iter': 0.11476, 'accuracy': 0.4717, 'f1': 0.44987, 'auc': 0.63086}\n",
      "test: {'epoch': 57, 'time_epoch': 0.79824, 'loss': 2.06449245, 'lr': 0, 'params': 135811, 'time_iter': 0.11403, 'accuracy': 0.50467, 'f1': 0.49415, 'auc': 0.62974}\n",
      "> Epoch 57: took 12.1s (avg 14.3s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 58, 'time_epoch': 10.76692, 'eta': 264.74355, 'eta_hours': 0.07354, 'loss': 0.06389227, 'lr': 0.00018826, 'params': 135811, 'time_iter': 0.19939, 'accuracy': 0.98944, 'f1': 0.98882, 'auc': 0.99598}\n",
      "val: {'epoch': 58, 'time_epoch': 0.79531, 'loss': 2.16484115, 'lr': 0, 'params': 135811, 'time_iter': 0.11362, 'accuracy': 0.48113, 'f1': 0.46079, 'auc': 0.62078}\n",
      "test: {'epoch': 58, 'time_epoch': 0.80412, 'loss': 2.02747857, 'lr': 0, 'params': 135811, 'time_iter': 0.11487, 'accuracy': 0.49533, 'f1': 0.48595, 'auc': 0.64282}\n",
      "> Epoch 58: took 12.4s (avg 14.2s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 59, 'time_epoch': 10.17803, 'eta': 251.32712, 'eta_hours': 0.06981, 'loss': 0.0585825, 'lr': 0.00017257, 'params': 135811, 'time_iter': 0.18848, 'accuracy': 0.98944, 'f1': 0.98924, 'auc': 0.99616}\n",
      "val: {'epoch': 59, 'time_epoch': 0.79189, 'loss': 2.16433673, 'lr': 0, 'params': 135811, 'time_iter': 0.11313, 'accuracy': 0.4717, 'f1': 0.45547, 'auc': 0.63555}\n",
      "test: {'epoch': 59, 'time_epoch': 0.79065, 'loss': 2.03416577, 'lr': 0, 'params': 135811, 'time_iter': 0.11295, 'accuracy': 0.50467, 'f1': 0.47984, 'auc': 0.63937}\n",
      "> Epoch 59: took 11.8s (avg 14.2s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 60, 'time_epoch': 11.35971, 'eta': 238.38492, 'eta_hours': 0.06622, 'loss': 0.06673941, 'lr': 0.00015743, 'params': 135811, 'time_iter': 0.21036, 'accuracy': 0.98592, 'f1': 0.98539, 'auc': 0.99526}\n",
      "val: {'epoch': 60, 'time_epoch': 0.79322, 'loss': 2.22687584, 'lr': 0, 'params': 135811, 'time_iter': 0.11332, 'accuracy': 0.43396, 'f1': 0.41214, 'auc': 0.62416}\n",
      "test: {'epoch': 60, 'time_epoch': 0.80917, 'loss': 2.17227316, 'lr': 0, 'params': 135811, 'time_iter': 0.1156, 'accuracy': 0.47664, 'f1': 0.46769, 'auc': 0.62051}\n",
      "> Epoch 60: took 13.0s (avg 14.2s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 61, 'time_epoch': 10.19666, 'eta': 225.15611, 'eta_hours': 0.06254, 'loss': 0.05801092, 'lr': 0.00014286, 'params': 135811, 'time_iter': 0.18883, 'accuracy': 0.99061, 'f1': 0.99067, 'auc': 0.99505}\n",
      "val: {'epoch': 61, 'time_epoch': 0.7972, 'loss': 2.20758886, 'lr': 0, 'params': 135811, 'time_iter': 0.11389, 'accuracy': 0.4717, 'f1': 0.43197, 'auc': 0.62813}\n",
      "test: {'epoch': 61, 'time_epoch': 0.79735, 'loss': 2.12945056, 'lr': 0, 'params': 135811, 'time_iter': 0.11391, 'accuracy': 0.50467, 'f1': 0.46884, 'auc': 0.61853}\n",
      "> Epoch 61: took 11.8s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 62, 'time_epoch': 10.82347, 'eta': 212.1927, 'eta_hours': 0.05894, 'loss': 0.06375703, 'lr': 0.00012888, 'params': 135811, 'time_iter': 0.20043, 'accuracy': 0.98944, 'f1': 0.98924, 'auc': 0.9961}\n",
      "val: {'epoch': 62, 'time_epoch': 0.81243, 'loss': 2.13356082, 'lr': 0, 'params': 135811, 'time_iter': 0.11606, 'accuracy': 0.48113, 'f1': 0.44689, 'auc': 0.62485}\n",
      "test: {'epoch': 62, 'time_epoch': 0.7903, 'loss': 2.06777108, 'lr': 0, 'params': 135811, 'time_iter': 0.1129, 'accuracy': 0.49533, 'f1': 0.46224, 'auc': 0.63761}\n",
      "> Epoch 62: took 12.4s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 63, 'time_epoch': 11.10135, 'eta': 199.36563, 'eta_hours': 0.05538, 'loss': 0.09485527, 'lr': 0.00011552, 'params': 135811, 'time_iter': 0.20558, 'accuracy': 0.98005, 'f1': 0.97959, 'auc': 0.99423}\n",
      "val: {'epoch': 63, 'time_epoch': 0.80134, 'loss': 2.23310139, 'lr': 0, 'params': 135811, 'time_iter': 0.11448, 'accuracy': 0.48113, 'f1': 0.47184, 'auc': 0.62377}\n",
      "test: {'epoch': 63, 'time_epoch': 0.79103, 'loss': 2.10271897, 'lr': 0, 'params': 135811, 'time_iter': 0.113, 'accuracy': 0.46729, 'f1': 0.4539, 'auc': 0.61907}\n",
      "> Epoch 63: took 12.7s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 64, 'time_epoch': 11.11836, 'eta': 186.59559, 'eta_hours': 0.05183, 'loss': 0.0601807, 'lr': 0.00010281, 'params': 135811, 'time_iter': 0.2059, 'accuracy': 0.98944, 'f1': 0.98872, 'auc': 0.99652}\n",
      "val: {'epoch': 64, 'time_epoch': 0.86052, 'loss': 2.2163591, 'lr': 0, 'params': 135811, 'time_iter': 0.12293, 'accuracy': 0.46226, 'f1': 0.44762, 'auc': 0.61869}\n",
      "test: {'epoch': 64, 'time_epoch': 0.82632, 'loss': 2.09682396, 'lr': 0, 'params': 135811, 'time_iter': 0.11805, 'accuracy': 0.50467, 'f1': 0.48995, 'auc': 0.63013}\n",
      "> Epoch 64: took 12.8s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 65, 'time_epoch': 11.42159, 'eta': 173.93992, 'eta_hours': 0.04832, 'loss': 0.05481606, 'lr': 9.075e-05, 'params': 135811, 'time_iter': 0.21151, 'accuracy': 0.99061, 'f1': 0.98991, 'auc': 0.99685}\n",
      "val: {'epoch': 65, 'time_epoch': 0.80488, 'loss': 2.19378909, 'lr': 0, 'params': 135811, 'time_iter': 0.11498, 'accuracy': 0.4717, 'f1': 0.45499, 'auc': 0.62741}\n",
      "test: {'epoch': 65, 'time_epoch': 0.8169, 'loss': 2.08510974, 'lr': 0, 'params': 135811, 'time_iter': 0.1167, 'accuracy': 0.48598, 'f1': 0.4667, 'auc': 0.63078}\n",
      "> Epoch 65: took 13.1s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 66, 'time_epoch': 10.86891, 'eta': 161.21385, 'eta_hours': 0.04478, 'loss': 0.06103655, 'lr': 7.937e-05, 'params': 135811, 'time_iter': 0.20128, 'accuracy': 0.98826, 'f1': 0.98763, 'auc': 0.99622}\n",
      "val: {'epoch': 66, 'time_epoch': 0.80281, 'loss': 2.20871727, 'lr': 0, 'params': 135811, 'time_iter': 0.11469, 'accuracy': 0.49057, 'f1': 0.45206, 'auc': 0.6291}\n",
      "test: {'epoch': 66, 'time_epoch': 0.82048, 'loss': 2.07028559, 'lr': 0, 'params': 135811, 'time_iter': 0.11721, 'accuracy': 0.50467, 'f1': 0.47294, 'auc': 0.63869}\n",
      "> Epoch 66: took 12.5s (avg 14.0s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 67, 'time_epoch': 10.60275, 'eta': 148.49544, 'eta_hours': 0.04125, 'loss': 0.05245921, 'lr': 6.87e-05, 'params': 135811, 'time_iter': 0.19635, 'accuracy': 0.99178, 'f1': 0.99069, 'auc': 0.99768}\n",
      "val: {'epoch': 67, 'time_epoch': 0.8044, 'loss': 2.27197397, 'lr': 0, 'params': 135811, 'time_iter': 0.11491, 'accuracy': 0.46226, 'f1': 0.44619, 'auc': 0.62031}\n",
      "test: {'epoch': 67, 'time_epoch': 0.8035, 'loss': 2.13182649, 'lr': 0, 'params': 135811, 'time_iter': 0.11479, 'accuracy': 0.47664, 'f1': 0.46363, 'auc': 0.61784}\n",
      "> Epoch 67: took 12.2s (avg 14.0s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 68, 'time_epoch': 10.94227, 'eta': 135.89247, 'eta_hours': 0.03775, 'loss': 0.06252159, 'lr': 5.874e-05, 'params': 135811, 'time_iter': 0.20263, 'accuracy': 0.98709, 'f1': 0.98717, 'auc': 0.9972}\n",
      "val: {'epoch': 68, 'time_epoch': 0.80567, 'loss': 2.17588814, 'lr': 0, 'params': 135811, 'time_iter': 0.1151, 'accuracy': 0.48113, 'f1': 0.45735, 'auc': 0.62893}\n",
      "test: {'epoch': 68, 'time_epoch': 0.81341, 'loss': 2.04310269, 'lr': 0, 'params': 135811, 'time_iter': 0.1162, 'accuracy': 0.50467, 'f1': 0.48292, 'auc': 0.63738}\n",
      "> Epoch 68: took 12.6s (avg 14.0s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 69, 'time_epoch': 10.59531, 'eta': 123.28739, 'eta_hours': 0.03425, 'loss': 0.06750987, 'lr': 4.952e-05, 'params': 135811, 'time_iter': 0.19621, 'accuracy': 0.98592, 'f1': 0.98584, 'auc': 0.99588}\n",
      "val: {'epoch': 69, 'time_epoch': 0.80701, 'loss': 2.3035139, 'lr': 0, 'params': 135811, 'time_iter': 0.11529, 'accuracy': 0.45283, 'f1': 0.43802, 'auc': 0.61705}\n",
      "test: {'epoch': 69, 'time_epoch': 0.83002, 'loss': 2.09250893, 'lr': 0, 'params': 135811, 'time_iter': 0.11857, 'accuracy': 0.50467, 'f1': 0.4959, 'auc': 0.64218}\n",
      "> Epoch 69: took 12.3s (avg 14.0s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 70, 'time_epoch': 10.5924, 'eta': 110.73855, 'eta_hours': 0.03076, 'loss': 0.0544687, 'lr': 4.104e-05, 'params': 135811, 'time_iter': 0.19616, 'accuracy': 0.99178, 'f1': 0.99166, 'auc': 0.99705}\n",
      "val: {'epoch': 70, 'time_epoch': 0.80217, 'loss': 2.18965365, 'lr': 0, 'params': 135811, 'time_iter': 0.1146, 'accuracy': 0.48113, 'f1': 0.45817, 'auc': 0.62458}\n",
      "test: {'epoch': 70, 'time_epoch': 0.83292, 'loss': 2.09951798, 'lr': 0, 'params': 135811, 'time_iter': 0.11899, 'accuracy': 0.51402, 'f1': 0.49384, 'auc': 0.62868}\n",
      "> Epoch 70: took 12.3s (avg 13.9s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 71, 'time_epoch': 22.29737, 'eta': 99.54461, 'eta_hours': 0.02765, 'loss': 0.05211277, 'lr': 3.333e-05, 'params': 135811, 'time_iter': 0.41291, 'accuracy': 0.99178, 'f1': 0.99112, 'auc': 0.99735}\n",
      "val: {'epoch': 71, 'time_epoch': 0.80596, 'loss': 2.17612745, 'lr': 0, 'params': 135811, 'time_iter': 0.11514, 'accuracy': 0.48113, 'f1': 0.45744, 'auc': 0.62835}\n",
      "test: {'epoch': 71, 'time_epoch': 0.81632, 'loss': 2.08278573, 'lr': 0, 'params': 135811, 'time_iter': 0.11662, 'accuracy': 0.50467, 'f1': 0.47995, 'auc': 0.62781}\n",
      "> Epoch 71: took 23.9s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 72, 'time_epoch': 11.16971, 'eta': 86.97943, 'eta_hours': 0.02416, 'loss': 0.05466679, 'lr': 2.64e-05, 'params': 135811, 'time_iter': 0.20685, 'accuracy': 0.99061, 'f1': 0.99024, 'auc': 0.99726}\n",
      "val: {'epoch': 72, 'time_epoch': 0.82281, 'loss': 2.20570545, 'lr': 0, 'params': 135811, 'time_iter': 0.11754, 'accuracy': 0.45283, 'f1': 0.43514, 'auc': 0.61894}\n",
      "test: {'epoch': 72, 'time_epoch': 0.81754, 'loss': 2.11194659, 'lr': 0, 'params': 135811, 'time_iter': 0.11679, 'accuracy': 0.47664, 'f1': 0.45837, 'auc': 0.63173}\n",
      "> Epoch 72: took 12.8s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 73, 'time_epoch': 10.51257, 'eta': 74.39868, 'eta_hours': 0.02067, 'loss': 0.05865542, 'lr': 2.025e-05, 'params': 135811, 'time_iter': 0.19468, 'accuracy': 0.98944, 'f1': 0.9886, 'auc': 0.99675}\n",
      "val: {'epoch': 73, 'time_epoch': 0.81576, 'loss': 2.28800267, 'lr': 0, 'params': 135811, 'time_iter': 0.11654, 'accuracy': 0.41509, 'f1': 0.39965, 'auc': 0.61616}\n",
      "test: {'epoch': 73, 'time_epoch': 0.83031, 'loss': 2.10269749, 'lr': 0, 'params': 135811, 'time_iter': 0.11862, 'accuracy': 0.49533, 'f1': 0.48628, 'auc': 0.6326}\n",
      "> Epoch 73: took 12.2s (avg 14.0s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 74, 'time_epoch': 10.24683, 'eta': 61.85537, 'eta_hours': 0.01718, 'loss': 0.06623609, 'lr': 1.491e-05, 'params': 135811, 'time_iter': 0.18976, 'accuracy': 0.98592, 'f1': 0.98672, 'auc': 0.99644}\n",
      "val: {'epoch': 74, 'time_epoch': 0.81545, 'loss': 2.2220077, 'lr': 0, 'params': 135811, 'time_iter': 0.11649, 'accuracy': 0.45283, 'f1': 0.43502, 'auc': 0.62023}\n",
      "test: {'epoch': 74, 'time_epoch': 0.80177, 'loss': 2.08405795, 'lr': 0, 'params': 135811, 'time_iter': 0.11454, 'accuracy': 0.48598, 'f1': 0.474, 'auc': 0.63215}\n",
      "> Epoch 74: took 11.9s (avg 14.0s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 75, 'time_epoch': 10.92816, 'eta': 49.40836, 'eta_hours': 0.01372, 'loss': 0.05297283, 'lr': 1.037e-05, 'params': 135811, 'time_iter': 0.20237, 'accuracy': 0.99061, 'f1': 0.98979, 'auc': 0.99762}\n",
      "val: {'epoch': 75, 'time_epoch': 0.81834, 'loss': 2.19463674, 'lr': 0, 'params': 135811, 'time_iter': 0.11691, 'accuracy': 0.48113, 'f1': 0.4444, 'auc': 0.62916}\n",
      "test: {'epoch': 75, 'time_epoch': 0.81564, 'loss': 2.128442, 'lr': 0, 'params': 135811, 'time_iter': 0.11652, 'accuracy': 0.49533, 'f1': 0.47498, 'auc': 0.63038}\n",
      "> Epoch 75: took 12.6s (avg 14.0s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 76, 'time_epoch': 22.1305, 'eta': 37.43724, 'eta_hours': 0.0104, 'loss': 0.0554896, 'lr': 6.64e-06, 'params': 135811, 'time_iter': 0.40982, 'accuracy': 0.98944, 'f1': 0.98889, 'auc': 0.99782}\n",
      "val: {'epoch': 76, 'time_epoch': 0.79278, 'loss': 2.21684737, 'lr': 0, 'params': 135811, 'time_iter': 0.11325, 'accuracy': 0.4434, 'f1': 0.42683, 'auc': 0.61667}\n",
      "test: {'epoch': 76, 'time_epoch': 0.79338, 'loss': 2.13836708, 'lr': 0, 'params': 135811, 'time_iter': 0.11334, 'accuracy': 0.47664, 'f1': 0.46331, 'auc': 0.62932}\n",
      "> Epoch 76: took 23.7s (avg 14.1s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 77, 'time_epoch': 22.07341, 'eta': 25.20417, 'eta_hours': 0.007, 'loss': 0.06339538, 'lr': 3.74e-06, 'params': 135811, 'time_iter': 0.40877, 'accuracy': 0.98826, 'f1': 0.98815, 'auc': 0.99716}\n",
      "val: {'epoch': 77, 'time_epoch': 0.80438, 'loss': 2.30753033, 'lr': 0, 'params': 135811, 'time_iter': 0.11491, 'accuracy': 0.43396, 'f1': 0.42185, 'auc': 0.61871}\n",
      "test: {'epoch': 77, 'time_epoch': 0.79426, 'loss': 2.08386304, 'lr': 0, 'params': 135811, 'time_iter': 0.11347, 'accuracy': 0.50467, 'f1': 0.49474, 'auc': 0.63097}\n",
      "> Epoch 77: took 23.7s (avg 14.2s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 78, 'time_epoch': 21.81554, 'eta': 12.71871, 'eta_hours': 0.00353, 'loss': 0.06590363, 'lr': 1.66e-06, 'params': 135811, 'time_iter': 0.40399, 'accuracy': 0.98826, 'f1': 0.98817, 'auc': 0.99605}\n",
      "val: {'epoch': 78, 'time_epoch': 0.79442, 'loss': 2.15750093, 'lr': 0, 'params': 135811, 'time_iter': 0.11349, 'accuracy': 0.48113, 'f1': 0.45744, 'auc': 0.62487}\n",
      "test: {'epoch': 78, 'time_epoch': 0.79709, 'loss': 2.14285308, 'lr': 0, 'params': 135811, 'time_iter': 0.11387, 'accuracy': 0.49533, 'f1': 0.47009, 'auc': 0.62835}\n",
      "> Epoch 78: took 23.4s (avg 14.4s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "train: {'epoch': 79, 'time_epoch': 10.16801, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.05624176, 'lr': 4.2e-07, 'params': 135811, 'time_iter': 0.1883, 'accuracy': 0.98944, 'f1': 0.98882, 'auc': 0.99746}\n",
      "val: {'epoch': 79, 'time_epoch': 0.78805, 'loss': 2.1716748, 'lr': 0, 'params': 135811, 'time_iter': 0.11258, 'accuracy': 0.49057, 'f1': 0.46502, 'auc': 0.62435}\n",
      "test: {'epoch': 79, 'time_epoch': 0.79477, 'loss': 2.1390216, 'lr': 0, 'params': 135811, 'time_iter': 0.11354, 'accuracy': 0.49533, 'f1': 0.47341, 'auc': 0.63032}\n",
      "> Epoch 79: took 11.8s (avg 14.3s) | Best so far: epoch 31\ttrain_loss: 0.2089 train_accuracy: 0.9390\tval_loss: 1.5720 val_accuracy: 0.5472\ttest_loss: 1.9603 test_accuracy: 0.4299\n",
      "Avg time per epoch: 14.33s\n",
      "Total train loop time: 0.32h\n",
      "Task done, results saved in results\\neural-Age\\0\n",
      "31\n",
      "{'epoch': 31, 'time_epoch': 0.80646, 'loss': 1.96031895, 'lr': 0, 'params': 135811, 'time_iter': 0.11521, 'accuracy': 0.42991, 'f1': 0.30875, 'auc': 0.61688}\n",
      "{'epoch': 31, 'time_epoch': 11.01826, 'eta': 575.10896, 'eta_hours': 0.15975, 'loss': 0.20892315, 'lr': 0.00070771, 'params': 135811, 'time_iter': 0.20404, 'accuracy': 0.93897, 'f1': 0.93766, 'auc': 0.98462}\n",
      "{'epoch': 31, 'time_epoch': 0.78589, 'loss': 1.57201175, 'lr': 0, 'params': 135811, 'time_iter': 0.11227, 'accuracy': 0.54717, 'f1': 0.48025, 'auc': 0.64557}\n",
      "Results aggregated across runs saved in results\\neural-Age\\agg\n",
      "[*] All done: 2024-03-01 22:31:07.178179\n"
     ]
    }
   ],
   "source": [
    "#Age using Exphormer 2 layers 0.3 att dropout 0.1 dropout\n",
    "%run main.py --cfg configs/Exphormer/neural-Age.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea19f00-d2f5-41cf-8778-f26088ef04f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-02 01:50:45.225490\n",
      "[*] Loaded dataset 'HCPAge' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1065000, 1000], edge_index=[2, 48551656], y=[1065])\n",
      "  undirected: True\n",
      "  num graphs: 1065\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 3\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [06:47<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:07:00.02\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [04:17<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:04:20.37\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=2\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=2\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 3, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPAge\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 2\n",
      "  n_heads: 2\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 80\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 3\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Age\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Age\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 3\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 135811\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 20.46845, 'eta': 1617.00786, 'eta_hours': 0.44917, 'loss': 1.10824843, 'lr': 0.0, 'params': 135811, 'time_iter': 0.37905, 'accuracy': 0.35446, 'f1': 0.18276, 'auc': 0.51445}\n",
      "...computing epoch stats took: 0.33s\n",
      "val: {'epoch': 0, 'time_epoch': 1.34719, 'loss': 1.12432465, 'lr': 0, 'params': 135811, 'time_iter': 0.19246, 'accuracy': 0.25472, 'f1': 0.13534, 'auc': 0.51637}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 0, 'time_epoch': 1.21051, 'loss': 1.11301786, 'lr': 0, 'params': 135811, 'time_iter': 0.17293, 'accuracy': 0.31776, 'f1': 0.16307, 'auc': 0.4915}\n",
      "...computing epoch stats took: 0.03s\n",
      "> Epoch 0: took 23.4s (avg 23.4s) | Best so far: epoch 0\ttrain_loss: 1.1082 train_accuracy: 0.3545\tval_loss: 1.1243 val_accuracy: 0.2547\ttest_loss: 1.1130 test_accuracy: 0.3178\n",
      "train: {'epoch': 1, 'time_epoch': 15.55446, 'eta': 1404.89382, 'eta_hours': 0.39025, 'loss': 1.08019687, 'lr': 0.00033333, 'params': 135811, 'time_iter': 0.28805, 'accuracy': 0.37324, 'f1': 0.23969, 'auc': 0.54848}\n",
      "...computing epoch stats took: 0.04s\n",
      "val: {'epoch': 1, 'time_epoch': 1.28257, 'loss': 1.08965489, 'lr': 0, 'params': 135811, 'time_iter': 0.18322, 'accuracy': 0.26415, 'f1': 0.1393, 'auc': 0.58086}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 1.13072, 'loss': 1.09714314, 'lr': 0, 'params': 135811, 'time_iter': 0.16153, 'accuracy': 0.31776, 'f1': 0.16076, 'auc': 0.51904}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 1: took 18.1s (avg 20.7s) | Best so far: epoch 1\ttrain_loss: 1.0802 train_accuracy: 0.3732\tval_loss: 1.0897 val_accuracy: 0.2641\ttest_loss: 1.0971 test_accuracy: 0.3178\n",
      "train: {'epoch': 2, 'time_epoch': 15.32282, 'eta': 1317.87392, 'eta_hours': 0.36608, 'loss': 1.04279013, 'lr': 0.00066667, 'params': 135811, 'time_iter': 0.28376, 'accuracy': 0.47418, 'f1': 0.39497, 'auc': 0.61555}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 2, 'time_epoch': 1.27847, 'loss': 1.04387822, 'lr': 0, 'params': 135811, 'time_iter': 0.18264, 'accuracy': 0.40566, 'f1': 0.35313, 'auc': 0.6151}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 2, 'time_epoch': 1.18214, 'loss': 1.07530685, 'lr': 0, 'params': 135811, 'time_iter': 0.16888, 'accuracy': 0.43925, 'f1': 0.3841, 'auc': 0.56863}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 2: took 17.9s (avg 19.8s) | Best so far: epoch 2\ttrain_loss: 1.0428 train_accuracy: 0.4742\tval_loss: 1.0439 val_accuracy: 0.4057\ttest_loss: 1.0753 test_accuracy: 0.4392\n",
      "train: {'epoch': 3, 'time_epoch': 15.76724, 'eta': 1275.14661, 'eta_hours': 0.35421, 'loss': 0.99766461, 'lr': 0.001, 'params': 135811, 'time_iter': 0.29199, 'accuracy': 0.53521, 'f1': 0.48794, 'auc': 0.69664}\n",
      "val: {'epoch': 3, 'time_epoch': 1.24116, 'loss': 1.0883952, 'lr': 0, 'params': 135811, 'time_iter': 0.17731, 'accuracy': 0.32075, 'f1': 0.23023, 'auc': 0.65929}\n",
      "test: {'epoch': 3, 'time_epoch': 1.14324, 'loss': 1.12288383, 'lr': 0, 'params': 135811, 'time_iter': 0.16332, 'accuracy': 0.28972, 'f1': 0.17654, 'auc': 0.57778}\n",
      "> Epoch 3: took 18.2s (avg 19.4s) | Best so far: epoch 2\ttrain_loss: 1.0428 train_accuracy: 0.4742\tval_loss: 1.0439 val_accuracy: 0.4057\ttest_loss: 1.0753 test_accuracy: 0.4392\n",
      "train: {'epoch': 4, 'time_epoch': 15.82812, 'eta': 1244.11655, 'eta_hours': 0.34559, 'loss': 0.93309827, 'lr': 0.00099958, 'params': 135811, 'time_iter': 0.29311, 'accuracy': 0.58216, 'f1': 0.57099, 'auc': 0.75775}\n",
      "val: {'epoch': 4, 'time_epoch': 1.27301, 'loss': 1.15068401, 'lr': 0, 'params': 135811, 'time_iter': 0.18186, 'accuracy': 0.31132, 'f1': 0.20348, 'auc': 0.61733}\n",
      "test: {'epoch': 4, 'time_epoch': 1.17256, 'loss': 1.15836971, 'lr': 0, 'params': 135811, 'time_iter': 0.16751, 'accuracy': 0.35514, 'f1': 0.2381, 'auc': 0.54394}\n",
      "> Epoch 4: took 18.3s (avg 19.2s) | Best so far: epoch 2\ttrain_loss: 1.0428 train_accuracy: 0.4742\tval_loss: 1.0439 val_accuracy: 0.4057\ttest_loss: 1.0753 test_accuracy: 0.4392\n",
      "train: {'epoch': 5, 'time_epoch': 14.87077, 'eta': 1206.34639, 'eta_hours': 0.3351, 'loss': 0.83358573, 'lr': 0.00099834, 'params': 135811, 'time_iter': 0.27538, 'accuracy': 0.68545, 'f1': 0.67139, 'auc': 0.83181}\n",
      "val: {'epoch': 5, 'time_epoch': 1.30979, 'loss': 1.02615486, 'lr': 0, 'params': 135811, 'time_iter': 0.18711, 'accuracy': 0.49057, 'f1': 0.30087, 'auc': 0.6793}\n",
      "test: {'epoch': 5, 'time_epoch': 1.16233, 'loss': 1.12621939, 'lr': 0, 'params': 135811, 'time_iter': 0.16605, 'accuracy': 0.40187, 'f1': 0.24074, 'auc': 0.61822}\n",
      "> Epoch 5: took 17.4s (avg 18.9s) | Best so far: epoch 5\ttrain_loss: 0.8336 train_accuracy: 0.6855\tval_loss: 1.0262 val_accuracy: 0.4906\ttest_loss: 1.1262 test_accuracy: 0.4019\n",
      "train: {'epoch': 6, 'time_epoch': 15.34693, 'eta': 1180.08466, 'eta_hours': 0.3278, 'loss': 0.78649969, 'lr': 0.00099626, 'params': 135811, 'time_iter': 0.2842, 'accuracy': 0.69249, 'f1': 0.69448, 'auc': 0.84554}\n",
      "val: {'epoch': 6, 'time_epoch': 1.33742, 'loss': 1.09564255, 'lr': 0, 'params': 135811, 'time_iter': 0.19106, 'accuracy': 0.40566, 'f1': 0.40513, 'auc': 0.64002}\n",
      "test: {'epoch': 6, 'time_epoch': 1.24681, 'loss': 1.1665456, 'lr': 0, 'params': 135811, 'time_iter': 0.17812, 'accuracy': 0.28972, 'f1': 0.26472, 'auc': 0.57568}\n",
      "> Epoch 6: took 18.0s (avg 18.8s) | Best so far: epoch 5\ttrain_loss: 0.8336 train_accuracy: 0.6855\tval_loss: 1.0262 val_accuracy: 0.4906\ttest_loss: 1.1262 test_accuracy: 0.4019\n",
      "train: {'epoch': 7, 'time_epoch': 15.25643, 'eta': 1155.73707, 'eta_hours': 0.32104, 'loss': 0.70884855, 'lr': 0.00099336, 'params': 135811, 'time_iter': 0.28253, 'accuracy': 0.75469, 'f1': 0.75158, 'auc': 0.87963}\n",
      "val: {'epoch': 7, 'time_epoch': 1.13977, 'loss': 1.2693305, 'lr': 0, 'params': 135811, 'time_iter': 0.16282, 'accuracy': 0.36792, 'f1': 0.27729, 'auc': 0.56754}\n",
      "test: {'epoch': 7, 'time_epoch': 1.12338, 'loss': 1.19099725, 'lr': 0, 'params': 135811, 'time_iter': 0.16048, 'accuracy': 0.42991, 'f1': 0.36348, 'auc': 0.60396}\n",
      "> Epoch 7: took 17.6s (avg 18.6s) | Best so far: epoch 5\ttrain_loss: 0.8336 train_accuracy: 0.6855\tval_loss: 1.0262 val_accuracy: 0.4906\ttest_loss: 1.1262 test_accuracy: 0.4019\n",
      "train: {'epoch': 8, 'time_epoch': 15.57675, 'eta': 1135.93672, 'eta_hours': 0.31554, 'loss': 0.70117745, 'lr': 0.00098963, 'params': 135811, 'time_iter': 0.28846, 'accuracy': 0.73357, 'f1': 0.72383, 'auc': 0.87596}\n",
      "val: {'epoch': 8, 'time_epoch': 1.28009, 'loss': 1.30781039, 'lr': 0, 'params': 135811, 'time_iter': 0.18287, 'accuracy': 0.28302, 'f1': 0.18905, 'auc': 0.6515}\n",
      "test: {'epoch': 8, 'time_epoch': 1.17558, 'loss': 1.31200077, 'lr': 0, 'params': 135811, 'time_iter': 0.16794, 'accuracy': 0.3271, 'f1': 0.25109, 'auc': 0.55552}\n",
      "> Epoch 8: took 18.1s (avg 18.6s) | Best so far: epoch 5\ttrain_loss: 0.8336 train_accuracy: 0.6855\tval_loss: 1.0262 val_accuracy: 0.4906\ttest_loss: 1.1262 test_accuracy: 0.4019\n",
      "train: {'epoch': 9, 'time_epoch': 16.89345, 'eta': 1126.19802, 'eta_hours': 0.31283, 'loss': 0.60519777, 'lr': 0.00098509, 'params': 135811, 'time_iter': 0.31284, 'accuracy': 0.80516, 'f1': 0.80314, 'auc': 0.91424}\n",
      "val: {'epoch': 9, 'time_epoch': 1.28472, 'loss': 1.13106595, 'lr': 0, 'params': 135811, 'time_iter': 0.18353, 'accuracy': 0.50943, 'f1': 0.38523, 'auc': 0.62922}\n",
      "test: {'epoch': 9, 'time_epoch': 1.1723, 'loss': 1.23450482, 'lr': 0, 'params': 135811, 'time_iter': 0.16747, 'accuracy': 0.46729, 'f1': 0.32025, 'auc': 0.63863}\n",
      "> Epoch 9: took 19.4s (avg 18.6s) | Best so far: epoch 9\ttrain_loss: 0.6052 train_accuracy: 0.8052\tval_loss: 1.1311 val_accuracy: 0.5094\ttest_loss: 1.2345 test_accuracy: 0.4673\n",
      "train: {'epoch': 10, 'time_epoch': 29.1664, 'eta': 1192.14332, 'eta_hours': 0.33115, 'loss': 0.58439551, 'lr': 0.00097975, 'params': 135811, 'time_iter': 0.54012, 'accuracy': 0.79812, 'f1': 0.7934, 'auc': 0.91754}\n",
      "val: {'epoch': 10, 'time_epoch': 1.34624, 'loss': 1.17927947, 'lr': 0, 'params': 135811, 'time_iter': 0.19232, 'accuracy': 0.4717, 'f1': 0.44192, 'auc': 0.6443}\n",
      "test: {'epoch': 10, 'time_epoch': 1.18985, 'loss': 1.2559644, 'lr': 0, 'params': 135811, 'time_iter': 0.16998, 'accuracy': 0.42991, 'f1': 0.37436, 'auc': 0.61438}\n",
      "> Epoch 10: took 31.8s (avg 19.8s) | Best so far: epoch 9\ttrain_loss: 0.6052 train_accuracy: 0.8052\tval_loss: 1.1311 val_accuracy: 0.5094\ttest_loss: 1.2345 test_accuracy: 0.4673\n",
      "train: {'epoch': 11, 'time_epoch': 16.27588, 'eta': 1169.19036, 'eta_hours': 0.32478, 'loss': 0.53187871, 'lr': 0.0009736, 'params': 135811, 'time_iter': 0.30141, 'accuracy': 0.82864, 'f1': 0.81966, 'auc': 0.9344}\n",
      "val: {'epoch': 11, 'time_epoch': 1.25508, 'loss': 1.52351534, 'lr': 0, 'params': 135811, 'time_iter': 0.1793, 'accuracy': 0.32075, 'f1': 0.27331, 'auc': 0.63242}\n",
      "test: {'epoch': 11, 'time_epoch': 1.17946, 'loss': 1.51590556, 'lr': 0, 'params': 135811, 'time_iter': 0.16849, 'accuracy': 0.33645, 'f1': 0.2668, 'auc': 0.55594}\n",
      "> Epoch 11: took 18.8s (avg 19.8s) | Best so far: epoch 9\ttrain_loss: 0.6052 train_accuracy: 0.8052\tval_loss: 1.1311 val_accuracy: 0.5094\ttest_loss: 1.2345 test_accuracy: 0.4673\n",
      "train: {'epoch': 12, 'time_epoch': 15.44295, 'eta': 1142.97188, 'eta_hours': 0.31749, 'loss': 0.54640011, 'lr': 0.00096667, 'params': 135811, 'time_iter': 0.28598, 'accuracy': 0.80516, 'f1': 0.79602, 'auc': 0.92863}\n",
      "val: {'epoch': 12, 'time_epoch': 1.26313, 'loss': 1.66108976, 'lr': 0, 'params': 135811, 'time_iter': 0.18045, 'accuracy': 0.27358, 'f1': 0.18326, 'auc': 0.6358}\n",
      "test: {'epoch': 12, 'time_epoch': 1.12188, 'loss': 1.54831419, 'lr': 0, 'params': 135811, 'time_iter': 0.16027, 'accuracy': 0.37383, 'f1': 0.27829, 'auc': 0.56851}\n",
      "> Epoch 12: took 17.9s (avg 19.6s) | Best so far: epoch 9\ttrain_loss: 0.6052 train_accuracy: 0.8052\tval_loss: 1.1311 val_accuracy: 0.5094\ttest_loss: 1.2345 test_accuracy: 0.4673\n",
      "train: {'epoch': 13, 'time_epoch': 26.83688, 'eta': 1172.00697, 'eta_hours': 0.32556, 'loss': 0.48651081, 'lr': 0.00095896, 'params': 135811, 'time_iter': 0.49698, 'accuracy': 0.84155, 'f1': 0.84054, 'auc': 0.93915}\n",
      "val: {'epoch': 13, 'time_epoch': 1.26397, 'loss': 1.30549527, 'lr': 0, 'params': 135811, 'time_iter': 0.18057, 'accuracy': 0.36792, 'f1': 0.33831, 'auc': 0.6212}\n",
      "test: {'epoch': 13, 'time_epoch': 1.17141, 'loss': 1.41886253, 'lr': 0, 'params': 135811, 'time_iter': 0.16734, 'accuracy': 0.30841, 'f1': 0.24906, 'auc': 0.58942}\n",
      "> Epoch 13: took 29.3s (avg 20.3s) | Best so far: epoch 9\ttrain_loss: 0.6052 train_accuracy: 0.8052\tval_loss: 1.1311 val_accuracy: 0.5094\ttest_loss: 1.2345 test_accuracy: 0.4673\n",
      "train: {'epoch': 14, 'time_epoch': 15.82122, 'eta': 1145.85798, 'eta_hours': 0.31829, 'loss': 0.45173767, 'lr': 0.00095048, 'params': 135811, 'time_iter': 0.29299, 'accuracy': 0.86502, 'f1': 0.85794, 'auc': 0.94325}\n",
      "val: {'epoch': 14, 'time_epoch': 1.28535, 'loss': 1.07147657, 'lr': 0, 'params': 135811, 'time_iter': 0.18362, 'accuracy': 0.54717, 'f1': 0.47321, 'auc': 0.70567}\n",
      "test: {'epoch': 14, 'time_epoch': 1.19691, 'loss': 1.26978073, 'lr': 0, 'params': 135811, 'time_iter': 0.17099, 'accuracy': 0.46729, 'f1': 0.38804, 'auc': 0.68813}\n",
      "> Epoch 14: took 18.4s (avg 20.2s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 15, 'time_epoch': 15.56308, 'eta': 1119.96739, 'eta_hours': 0.3111, 'loss': 0.42523811, 'lr': 0.00094126, 'params': 135811, 'time_iter': 0.28821, 'accuracy': 0.87089, 'f1': 0.86725, 'auc': 0.95258}\n",
      "val: {'epoch': 15, 'time_epoch': 1.28133, 'loss': 1.60957018, 'lr': 0, 'params': 135811, 'time_iter': 0.18305, 'accuracy': 0.33962, 'f1': 0.30152, 'auc': 0.61231}\n",
      "test: {'epoch': 15, 'time_epoch': 1.19731, 'loss': 1.5528023, 'lr': 0, 'params': 135811, 'time_iter': 0.17104, 'accuracy': 0.34579, 'f1': 0.30326, 'auc': 0.5289}\n",
      "> Epoch 15: took 18.1s (avg 20.0s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 16, 'time_epoch': 16.07595, 'eta': 1097.19241, 'eta_hours': 0.30478, 'loss': 0.43468777, 'lr': 0.0009313, 'params': 135811, 'time_iter': 0.2977, 'accuracy': 0.85329, 'f1': 0.85197, 'auc': 0.94805}\n",
      "val: {'epoch': 16, 'time_epoch': 1.2858, 'loss': 1.37915794, 'lr': 0, 'params': 135811, 'time_iter': 0.18369, 'accuracy': 0.48113, 'f1': 0.39122, 'auc': 0.62186}\n",
      "test: {'epoch': 16, 'time_epoch': 1.20594, 'loss': 1.51369909, 'lr': 0, 'params': 135811, 'time_iter': 0.17228, 'accuracy': 0.43925, 'f1': 0.32848, 'auc': 0.59492}\n",
      "> Epoch 16: took 18.6s (avg 20.0s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 17, 'time_epoch': 14.98442, 'eta': 1071.40206, 'eta_hours': 0.29761, 'loss': 0.34709259, 'lr': 0.00092063, 'params': 135811, 'time_iter': 0.27749, 'accuracy': 0.90023, 'f1': 0.89459, 'auc': 0.96605}\n",
      "val: {'epoch': 17, 'time_epoch': 1.24159, 'loss': 1.31240966, 'lr': 0, 'params': 135811, 'time_iter': 0.17737, 'accuracy': 0.45283, 'f1': 0.41445, 'auc': 0.6226}\n",
      "test: {'epoch': 17, 'time_epoch': 1.13328, 'loss': 1.5520857, 'lr': 0, 'params': 135811, 'time_iter': 0.1619, 'accuracy': 0.3271, 'f1': 0.27443, 'auc': 0.58243}\n",
      "> Epoch 17: took 17.4s (avg 19.8s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 18, 'time_epoch': 15.5836, 'eta': 1048.67287, 'eta_hours': 0.2913, 'loss': 0.38971405, 'lr': 0.00090925, 'params': 135811, 'time_iter': 0.28859, 'accuracy': 0.87676, 'f1': 0.8716, 'auc': 0.96088}\n",
      "val: {'epoch': 18, 'time_epoch': 1.25479, 'loss': 1.81756343, 'lr': 0, 'params': 135811, 'time_iter': 0.17926, 'accuracy': 0.32075, 'f1': 0.2847, 'auc': 0.60267}\n",
      "test: {'epoch': 18, 'time_epoch': 1.20792, 'loss': 1.70178996, 'lr': 0, 'params': 135811, 'time_iter': 0.17256, 'accuracy': 0.37383, 'f1': 0.31043, 'auc': 0.5525}\n",
      "> Epoch 18: took 18.1s (avg 19.7s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 19, 'time_epoch': 15.57333, 'eta': 1026.62744, 'eta_hours': 0.28517, 'loss': 0.34661101, 'lr': 0.00089719, 'params': 135811, 'time_iter': 0.2884, 'accuracy': 0.89437, 'f1': 0.8895, 'auc': 0.96688}\n",
      "val: {'epoch': 19, 'time_epoch': 1.27659, 'loss': 1.40697686, 'lr': 0, 'params': 135811, 'time_iter': 0.18237, 'accuracy': 0.45283, 'f1': 0.44427, 'auc': 0.6576}\n",
      "test: {'epoch': 19, 'time_epoch': 1.24288, 'loss': 1.30936584, 'lr': 0, 'params': 135811, 'time_iter': 0.17755, 'accuracy': 0.51402, 'f1': 0.50533, 'auc': 0.65316}\n",
      "> Epoch 19: took 18.2s (avg 19.7s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 20, 'time_epoch': 16.19649, 'eta': 1006.94917, 'eta_hours': 0.27971, 'loss': 0.29875542, 'lr': 0.00088448, 'params': 135811, 'time_iter': 0.29994, 'accuracy': 0.91315, 'f1': 0.9138, 'auc': 0.97062}\n",
      "val: {'epoch': 20, 'time_epoch': 1.27893, 'loss': 1.38832451, 'lr': 0, 'params': 135811, 'time_iter': 0.1827, 'accuracy': 0.43396, 'f1': 0.40159, 'auc': 0.60987}\n",
      "test: {'epoch': 20, 'time_epoch': 1.22499, 'loss': 1.56209797, 'lr': 0, 'params': 135811, 'time_iter': 0.175, 'accuracy': 0.38318, 'f1': 0.32942, 'auc': 0.59293}\n",
      "> Epoch 20: took 18.8s (avg 19.6s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 21, 'time_epoch': 15.62985, 'eta': 986.09356, 'eta_hours': 0.27391, 'loss': 0.30350306, 'lr': 0.00087112, 'params': 135811, 'time_iter': 0.28944, 'accuracy': 0.91667, 'f1': 0.91501, 'auc': 0.96739}\n",
      "val: {'epoch': 21, 'time_epoch': 1.18701, 'loss': 1.6887232, 'lr': 0, 'params': 135811, 'time_iter': 0.16957, 'accuracy': 0.43396, 'f1': 0.4019, 'auc': 0.61513}\n",
      "test: {'epoch': 21, 'time_epoch': 1.14115, 'loss': 1.57796485, 'lr': 0, 'params': 135811, 'time_iter': 0.16302, 'accuracy': 0.45794, 'f1': 0.42144, 'auc': 0.62794}\n",
      "> Epoch 21: took 18.0s (avg 19.5s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 22, 'time_epoch': 15.70153, 'eta': 965.87, 'eta_hours': 0.2683, 'loss': 0.3170513, 'lr': 0.00085714, 'params': 135811, 'time_iter': 0.29077, 'accuracy': 0.90962, 'f1': 0.90499, 'auc': 0.96685}\n",
      "val: {'epoch': 22, 'time_epoch': 1.28007, 'loss': 1.68385507, 'lr': 0, 'params': 135811, 'time_iter': 0.18287, 'accuracy': 0.42453, 'f1': 0.39401, 'auc': 0.60828}\n",
      "test: {'epoch': 22, 'time_epoch': 1.21016, 'loss': 1.61280552, 'lr': 0, 'params': 135811, 'time_iter': 0.17288, 'accuracy': 0.4486, 'f1': 0.41298, 'auc': 0.6139}\n",
      "> Epoch 22: took 18.3s (avg 19.5s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 23, 'time_epoch': 16.86374, 'eta': 948.7351, 'eta_hours': 0.26354, 'loss': 0.27578233, 'lr': 0.00084257, 'params': 135811, 'time_iter': 0.31229, 'accuracy': 0.92723, 'f1': 0.92426, 'auc': 0.97692}\n",
      "val: {'epoch': 23, 'time_epoch': 1.27329, 'loss': 1.66255942, 'lr': 0, 'params': 135811, 'time_iter': 0.1819, 'accuracy': 0.36792, 'f1': 0.36324, 'auc': 0.62326}\n",
      "test: {'epoch': 23, 'time_epoch': 1.17521, 'loss': 1.63405474, 'lr': 0, 'params': 135811, 'time_iter': 0.16789, 'accuracy': 0.40187, 'f1': 0.37399, 'auc': 0.63896}\n",
      "> Epoch 23: took 19.4s (avg 19.5s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 24, 'time_epoch': 15.51594, 'eta': 928.65673, 'eta_hours': 0.25796, 'loss': 0.2516653, 'lr': 0.00082743, 'params': 135811, 'time_iter': 0.28733, 'accuracy': 0.93192, 'f1': 0.92991, 'auc': 0.97923}\n",
      "val: {'epoch': 24, 'time_epoch': 1.12122, 'loss': 1.53498436, 'lr': 0, 'params': 135811, 'time_iter': 0.16017, 'accuracy': 0.51887, 'f1': 0.49501, 'auc': 0.64513}\n",
      "test: {'epoch': 24, 'time_epoch': 1.15199, 'loss': 1.45443237, 'lr': 0, 'params': 135811, 'time_iter': 0.16457, 'accuracy': 0.52336, 'f1': 0.49235, 'auc': 0.673}\n",
      "> Epoch 24: took 17.9s (avg 19.4s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 25, 'time_epoch': 15.6697, 'eta': 909.24867, 'eta_hours': 0.25257, 'loss': 0.23973022, 'lr': 0.00081174, 'params': 135811, 'time_iter': 0.29018, 'accuracy': 0.93427, 'f1': 0.9298, 'auc': 0.9805}\n",
      "val: {'epoch': 25, 'time_epoch': 1.26891, 'loss': 1.73344869, 'lr': 0, 'params': 135811, 'time_iter': 0.18127, 'accuracy': 0.41509, 'f1': 0.41832, 'auc': 0.64415}\n",
      "test: {'epoch': 25, 'time_epoch': 1.19435, 'loss': 1.64161922, 'lr': 0, 'params': 135811, 'time_iter': 0.17062, 'accuracy': 0.48598, 'f1': 0.46783, 'auc': 0.59754}\n",
      "> Epoch 25: took 18.2s (avg 19.4s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 26, 'time_epoch': 16.21449, 'eta': 891.18693, 'eta_hours': 0.24755, 'loss': 0.22159585, 'lr': 0.00079554, 'params': 135811, 'time_iter': 0.30027, 'accuracy': 0.94014, 'f1': 0.93757, 'auc': 0.98418}\n",
      "val: {'epoch': 26, 'time_epoch': 1.23731, 'loss': 1.81228162, 'lr': 0, 'params': 135811, 'time_iter': 0.17676, 'accuracy': 0.38679, 'f1': 0.37687, 'auc': 0.60144}\n",
      "test: {'epoch': 26, 'time_epoch': 1.18295, 'loss': 1.70249781, 'lr': 0, 'params': 135811, 'time_iter': 0.16899, 'accuracy': 0.4486, 'f1': 0.44568, 'auc': 0.62683}\n",
      "> Epoch 26: took 18.7s (avg 19.3s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 27, 'time_epoch': 15.77596, 'eta': 872.44272, 'eta_hours': 0.24235, 'loss': 0.24122254, 'lr': 0.00077884, 'params': 135811, 'time_iter': 0.29215, 'accuracy': 0.92254, 'f1': 0.92075, 'auc': 0.98243}\n",
      "val: {'epoch': 27, 'time_epoch': 1.26141, 'loss': 1.57736427, 'lr': 0, 'params': 135811, 'time_iter': 0.1802, 'accuracy': 0.48113, 'f1': 0.45568, 'auc': 0.66164}\n",
      "test: {'epoch': 27, 'time_epoch': 1.18323, 'loss': 1.51027854, 'lr': 0, 'params': 135811, 'time_iter': 0.16903, 'accuracy': 0.53271, 'f1': 0.49222, 'auc': 0.68282}\n",
      "> Epoch 27: took 18.3s (avg 19.3s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 28, 'time_epoch': 16.42292, 'eta': 855.04098, 'eta_hours': 0.23751, 'loss': 0.22409708, 'lr': 0.00076168, 'params': 135811, 'time_iter': 0.30413, 'accuracy': 0.93779, 'f1': 0.93511, 'auc': 0.9836}\n",
      "val: {'epoch': 28, 'time_epoch': 1.30166, 'loss': 2.08738722, 'lr': 0, 'params': 135811, 'time_iter': 0.18595, 'accuracy': 0.38679, 'f1': 0.34315, 'auc': 0.60362}\n",
      "test: {'epoch': 28, 'time_epoch': 1.18893, 'loss': 1.9430462, 'lr': 0, 'params': 135811, 'time_iter': 0.16985, 'accuracy': 0.41121, 'f1': 0.35704, 'auc': 0.61244}\n",
      "> Epoch 28: took 19.0s (avg 19.3s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 29, 'time_epoch': 15.81247, 'eta': 836.68707, 'eta_hours': 0.23241, 'loss': 0.2155571, 'lr': 0.00074409, 'params': 135811, 'time_iter': 0.29282, 'accuracy': 0.93662, 'f1': 0.93321, 'auc': 0.98699}\n",
      "val: {'epoch': 29, 'time_epoch': 1.26511, 'loss': 1.74499723, 'lr': 0, 'params': 135811, 'time_iter': 0.18073, 'accuracy': 0.46226, 'f1': 0.39749, 'auc': 0.65583}\n",
      "test: {'epoch': 29, 'time_epoch': 1.21997, 'loss': 1.66112489, 'lr': 0, 'params': 135811, 'time_iter': 0.17428, 'accuracy': 0.50467, 'f1': 0.45617, 'auc': 0.65289}\n",
      "> Epoch 29: took 18.4s (avg 19.3s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 30, 'time_epoch': 27.57492, 'eta': 837.08938, 'eta_hours': 0.23252, 'loss': 0.15563438, 'lr': 0.00072609, 'params': 135811, 'time_iter': 0.51065, 'accuracy': 0.96127, 'f1': 0.96113, 'auc': 0.99019}\n",
      "val: {'epoch': 30, 'time_epoch': 1.25311, 'loss': 1.68781728, 'lr': 0, 'params': 135811, 'time_iter': 0.17902, 'accuracy': 0.48113, 'f1': 0.47135, 'auc': 0.6423}\n",
      "test: {'epoch': 30, 'time_epoch': 1.21341, 'loss': 1.57723859, 'lr': 0, 'params': 135811, 'time_iter': 0.17334, 'accuracy': 0.52336, 'f1': 0.51286, 'auc': 0.62992}\n",
      "> Epoch 30: took 30.1s (avg 19.6s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 31, 'time_epoch': 16.0608, 'eta': 818.47193, 'eta_hours': 0.22735, 'loss': 0.18357607, 'lr': 0.00070771, 'params': 135811, 'time_iter': 0.29742, 'accuracy': 0.9554, 'f1': 0.95181, 'auc': 0.98684}\n",
      "val: {'epoch': 31, 'time_epoch': 1.24912, 'loss': 1.89290008, 'lr': 0, 'params': 135811, 'time_iter': 0.17845, 'accuracy': 0.40566, 'f1': 0.40765, 'auc': 0.62669}\n",
      "test: {'epoch': 31, 'time_epoch': 1.19373, 'loss': 1.87669344, 'lr': 0, 'params': 135811, 'time_iter': 0.17053, 'accuracy': 0.38318, 'f1': 0.38131, 'auc': 0.6046}\n",
      "> Epoch 31: took 18.6s (avg 19.6s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 32, 'time_epoch': 27.40576, 'eta': 816.16742, 'eta_hours': 0.22671, 'loss': 0.17136438, 'lr': 0.00068898, 'params': 135811, 'time_iter': 0.50751, 'accuracy': 0.95188, 'f1': 0.95213, 'auc': 0.99141}\n",
      "val: {'epoch': 32, 'time_epoch': 1.27977, 'loss': 2.12325636, 'lr': 0, 'params': 135811, 'time_iter': 0.18282, 'accuracy': 0.36792, 'f1': 0.34312, 'auc': 0.61079}\n",
      "test: {'epoch': 32, 'time_epoch': 1.17031, 'loss': 2.03705431, 'lr': 0, 'params': 135811, 'time_iter': 0.16719, 'accuracy': 0.4486, 'f1': 0.40727, 'auc': 0.55985}\n",
      "> Epoch 32: took 29.9s (avg 19.9s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 33, 'time_epoch': 16.12826, 'eta': 797.12855, 'eta_hours': 0.22142, 'loss': 0.15554501, 'lr': 0.00066994, 'params': 135811, 'time_iter': 0.29867, 'accuracy': 0.96362, 'f1': 0.96302, 'auc': 0.98744}\n",
      "val: {'epoch': 33, 'time_epoch': 1.24846, 'loss': 1.83638092, 'lr': 0, 'params': 135811, 'time_iter': 0.17835, 'accuracy': 0.5, 'f1': 0.42255, 'auc': 0.6209}\n",
      "test: {'epoch': 33, 'time_epoch': 1.14926, 'loss': 1.85099302, 'lr': 0, 'params': 135811, 'time_iter': 0.16418, 'accuracy': 0.52336, 'f1': 0.45647, 'auc': 0.65257}\n",
      "> Epoch 33: took 18.6s (avg 19.9s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 34, 'time_epoch': 16.43199, 'eta': 778.64653, 'eta_hours': 0.21629, 'loss': 0.11536249, 'lr': 0.00065062, 'params': 135811, 'time_iter': 0.3043, 'accuracy': 0.97535, 'f1': 0.97321, 'auc': 0.99391}\n",
      "val: {'epoch': 34, 'time_epoch': 1.25802, 'loss': 1.88011874, 'lr': 0, 'params': 135811, 'time_iter': 0.17972, 'accuracy': 0.50943, 'f1': 0.45545, 'auc': 0.62011}\n",
      "test: {'epoch': 34, 'time_epoch': 1.24213, 'loss': 1.74784035, 'lr': 0, 'params': 135811, 'time_iter': 0.17745, 'accuracy': 0.53271, 'f1': 0.4799, 'auc': 0.67674}\n",
      "> Epoch 34: took 19.0s (avg 19.8s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 35, 'time_epoch': 16.0707, 'eta': 759.83682, 'eta_hours': 0.21107, 'loss': 0.10813998, 'lr': 0.00063105, 'params': 135811, 'time_iter': 0.29761, 'accuracy': 0.97653, 'f1': 0.97636, 'auc': 0.99241}\n",
      "val: {'epoch': 35, 'time_epoch': 1.30779, 'loss': 1.99466018, 'lr': 0, 'params': 135811, 'time_iter': 0.18683, 'accuracy': 0.48113, 'f1': 0.41083, 'auc': 0.63205}\n",
      "test: {'epoch': 35, 'time_epoch': 1.24004, 'loss': 1.87032298, 'lr': 0, 'params': 135811, 'time_iter': 0.17715, 'accuracy': 0.51402, 'f1': 0.44586, 'auc': 0.64687}\n",
      "> Epoch 35: took 18.7s (avg 19.8s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 36, 'time_epoch': 16.26558, 'eta': 741.40164, 'eta_hours': 0.20594, 'loss': 0.14517606, 'lr': 0.00061126, 'params': 135811, 'time_iter': 0.30121, 'accuracy': 0.96244, 'f1': 0.96035, 'auc': 0.99211}\n",
      "val: {'epoch': 36, 'time_epoch': 1.29566, 'loss': 2.07025069, 'lr': 0, 'params': 135811, 'time_iter': 0.18509, 'accuracy': 0.43396, 'f1': 0.41929, 'auc': 0.61709}\n",
      "test: {'epoch': 36, 'time_epoch': 1.22187, 'loss': 2.08461163, 'lr': 0, 'params': 135811, 'time_iter': 0.17455, 'accuracy': 0.4486, 'f1': 0.44103, 'auc': 0.59227}\n",
      "> Epoch 36: took 18.8s (avg 19.8s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 37, 'time_epoch': 15.97918, 'eta': 722.7641, 'eta_hours': 0.20077, 'loss': 0.13079336, 'lr': 0.00059128, 'params': 135811, 'time_iter': 0.29591, 'accuracy': 0.96831, 'f1': 0.96488, 'auc': 0.99272}\n",
      "val: {'epoch': 37, 'time_epoch': 1.27569, 'loss': 2.11375272, 'lr': 0, 'params': 135811, 'time_iter': 0.18224, 'accuracy': 0.4434, 'f1': 0.37116, 'auc': 0.61347}\n",
      "test: {'epoch': 37, 'time_epoch': 1.25906, 'loss': 1.98332201, 'lr': 0, 'params': 135811, 'time_iter': 0.17987, 'accuracy': 0.49533, 'f1': 0.44128, 'auc': 0.61438}\n",
      "> Epoch 37: took 18.6s (avg 19.7s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 38, 'time_epoch': 27.25984, 'eta': 716.12204, 'eta_hours': 0.19892, 'loss': 0.10076565, 'lr': 0.00057116, 'params': 135811, 'time_iter': 0.50481, 'accuracy': 0.9777, 'f1': 0.97479, 'auc': 0.99465}\n",
      "val: {'epoch': 38, 'time_epoch': 1.29339, 'loss': 2.01547425, 'lr': 0, 'params': 135811, 'time_iter': 0.18477, 'accuracy': 0.4434, 'f1': 0.44265, 'auc': 0.62582}\n",
      "test: {'epoch': 38, 'time_epoch': 1.21058, 'loss': 1.75579652, 'lr': 0, 'params': 135811, 'time_iter': 0.17294, 'accuracy': 0.47664, 'f1': 0.47403, 'auc': 0.67334}\n",
      "> Epoch 38: took 29.8s (avg 20.0s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 39, 'time_epoch': 15.08423, 'eta': 696.27349, 'eta_hours': 0.19341, 'loss': 0.13539727, 'lr': 0.00055091, 'params': 135811, 'time_iter': 0.27934, 'accuracy': 0.96479, 'f1': 0.96483, 'auc': 0.99479}\n",
      "val: {'epoch': 39, 'time_epoch': 1.2588, 'loss': 1.9586126, 'lr': 0, 'params': 135811, 'time_iter': 0.17983, 'accuracy': 0.43396, 'f1': 0.40691, 'auc': 0.60916}\n",
      "test: {'epoch': 39, 'time_epoch': 1.18267, 'loss': 1.88326208, 'lr': 0, 'params': 135811, 'time_iter': 0.16895, 'accuracy': 0.46729, 'f1': 0.43575, 'auc': 0.66118}\n",
      "> Epoch 39: took 17.6s (avg 19.9s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 40, 'time_epoch': 15.77215, 'eta': 677.31171, 'eta_hours': 0.18814, 'loss': 0.09793559, 'lr': 0.00053058, 'params': 135811, 'time_iter': 0.29208, 'accuracy': 0.97887, 'f1': 0.97835, 'auc': 0.99459}\n",
      "val: {'epoch': 40, 'time_epoch': 1.24747, 'loss': 2.1326758, 'lr': 0, 'params': 135811, 'time_iter': 0.17821, 'accuracy': 0.43396, 'f1': 0.43097, 'auc': 0.6081}\n",
      "test: {'epoch': 40, 'time_epoch': 1.20972, 'loss': 1.96079088, 'lr': 0, 'params': 135811, 'time_iter': 0.17282, 'accuracy': 0.50467, 'f1': 0.49831, 'auc': 0.637}\n",
      "> Epoch 40: took 18.3s (avg 19.9s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 41, 'time_epoch': 15.90447, 'eta': 658.62153, 'eta_hours': 0.18295, 'loss': 0.09980696, 'lr': 0.0005102, 'params': 135811, 'time_iter': 0.29453, 'accuracy': 0.97418, 'f1': 0.97141, 'auc': 0.99764}\n",
      "val: {'epoch': 41, 'time_epoch': 1.28469, 'loss': 1.97591197, 'lr': 0, 'params': 135811, 'time_iter': 0.18353, 'accuracy': 0.46226, 'f1': 0.46231, 'auc': 0.63222}\n",
      "test: {'epoch': 41, 'time_epoch': 1.23082, 'loss': 1.86420927, 'lr': 0, 'params': 135811, 'time_iter': 0.17583, 'accuracy': 0.51402, 'f1': 0.51266, 'auc': 0.64482}\n",
      "> Epoch 41: took 18.5s (avg 19.9s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 42, 'time_epoch': 16.23218, 'eta': 640.3429, 'eta_hours': 0.17787, 'loss': 0.12320591, 'lr': 0.0004898, 'params': 135811, 'time_iter': 0.3006, 'accuracy': 0.97066, 'f1': 0.96779, 'auc': 0.99476}\n",
      "val: {'epoch': 42, 'time_epoch': 1.13295, 'loss': 1.98566076, 'lr': 0, 'params': 135811, 'time_iter': 0.16185, 'accuracy': 0.4717, 'f1': 0.46539, 'auc': 0.62688}\n",
      "test: {'epoch': 42, 'time_epoch': 1.16964, 'loss': 1.78734141, 'lr': 0, 'params': 135811, 'time_iter': 0.16709, 'accuracy': 0.47664, 'f1': 0.46989, 'auc': 0.66812}\n",
      "> Epoch 42: took 18.6s (avg 19.8s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 43, 'time_epoch': 27.07511, 'eta': 631.02879, 'eta_hours': 0.17529, 'loss': 0.08807633, 'lr': 0.00046942, 'params': 135811, 'time_iter': 0.50139, 'accuracy': 0.9777, 'f1': 0.97691, 'auc': 0.9967}\n",
      "val: {'epoch': 43, 'time_epoch': 1.21337, 'loss': 2.05948042, 'lr': 0, 'params': 135811, 'time_iter': 0.17334, 'accuracy': 0.49057, 'f1': 0.46873, 'auc': 0.63337}\n",
      "test: {'epoch': 43, 'time_epoch': 1.1789, 'loss': 1.79578884, 'lr': 0, 'params': 135811, 'time_iter': 0.16841, 'accuracy': 0.5514, 'f1': 0.52177, 'auc': 0.70287}\n",
      "> Epoch 43: took 29.5s (avg 20.1s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 44, 'time_epoch': 15.55753, 'eta': 611.96717, 'eta_hours': 0.16999, 'loss': 0.0838392, 'lr': 0.00044909, 'params': 135811, 'time_iter': 0.2881, 'accuracy': 0.98122, 'f1': 0.97907, 'auc': 0.99679}\n",
      "val: {'epoch': 44, 'time_epoch': 1.29003, 'loss': 2.1645408, 'lr': 0, 'params': 135811, 'time_iter': 0.18429, 'accuracy': 0.43396, 'f1': 0.43608, 'auc': 0.63206}\n",
      "test: {'epoch': 44, 'time_epoch': 1.12745, 'loss': 1.78298394, 'lr': 0, 'params': 135811, 'time_iter': 0.16106, 'accuracy': 0.54206, 'f1': 0.54196, 'auc': 0.64907}\n",
      "> Epoch 44: took 18.1s (avg 20.0s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 45, 'time_epoch': 16.54564, 'eta': 593.78825, 'eta_hours': 0.16494, 'loss': 0.08478957, 'lr': 0.00042884, 'params': 135811, 'time_iter': 0.3064, 'accuracy': 0.98122, 'f1': 0.97995, 'auc': 0.99585}\n",
      "val: {'epoch': 45, 'time_epoch': 1.30352, 'loss': 2.06674671, 'lr': 0, 'params': 135811, 'time_iter': 0.18622, 'accuracy': 0.46226, 'f1': 0.45561, 'auc': 0.62399}\n",
      "test: {'epoch': 45, 'time_epoch': 1.23622, 'loss': 1.86317166, 'lr': 0, 'params': 135811, 'time_iter': 0.1766, 'accuracy': 0.52336, 'f1': 0.51226, 'auc': 0.6702}\n",
      "> Epoch 45: took 19.2s (avg 20.0s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 46, 'time_epoch': 27.86435, 'eta': 583.62601, 'eta_hours': 0.16212, 'loss': 0.05839898, 'lr': 0.00040872, 'params': 135811, 'time_iter': 0.51601, 'accuracy': 0.99178, 'f1': 0.99167, 'auc': 0.99672}\n",
      "val: {'epoch': 46, 'time_epoch': 1.23709, 'loss': 2.1143175, 'lr': 0, 'params': 135811, 'time_iter': 0.17673, 'accuracy': 0.46226, 'f1': 0.4456, 'auc': 0.63598}\n",
      "test: {'epoch': 46, 'time_epoch': 1.19983, 'loss': 1.88146012, 'lr': 0, 'params': 135811, 'time_iter': 0.1714, 'accuracy': 0.49533, 'f1': 0.48204, 'auc': 0.6547}\n",
      "> Epoch 46: took 30.4s (avg 20.2s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 47, 'time_epoch': 15.46086, 'eta': 564.45719, 'eta_hours': 0.15679, 'loss': 0.08332859, 'lr': 0.00038874, 'params': 135811, 'time_iter': 0.28631, 'accuracy': 0.98239, 'f1': 0.98202, 'auc': 0.99724}\n",
      "val: {'epoch': 47, 'time_epoch': 1.21179, 'loss': 2.30745464, 'lr': 0, 'params': 135811, 'time_iter': 0.17311, 'accuracy': 0.41509, 'f1': 0.41902, 'auc': 0.60998}\n",
      "test: {'epoch': 47, 'time_epoch': 1.17189, 'loss': 2.07260758, 'lr': 0, 'params': 135811, 'time_iter': 0.16741, 'accuracy': 0.49533, 'f1': 0.4922, 'auc': 0.63609}\n",
      "> Epoch 47: took 17.9s (avg 20.2s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 48, 'time_epoch': 15.55359, 'eta': 545.49838, 'eta_hours': 0.15153, 'loss': 0.05789526, 'lr': 0.00036895, 'params': 135811, 'time_iter': 0.28803, 'accuracy': 0.99296, 'f1': 0.9931, 'auc': 0.99739}\n",
      "val: {'epoch': 48, 'time_epoch': 1.28669, 'loss': 2.13418772, 'lr': 0, 'params': 135811, 'time_iter': 0.18381, 'accuracy': 0.45283, 'f1': 0.45428, 'auc': 0.63372}\n",
      "test: {'epoch': 48, 'time_epoch': 1.18634, 'loss': 1.84663769, 'lr': 0, 'params': 135811, 'time_iter': 0.16948, 'accuracy': 0.53271, 'f1': 0.5306, 'auc': 0.65189}\n",
      "> Epoch 48: took 18.1s (avg 20.1s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 49, 'time_epoch': 16.61234, 'eta': 527.31103, 'eta_hours': 0.14648, 'loss': 0.06523689, 'lr': 0.00034938, 'params': 135811, 'time_iter': 0.30764, 'accuracy': 0.98592, 'f1': 0.98587, 'auc': 0.99871}\n",
      "val: {'epoch': 49, 'time_epoch': 1.28929, 'loss': 2.00261583, 'lr': 0, 'params': 135811, 'time_iter': 0.18418, 'accuracy': 0.5, 'f1': 0.48265, 'auc': 0.62203}\n",
      "test: {'epoch': 49, 'time_epoch': 1.18062, 'loss': 1.88387351, 'lr': 0, 'params': 135811, 'time_iter': 0.16866, 'accuracy': 0.56075, 'f1': 0.54225, 'auc': 0.68788}\n",
      "> Epoch 49: took 19.2s (avg 20.1s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 50, 'time_epoch': 15.55775, 'eta': 508.58578, 'eta_hours': 0.14127, 'loss': 0.05520623, 'lr': 0.00033006, 'params': 135811, 'time_iter': 0.28811, 'accuracy': 0.99061, 'f1': 0.99027, 'auc': 0.99861}\n",
      "val: {'epoch': 50, 'time_epoch': 1.273, 'loss': 2.13057686, 'lr': 0, 'params': 135811, 'time_iter': 0.18186, 'accuracy': 0.46226, 'f1': 0.44194, 'auc': 0.63454}\n",
      "test: {'epoch': 50, 'time_epoch': 1.16112, 'loss': 1.86922863, 'lr': 0, 'params': 135811, 'time_iter': 0.16587, 'accuracy': 0.57009, 'f1': 0.55004, 'auc': 0.66232}\n",
      "> Epoch 50: took 18.1s (avg 20.1s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 51, 'time_epoch': 15.92799, 'eta': 490.18171, 'eta_hours': 0.13616, 'loss': 0.0613697, 'lr': 0.00031102, 'params': 135811, 'time_iter': 0.29496, 'accuracy': 0.98709, 'f1': 0.98639, 'auc': 0.99887}\n",
      "val: {'epoch': 51, 'time_epoch': 1.26824, 'loss': 2.32375044, 'lr': 0, 'params': 135811, 'time_iter': 0.18118, 'accuracy': 0.45283, 'f1': 0.42567, 'auc': 0.61876}\n",
      "test: {'epoch': 51, 'time_epoch': 1.1502, 'loss': 2.1112579, 'lr': 0, 'params': 135811, 'time_iter': 0.16431, 'accuracy': 0.48598, 'f1': 0.47283, 'auc': 0.64755}\n",
      "> Epoch 51: took 18.4s (avg 20.0s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 52, 'time_epoch': 27.64558, 'eta': 477.84042, 'eta_hours': 0.13273, 'loss': 0.07483437, 'lr': 0.00029229, 'params': 135811, 'time_iter': 0.51196, 'accuracy': 0.98239, 'f1': 0.98178, 'auc': 0.99812}\n",
      "val: {'epoch': 52, 'time_epoch': 1.30916, 'loss': 2.41386117, 'lr': 0, 'params': 135811, 'time_iter': 0.18702, 'accuracy': 0.43396, 'f1': 0.43037, 'auc': 0.61049}\n",
      "test: {'epoch': 52, 'time_epoch': 1.22238, 'loss': 2.14543009, 'lr': 0, 'params': 135811, 'time_iter': 0.17463, 'accuracy': 0.47664, 'f1': 0.4645, 'auc': 0.64211}\n",
      "> Epoch 52: took 30.3s (avg 20.2s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 53, 'time_epoch': 16.44637, 'eta': 459.54009, 'eta_hours': 0.12765, 'loss': 0.0540489, 'lr': 0.00027391, 'params': 135811, 'time_iter': 0.30456, 'accuracy': 0.98944, 'f1': 0.98917, 'auc': 0.99857}\n",
      "val: {'epoch': 53, 'time_epoch': 1.2532, 'loss': 2.24200476, 'lr': 0, 'params': 135811, 'time_iter': 0.17903, 'accuracy': 0.42453, 'f1': 0.41613, 'auc': 0.62299}\n",
      "test: {'epoch': 53, 'time_epoch': 1.19027, 'loss': 1.97405211, 'lr': 0, 'params': 135811, 'time_iter': 0.17004, 'accuracy': 0.48598, 'f1': 0.4848, 'auc': 0.6519}\n",
      "> Epoch 53: took 19.0s (avg 20.2s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 54, 'time_epoch': 27.23153, 'eta': 446.20952, 'eta_hours': 0.12395, 'loss': 0.0636326, 'lr': 0.00025591, 'params': 135811, 'time_iter': 0.50429, 'accuracy': 0.98709, 'f1': 0.98718, 'auc': 0.9977}\n",
      "val: {'epoch': 54, 'time_epoch': 1.282, 'loss': 2.1296395, 'lr': 0, 'params': 135811, 'time_iter': 0.18314, 'accuracy': 0.4717, 'f1': 0.4622, 'auc': 0.62445}\n",
      "test: {'epoch': 54, 'time_epoch': 1.24219, 'loss': 1.87654097, 'lr': 0, 'params': 135811, 'time_iter': 0.17746, 'accuracy': 0.53271, 'f1': 0.52163, 'auc': 0.66442}\n",
      "> Epoch 54: took 29.8s (avg 20.4s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 55, 'time_epoch': 15.71877, 'eta': 427.44845, 'eta_hours': 0.11874, 'loss': 0.05208671, 'lr': 0.00023832, 'params': 135811, 'time_iter': 0.29109, 'accuracy': 0.99178, 'f1': 0.99135, 'auc': 0.99868}\n",
      "val: {'epoch': 55, 'time_epoch': 1.26789, 'loss': 2.37810285, 'lr': 0, 'params': 135811, 'time_iter': 0.18113, 'accuracy': 0.42453, 'f1': 0.40997, 'auc': 0.61141}\n",
      "test: {'epoch': 55, 'time_epoch': 1.18134, 'loss': 2.09223302, 'lr': 0, 'params': 135811, 'time_iter': 0.16876, 'accuracy': 0.48598, 'f1': 0.46903, 'auc': 0.65973}\n",
      "> Epoch 55: took 18.2s (avg 20.3s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 56, 'time_epoch': 15.83143, 'eta': 408.83958, 'eta_hours': 0.11357, 'loss': 0.07089813, 'lr': 0.00022116, 'params': 135811, 'time_iter': 0.29317, 'accuracy': 0.98709, 'f1': 0.98489, 'auc': 0.99814}\n",
      "val: {'epoch': 56, 'time_epoch': 1.13303, 'loss': 2.13944824, 'lr': 0, 'params': 135811, 'time_iter': 0.16186, 'accuracy': 0.49057, 'f1': 0.46668, 'auc': 0.63316}\n",
      "test: {'epoch': 56, 'time_epoch': 1.1238, 'loss': 2.01073564, 'lr': 0, 'params': 135811, 'time_iter': 0.16054, 'accuracy': 0.51402, 'f1': 0.49319, 'auc': 0.64703}\n",
      "> Epoch 56: took 18.1s (avg 20.3s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 57, 'time_epoch': 15.54074, 'eta': 390.21623, 'eta_hours': 0.10839, 'loss': 0.06724244, 'lr': 0.00020446, 'params': 135811, 'time_iter': 0.28779, 'accuracy': 0.98474, 'f1': 0.98522, 'auc': 0.99791}\n",
      "val: {'epoch': 57, 'time_epoch': 1.27771, 'loss': 2.17815122, 'lr': 0, 'params': 135811, 'time_iter': 0.18253, 'accuracy': 0.48113, 'f1': 0.47413, 'auc': 0.6398}\n",
      "test: {'epoch': 57, 'time_epoch': 1.22363, 'loss': 1.94981023, 'lr': 0, 'params': 135811, 'time_iter': 0.1748, 'accuracy': 0.53271, 'f1': 0.51509, 'auc': 0.66701}\n",
      "> Epoch 57: took 18.1s (avg 20.3s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 58, 'time_epoch': 15.9061, 'eta': 371.82742, 'eta_hours': 0.10329, 'loss': 0.04616391, 'lr': 0.00018826, 'params': 135811, 'time_iter': 0.29456, 'accuracy': 0.99061, 'f1': 0.98961, 'auc': 0.99913}\n",
      "val: {'epoch': 58, 'time_epoch': 1.33556, 'loss': 2.19092041, 'lr': 0, 'params': 135811, 'time_iter': 0.19079, 'accuracy': 0.4717, 'f1': 0.46333, 'auc': 0.61904}\n",
      "test: {'epoch': 58, 'time_epoch': 1.21167, 'loss': 1.93308476, 'lr': 0, 'params': 135811, 'time_iter': 0.1731, 'accuracy': 0.52336, 'f1': 0.51524, 'auc': 0.66045}\n",
      "> Epoch 58: took 18.5s (avg 20.2s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 59, 'time_epoch': 15.99155, 'eta': 353.54985, 'eta_hours': 0.09821, 'loss': 0.03932885, 'lr': 0.00017257, 'params': 135811, 'time_iter': 0.29614, 'accuracy': 0.99531, 'f1': 0.99508, 'auc': 0.99952}\n",
      "val: {'epoch': 59, 'time_epoch': 1.36166, 'loss': 2.14764169, 'lr': 0, 'params': 135811, 'time_iter': 0.19452, 'accuracy': 0.48113, 'f1': 0.46444, 'auc': 0.62868}\n",
      "test: {'epoch': 59, 'time_epoch': 1.23024, 'loss': 2.02809068, 'lr': 0, 'params': 135811, 'time_iter': 0.17575, 'accuracy': 0.54206, 'f1': 0.51711, 'auc': 0.65354}\n",
      "> Epoch 59: took 18.7s (avg 20.2s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 60, 'time_epoch': 16.54922, 'eta': 335.52093, 'eta_hours': 0.0932, 'loss': 0.04543079, 'lr': 0.00015743, 'params': 135811, 'time_iter': 0.30647, 'accuracy': 0.99296, 'f1': 0.99181, 'auc': 0.9986}\n",
      "val: {'epoch': 60, 'time_epoch': 1.27799, 'loss': 2.17138866, 'lr': 0, 'params': 135811, 'time_iter': 0.18257, 'accuracy': 0.4717, 'f1': 0.45641, 'auc': 0.6393}\n",
      "test: {'epoch': 60, 'time_epoch': 1.17432, 'loss': 1.99457752, 'lr': 0, 'params': 135811, 'time_iter': 0.16776, 'accuracy': 0.5514, 'f1': 0.52786, 'auc': 0.65807}\n",
      "> Epoch 60: took 19.1s (avg 20.2s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 61, 'time_epoch': 15.2495, 'eta': 317.1624, 'eta_hours': 0.0881, 'loss': 0.04364904, 'lr': 0.00014286, 'params': 135811, 'time_iter': 0.2824, 'accuracy': 0.99296, 'f1': 0.99364, 'auc': 0.99846}\n",
      "val: {'epoch': 61, 'time_epoch': 1.21815, 'loss': 2.11074678, 'lr': 0, 'params': 135811, 'time_iter': 0.17402, 'accuracy': 0.5, 'f1': 0.46545, 'auc': 0.63236}\n",
      "test: {'epoch': 61, 'time_epoch': 1.1059, 'loss': 2.07287729, 'lr': 0, 'params': 135811, 'time_iter': 0.15799, 'accuracy': 0.5514, 'f1': 0.51653, 'auc': 0.66468}\n",
      "> Epoch 61: took 17.6s (avg 20.2s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 62, 'time_epoch': 16.81897, 'eta': 299.32608, 'eta_hours': 0.08315, 'loss': 0.04593101, 'lr': 0.00012888, 'params': 135811, 'time_iter': 0.31146, 'accuracy': 0.99178, 'f1': 0.99135, 'auc': 0.99929}\n",
      "val: {'epoch': 62, 'time_epoch': 1.19677, 'loss': 2.13899665, 'lr': 0, 'params': 135811, 'time_iter': 0.17097, 'accuracy': 0.49057, 'f1': 0.46717, 'auc': 0.64537}\n",
      "test: {'epoch': 62, 'time_epoch': 1.04911, 'loss': 1.93437489, 'lr': 0, 'params': 135811, 'time_iter': 0.14987, 'accuracy': 0.54206, 'f1': 0.50828, 'auc': 0.68375}\n",
      "> Epoch 62: took 19.1s (avg 20.1s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 63, 'time_epoch': 15.86085, 'eta': 281.28202, 'eta_hours': 0.07813, 'loss': 0.05730922, 'lr': 0.00011552, 'params': 135811, 'time_iter': 0.29372, 'accuracy': 0.98826, 'f1': 0.98829, 'auc': 0.99865}\n",
      "val: {'epoch': 63, 'time_epoch': 1.27443, 'loss': 2.17677892, 'lr': 0, 'params': 135811, 'time_iter': 0.18206, 'accuracy': 0.48113, 'f1': 0.46689, 'auc': 0.63868}\n",
      "test: {'epoch': 63, 'time_epoch': 1.21311, 'loss': 1.96551468, 'lr': 0, 'params': 135811, 'time_iter': 0.1733, 'accuracy': 0.52336, 'f1': 0.50795, 'auc': 0.67468}\n",
      "> Epoch 63: took 18.4s (avg 20.1s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 64, 'time_epoch': 16.22217, 'eta': 263.38852, 'eta_hours': 0.07316, 'loss': 0.05202549, 'lr': 0.00010281, 'params': 135811, 'time_iter': 0.30041, 'accuracy': 0.98944, 'f1': 0.9897, 'auc': 0.99859}\n",
      "val: {'epoch': 64, 'time_epoch': 1.27087, 'loss': 2.26928975, 'lr': 0, 'params': 135811, 'time_iter': 0.18155, 'accuracy': 0.49057, 'f1': 0.48105, 'auc': 0.62457}\n",
      "test: {'epoch': 64, 'time_epoch': 1.18458, 'loss': 2.08490572, 'lr': 0, 'params': 135811, 'time_iter': 0.16923, 'accuracy': 0.53271, 'f1': 0.52256, 'auc': 0.64181}\n",
      "> Epoch 64: took 18.8s (avg 20.1s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 65, 'time_epoch': 16.61123, 'eta': 245.62819, 'eta_hours': 0.06823, 'loss': 0.04039826, 'lr': 9.075e-05, 'params': 135811, 'time_iter': 0.30762, 'accuracy': 0.99413, 'f1': 0.99463, 'auc': 0.99882}\n",
      "val: {'epoch': 65, 'time_epoch': 1.26145, 'loss': 2.26397961, 'lr': 0, 'params': 135811, 'time_iter': 0.18021, 'accuracy': 0.4717, 'f1': 0.45854, 'auc': 0.63394}\n",
      "test: {'epoch': 65, 'time_epoch': 1.1813, 'loss': 2.04050308, 'lr': 0, 'params': 135811, 'time_iter': 0.16876, 'accuracy': 0.54206, 'f1': 0.52099, 'auc': 0.65959}\n",
      "> Epoch 65: took 19.1s (avg 20.1s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 66, 'time_epoch': 15.92176, 'eta': 227.76839, 'eta_hours': 0.06327, 'loss': 0.05183921, 'lr': 7.937e-05, 'params': 135811, 'time_iter': 0.29485, 'accuracy': 0.98592, 'f1': 0.98631, 'auc': 0.99974}\n",
      "val: {'epoch': 66, 'time_epoch': 1.26549, 'loss': 2.26261198, 'lr': 0, 'params': 135811, 'time_iter': 0.18078, 'accuracy': 0.48113, 'f1': 0.46651, 'auc': 0.63867}\n",
      "test: {'epoch': 66, 'time_epoch': 1.26277, 'loss': 2.04189348, 'lr': 0, 'params': 135811, 'time_iter': 0.1804, 'accuracy': 0.53271, 'f1': 0.50916, 'auc': 0.65889}\n",
      "> Epoch 66: took 18.5s (avg 20.1s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 67, 'time_epoch': 16.0967, 'eta': 209.99646, 'eta_hours': 0.05833, 'loss': 0.03579721, 'lr': 6.87e-05, 'params': 135811, 'time_iter': 0.29809, 'accuracy': 0.99531, 'f1': 0.99465, 'auc': 0.99958}\n",
      "val: {'epoch': 67, 'time_epoch': 1.24516, 'loss': 2.23600798, 'lr': 0, 'params': 135811, 'time_iter': 0.17788, 'accuracy': 0.4717, 'f1': 0.45534, 'auc': 0.63694}\n",
      "test: {'epoch': 67, 'time_epoch': 1.16876, 'loss': 2.07727366, 'lr': 0, 'params': 135811, 'time_iter': 0.16697, 'accuracy': 0.51402, 'f1': 0.49923, 'auc': 0.66451}\n",
      "> Epoch 67: took 18.6s (avg 20.0s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 68, 'time_epoch': 15.668, 'eta': 192.20475, 'eta_hours': 0.05339, 'loss': 0.0477458, 'lr': 5.874e-05, 'params': 135811, 'time_iter': 0.29015, 'accuracy': 0.99061, 'f1': 0.99156, 'auc': 0.99928}\n",
      "val: {'epoch': 68, 'time_epoch': 1.21808, 'loss': 2.29099574, 'lr': 0, 'params': 135811, 'time_iter': 0.17401, 'accuracy': 0.48113, 'f1': 0.47173, 'auc': 0.62902}\n",
      "test: {'epoch': 68, 'time_epoch': 1.04384, 'loss': 2.0135077, 'lr': 0, 'params': 135811, 'time_iter': 0.14912, 'accuracy': 0.54206, 'f1': 0.53373, 'auc': 0.66397}\n",
      "> Epoch 68: took 18.0s (avg 20.0s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 69, 'time_epoch': 15.42932, 'eta': 174.43961, 'eta_hours': 0.04846, 'loss': 0.05379212, 'lr': 4.952e-05, 'params': 135811, 'time_iter': 0.28573, 'accuracy': 0.99061, 'f1': 0.99069, 'auc': 0.99872}\n",
      "val: {'epoch': 69, 'time_epoch': 1.20473, 'loss': 2.30023682, 'lr': 0, 'params': 135811, 'time_iter': 0.1721, 'accuracy': 0.48113, 'f1': 0.47363, 'auc': 0.62086}\n",
      "test: {'epoch': 69, 'time_epoch': 1.13863, 'loss': 2.10030335, 'lr': 0, 'params': 135811, 'time_iter': 0.16266, 'accuracy': 0.52336, 'f1': 0.51556, 'auc': 0.64591}\n",
      "> Epoch 69: took 17.8s (avg 20.0s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 70, 'time_epoch': 15.46715, 'eta': 156.74507, 'eta_hours': 0.04354, 'loss': 0.03957652, 'lr': 4.104e-05, 'params': 135811, 'time_iter': 0.28643, 'accuracy': 0.99413, 'f1': 0.99376, 'auc': 0.99988}\n",
      "val: {'epoch': 70, 'time_epoch': 1.28098, 'loss': 2.28023111, 'lr': 0, 'params': 135811, 'time_iter': 0.183, 'accuracy': 0.49057, 'f1': 0.48003, 'auc': 0.62926}\n",
      "test: {'epoch': 70, 'time_epoch': 1.22197, 'loss': 2.03486272, 'lr': 0, 'params': 135811, 'time_iter': 0.17457, 'accuracy': 0.53271, 'f1': 0.52348, 'auc': 0.65229}\n",
      "> Epoch 70: took 18.0s (avg 19.9s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 71, 'time_epoch': 27.42134, 'eta': 140.44064, 'eta_hours': 0.03901, 'loss': 0.0371367, 'lr': 3.333e-05, 'params': 135811, 'time_iter': 0.5078, 'accuracy': 0.99413, 'f1': 0.99366, 'auc': 0.99948}\n",
      "val: {'epoch': 71, 'time_epoch': 1.14775, 'loss': 2.29351556, 'lr': 0, 'params': 135811, 'time_iter': 0.16396, 'accuracy': 0.4717, 'f1': 0.46114, 'auc': 0.62318}\n",
      "test: {'epoch': 71, 'time_epoch': 1.19653, 'loss': 2.05557917, 'lr': 0, 'params': 135811, 'time_iter': 0.17093, 'accuracy': 0.50467, 'f1': 0.49774, 'auc': 0.65502}\n",
      "> Epoch 71: took 29.8s (avg 20.1s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 72, 'time_epoch': 16.1477, 'eta': 122.75061, 'eta_hours': 0.0341, 'loss': 0.0406579, 'lr': 2.64e-05, 'params': 135811, 'time_iter': 0.29903, 'accuracy': 0.99413, 'f1': 0.99376, 'auc': 0.99923}\n",
      "val: {'epoch': 72, 'time_epoch': 1.277, 'loss': 2.28894417, 'lr': 0, 'params': 135811, 'time_iter': 0.18243, 'accuracy': 0.46226, 'f1': 0.45142, 'auc': 0.62594}\n",
      "test: {'epoch': 72, 'time_epoch': 1.19461, 'loss': 2.03046241, 'lr': 0, 'params': 135811, 'time_iter': 0.17066, 'accuracy': 0.53271, 'f1': 0.52131, 'auc': 0.65049}\n",
      "> Epoch 72: took 18.7s (avg 20.1s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 73, 'time_epoch': 15.73686, 'eta': 105.06894, 'eta_hours': 0.02919, 'loss': 0.05015239, 'lr': 2.025e-05, 'params': 135811, 'time_iter': 0.29142, 'accuracy': 0.98944, 'f1': 0.98882, 'auc': 0.99919}\n",
      "val: {'epoch': 73, 'time_epoch': 1.26456, 'loss': 2.32268232, 'lr': 0, 'params': 135811, 'time_iter': 0.18065, 'accuracy': 0.4717, 'f1': 0.46615, 'auc': 0.61983}\n",
      "test: {'epoch': 73, 'time_epoch': 1.22815, 'loss': 2.08435898, 'lr': 0, 'params': 135811, 'time_iter': 0.17545, 'accuracy': 0.50467, 'f1': 0.49926, 'auc': 0.64818}\n",
      "> Epoch 73: took 18.3s (avg 20.0s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 74, 'time_epoch': 15.38765, 'eta': 87.41586, 'eta_hours': 0.02428, 'loss': 0.04563864, 'lr': 1.491e-05, 'params': 135811, 'time_iter': 0.28496, 'accuracy': 0.99296, 'f1': 0.9931, 'auc': 0.99826}\n",
      "val: {'epoch': 74, 'time_epoch': 1.24129, 'loss': 2.29842097, 'lr': 0, 'params': 135811, 'time_iter': 0.17733, 'accuracy': 0.4717, 'f1': 0.46114, 'auc': 0.62549}\n",
      "test: {'epoch': 74, 'time_epoch': 1.17086, 'loss': 2.03769991, 'lr': 0, 'params': 135811, 'time_iter': 0.16727, 'accuracy': 0.51402, 'f1': 0.50601, 'auc': 0.65657}\n",
      "> Epoch 74: took 17.9s (avg 20.0s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 75, 'time_epoch': 15.84417, 'eta': 69.84643, 'eta_hours': 0.0194, 'loss': 0.03490014, 'lr': 1.037e-05, 'params': 135811, 'time_iter': 0.29341, 'accuracy': 0.99531, 'f1': 0.99551, 'auc': 0.99956}\n",
      "val: {'epoch': 75, 'time_epoch': 1.25157, 'loss': 2.25656416, 'lr': 0, 'params': 135811, 'time_iter': 0.1788, 'accuracy': 0.49057, 'f1': 0.47753, 'auc': 0.63513}\n",
      "test: {'epoch': 75, 'time_epoch': 1.18747, 'loss': 2.02383201, 'lr': 0, 'params': 135811, 'time_iter': 0.16964, 'accuracy': 0.53271, 'f1': 0.51756, 'auc': 0.66002}\n",
      "> Epoch 75: took 18.4s (avg 20.0s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 76, 'time_epoch': 27.26188, 'eta': 52.76665, 'eta_hours': 0.01466, 'loss': 0.03945402, 'lr': 6.64e-06, 'params': 135811, 'time_iter': 0.50485, 'accuracy': 0.99296, 'f1': 0.9917, 'auc': 0.9999}\n",
      "val: {'epoch': 76, 'time_epoch': 1.23374, 'loss': 2.28156495, 'lr': 0, 'params': 135811, 'time_iter': 0.17625, 'accuracy': 0.46226, 'f1': 0.44843, 'auc': 0.62531}\n",
      "test: {'epoch': 76, 'time_epoch': 1.13516, 'loss': 2.03346499, 'lr': 0, 'params': 135811, 'time_iter': 0.16217, 'accuracy': 0.52336, 'f1': 0.51326, 'auc': 0.65714}\n",
      "> Epoch 76: took 29.7s (avg 20.1s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 77, 'time_epoch': 27.22241, 'eta': 35.42478, 'eta_hours': 0.00984, 'loss': 0.03874049, 'lr': 3.74e-06, 'params': 135811, 'time_iter': 0.50412, 'accuracy': 0.99413, 'f1': 0.99409, 'auc': 0.9999}\n",
      "val: {'epoch': 77, 'time_epoch': 1.24688, 'loss': 2.3129897, 'lr': 0, 'params': 135811, 'time_iter': 0.17813, 'accuracy': 0.4717, 'f1': 0.46615, 'auc': 0.62096}\n",
      "test: {'epoch': 77, 'time_epoch': 1.18384, 'loss': 2.04040276, 'lr': 0, 'params': 135811, 'time_iter': 0.16912, 'accuracy': 0.51402, 'f1': 0.50888, 'auc': 0.65715}\n",
      "> Epoch 77: took 29.7s (avg 20.2s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 78, 'time_epoch': 27.03502, 'eta': 17.8304, 'eta_hours': 0.00495, 'loss': 0.03273597, 'lr': 1.66e-06, 'params': 135811, 'time_iter': 0.50065, 'accuracy': 0.99648, 'f1': 0.99606, 'auc': 0.99984}\n",
      "val: {'epoch': 78, 'time_epoch': 1.27028, 'loss': 2.28698097, 'lr': 0, 'params': 135811, 'time_iter': 0.18147, 'accuracy': 0.4717, 'f1': 0.45848, 'auc': 0.62795}\n",
      "test: {'epoch': 78, 'time_epoch': 1.24136, 'loss': 2.00537249, 'lr': 0, 'params': 135811, 'time_iter': 0.17734, 'accuracy': 0.53271, 'f1': 0.52002, 'auc': 0.65882}\n",
      "> Epoch 78: took 29.6s (avg 20.4s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "train: {'epoch': 79, 'time_epoch': 15.41774, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.05057501, 'lr': 4.2e-07, 'params': 135811, 'time_iter': 0.28551, 'accuracy': 0.98944, 'f1': 0.98895, 'auc': 0.99927}\n",
      "val: {'epoch': 79, 'time_epoch': 1.25349, 'loss': 2.27298368, 'lr': 0, 'params': 135811, 'time_iter': 0.17907, 'accuracy': 0.46226, 'f1': 0.44843, 'auc': 0.62899}\n",
      "test: {'epoch': 79, 'time_epoch': 1.19388, 'loss': 2.02186808, 'lr': 0, 'params': 135811, 'time_iter': 0.17055, 'accuracy': 0.54206, 'f1': 0.52741, 'auc': 0.66225}\n",
      "> Epoch 79: took 17.9s (avg 20.3s) | Best so far: epoch 14\ttrain_loss: 0.4517 train_accuracy: 0.8650\tval_loss: 1.0715 val_accuracy: 0.5472\ttest_loss: 1.2698 test_accuracy: 0.4673\n",
      "Avg time per epoch: 20.32s\n",
      "Total train loop time: 0.45h\n",
      "Task done, results saved in results\\neural-Age\\0\n",
      "14\n",
      "{'epoch': 14, 'time_epoch': 1.19691, 'loss': 1.26978073, 'lr': 0, 'params': 135811, 'time_iter': 0.17099, 'accuracy': 0.46729, 'f1': 0.38804, 'auc': 0.68813}\n",
      "{'epoch': 14, 'time_epoch': 15.82122, 'eta': 1145.85798, 'eta_hours': 0.31829, 'loss': 0.45173767, 'lr': 0.00095048, 'params': 135811, 'time_iter': 0.29299, 'accuracy': 0.86502, 'f1': 0.85794, 'auc': 0.94325}\n",
      "{'epoch': 14, 'time_epoch': 1.28535, 'loss': 1.07147657, 'lr': 0, 'params': 135811, 'time_iter': 0.18362, 'accuracy': 0.54717, 'f1': 0.47321, 'auc': 0.70567}\n",
      "Results aggregated across runs saved in results\\neural-Age\\agg\n",
      "[*] All done: 2024-03-02 02:29:33.344023\n"
     ]
    }
   ],
   "source": [
    "#Age using Exphormer 2 layers and 2 att heads 0.1 att dropout 0.1 dropout\n",
    "%run main.py --cfg configs/Exphormer/neural-Age.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38177919-0434-49a3-9260-7fa7cf11a896",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-02 02:31:06.863490\n",
      "[*] Loaded dataset 'HCPAge' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[1065000, 1000], edge_index=[2, 48551656], y=[1065])\n",
      "  undirected: True\n",
      "  num graphs: 1065\n",
      "  avg num_nodes/graph: 1000\n",
      "  num node features: 1000\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 3\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [05:41<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:05:44.34\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [04:08<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:04:10.91\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=1000, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=2\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=2\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 3, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPAge\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.3\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 2\n",
      "  n_heads: 2\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 80\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 3\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Age\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Age\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1000\n",
      "  dim_out: 3\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 135811\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 21.06437, 'eta': 1664.08524, 'eta_hours': 0.46225, 'loss': 1.10821039, 'lr': 0.0, 'params': 135811, 'time_iter': 0.39008, 'accuracy': 0.35563, 'f1': 0.18637, 'auc': 0.51473}\n",
      "...computing epoch stats took: 0.20s\n",
      "val: {'epoch': 0, 'time_epoch': 1.29928, 'loss': 1.12428325, 'lr': 0, 'params': 135811, 'time_iter': 0.18561, 'accuracy': 0.25472, 'f1': 0.13534, 'auc': 0.5173}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 0, 'time_epoch': 1.1984, 'loss': 1.11297119, 'lr': 0, 'params': 135811, 'time_iter': 0.1712, 'accuracy': 0.31776, 'f1': 0.16307, 'auc': 0.49238}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 23.8s (avg 23.8s) | Best so far: epoch 0\ttrain_loss: 1.1082 train_accuracy: 0.3556\tval_loss: 1.1243 val_accuracy: 0.2547\ttest_loss: 1.1130 test_accuracy: 0.3178\n",
      "train: {'epoch': 1, 'time_epoch': 15.62205, 'eta': 1430.77043, 'eta_hours': 0.39744, 'loss': 1.08040546, 'lr': 0.00033333, 'params': 135811, 'time_iter': 0.2893, 'accuracy': 0.37676, 'f1': 0.24822, 'auc': 0.5484}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 1, 'time_epoch': 1.26814, 'loss': 1.08926325, 'lr': 0, 'params': 135811, 'time_iter': 0.18116, 'accuracy': 0.26415, 'f1': 0.1393, 'auc': 0.58374}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 1.11188, 'loss': 1.09899022, 'lr': 0, 'params': 135811, 'time_iter': 0.15884, 'accuracy': 0.3271, 'f1': 0.16432, 'auc': 0.50735}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 1: took 18.1s (avg 20.9s) | Best so far: epoch 1\ttrain_loss: 1.0804 train_accuracy: 0.3768\tval_loss: 1.0893 val_accuracy: 0.2641\ttest_loss: 1.0990 test_accuracy: 0.3271\n",
      "train: {'epoch': 2, 'time_epoch': 15.90033, 'eta': 1349.72669, 'eta_hours': 0.37492, 'loss': 1.04272225, 'lr': 0.00066667, 'params': 135811, 'time_iter': 0.29445, 'accuracy': 0.48709, 'f1': 0.39871, 'auc': 0.61782}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 2, 'time_epoch': 1.21145, 'loss': 1.04411966, 'lr': 0, 'params': 135811, 'time_iter': 0.17306, 'accuracy': 0.42453, 'f1': 0.35816, 'auc': 0.63425}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 2, 'time_epoch': 1.15024, 'loss': 1.07254016, 'lr': 0, 'params': 135811, 'time_iter': 0.16432, 'accuracy': 0.45794, 'f1': 0.39607, 'auc': 0.59447}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 2: took 18.3s (avg 20.1s) | Best so far: epoch 2\ttrain_loss: 1.0427 train_accuracy: 0.4871\tval_loss: 1.0441 val_accuracy: 0.4245\ttest_loss: 1.0725 test_accuracy: 0.4579\n",
      "train: {'epoch': 3, 'time_epoch': 16.1871, 'eta': 1306.70326, 'eta_hours': 0.36297, 'loss': 0.99620173, 'lr': 0.001, 'params': 135811, 'time_iter': 0.29976, 'accuracy': 0.52113, 'f1': 0.45878, 'auc': 0.7021}\n",
      "val: {'epoch': 3, 'time_epoch': 1.29675, 'loss': 1.02229031, 'lr': 0, 'params': 135811, 'time_iter': 0.18525, 'accuracy': 0.50943, 'f1': 0.40022, 'auc': 0.67157}\n",
      "test: {'epoch': 3, 'time_epoch': 1.16702, 'loss': 1.07033837, 'lr': 0, 'params': 135811, 'time_iter': 0.16672, 'accuracy': 0.42991, 'f1': 0.32621, 'auc': 0.64271}\n",
      "> Epoch 3: took 18.7s (avg 19.7s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 4, 'time_epoch': 15.88788, 'eta': 1269.92611, 'eta_hours': 0.35276, 'loss': 0.9204069, 'lr': 0.00099958, 'params': 135811, 'time_iter': 0.29422, 'accuracy': 0.60681, 'f1': 0.60019, 'auc': 0.77449}\n",
      "val: {'epoch': 4, 'time_epoch': 1.29306, 'loss': 1.07849876, 'lr': 0, 'params': 135811, 'time_iter': 0.18472, 'accuracy': 0.36792, 'f1': 0.32639, 'auc': 0.65956}\n",
      "test: {'epoch': 4, 'time_epoch': 1.1385, 'loss': 1.08993232, 'lr': 0, 'params': 135811, 'time_iter': 0.16264, 'accuracy': 0.34579, 'f1': 0.28405, 'auc': 0.5972}\n",
      "> Epoch 4: took 18.4s (avg 19.5s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 5, 'time_epoch': 15.25838, 'eta': 1232.34821, 'eta_hours': 0.34232, 'loss': 0.84068111, 'lr': 0.00099834, 'params': 135811, 'time_iter': 0.28256, 'accuracy': 0.65023, 'f1': 0.64115, 'auc': 0.82196}\n",
      "val: {'epoch': 5, 'time_epoch': 1.24342, 'loss': 1.1598284, 'lr': 0, 'params': 135811, 'time_iter': 0.17763, 'accuracy': 0.33019, 'f1': 0.28645, 'auc': 0.62546}\n",
      "test: {'epoch': 5, 'time_epoch': 1.20104, 'loss': 1.19087255, 'lr': 0, 'params': 135811, 'time_iter': 0.17158, 'accuracy': 0.3271, 'f1': 0.26396, 'auc': 0.54375}\n",
      "> Epoch 5: took 17.8s (avg 19.2s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 6, 'time_epoch': 15.60375, 'eta': 1204.74897, 'eta_hours': 0.33465, 'loss': 0.7621859, 'lr': 0.00099626, 'params': 135811, 'time_iter': 0.28896, 'accuracy': 0.72887, 'f1': 0.72776, 'auc': 0.86289}\n",
      "val: {'epoch': 6, 'time_epoch': 1.27659, 'loss': 1.125387, 'lr': 0, 'params': 135811, 'time_iter': 0.18237, 'accuracy': 0.39623, 'f1': 0.37878, 'auc': 0.64978}\n",
      "test: {'epoch': 6, 'time_epoch': 1.20546, 'loss': 1.15399615, 'lr': 0, 'params': 135811, 'time_iter': 0.17221, 'accuracy': 0.39252, 'f1': 0.36839, 'auc': 0.56839}\n",
      "> Epoch 6: took 18.2s (avg 19.0s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 7, 'time_epoch': 15.29933, 'eta': 1177.40885, 'eta_hours': 0.32706, 'loss': 0.70122878, 'lr': 0.00099336, 'params': 135811, 'time_iter': 0.28332, 'accuracy': 0.74883, 'f1': 0.74395, 'auc': 0.88235}\n",
      "val: {'epoch': 7, 'time_epoch': 1.28672, 'loss': 1.05632136, 'lr': 0, 'params': 135811, 'time_iter': 0.18382, 'accuracy': 0.46226, 'f1': 0.35744, 'auc': 0.65829}\n",
      "test: {'epoch': 7, 'time_epoch': 1.18858, 'loss': 1.13904182, 'lr': 0, 'params': 135811, 'time_iter': 0.1698, 'accuracy': 0.45794, 'f1': 0.346, 'auc': 0.64127}\n",
      "> Epoch 7: took 17.9s (avg 18.9s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 8, 'time_epoch': 15.80255, 'eta': 1156.7143, 'eta_hours': 0.32131, 'loss': 0.64165134, 'lr': 0.00098963, 'params': 135811, 'time_iter': 0.29264, 'accuracy': 0.78873, 'f1': 0.78184, 'auc': 0.89666}\n",
      "val: {'epoch': 8, 'time_epoch': 1.28355, 'loss': 1.12232759, 'lr': 0, 'params': 135811, 'time_iter': 0.18336, 'accuracy': 0.4717, 'f1': 0.41798, 'auc': 0.64395}\n",
      "test: {'epoch': 8, 'time_epoch': 1.2037, 'loss': 1.18208813, 'lr': 0, 'params': 135811, 'time_iter': 0.17196, 'accuracy': 0.43925, 'f1': 0.39384, 'auc': 0.61184}\n",
      "> Epoch 8: took 18.4s (avg 18.8s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 9, 'time_epoch': 18.03018, 'eta': 1152.59154, 'eta_hours': 0.32016, 'loss': 0.59838309, 'lr': 0.00098509, 'params': 135811, 'time_iter': 0.33389, 'accuracy': 0.80282, 'f1': 0.80215, 'auc': 0.91512}\n",
      "val: {'epoch': 9, 'time_epoch': 1.27767, 'loss': 1.32210189, 'lr': 0, 'params': 135811, 'time_iter': 0.18252, 'accuracy': 0.34906, 'f1': 0.30313, 'auc': 0.67202}\n",
      "test: {'epoch': 9, 'time_epoch': 1.22962, 'loss': 1.28650588, 'lr': 0, 'params': 135811, 'time_iter': 0.17566, 'accuracy': 0.41121, 'f1': 0.35563, 'auc': 0.56325}\n",
      "> Epoch 9: took 20.6s (avg 19.0s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 10, 'time_epoch': 29.01445, 'eta': 1214.84149, 'eta_hours': 0.33746, 'loss': 0.56590092, 'lr': 0.00097975, 'params': 135811, 'time_iter': 0.5373, 'accuracy': 0.81455, 'f1': 0.80687, 'auc': 0.92178}\n",
      "val: {'epoch': 10, 'time_epoch': 1.27561, 'loss': 1.28401981, 'lr': 0, 'params': 135811, 'time_iter': 0.18223, 'accuracy': 0.38679, 'f1': 0.31425, 'auc': 0.64594}\n",
      "test: {'epoch': 10, 'time_epoch': 1.18318, 'loss': 1.37073476, 'lr': 0, 'params': 135811, 'time_iter': 0.16903, 'accuracy': 0.39252, 'f1': 0.34817, 'auc': 0.56379}\n",
      "> Epoch 10: took 31.5s (avg 20.2s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 11, 'time_epoch': 16.29208, 'eta': 1189.78728, 'eta_hours': 0.3305, 'loss': 0.49944543, 'lr': 0.0009736, 'params': 135811, 'time_iter': 0.30171, 'accuracy': 0.84507, 'f1': 0.83891, 'auc': 0.94418}\n",
      "val: {'epoch': 11, 'time_epoch': 1.2638, 'loss': 1.37335901, 'lr': 0, 'params': 135811, 'time_iter': 0.18054, 'accuracy': 0.40566, 'f1': 0.38009, 'auc': 0.64916}\n",
      "test: {'epoch': 11, 'time_epoch': 1.18189, 'loss': 1.4135526, 'lr': 0, 'params': 135811, 'time_iter': 0.16884, 'accuracy': 0.38318, 'f1': 0.33265, 'auc': 0.58642}\n",
      "> Epoch 11: took 18.8s (avg 20.0s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 12, 'time_epoch': 15.54094, 'eta': 1162.20984, 'eta_hours': 0.32284, 'loss': 0.49217592, 'lr': 0.00096667, 'params': 135811, 'time_iter': 0.2878, 'accuracy': 0.84272, 'f1': 0.8408, 'auc': 0.93952}\n",
      "val: {'epoch': 12, 'time_epoch': 1.25358, 'loss': 1.67331494, 'lr': 0, 'params': 135811, 'time_iter': 0.17908, 'accuracy': 0.27358, 'f1': 0.19073, 'auc': 0.58946}\n",
      "test: {'epoch': 12, 'time_epoch': 1.18377, 'loss': 1.61475833, 'lr': 0, 'params': 135811, 'time_iter': 0.16911, 'accuracy': 0.34579, 'f1': 0.25049, 'auc': 0.53964}\n",
      "> Epoch 12: took 18.0s (avg 19.9s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 13, 'time_epoch': 26.98884, 'eta': 1190.32054, 'eta_hours': 0.33064, 'loss': 0.44855746, 'lr': 0.00095896, 'params': 135811, 'time_iter': 0.49979, 'accuracy': 0.85915, 'f1': 0.85882, 'auc': 0.95189}\n",
      "val: {'epoch': 13, 'time_epoch': 1.27854, 'loss': 1.38785379, 'lr': 0, 'params': 135811, 'time_iter': 0.18265, 'accuracy': 0.41509, 'f1': 0.41741, 'auc': 0.65023}\n",
      "test: {'epoch': 13, 'time_epoch': 1.21913, 'loss': 1.4977981, 'lr': 0, 'params': 135811, 'time_iter': 0.17416, 'accuracy': 0.36449, 'f1': 0.34552, 'auc': 0.55415}\n",
      "> Epoch 13: took 29.6s (avg 20.6s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 14, 'time_epoch': 16.20645, 'eta': 1164.36097, 'eta_hours': 0.32343, 'loss': 0.47764729, 'lr': 0.00095048, 'params': 135811, 'time_iter': 0.30012, 'accuracy': 0.8392, 'f1': 0.83045, 'auc': 0.93738}\n",
      "val: {'epoch': 14, 'time_epoch': 1.28019, 'loss': 1.2817041, 'lr': 0, 'params': 135811, 'time_iter': 0.18288, 'accuracy': 0.49057, 'f1': 0.45259, 'auc': 0.66364}\n",
      "test: {'epoch': 14, 'time_epoch': 1.19961, 'loss': 1.47194786, 'lr': 0, 'params': 135811, 'time_iter': 0.17137, 'accuracy': 0.39252, 'f1': 0.3504, 'auc': 0.59601}\n",
      "> Epoch 14: took 18.7s (avg 20.5s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 15, 'time_epoch': 15.95318, 'eta': 1138.60747, 'eta_hours': 0.31628, 'loss': 0.39871781, 'lr': 0.00094126, 'params': 135811, 'time_iter': 0.29543, 'accuracy': 0.8838, 'f1': 0.87855, 'auc': 0.95984}\n",
      "val: {'epoch': 15, 'time_epoch': 1.23621, 'loss': 1.43500863, 'lr': 0, 'params': 135811, 'time_iter': 0.1766, 'accuracy': 0.34906, 'f1': 0.31078, 'auc': 0.63117}\n",
      "test: {'epoch': 15, 'time_epoch': 1.18867, 'loss': 1.58914043, 'lr': 0, 'params': 135811, 'time_iter': 0.16981, 'accuracy': 0.30841, 'f1': 0.22745, 'auc': 0.60733}\n",
      "> Epoch 15: took 18.4s (avg 20.3s) | Best so far: epoch 3\ttrain_loss: 0.9962 train_accuracy: 0.5211\tval_loss: 1.0223 val_accuracy: 0.5094\ttest_loss: 1.0703 test_accuracy: 0.4299\n",
      "train: {'epoch': 16, 'time_epoch': 15.84413, 'eta': 1113.6028, 'eta_hours': 0.30933, 'loss': 0.39640704, 'lr': 0.0009313, 'params': 135811, 'time_iter': 0.29341, 'accuracy': 0.88028, 'f1': 0.87256, 'auc': 0.95616}\n",
      "val: {'epoch': 16, 'time_epoch': 1.18697, 'loss': 1.23660715, 'lr': 0, 'params': 135811, 'time_iter': 0.16957, 'accuracy': 0.53774, 'f1': 0.45951, 'auc': 0.67318}\n",
      "test: {'epoch': 16, 'time_epoch': 1.1617, 'loss': 1.50825563, 'lr': 0, 'params': 135811, 'time_iter': 0.16596, 'accuracy': 0.45794, 'f1': 0.3387, 'auc': 0.6316}\n",
      "> Epoch 16: took 18.3s (avg 20.2s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 17, 'time_epoch': 15.54235, 'eta': 1088.5765, 'eta_hours': 0.30238, 'loss': 0.35363501, 'lr': 0.00092063, 'params': 135811, 'time_iter': 0.28782, 'accuracy': 0.88967, 'f1': 0.88325, 'auc': 0.9684}\n",
      "val: {'epoch': 17, 'time_epoch': 1.19168, 'loss': 1.3624656, 'lr': 0, 'params': 135811, 'time_iter': 0.17024, 'accuracy': 0.49057, 'f1': 0.42293, 'auc': 0.66311}\n",
      "test: {'epoch': 17, 'time_epoch': 1.12001, 'loss': 1.50743704, 'lr': 0, 'params': 135811, 'time_iter': 0.16, 'accuracy': 0.4486, 'f1': 0.36101, 'auc': 0.60438}\n",
      "> Epoch 17: took 17.9s (avg 20.1s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 18, 'time_epoch': 11.74716, 'eta': 1052.36399, 'eta_hours': 0.29232, 'loss': 0.32527554, 'lr': 0.00090925, 'params': 135811, 'time_iter': 0.21754, 'accuracy': 0.90845, 'f1': 0.9101, 'auc': 0.96793}\n",
      "val: {'epoch': 18, 'time_epoch': 0.7945, 'loss': 1.6606815, 'lr': 0, 'params': 135811, 'time_iter': 0.1135, 'accuracy': 0.36792, 'f1': 0.34884, 'auc': 0.62257}\n",
      "test: {'epoch': 18, 'time_epoch': 0.79069, 'loss': 1.51477277, 'lr': 0, 'params': 135811, 'time_iter': 0.11296, 'accuracy': 0.42991, 'f1': 0.40447, 'auc': 0.59518}\n",
      "> Epoch 18: took 13.4s (avg 19.7s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 19, 'time_epoch': 10.45062, 'eta': 1014.70838, 'eta_hours': 0.28186, 'loss': 0.28519227, 'lr': 0.00089719, 'params': 135811, 'time_iter': 0.19353, 'accuracy': 0.92254, 'f1': 0.92347, 'auc': 0.97306}\n",
      "val: {'epoch': 19, 'time_epoch': 0.79184, 'loss': 1.60729913, 'lr': 0, 'params': 135811, 'time_iter': 0.11312, 'accuracy': 0.40566, 'f1': 0.3954, 'auc': 0.64791}\n",
      "test: {'epoch': 19, 'time_epoch': 0.81057, 'loss': 1.65064, 'lr': 0, 'params': 135811, 'time_iter': 0.1158, 'accuracy': 0.38318, 'f1': 0.3822, 'auc': 0.57539}\n",
      "> Epoch 19: took 12.1s (avg 19.3s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 20, 'time_epoch': 10.97661, 'eta': 981.12151, 'eta_hours': 0.27253, 'loss': 0.29661975, 'lr': 0.00088448, 'params': 135811, 'time_iter': 0.20327, 'accuracy': 0.9108, 'f1': 0.90711, 'auc': 0.97434}\n",
      "val: {'epoch': 20, 'time_epoch': 0.78689, 'loss': 1.6278795, 'lr': 0, 'params': 135811, 'time_iter': 0.11241, 'accuracy': 0.39623, 'f1': 0.39619, 'auc': 0.6242}\n",
      "test: {'epoch': 20, 'time_epoch': 0.80017, 'loss': 1.52591576, 'lr': 0, 'params': 135811, 'time_iter': 0.11431, 'accuracy': 0.43925, 'f1': 0.43215, 'auc': 0.60706}\n",
      "> Epoch 20: took 12.6s (avg 19.0s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 21, 'time_epoch': 10.41548, 'eta': 948.11077, 'eta_hours': 0.26336, 'loss': 0.2553858, 'lr': 0.00087112, 'params': 135811, 'time_iter': 0.19288, 'accuracy': 0.92723, 'f1': 0.92379, 'auc': 0.97952}\n",
      "val: {'epoch': 21, 'time_epoch': 0.7884, 'loss': 1.61318411, 'lr': 0, 'params': 135811, 'time_iter': 0.11263, 'accuracy': 0.4434, 'f1': 0.40854, 'auc': 0.61538}\n",
      "test: {'epoch': 21, 'time_epoch': 0.81, 'loss': 1.67514132, 'lr': 0, 'params': 135811, 'time_iter': 0.11571, 'accuracy': 0.45794, 'f1': 0.4258, 'auc': 0.58572}\n",
      "> Epoch 21: took 12.0s (avg 18.7s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 22, 'time_epoch': 10.73475, 'eta': 917.85606, 'eta_hours': 0.25496, 'loss': 0.26695201, 'lr': 0.00085714, 'params': 135811, 'time_iter': 0.19879, 'accuracy': 0.92254, 'f1': 0.92088, 'auc': 0.98141}\n",
      "val: {'epoch': 22, 'time_epoch': 0.78255, 'loss': 1.35317216, 'lr': 0, 'params': 135811, 'time_iter': 0.11179, 'accuracy': 0.51887, 'f1': 0.45481, 'auc': 0.66736}\n",
      "test: {'epoch': 22, 'time_epoch': 0.81004, 'loss': 1.67881846, 'lr': 0, 'params': 135811, 'time_iter': 0.11572, 'accuracy': 0.45794, 'f1': 0.36585, 'auc': 0.61864}\n",
      "> Epoch 22: took 12.3s (avg 18.4s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 23, 'time_epoch': 11.68196, 'eta': 891.43818, 'eta_hours': 0.24762, 'loss': 0.22430949, 'lr': 0.00084257, 'params': 135811, 'time_iter': 0.21633, 'accuracy': 0.94131, 'f1': 0.94246, 'auc': 0.9848}\n",
      "val: {'epoch': 23, 'time_epoch': 0.78583, 'loss': 1.74560099, 'lr': 0, 'params': 135811, 'time_iter': 0.11226, 'accuracy': 0.42453, 'f1': 0.42139, 'auc': 0.62955}\n",
      "test: {'epoch': 23, 'time_epoch': 0.80465, 'loss': 1.67860245, 'lr': 0, 'params': 135811, 'time_iter': 0.11495, 'accuracy': 0.45794, 'f1': 0.45579, 'auc': 0.59706}\n",
      "> Epoch 23: took 13.3s (avg 18.2s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 24, 'time_epoch': 10.15672, 'eta': 862.84364, 'eta_hours': 0.23968, 'loss': 0.25093022, 'lr': 0.00082743, 'params': 135811, 'time_iter': 0.18809, 'accuracy': 0.93192, 'f1': 0.93036, 'auc': 0.97885}\n",
      "val: {'epoch': 24, 'time_epoch': 0.80312, 'loss': 1.9098184, 'lr': 0, 'params': 135811, 'time_iter': 0.11473, 'accuracy': 0.40566, 'f1': 0.35875, 'auc': 0.6337}\n",
      "test: {'epoch': 24, 'time_epoch': 0.82059, 'loss': 1.92218902, 'lr': 0, 'params': 135811, 'time_iter': 0.11723, 'accuracy': 0.43925, 'f1': 0.39484, 'auc': 0.60093}\n",
      "> Epoch 24: took 11.8s (avg 18.0s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 25, 'time_epoch': 10.48465, 'eta': 836.34849, 'eta_hours': 0.23232, 'loss': 0.23412545, 'lr': 0.00081174, 'params': 135811, 'time_iter': 0.19416, 'accuracy': 0.9331, 'f1': 0.93221, 'auc': 0.98203}\n",
      "val: {'epoch': 25, 'time_epoch': 0.79744, 'loss': 1.37247039, 'lr': 0, 'params': 135811, 'time_iter': 0.11392, 'accuracy': 0.5283, 'f1': 0.50476, 'auc': 0.68249}\n",
      "test: {'epoch': 25, 'time_epoch': 0.79878, 'loss': 1.68337474, 'lr': 0, 'params': 135811, 'time_iter': 0.11411, 'accuracy': 0.42991, 'f1': 0.39162, 'auc': 0.61813}\n",
      "> Epoch 25: took 12.1s (avg 17.7s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 26, 'time_epoch': 11.03787, 'eta': 812.12524, 'eta_hours': 0.22559, 'loss': 0.20129269, 'lr': 0.00079554, 'params': 135811, 'time_iter': 0.20441, 'accuracy': 0.94249, 'f1': 0.94166, 'auc': 0.98547}\n",
      "val: {'epoch': 26, 'time_epoch': 0.80748, 'loss': 1.64717817, 'lr': 0, 'params': 135811, 'time_iter': 0.11535, 'accuracy': 0.49057, 'f1': 0.48083, 'auc': 0.66196}\n",
      "test: {'epoch': 26, 'time_epoch': 0.81755, 'loss': 1.60230697, 'lr': 0, 'params': 135811, 'time_iter': 0.11679, 'accuracy': 0.46729, 'f1': 0.45048, 'auc': 0.64273}\n",
      "> Epoch 26: took 12.7s (avg 17.5s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 27, 'time_epoch': 10.73072, 'eta': 788.2734, 'eta_hours': 0.21896, 'loss': 0.22124101, 'lr': 0.00077884, 'params': 135811, 'time_iter': 0.19872, 'accuracy': 0.93779, 'f1': 0.9338, 'auc': 0.98556}\n",
      "val: {'epoch': 27, 'time_epoch': 0.79985, 'loss': 1.87240713, 'lr': 0, 'params': 135811, 'time_iter': 0.11426, 'accuracy': 0.37736, 'f1': 0.34607, 'auc': 0.63665}\n",
      "test: {'epoch': 27, 'time_epoch': 0.79845, 'loss': 1.84552852, 'lr': 0, 'params': 135811, 'time_iter': 0.11406, 'accuracy': 0.38318, 'f1': 0.33551, 'auc': 0.6263}\n",
      "> Epoch 27: took 12.4s (avg 17.4s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 28, 'time_epoch': 11.34816, 'eta': 766.41228, 'eta_hours': 0.21289, 'loss': 0.20846131, 'lr': 0.00076168, 'params': 135811, 'time_iter': 0.21015, 'accuracy': 0.94718, 'f1': 0.94418, 'auc': 0.98107}\n",
      "val: {'epoch': 28, 'time_epoch': 0.80207, 'loss': 2.24858869, 'lr': 0, 'params': 135811, 'time_iter': 0.11458, 'accuracy': 0.36792, 'f1': 0.27628, 'auc': 0.61642}\n",
      "test: {'epoch': 28, 'time_epoch': 0.79318, 'loss': 2.18812864, 'lr': 0, 'params': 135811, 'time_iter': 0.11331, 'accuracy': 0.36449, 'f1': 0.28829, 'auc': 0.5707}\n",
      "> Epoch 28: took 13.0s (avg 17.2s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 29, 'time_epoch': 10.7641, 'eta': 744.2786, 'eta_hours': 0.20674, 'loss': 0.21708175, 'lr': 0.00074409, 'params': 135811, 'time_iter': 0.19934, 'accuracy': 0.93897, 'f1': 0.93801, 'auc': 0.98432}\n",
      "val: {'epoch': 29, 'time_epoch': 0.81107, 'loss': 1.88126269, 'lr': 0, 'params': 135811, 'time_iter': 0.11587, 'accuracy': 0.4434, 'f1': 0.34588, 'auc': 0.61465}\n",
      "test: {'epoch': 29, 'time_epoch': 0.79988, 'loss': 2.06874206, 'lr': 0, 'params': 135811, 'time_iter': 0.11427, 'accuracy': 0.42056, 'f1': 0.35517, 'auc': 0.55537}\n",
      "> Epoch 29: took 12.4s (avg 17.0s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 30, 'time_epoch': 22.42612, 'eta': 741.31196, 'eta_hours': 0.20592, 'loss': 0.17658207, 'lr': 0.00072609, 'params': 135811, 'time_iter': 0.4153, 'accuracy': 0.9507, 'f1': 0.94906, 'auc': 0.98817}\n",
      "val: {'epoch': 30, 'time_epoch': 0.78244, 'loss': 1.92003517, 'lr': 0, 'params': 135811, 'time_iter': 0.11178, 'accuracy': 0.4717, 'f1': 0.40927, 'auc': 0.62629}\n",
      "test: {'epoch': 30, 'time_epoch': 0.7841, 'loss': 2.07250383, 'lr': 0, 'params': 135811, 'time_iter': 0.11201, 'accuracy': 0.45794, 'f1': 0.37071, 'auc': 0.59127}\n",
      "> Epoch 30: took 24.0s (avg 17.3s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 31, 'time_epoch': 10.98297, 'eta': 719.96437, 'eta_hours': 0.19999, 'loss': 0.17710767, 'lr': 0.00070771, 'params': 135811, 'time_iter': 0.20339, 'accuracy': 0.95188, 'f1': 0.9499, 'auc': 0.98842}\n",
      "val: {'epoch': 31, 'time_epoch': 0.80061, 'loss': 2.1383917, 'lr': 0, 'params': 135811, 'time_iter': 0.11437, 'accuracy': 0.42453, 'f1': 0.34204, 'auc': 0.63345}\n",
      "test: {'epoch': 31, 'time_epoch': 0.80839, 'loss': 2.17905688, 'lr': 0, 'params': 135811, 'time_iter': 0.11548, 'accuracy': 0.40187, 'f1': 0.3098, 'auc': 0.55333}\n",
      "> Epoch 31: took 12.6s (avg 17.1s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 32, 'time_epoch': 22.32557, 'eta': 715.39955, 'eta_hours': 0.19872, 'loss': 0.12964865, 'lr': 0.00068898, 'params': 135811, 'time_iter': 0.41344, 'accuracy': 0.96714, 'f1': 0.96711, 'auc': 0.99214}\n",
      "val: {'epoch': 32, 'time_epoch': 0.80752, 'loss': 1.9887234, 'lr': 0, 'params': 135811, 'time_iter': 0.11536, 'accuracy': 0.46226, 'f1': 0.4275, 'auc': 0.6078}\n",
      "test: {'epoch': 32, 'time_epoch': 0.78812, 'loss': 1.97014838, 'lr': 0, 'params': 135811, 'time_iter': 0.11259, 'accuracy': 0.45794, 'f1': 0.40961, 'auc': 0.60879}\n",
      "> Epoch 32: took 23.9s (avg 17.3s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 33, 'time_epoch': 10.94527, 'eta': 694.39311, 'eta_hours': 0.19289, 'loss': 0.13475487, 'lr': 0.00066994, 'params': 135811, 'time_iter': 0.20269, 'accuracy': 0.96948, 'f1': 0.96795, 'auc': 0.99103}\n",
      "val: {'epoch': 33, 'time_epoch': 0.79158, 'loss': 2.22171549, 'lr': 0, 'params': 135811, 'time_iter': 0.11308, 'accuracy': 0.39623, 'f1': 0.37981, 'auc': 0.61006}\n",
      "test: {'epoch': 33, 'time_epoch': 0.78893, 'loss': 2.0768179, 'lr': 0, 'params': 135811, 'time_iter': 0.1127, 'accuracy': 0.45794, 'f1': 0.4404, 'auc': 0.6129}\n",
      "> Epoch 33: took 12.5s (avg 17.2s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 34, 'time_epoch': 11.26613, 'eta': 674.37413, 'eta_hours': 0.18733, 'loss': 0.09548388, 'lr': 0.00065062, 'params': 135811, 'time_iter': 0.20863, 'accuracy': 0.98005, 'f1': 0.97804, 'auc': 0.99707}\n",
      "val: {'epoch': 34, 'time_epoch': 0.78345, 'loss': 1.80844397, 'lr': 0, 'params': 135811, 'time_iter': 0.11192, 'accuracy': 0.46226, 'f1': 0.43922, 'auc': 0.67669}\n",
      "test: {'epoch': 34, 'time_epoch': 0.79089, 'loss': 2.20007931, 'lr': 0, 'params': 135811, 'time_iter': 0.11298, 'accuracy': 0.3271, 'f1': 0.27897, 'auc': 0.57118}\n",
      "> Epoch 34: took 12.9s (avg 17.1s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 35, 'time_epoch': 10.69655, 'eta': 654.14527, 'eta_hours': 0.18171, 'loss': 0.09257979, 'lr': 0.00063105, 'params': 135811, 'time_iter': 0.19808, 'accuracy': 0.98239, 'f1': 0.98175, 'auc': 0.99565}\n",
      "val: {'epoch': 35, 'time_epoch': 0.79785, 'loss': 2.07033112, 'lr': 0, 'params': 135811, 'time_iter': 0.11398, 'accuracy': 0.42453, 'f1': 0.41225, 'auc': 0.6077}\n",
      "test: {'epoch': 35, 'time_epoch': 0.82654, 'loss': 1.92027602, 'lr': 0, 'params': 135811, 'time_iter': 0.11808, 'accuracy': 0.45794, 'f1': 0.43739, 'auc': 0.6349}\n",
      "> Epoch 35: took 12.3s (avg 16.9s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 36, 'time_epoch': 11.05546, 'eta': 634.84877, 'eta_hours': 0.17635, 'loss': 0.13461118, 'lr': 0.00061126, 'params': 135811, 'time_iter': 0.20473, 'accuracy': 0.96479, 'f1': 0.96379, 'auc': 0.99087}\n",
      "val: {'epoch': 36, 'time_epoch': 0.80087, 'loss': 1.97380766, 'lr': 0, 'params': 135811, 'time_iter': 0.11441, 'accuracy': 0.51887, 'f1': 0.43681, 'auc': 0.65311}\n",
      "test: {'epoch': 36, 'time_epoch': 0.8087, 'loss': 2.16652751, 'lr': 0, 'params': 135811, 'time_iter': 0.11553, 'accuracy': 0.45794, 'f1': 0.35923, 'auc': 0.5754}\n",
      "> Epoch 36: took 12.7s (avg 16.8s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 37, 'time_epoch': 10.75068, 'eta': 615.64916, 'eta_hours': 0.17101, 'loss': 0.10040073, 'lr': 0.00059128, 'params': 135811, 'time_iter': 0.19909, 'accuracy': 0.97535, 'f1': 0.97356, 'auc': 0.99551}\n",
      "val: {'epoch': 37, 'time_epoch': 0.82425, 'loss': 2.33283632, 'lr': 0, 'params': 135811, 'time_iter': 0.11775, 'accuracy': 0.41509, 'f1': 0.33691, 'auc': 0.58386}\n",
      "test: {'epoch': 37, 'time_epoch': 0.8074, 'loss': 2.26168632, 'lr': 0, 'params': 135811, 'time_iter': 0.11534, 'accuracy': 0.42991, 'f1': 0.36295, 'auc': 0.59441}\n",
      "> Epoch 37: took 12.4s (avg 16.7s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 38, 'time_epoch': 21.93083, 'eta': 608.63631, 'eta_hours': 0.16907, 'loss': 0.09886729, 'lr': 0.00057116, 'params': 135811, 'time_iter': 0.40613, 'accuracy': 0.97535, 'f1': 0.97282, 'auc': 0.99547}\n",
      "val: {'epoch': 38, 'time_epoch': 0.79155, 'loss': 2.03419976, 'lr': 0, 'params': 135811, 'time_iter': 0.11308, 'accuracy': 0.45283, 'f1': 0.44088, 'auc': 0.63161}\n",
      "test: {'epoch': 38, 'time_epoch': 0.80217, 'loss': 2.06630168, 'lr': 0, 'params': 135811, 'time_iter': 0.1146, 'accuracy': 0.42991, 'f1': 0.41455, 'auc': 0.60497}\n",
      "> Epoch 38: took 23.5s (avg 16.9s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 39, 'time_epoch': 10.33235, 'eta': 589.27909, 'eta_hours': 0.16369, 'loss': 0.0999391, 'lr': 0.00055091, 'params': 135811, 'time_iter': 0.19134, 'accuracy': 0.97653, 'f1': 0.97697, 'auc': 0.99322}\n",
      "val: {'epoch': 39, 'time_epoch': 0.82374, 'loss': 2.19472809, 'lr': 0, 'params': 135811, 'time_iter': 0.11768, 'accuracy': 0.43396, 'f1': 0.43067, 'auc': 0.60614}\n",
      "test: {'epoch': 39, 'time_epoch': 0.82717, 'loss': 1.88344182, 'lr': 0, 'params': 135811, 'time_iter': 0.11817, 'accuracy': 0.54206, 'f1': 0.54151, 'auc': 0.64679}\n",
      "> Epoch 39: took 12.0s (avg 16.8s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 40, 'time_epoch': 10.80491, 'eta': 570.8116, 'eta_hours': 0.15856, 'loss': 0.06980691, 'lr': 0.00053058, 'params': 135811, 'time_iter': 0.20009, 'accuracy': 0.98592, 'f1': 0.98432, 'auc': 0.99896}\n",
      "val: {'epoch': 40, 'time_epoch': 0.8222, 'loss': 2.40333891, 'lr': 0, 'params': 135811, 'time_iter': 0.11746, 'accuracy': 0.41509, 'f1': 0.41428, 'auc': 0.5924}\n",
      "test: {'epoch': 40, 'time_epoch': 0.81948, 'loss': 2.00232197, 'lr': 0, 'params': 135811, 'time_iter': 0.11707, 'accuracy': 0.50467, 'f1': 0.50637, 'auc': 0.61318}\n",
      "> Epoch 40: took 12.5s (avg 16.7s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 41, 'time_epoch': 10.53451, 'eta': 552.46436, 'eta_hours': 0.15346, 'loss': 0.07510249, 'lr': 0.0005102, 'params': 135811, 'time_iter': 0.19508, 'accuracy': 0.98357, 'f1': 0.98211, 'auc': 0.99621}\n",
      "val: {'epoch': 41, 'time_epoch': 0.8098, 'loss': 2.2685314, 'lr': 0, 'params': 135811, 'time_iter': 0.11569, 'accuracy': 0.43396, 'f1': 0.4058, 'auc': 0.60699}\n",
      "test: {'epoch': 41, 'time_epoch': 0.80322, 'loss': 2.12447803, 'lr': 0, 'params': 135811, 'time_iter': 0.11475, 'accuracy': 0.47664, 'f1': 0.44397, 'auc': 0.64544}\n",
      "> Epoch 41: took 12.2s (avg 16.6s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 42, 'time_epoch': 11.14378, 'eta': 535.00476, 'eta_hours': 0.14861, 'loss': 0.07878069, 'lr': 0.0004898, 'params': 135811, 'time_iter': 0.20637, 'accuracy': 0.97887, 'f1': 0.97712, 'auc': 0.9954}\n",
      "val: {'epoch': 42, 'time_epoch': 0.82069, 'loss': 2.13434568, 'lr': 0, 'params': 135811, 'time_iter': 0.11724, 'accuracy': 0.43396, 'f1': 0.432, 'auc': 0.63236}\n",
      "test: {'epoch': 42, 'time_epoch': 0.81335, 'loss': 2.33871823, 'lr': 0, 'params': 135811, 'time_iter': 0.11619, 'accuracy': 0.38318, 'f1': 0.37121, 'auc': 0.57556}\n",
      "> Epoch 42: took 12.8s (avg 16.5s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 43, 'time_epoch': 21.94951, 'eta': 526.67329, 'eta_hours': 0.1463, 'loss': 0.08922775, 'lr': 0.00046942, 'params': 135811, 'time_iter': 0.40647, 'accuracy': 0.97887, 'f1': 0.97528, 'auc': 0.99753}\n",
      "val: {'epoch': 43, 'time_epoch': 0.82563, 'loss': 2.25820924, 'lr': 0, 'params': 135811, 'time_iter': 0.11795, 'accuracy': 0.43396, 'f1': 0.43377, 'auc': 0.60749}\n",
      "test: {'epoch': 43, 'time_epoch': 0.81747, 'loss': 2.09784777, 'lr': 0, 'params': 135811, 'time_iter': 0.11678, 'accuracy': 0.45794, 'f1': 0.45798, 'auc': 0.62581}\n",
      "> Epoch 43: took 23.6s (avg 16.6s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 44, 'time_epoch': 10.64791, 'eta': 508.94644, 'eta_hours': 0.14137, 'loss': 0.08698621, 'lr': 0.00044909, 'params': 135811, 'time_iter': 0.19718, 'accuracy': 0.98005, 'f1': 0.97951, 'auc': 0.99767}\n",
      "val: {'epoch': 44, 'time_epoch': 0.79588, 'loss': 2.46244757, 'lr': 0, 'params': 135811, 'time_iter': 0.1137, 'accuracy': 0.40566, 'f1': 0.4033, 'auc': 0.59651}\n",
      "test: {'epoch': 44, 'time_epoch': 0.80902, 'loss': 2.23613639, 'lr': 0, 'params': 135811, 'time_iter': 0.11557, 'accuracy': 0.43925, 'f1': 0.41917, 'auc': 0.61792}\n",
      "> Epoch 44: took 12.3s (avg 16.5s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 45, 'time_epoch': 11.70107, 'eta': 492.30579, 'eta_hours': 0.13675, 'loss': 0.07111092, 'lr': 0.00042884, 'params': 135811, 'time_iter': 0.21669, 'accuracy': 0.98474, 'f1': 0.98224, 'auc': 0.99785}\n",
      "val: {'epoch': 45, 'time_epoch': 0.82398, 'loss': 2.20348516, 'lr': 0, 'params': 135811, 'time_iter': 0.11771, 'accuracy': 0.4717, 'f1': 0.43458, 'auc': 0.63356}\n",
      "test: {'epoch': 45, 'time_epoch': 0.82251, 'loss': 2.04776359, 'lr': 0, 'params': 135811, 'time_iter': 0.1175, 'accuracy': 0.49533, 'f1': 0.46592, 'auc': 0.62612}\n",
      "> Epoch 45: took 13.4s (avg 16.5s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 46, 'time_epoch': 22.45645, 'eta': 483.42698, 'eta_hours': 0.13429, 'loss': 0.05952572, 'lr': 0.00040872, 'params': 135811, 'time_iter': 0.41586, 'accuracy': 0.98709, 'f1': 0.98495, 'auc': 0.99815}\n",
      "val: {'epoch': 46, 'time_epoch': 0.79338, 'loss': 2.40202139, 'lr': 0, 'params': 135811, 'time_iter': 0.11334, 'accuracy': 0.41509, 'f1': 0.41705, 'auc': 0.595}\n",
      "test: {'epoch': 46, 'time_epoch': 0.79994, 'loss': 2.19049034, 'lr': 0, 'params': 135811, 'time_iter': 0.11428, 'accuracy': 0.46729, 'f1': 0.46704, 'auc': 0.60056}\n",
      "> Epoch 46: took 24.1s (avg 16.6s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 47, 'time_epoch': 10.44825, 'eta': 465.97698, 'eta_hours': 0.12944, 'loss': 0.06473963, 'lr': 0.00038874, 'params': 135811, 'time_iter': 0.19349, 'accuracy': 0.98826, 'f1': 0.98699, 'auc': 0.99607}\n",
      "val: {'epoch': 47, 'time_epoch': 0.8007, 'loss': 2.28966862, 'lr': 0, 'params': 135811, 'time_iter': 0.11439, 'accuracy': 0.46226, 'f1': 0.42049, 'auc': 0.59585}\n",
      "test: {'epoch': 47, 'time_epoch': 0.80062, 'loss': 2.2551185, 'lr': 0, 'params': 135811, 'time_iter': 0.11437, 'accuracy': 0.48598, 'f1': 0.44028, 'auc': 0.65089}\n",
      "> Epoch 47: took 12.1s (avg 16.5s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 48, 'time_epoch': 10.41377, 'eta': 448.79095, 'eta_hours': 0.12466, 'loss': 0.04516862, 'lr': 0.00036895, 'params': 135811, 'time_iter': 0.19285, 'accuracy': 0.99531, 'f1': 0.99561, 'auc': 0.99802}\n",
      "val: {'epoch': 48, 'time_epoch': 0.79207, 'loss': 2.62846651, 'lr': 0, 'params': 135811, 'time_iter': 0.11315, 'accuracy': 0.37736, 'f1': 0.36753, 'auc': 0.58453}\n",
      "test: {'epoch': 48, 'time_epoch': 0.80425, 'loss': 2.33518071, 'lr': 0, 'params': 135811, 'time_iter': 0.11489, 'accuracy': 0.47664, 'f1': 0.46451, 'auc': 0.61091}\n",
      "> Epoch 48: took 12.0s (avg 16.4s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 49, 'time_epoch': 10.71969, 'eta': 432.05936, 'eta_hours': 0.12002, 'loss': 0.0631292, 'lr': 0.00034938, 'params': 135811, 'time_iter': 0.19851, 'accuracy': 0.98709, 'f1': 0.98684, 'auc': 0.99728}\n",
      "val: {'epoch': 49, 'time_epoch': 0.79332, 'loss': 2.22733312, 'lr': 0, 'params': 135811, 'time_iter': 0.11333, 'accuracy': 0.49057, 'f1': 0.4544, 'auc': 0.63403}\n",
      "test: {'epoch': 49, 'time_epoch': 0.79497, 'loss': 2.0181333, 'lr': 0, 'params': 135811, 'time_iter': 0.11357, 'accuracy': 0.50467, 'f1': 0.45213, 'auc': 0.63141}\n",
      "> Epoch 49: took 12.3s (avg 16.4s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 50, 'time_epoch': 10.41643, 'eta': 415.39109, 'eta_hours': 0.11539, 'loss': 0.04964579, 'lr': 0.00033006, 'params': 135811, 'time_iter': 0.1929, 'accuracy': 0.99178, 'f1': 0.99061, 'auc': 0.99742}\n",
      "val: {'epoch': 50, 'time_epoch': 0.80271, 'loss': 2.30118766, 'lr': 0, 'params': 135811, 'time_iter': 0.11467, 'accuracy': 0.4434, 'f1': 0.44187, 'auc': 0.62052}\n",
      "test: {'epoch': 50, 'time_epoch': 0.79551, 'loss': 2.23476176, 'lr': 0, 'params': 135811, 'time_iter': 0.11364, 'accuracy': 0.42991, 'f1': 0.42285, 'auc': 0.62699}\n",
      "> Epoch 50: took 12.0s (avg 16.3s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 51, 'time_epoch': 10.79113, 'eta': 399.16504, 'eta_hours': 0.11088, 'loss': 0.0513837, 'lr': 0.00031102, 'params': 135811, 'time_iter': 0.19984, 'accuracy': 0.99061, 'f1': 0.98906, 'auc': 0.99841}\n",
      "val: {'epoch': 51, 'time_epoch': 0.79171, 'loss': 2.29963289, 'lr': 0, 'params': 135811, 'time_iter': 0.1131, 'accuracy': 0.48113, 'f1': 0.46068, 'auc': 0.60756}\n",
      "test: {'epoch': 51, 'time_epoch': 0.8141, 'loss': 2.10169276, 'lr': 0, 'params': 135811, 'time_iter': 0.1163, 'accuracy': 0.50467, 'f1': 0.49266, 'auc': 0.64821}\n",
      "> Epoch 51: took 12.4s (avg 16.2s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n",
      "train: {'epoch': 52, 'time_epoch': 22.37097, 'eta': 389.04324, 'eta_hours': 0.10807, 'loss': 0.06468606, 'lr': 0.00029229, 'params': 135811, 'time_iter': 0.41428, 'accuracy': 0.98474, 'f1': 0.98454, 'auc': 0.99766}\n",
      "val: {'epoch': 52, 'time_epoch': 0.79546, 'loss': 2.23544617, 'lr': 0, 'params': 135811, 'time_iter': 0.11364, 'accuracy': 0.46226, 'f1': 0.44692, 'auc': 0.60982}\n",
      "test: {'epoch': 52, 'time_epoch': 0.8037, 'loss': 2.05637114, 'lr': 0, 'params': 135811, 'time_iter': 0.11481, 'accuracy': 0.49533, 'f1': 0.483, 'auc': 0.64962}\n",
      "> Epoch 52: took 24.0s (avg 16.3s) | Best so far: epoch 16\ttrain_loss: 0.3964 train_accuracy: 0.8803\tval_loss: 1.2366 val_accuracy: 0.5377\ttest_loss: 1.5083 test_accuracy: 0.4579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Age using Exphormer 2 layers and 2 att heads 0.1 att dropout 0.3 dropout\n",
    "%run main.py --cfg configs/Exphormer/neural-Age.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077280c-dae7-496e-b927-70e97c644c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a533d-c3cc-4ae0-b25a-add5ad1cea0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e28d3d-bad0-4172-b097-59a74ae32bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c0d4e7-a9fd-4982-af45-464899c33a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3620e-cb63-486c-bea3-3c685b4a4178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed676c6-9e38-4184-85ce-72c5d6ed5070",
   "metadata": {},
   "source": [
    "## Regularized Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05622028-fa86-4332-8096-ae754d76eda7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-27 15:16:27.160803\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 7\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [05:54<00:00, 21.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:06:11.31\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [01:44<00:00, 71.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:50.28\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=400, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.5, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.5, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.5, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (3): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.5, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (4): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.5, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.5\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 5\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 45\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 197319\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 39.48631, 'eta': 1737.39773, 'eta_hours': 0.48261, 'loss': 1.9510189, 'lr': 0.0, 'params': 197319, 'time_iter': 0.10586, 'accuracy': 0.14394, 'f1': 0.06143, 'auc': 0.48441}\n",
      "...computing epoch stats took: 0.16s\n",
      "val: {'epoch': 0, 'time_epoch': 2.3745, 'loss': 1.94981928, 'lr': 0, 'params': 197319, 'time_iter': 0.05052, 'accuracy': 0.15726, 'f1': 0.07253, 'auc': 0.48922}\n",
      "...computing epoch stats took: 0.05s\n",
      "test: {'epoch': 0, 'time_epoch': 2.32561, 'loss': 1.95888578, 'lr': 0, 'params': 197319, 'time_iter': 0.04948, 'accuracy': 0.11141, 'f1': 0.06313, 'auc': 0.48884}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 44.4s (avg 44.4s) | Best so far: epoch 0\ttrain_loss: 1.9510 train_accuracy: 0.1439\tval_loss: 1.9498 val_accuracy: 0.1573\ttest_loss: 1.9589 test_accuracy: 0.1114\n",
      "train: {'epoch': 1, 'time_epoch': 36.59392, 'eta': 1635.72502, 'eta_hours': 0.45437, 'loss': 1.72668416, 'lr': 0.0002, 'params': 197319, 'time_iter': 0.09811, 'accuracy': 0.57709, 'f1': 0.57678, 'auc': 0.87205}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 1, 'time_epoch': 2.39665, 'loss': 1.55785765, 'lr': 0, 'params': 197319, 'time_iter': 0.05099, 'accuracy': 0.74194, 'f1': 0.73626, 'auc': 0.95477}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 1, 'time_epoch': 2.40076, 'loss': 1.55751174, 'lr': 0, 'params': 197319, 'time_iter': 0.05108, 'accuracy': 0.72349, 'f1': 0.72292, 'auc': 0.96077}\n",
      "...computing epoch stats took: 0.03s\n",
      "> Epoch 1: took 41.5s (avg 43.0s) | Best so far: epoch 1\ttrain_loss: 1.7267 train_accuracy: 0.5771\tval_loss: 1.5579 val_accuracy: 0.7419\ttest_loss: 1.5575 test_accuracy: 0.7235\n",
      "train: {'epoch': 2, 'time_epoch': 36.72531, 'eta': 1579.27767, 'eta_hours': 0.43869, 'loss': 1.34271285, 'lr': 0.0004, 'params': 197319, 'time_iter': 0.09846, 'accuracy': 0.82314, 'f1': 0.82083, 'auc': 0.96432}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 2, 'time_epoch': 2.22021, 'loss': 1.15061428, 'lr': 0, 'params': 197319, 'time_iter': 0.04724, 'accuracy': 0.8871, 'f1': 0.89127, 'auc': 0.98281}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 2.21795, 'loss': 1.14913358, 'lr': 0, 'params': 197319, 'time_iter': 0.04719, 'accuracy': 0.88188, 'f1': 0.88608, 'auc': 0.98362}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 2: took 41.2s (avg 42.4s) | Best so far: epoch 2\ttrain_loss: 1.3427 train_accuracy: 0.8231\tval_loss: 1.1506 val_accuracy: 0.8871\ttest_loss: 1.1491 test_accuracy: 0.8819\n",
      "train: {'epoch': 3, 'time_epoch': 35.96986, 'eta': 1524.94797, 'eta_hours': 0.4236, 'loss': 0.95439136, 'lr': 0.0006, 'params': 197319, 'time_iter': 0.09643, 'accuracy': 0.891, 'f1': 0.8902, 'auc': 0.98276}\n",
      "val: {'epoch': 3, 'time_epoch': 2.17939, 'loss': 0.81848344, 'lr': 0, 'params': 197319, 'time_iter': 0.04637, 'accuracy': 0.87366, 'f1': 0.87928, 'auc': 0.98612}\n",
      "test: {'epoch': 3, 'time_epoch': 2.16958, 'loss': 0.79229362, 'lr': 0, 'params': 197319, 'time_iter': 0.04616, 'accuracy': 0.90336, 'f1': 0.90564, 'auc': 0.98895}\n",
      "> Epoch 3: took 40.4s (avg 41.9s) | Best so far: epoch 2\ttrain_loss: 1.3427 train_accuracy: 0.8231\tval_loss: 1.1506 val_accuracy: 0.8871\ttest_loss: 1.1491 test_accuracy: 0.8819\n",
      "train: {'epoch': 4, 'time_epoch': 35.53899, 'eta': 1474.51522, 'eta_hours': 0.40959, 'loss': 0.66175385, 'lr': 0.0008, 'params': 197319, 'time_iter': 0.09528, 'accuracy': 0.90527, 'f1': 0.90474, 'auc': 0.98428}\n",
      "val: {'epoch': 4, 'time_epoch': 2.1933, 'loss': 0.5343207, 'lr': 0, 'params': 197319, 'time_iter': 0.04667, 'accuracy': 0.92339, 'f1': 0.9261, 'auc': 0.98713}\n",
      "test: {'epoch': 4, 'time_epoch': 2.22259, 'loss': 0.50923127, 'lr': 0, 'params': 197319, 'time_iter': 0.04729, 'accuracy': 0.92752, 'f1': 0.92611, 'auc': 0.99075}\n",
      "> Epoch 4: took 40.0s (avg 41.5s) | Best so far: epoch 4\ttrain_loss: 0.6618 train_accuracy: 0.9053\tval_loss: 0.5343 val_accuracy: 0.9234\ttest_loss: 0.5092 test_accuracy: 0.9275\n",
      "train: {'epoch': 5, 'time_epoch': 36.41542, 'eta': 1434.74383, 'eta_hours': 0.39854, 'loss': 0.4682469, 'lr': 0.001, 'params': 197319, 'time_iter': 0.09763, 'accuracy': 0.91921, 'f1': 0.91897, 'auc': 0.98774}\n",
      "val: {'epoch': 5, 'time_epoch': 2.14728, 'loss': 0.36702236, 'lr': 0, 'params': 197319, 'time_iter': 0.04569, 'accuracy': 0.93817, 'f1': 0.93931, 'auc': 0.99314}\n",
      "test: {'epoch': 5, 'time_epoch': 2.16485, 'loss': 0.33803748, 'lr': 0, 'params': 197319, 'time_iter': 0.04606, 'accuracy': 0.94765, 'f1': 0.94906, 'auc': 0.99411}\n",
      "> Epoch 5: took 40.8s (avg 41.4s) | Best so far: epoch 5\ttrain_loss: 0.4682 train_accuracy: 0.9192\tval_loss: 0.3670 val_accuracy: 0.9382\ttest_loss: 0.3380 test_accuracy: 0.9476\n",
      "train: {'epoch': 6, 'time_epoch': 36.73937, 'eta': 1397.68987, 'eta_hours': 0.38825, 'loss': 0.34964295, 'lr': 0.00099846, 'params': 197319, 'time_iter': 0.0985, 'accuracy': 0.9308, 'f1': 0.93045, 'auc': 0.99163}\n",
      "val: {'epoch': 6, 'time_epoch': 2.1582, 'loss': 0.29316342, 'lr': 0, 'params': 197319, 'time_iter': 0.04592, 'accuracy': 0.94489, 'f1': 0.9465, 'auc': 0.993}\n",
      "test: {'epoch': 6, 'time_epoch': 2.18354, 'loss': 0.27594659, 'lr': 0, 'params': 197319, 'time_iter': 0.04646, 'accuracy': 0.95705, 'f1': 0.9574, 'auc': 0.99075}\n",
      "> Epoch 6: took 41.2s (avg 41.4s) | Best so far: epoch 6\ttrain_loss: 0.3496 train_accuracy: 0.9308\tval_loss: 0.2932 val_accuracy: 0.9449\ttest_loss: 0.2759 test_accuracy: 0.9570\n",
      "train: {'epoch': 7, 'time_epoch': 38.05827, 'eta': 1366.8145, 'eta_hours': 0.37967, 'loss': 0.28071295, 'lr': 0.00099384, 'params': 197319, 'time_iter': 0.10203, 'accuracy': 0.9397, 'f1': 0.93966, 'auc': 0.99277}\n",
      "val: {'epoch': 7, 'time_epoch': 2.6595, 'loss': 0.2748264, 'lr': 0, 'params': 197319, 'time_iter': 0.05659, 'accuracy': 0.94086, 'f1': 0.94266, 'auc': 0.99486}\n",
      "test: {'epoch': 7, 'time_epoch': 2.23203, 'loss': 0.2459018, 'lr': 0, 'params': 197319, 'time_iter': 0.04749, 'accuracy': 0.95034, 'f1': 0.95015, 'auc': 0.99347}\n",
      "> Epoch 7: took 43.0s (avg 41.6s) | Best so far: epoch 6\ttrain_loss: 0.3496 train_accuracy: 0.9308\tval_loss: 0.2932 val_accuracy: 0.9449\ttest_loss: 0.2759 test_accuracy: 0.9570\n",
      "train: {'epoch': 8, 'time_epoch': 37.32881, 'eta': 1331.4251, 'eta_hours': 0.36984, 'loss': 0.22784447, 'lr': 0.00098618, 'params': 197319, 'time_iter': 0.10008, 'accuracy': 0.94894, 'f1': 0.94889, 'auc': 0.99462}\n",
      "val: {'epoch': 8, 'time_epoch': 2.29104, 'loss': 0.2296111, 'lr': 0, 'params': 197319, 'time_iter': 0.04875, 'accuracy': 0.94489, 'f1': 0.94638, 'auc': 0.99489}\n",
      "test: {'epoch': 8, 'time_epoch': 2.27496, 'loss': 0.24082961, 'lr': 0, 'params': 197319, 'time_iter': 0.0484, 'accuracy': 0.94497, 'f1': 0.94517, 'auc': 0.99265}\n",
      "> Epoch 8: took 42.0s (avg 41.6s) | Best so far: epoch 6\ttrain_loss: 0.3496 train_accuracy: 0.9308\tval_loss: 0.2932 val_accuracy: 0.9449\ttest_loss: 0.2759 test_accuracy: 0.9570\n",
      "train: {'epoch': 9, 'time_epoch': 37.62828, 'eta': 1296.69594, 'eta_hours': 0.36019, 'loss': 0.19303003, 'lr': 0.00097553, 'params': 197319, 'time_iter': 0.10088, 'accuracy': 0.95566, 'f1': 0.95557, 'auc': 0.99586}\n",
      "val: {'epoch': 9, 'time_epoch': 2.43179, 'loss': 0.24836886, 'lr': 0, 'params': 197319, 'time_iter': 0.05174, 'accuracy': 0.94086, 'f1': 0.94232, 'auc': 0.99444}\n",
      "test: {'epoch': 9, 'time_epoch': 2.31312, 'loss': 0.20790852, 'lr': 0, 'params': 197319, 'time_iter': 0.04922, 'accuracy': 0.94899, 'f1': 0.94901, 'auc': 0.99534}\n",
      "> Epoch 9: took 42.5s (avg 41.7s) | Best so far: epoch 6\ttrain_loss: 0.3496 train_accuracy: 0.9308\tval_loss: 0.2932 val_accuracy: 0.9449\ttest_loss: 0.2759 test_accuracy: 0.9570\n",
      "train: {'epoch': 10, 'time_epoch': 37.98671, 'eta': 1262.54755, 'eta_hours': 0.35071, 'loss': 0.17547229, 'lr': 0.00096194, 'params': 197319, 'time_iter': 0.10184, 'accuracy': 0.95684, 'f1': 0.95667, 'auc': 0.99635}\n",
      "val: {'epoch': 10, 'time_epoch': 2.41158, 'loss': 0.20398054, 'lr': 0, 'params': 197319, 'time_iter': 0.05131, 'accuracy': 0.94758, 'f1': 0.94897, 'auc': 0.99498}\n",
      "test: {'epoch': 10, 'time_epoch': 2.31728, 'loss': 0.16375405, 'lr': 0, 'params': 197319, 'time_iter': 0.0493, 'accuracy': 0.96376, 'f1': 0.96255, 'auc': 0.99668}\n",
      "> Epoch 10: took 42.8s (avg 41.8s) | Best so far: epoch 10\ttrain_loss: 0.1755 train_accuracy: 0.9568\tval_loss: 0.2040 val_accuracy: 0.9476\ttest_loss: 0.1638 test_accuracy: 0.9638\n",
      "train: {'epoch': 11, 'time_epoch': 37.08992, 'eta': 1225.29326, 'eta_hours': 0.34036, 'loss': 0.14915568, 'lr': 0.0009455, 'params': 197319, 'time_iter': 0.09944, 'accuracy': 0.96271, 'f1': 0.96258, 'auc': 0.997}\n",
      "val: {'epoch': 11, 'time_epoch': 2.59918, 'loss': 0.33504006, 'lr': 0, 'params': 197319, 'time_iter': 0.0553, 'accuracy': 0.91667, 'f1': 0.92059, 'auc': 0.99303}\n",
      "test: {'epoch': 11, 'time_epoch': 2.35593, 'loss': 0.35209291, 'lr': 0, 'params': 197319, 'time_iter': 0.05013, 'accuracy': 0.90336, 'f1': 0.91015, 'auc': 0.9918}\n",
      "> Epoch 11: took 42.1s (avg 41.8s) | Best so far: epoch 10\ttrain_loss: 0.1755 train_accuracy: 0.9568\tval_loss: 0.2040 val_accuracy: 0.9476\ttest_loss: 0.1638 test_accuracy: 0.9638\n",
      "train: {'epoch': 12, 'time_epoch': 36.94732, 'eta': 1187.71324, 'eta_hours': 0.32992, 'loss': 0.13942308, 'lr': 0.00092632, 'params': 197319, 'time_iter': 0.09905, 'accuracy': 0.9654, 'f1': 0.96539, 'auc': 0.99744}\n",
      "val: {'epoch': 12, 'time_epoch': 2.39138, 'loss': 0.18094938, 'lr': 0, 'params': 197319, 'time_iter': 0.05088, 'accuracy': 0.95565, 'f1': 0.95706, 'auc': 0.99632}\n",
      "test: {'epoch': 12, 'time_epoch': 2.26793, 'loss': 0.1853168, 'lr': 0, 'params': 197319, 'time_iter': 0.04825, 'accuracy': 0.9557, 'f1': 0.95509, 'auc': 0.99582}\n",
      "> Epoch 12: took 41.7s (avg 41.8s) | Best so far: epoch 12\ttrain_loss: 0.1394 train_accuracy: 0.9654\tval_loss: 0.1809 val_accuracy: 0.9556\ttest_loss: 0.1853 test_accuracy: 0.9557\n",
      "train: {'epoch': 13, 'time_epoch': 38.31685, 'eta': 1153.25613, 'eta_hours': 0.32035, 'loss': 0.10520308, 'lr': 0.00090451, 'params': 197319, 'time_iter': 0.10273, 'accuracy': 0.97598, 'f1': 0.97592, 'auc': 0.99812}\n",
      "val: {'epoch': 13, 'time_epoch': 2.41971, 'loss': 0.21293959, 'lr': 0, 'params': 197319, 'time_iter': 0.05148, 'accuracy': 0.95027, 'f1': 0.95112, 'auc': 0.99432}\n",
      "test: {'epoch': 13, 'time_epoch': 2.24723, 'loss': 0.18180957, 'lr': 0, 'params': 197319, 'time_iter': 0.04781, 'accuracy': 0.95168, 'f1': 0.95093, 'auc': 0.99505}\n",
      "> Epoch 13: took 43.1s (avg 41.9s) | Best so far: epoch 12\ttrain_loss: 0.1394 train_accuracy: 0.9654\tval_loss: 0.1809 val_accuracy: 0.9556\ttest_loss: 0.1853 test_accuracy: 0.9557\n",
      "train: {'epoch': 14, 'time_epoch': 37.08757, 'eta': 1115.82585, 'eta_hours': 0.30995, 'loss': 0.10627179, 'lr': 0.0008802, 'params': 197319, 'time_iter': 0.09943, 'accuracy': 0.97279, 'f1': 0.97269, 'auc': 0.99858}\n",
      "val: {'epoch': 14, 'time_epoch': 2.23661, 'loss': 0.23484849, 'lr': 0, 'params': 197319, 'time_iter': 0.04759, 'accuracy': 0.93952, 'f1': 0.94098, 'auc': 0.9959}\n",
      "test: {'epoch': 14, 'time_epoch': 2.31919, 'loss': 0.15818465, 'lr': 0, 'params': 197319, 'time_iter': 0.04934, 'accuracy': 0.95973, 'f1': 0.96, 'auc': 0.99706}\n",
      "> Epoch 14: took 41.7s (avg 41.9s) | Best so far: epoch 12\ttrain_loss: 0.1394 train_accuracy: 0.9654\tval_loss: 0.1809 val_accuracy: 0.9556\ttest_loss: 0.1853 test_accuracy: 0.9557\n",
      "train: {'epoch': 15, 'time_epoch': 37.51684, 'eta': 1079.21645, 'eta_hours': 0.29978, 'loss': 0.10263656, 'lr': 0.00085355, 'params': 197319, 'time_iter': 0.10058, 'accuracy': 0.97414, 'f1': 0.97402, 'auc': 0.99851}\n",
      "val: {'epoch': 15, 'time_epoch': 2.27764, 'loss': 0.28375487, 'lr': 0, 'params': 197319, 'time_iter': 0.04846, 'accuracy': 0.9328, 'f1': 0.93471, 'auc': 0.99336}\n",
      "test: {'epoch': 15, 'time_epoch': 2.29613, 'loss': 0.26531041, 'lr': 0, 'params': 197319, 'time_iter': 0.04885, 'accuracy': 0.94362, 'f1': 0.94429, 'auc': 0.99265}\n",
      "> Epoch 15: took 42.2s (avg 41.9s) | Best so far: epoch 12\ttrain_loss: 0.1394 train_accuracy: 0.9654\tval_loss: 0.1809 val_accuracy: 0.9556\ttest_loss: 0.1853 test_accuracy: 0.9557\n",
      "train: {'epoch': 16, 'time_epoch': 36.95508, 'eta': 1041.57504, 'eta_hours': 0.28933, 'loss': 0.08939394, 'lr': 0.00082472, 'params': 197319, 'time_iter': 0.09908, 'accuracy': 0.97699, 'f1': 0.97702, 'auc': 0.99874}\n",
      "val: {'epoch': 16, 'time_epoch': 2.34762, 'loss': 0.17904654, 'lr': 0, 'params': 197319, 'time_iter': 0.04995, 'accuracy': 0.95968, 'f1': 0.96056, 'auc': 0.99561}\n",
      "test: {'epoch': 16, 'time_epoch': 2.29094, 'loss': 0.13812779, 'lr': 0, 'params': 197319, 'time_iter': 0.04874, 'accuracy': 0.96644, 'f1': 0.96601, 'auc': 0.99864}\n",
      "> Epoch 16: took 41.7s (avg 41.9s) | Best so far: epoch 16\ttrain_loss: 0.0894 train_accuracy: 0.9770\tval_loss: 0.1790 val_accuracy: 0.9597\ttest_loss: 0.1381 test_accuracy: 0.9664\n",
      "train: {'epoch': 17, 'time_epoch': 38.11096, 'eta': 1005.74372, 'eta_hours': 0.27937, 'loss': 0.07871581, 'lr': 0.00079389, 'params': 197319, 'time_iter': 0.10217, 'accuracy': 0.98018, 'f1': 0.98015, 'auc': 0.999}\n",
      "val: {'epoch': 17, 'time_epoch': 2.40148, 'loss': 0.23005383, 'lr': 0, 'params': 197319, 'time_iter': 0.0511, 'accuracy': 0.95027, 'f1': 0.9515, 'auc': 0.99473}\n",
      "test: {'epoch': 17, 'time_epoch': 2.39235, 'loss': 0.19557898, 'lr': 0, 'params': 197319, 'time_iter': 0.0509, 'accuracy': 0.95705, 'f1': 0.95637, 'auc': 0.99682}\n",
      "> Epoch 17: took 43.0s (avg 42.0s) | Best so far: epoch 16\ttrain_loss: 0.0894 train_accuracy: 0.9770\tval_loss: 0.1790 val_accuracy: 0.9597\ttest_loss: 0.1381 test_accuracy: 0.9664\n",
      "train: {'epoch': 18, 'time_epoch': 38.41117, 'eta': 970.08324, 'eta_hours': 0.26947, 'loss': 0.07099759, 'lr': 0.00076125, 'params': 197319, 'time_iter': 0.10298, 'accuracy': 0.98102, 'f1': 0.98102, 'auc': 0.99919}\n",
      "val: {'epoch': 18, 'time_epoch': 2.63059, 'loss': 0.21930785, 'lr': 0, 'params': 197319, 'time_iter': 0.05597, 'accuracy': 0.95565, 'f1': 0.95703, 'auc': 0.99461}\n",
      "test: {'epoch': 18, 'time_epoch': 2.35958, 'loss': 0.15769053, 'lr': 0, 'params': 197319, 'time_iter': 0.0502, 'accuracy': 0.9651, 'f1': 0.96491, 'auc': 0.99776}\n",
      "> Epoch 18: took 43.5s (avg 42.0s) | Best so far: epoch 16\ttrain_loss: 0.0894 train_accuracy: 0.9770\tval_loss: 0.1790 val_accuracy: 0.9597\ttest_loss: 0.1381 test_accuracy: 0.9664\n",
      "train: {'epoch': 19, 'time_epoch': 37.81146, 'eta': 933.39806, 'eta_hours': 0.25928, 'loss': 0.07687857, 'lr': 0.000727, 'params': 197319, 'time_iter': 0.10137, 'accuracy': 0.97968, 'f1': 0.97959, 'auc': 0.99899}\n",
      "val: {'epoch': 19, 'time_epoch': 2.33667, 'loss': 0.20478706, 'lr': 0, 'params': 197319, 'time_iter': 0.04972, 'accuracy': 0.95833, 'f1': 0.95925, 'auc': 0.99466}\n",
      "test: {'epoch': 19, 'time_epoch': 2.58401, 'loss': 0.21346378, 'lr': 0, 'params': 197319, 'time_iter': 0.05498, 'accuracy': 0.95436, 'f1': 0.95493, 'auc': 0.99701}\n",
      "> Epoch 19: took 42.8s (avg 42.1s) | Best so far: epoch 16\ttrain_loss: 0.0894 train_accuracy: 0.9770\tval_loss: 0.1790 val_accuracy: 0.9597\ttest_loss: 0.1381 test_accuracy: 0.9664\n",
      "train: {'epoch': 20, 'time_epoch': 37.74681, 'eta': 896.53172, 'eta_hours': 0.24904, 'loss': 0.0587571, 'lr': 0.00069134, 'params': 197319, 'time_iter': 0.1012, 'accuracy': 0.98522, 'f1': 0.98525, 'auc': 0.99957}\n",
      "val: {'epoch': 20, 'time_epoch': 2.29463, 'loss': 0.2118933, 'lr': 0, 'params': 197319, 'time_iter': 0.04882, 'accuracy': 0.95833, 'f1': 0.95936, 'auc': 0.99548}\n",
      "test: {'epoch': 20, 'time_epoch': 2.36433, 'loss': 0.16239452, 'lr': 0, 'params': 197319, 'time_iter': 0.0503, 'accuracy': 0.96376, 'f1': 0.96308, 'auc': 0.99765}\n",
      "> Epoch 20: took 42.5s (avg 42.1s) | Best so far: epoch 16\ttrain_loss: 0.0894 train_accuracy: 0.9770\tval_loss: 0.1790 val_accuracy: 0.9597\ttest_loss: 0.1381 test_accuracy: 0.9664\n",
      "train: {'epoch': 21, 'time_epoch': 37.59229, 'eta': 859.42379, 'eta_hours': 0.23873, 'loss': 0.04932976, 'lr': 0.00065451, 'params': 197319, 'time_iter': 0.10078, 'accuracy': 0.98791, 'f1': 0.98788, 'auc': 0.99947}\n",
      "val: {'epoch': 21, 'time_epoch': 2.64692, 'loss': 0.23106953, 'lr': 0, 'params': 197319, 'time_iter': 0.05632, 'accuracy': 0.95027, 'f1': 0.95136, 'auc': 0.99694}\n",
      "test: {'epoch': 21, 'time_epoch': 2.57416, 'loss': 0.19884024, 'lr': 0, 'params': 197319, 'time_iter': 0.05477, 'accuracy': 0.95705, 'f1': 0.95577, 'auc': 0.99514}\n",
      "> Epoch 21: took 42.9s (avg 42.1s) | Best so far: epoch 16\ttrain_loss: 0.0894 train_accuracy: 0.9770\tval_loss: 0.1790 val_accuracy: 0.9597\ttest_loss: 0.1381 test_accuracy: 0.9664\n",
      "train: {'epoch': 22, 'time_epoch': 38.23332, 'eta': 822.88691, 'eta_hours': 0.22858, 'loss': 0.05637809, 'lr': 0.00061672, 'params': 197319, 'time_iter': 0.1025, 'accuracy': 0.98589, 'f1': 0.98588, 'auc': 0.99958}\n",
      "val: {'epoch': 22, 'time_epoch': 2.48182, 'loss': 0.2122809, 'lr': 0, 'params': 197319, 'time_iter': 0.0528, 'accuracy': 0.9543, 'f1': 0.95556, 'auc': 0.9949}\n",
      "test: {'epoch': 22, 'time_epoch': 2.55673, 'loss': 0.16171552, 'lr': 0, 'params': 197319, 'time_iter': 0.0544, 'accuracy': 0.96242, 'f1': 0.9618, 'auc': 0.99783}\n",
      "> Epoch 22: took 43.4s (avg 42.2s) | Best so far: epoch 16\ttrain_loss: 0.0894 train_accuracy: 0.9770\tval_loss: 0.1790 val_accuracy: 0.9597\ttest_loss: 0.1381 test_accuracy: 0.9664\n",
      "train: {'epoch': 23, 'time_epoch': 38.10414, 'eta': 786.09562, 'eta_hours': 0.21836, 'loss': 0.04597904, 'lr': 0.00057822, 'params': 197319, 'time_iter': 0.10216, 'accuracy': 0.98841, 'f1': 0.98843, 'auc': 0.99957}\n",
      "val: {'epoch': 23, 'time_epoch': 2.31956, 'loss': 0.19573477, 'lr': 0, 'params': 197319, 'time_iter': 0.04935, 'accuracy': 0.95968, 'f1': 0.96063, 'auc': 0.9954}\n",
      "test: {'epoch': 23, 'time_epoch': 2.35043, 'loss': 0.16563215, 'lr': 0, 'params': 197319, 'time_iter': 0.05001, 'accuracy': 0.96913, 'f1': 0.96853, 'auc': 0.99753}\n",
      "> Epoch 23: took 42.9s (avg 42.2s) | Best so far: epoch 16\ttrain_loss: 0.0894 train_accuracy: 0.9770\tval_loss: 0.1790 val_accuracy: 0.9597\ttest_loss: 0.1381 test_accuracy: 0.9664\n",
      "train: {'epoch': 24, 'time_epoch': 38.48356, 'eta': 749.50284, 'eta_hours': 0.2082, 'loss': 0.04097237, 'lr': 0.00053923, 'params': 197319, 'time_iter': 0.10317, 'accuracy': 0.98959, 'f1': 0.98954, 'auc': 0.99968}\n",
      "val: {'epoch': 24, 'time_epoch': 2.32063, 'loss': 0.23680847, 'lr': 0, 'params': 197319, 'time_iter': 0.04938, 'accuracy': 0.95699, 'f1': 0.95773, 'auc': 0.9948}\n",
      "test: {'epoch': 24, 'time_epoch': 2.34394, 'loss': 0.18493629, 'lr': 0, 'params': 197319, 'time_iter': 0.04987, 'accuracy': 0.96107, 'f1': 0.96027, 'auc': 0.99743}\n",
      "> Epoch 24: took 43.2s (avg 42.3s) | Best so far: epoch 16\ttrain_loss: 0.0894 train_accuracy: 0.9770\tval_loss: 0.1790 val_accuracy: 0.9597\ttest_loss: 0.1381 test_accuracy: 0.9664\n",
      "train: {'epoch': 25, 'time_epoch': 37.92574, 'eta': 712.35698, 'eta_hours': 0.19788, 'loss': 0.03720079, 'lr': 0.0005, 'params': 197319, 'time_iter': 0.10168, 'accuracy': 0.99194, 'f1': 0.99192, 'auc': 0.99972}\n",
      "val: {'epoch': 25, 'time_epoch': 2.45983, 'loss': 0.17481079, 'lr': 0, 'params': 197319, 'time_iter': 0.05234, 'accuracy': 0.96102, 'f1': 0.96233, 'auc': 0.99701}\n",
      "test: {'epoch': 25, 'time_epoch': 2.58337, 'loss': 0.166668, 'lr': 0, 'params': 197319, 'time_iter': 0.05497, 'accuracy': 0.9651, 'f1': 0.9639, 'auc': 0.99678}\n",
      "> Epoch 25: took 43.1s (avg 42.3s) | Best so far: epoch 25\ttrain_loss: 0.0372 train_accuracy: 0.9919\tval_loss: 0.1748 val_accuracy: 0.9610\ttest_loss: 0.1667 test_accuracy: 0.9651\n",
      "train: {'epoch': 26, 'time_epoch': 38.38773, 'eta': 675.46134, 'eta_hours': 0.18763, 'loss': 0.02864117, 'lr': 0.00046077, 'params': 197319, 'time_iter': 0.10292, 'accuracy': 0.99379, 'f1': 0.99375, 'auc': 0.99974}\n",
      "val: {'epoch': 26, 'time_epoch': 2.34758, 'loss': 0.26334858, 'lr': 0, 'params': 197319, 'time_iter': 0.04995, 'accuracy': 0.95027, 'f1': 0.95181, 'auc': 0.99453}\n",
      "test: {'epoch': 26, 'time_epoch': 2.44633, 'loss': 0.17439894, 'lr': 0, 'params': 197319, 'time_iter': 0.05205, 'accuracy': 0.96644, 'f1': 0.96573, 'auc': 0.99747}\n",
      "> Epoch 26: took 43.3s (avg 42.3s) | Best so far: epoch 25\ttrain_loss: 0.0372 train_accuracy: 0.9919\tval_loss: 0.1748 val_accuracy: 0.9610\ttest_loss: 0.1667 test_accuracy: 0.9651\n",
      "train: {'epoch': 27, 'time_epoch': 38.26178, 'eta': 638.38266, 'eta_hours': 0.17733, 'loss': 0.02972464, 'lr': 0.00042178, 'params': 197319, 'time_iter': 0.10258, 'accuracy': 0.99194, 'f1': 0.99195, 'auc': 0.99986}\n",
      "val: {'epoch': 27, 'time_epoch': 2.36654, 'loss': 0.20778647, 'lr': 0, 'params': 197319, 'time_iter': 0.05035, 'accuracy': 0.95699, 'f1': 0.9578, 'auc': 0.9951}\n",
      "test: {'epoch': 27, 'time_epoch': 2.35891, 'loss': 0.17742729, 'lr': 0, 'params': 197319, 'time_iter': 0.05019, 'accuracy': 0.95973, 'f1': 0.9591, 'auc': 0.99802}\n",
      "> Epoch 27: took 43.1s (avg 42.4s) | Best so far: epoch 25\ttrain_loss: 0.0372 train_accuracy: 0.9919\tval_loss: 0.1748 val_accuracy: 0.9610\ttest_loss: 0.1667 test_accuracy: 0.9651\n",
      "train: {'epoch': 28, 'time_epoch': 37.85221, 'eta': 600.99642, 'eta_hours': 0.16694, 'loss': 0.0168135, 'lr': 0.00038328, 'params': 197319, 'time_iter': 0.10148, 'accuracy': 0.99614, 'f1': 0.99612, 'auc': 0.99988}\n",
      "val: {'epoch': 28, 'time_epoch': 2.43952, 'loss': 0.21213157, 'lr': 0, 'params': 197319, 'time_iter': 0.0519, 'accuracy': 0.96237, 'f1': 0.96304, 'auc': 0.99307}\n",
      "test: {'epoch': 28, 'time_epoch': 2.51896, 'loss': 0.21076174, 'lr': 0, 'params': 197319, 'time_iter': 0.05359, 'accuracy': 0.96242, 'f1': 0.96164, 'auc': 0.99647}\n",
      "> Epoch 28: took 42.9s (avg 42.4s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9961\tval_loss: 0.2121 val_accuracy: 0.9624\ttest_loss: 0.2108 test_accuracy: 0.9624\n",
      "train: {'epoch': 29, 'time_epoch': 37.83081, 'eta': 563.56841, 'eta_hours': 0.15655, 'loss': 0.01974789, 'lr': 0.00034549, 'params': 197319, 'time_iter': 0.10142, 'accuracy': 0.99547, 'f1': 0.99547, 'auc': 0.99989}\n",
      "val: {'epoch': 29, 'time_epoch': 2.24699, 'loss': 0.19966883, 'lr': 0, 'params': 197319, 'time_iter': 0.04781, 'accuracy': 0.96371, 'f1': 0.96431, 'auc': 0.99478}\n",
      "test: {'epoch': 29, 'time_epoch': 2.32465, 'loss': 0.19910334, 'lr': 0, 'params': 197319, 'time_iter': 0.04946, 'accuracy': 0.96376, 'f1': 0.96324, 'auc': 0.99688}\n",
      "> Epoch 29: took 42.5s (avg 42.4s) | Best so far: epoch 29\ttrain_loss: 0.0197 train_accuracy: 0.9955\tval_loss: 0.1997 val_accuracy: 0.9637\ttest_loss: 0.1991 test_accuracy: 0.9638\n",
      "train: {'epoch': 30, 'time_epoch': 38.18775, 'eta': 526.27561, 'eta_hours': 0.14619, 'loss': 0.01366412, 'lr': 0.00030866, 'params': 197319, 'time_iter': 0.10238, 'accuracy': 0.99681, 'f1': 0.99679, 'auc': 0.99993}\n",
      "val: {'epoch': 30, 'time_epoch': 2.33771, 'loss': 0.1810626, 'lr': 0, 'params': 197319, 'time_iter': 0.04974, 'accuracy': 0.96909, 'f1': 0.96978, 'auc': 0.99717}\n",
      "test: {'epoch': 30, 'time_epoch': 2.44583, 'loss': 0.18711701, 'lr': 0, 'params': 197319, 'time_iter': 0.05204, 'accuracy': 0.9651, 'f1': 0.9647, 'auc': 0.99702}\n",
      "> Epoch 30: took 43.0s (avg 42.4s) | Best so far: epoch 30\ttrain_loss: 0.0137 train_accuracy: 0.9968\tval_loss: 0.1811 val_accuracy: 0.9691\ttest_loss: 0.1871 test_accuracy: 0.9651\n",
      "train: {'epoch': 31, 'time_epoch': 37.39705, 'eta': 488.60566, 'eta_hours': 0.13572, 'loss': 0.01259908, 'lr': 0.000273, 'params': 197319, 'time_iter': 0.10026, 'accuracy': 0.99698, 'f1': 0.99698, 'auc': 0.99999}\n",
      "val: {'epoch': 31, 'time_epoch': 2.40945, 'loss': 0.20045953, 'lr': 0, 'params': 197319, 'time_iter': 0.05126, 'accuracy': 0.96505, 'f1': 0.96558, 'auc': 0.99594}\n",
      "test: {'epoch': 31, 'time_epoch': 2.35595, 'loss': 0.18238437, 'lr': 0, 'params': 197319, 'time_iter': 0.05013, 'accuracy': 0.9651, 'f1': 0.96458, 'auc': 0.99672}\n",
      "> Epoch 31: took 42.2s (avg 42.4s) | Best so far: epoch 30\ttrain_loss: 0.0137 train_accuracy: 0.9968\tval_loss: 0.1811 val_accuracy: 0.9691\ttest_loss: 0.1871 test_accuracy: 0.9651\n",
      "train: {'epoch': 32, 'time_epoch': 37.55633, 'eta': 451.01016, 'eta_hours': 0.12528, 'loss': 0.0116511, 'lr': 0.00023875, 'params': 197319, 'time_iter': 0.10069, 'accuracy': 0.99664, 'f1': 0.99666, 'auc': 0.99999}\n",
      "val: {'epoch': 32, 'time_epoch': 2.28385, 'loss': 0.19680749, 'lr': 0, 'params': 197319, 'time_iter': 0.04859, 'accuracy': 0.96774, 'f1': 0.96836, 'auc': 0.99529}\n",
      "test: {'epoch': 32, 'time_epoch': 2.34647, 'loss': 0.18322581, 'lr': 0, 'params': 197319, 'time_iter': 0.04992, 'accuracy': 0.96779, 'f1': 0.96676, 'auc': 0.99764}\n",
      "> Epoch 32: took 42.3s (avg 42.4s) | Best so far: epoch 30\ttrain_loss: 0.0137 train_accuracy: 0.9968\tval_loss: 0.1811 val_accuracy: 0.9691\ttest_loss: 0.1871 test_accuracy: 0.9651\n",
      "train: {'epoch': 33, 'time_epoch': 38.09263, 'eta': 413.59048, 'eta_hours': 0.11489, 'loss': 0.00944152, 'lr': 0.00020611, 'params': 197319, 'time_iter': 0.10213, 'accuracy': 0.99765, 'f1': 0.99766, 'auc': 0.99999}\n",
      "val: {'epoch': 33, 'time_epoch': 2.29742, 'loss': 0.1914093, 'lr': 0, 'params': 197319, 'time_iter': 0.04888, 'accuracy': 0.96774, 'f1': 0.96836, 'auc': 0.99505}\n",
      "test: {'epoch': 33, 'time_epoch': 2.44672, 'loss': 0.19690402, 'lr': 0, 'params': 197319, 'time_iter': 0.05206, 'accuracy': 0.96644, 'f1': 0.96516, 'auc': 0.99742}\n",
      "> Epoch 33: took 42.9s (avg 42.4s) | Best so far: epoch 30\ttrain_loss: 0.0137 train_accuracy: 0.9968\tval_loss: 0.1811 val_accuracy: 0.9691\ttest_loss: 0.1871 test_accuracy: 0.9651\n",
      "train: {'epoch': 34, 'time_epoch': 38.39086, 'eta': 376.21755, 'eta_hours': 0.1045, 'loss': 0.0065723, 'lr': 0.00017528, 'params': 197319, 'time_iter': 0.10292, 'accuracy': 0.99832, 'f1': 0.99831, 'auc': 1.0}\n",
      "val: {'epoch': 34, 'time_epoch': 2.58946, 'loss': 0.20858331, 'lr': 0, 'params': 197319, 'time_iter': 0.05509, 'accuracy': 0.9664, 'f1': 0.96706, 'auc': 0.99475}\n",
      "test: {'epoch': 34, 'time_epoch': 2.38446, 'loss': 0.21007602, 'lr': 0, 'params': 197319, 'time_iter': 0.05073, 'accuracy': 0.96376, 'f1': 0.96253, 'auc': 0.997}\n",
      "> Epoch 34: took 43.4s (avg 42.4s) | Best so far: epoch 30\ttrain_loss: 0.0137 train_accuracy: 0.9968\tval_loss: 0.1811 val_accuracy: 0.9691\ttest_loss: 0.1871 test_accuracy: 0.9651\n",
      "train: {'epoch': 35, 'time_epoch': 37.76613, 'eta': 338.63189, 'eta_hours': 0.09406, 'loss': 0.01076627, 'lr': 0.00014645, 'params': 197319, 'time_iter': 0.10125, 'accuracy': 0.99748, 'f1': 0.99748, 'auc': 0.99999}\n",
      "val: {'epoch': 35, 'time_epoch': 2.37462, 'loss': 0.2351106, 'lr': 0, 'params': 197319, 'time_iter': 0.05052, 'accuracy': 0.95833, 'f1': 0.95929, 'auc': 0.99443}\n",
      "test: {'epoch': 35, 'time_epoch': 2.46306, 'loss': 0.2065529, 'lr': 0, 'params': 197319, 'time_iter': 0.05241, 'accuracy': 0.96242, 'f1': 0.96171, 'auc': 0.99749}\n",
      "> Epoch 35: took 42.7s (avg 42.4s) | Best so far: epoch 30\ttrain_loss: 0.0137 train_accuracy: 0.9968\tval_loss: 0.1811 val_accuracy: 0.9691\ttest_loss: 0.1871 test_accuracy: 0.9651\n",
      "train: {'epoch': 36, 'time_epoch': 37.98493, 'eta': 301.08378, 'eta_hours': 0.08363, 'loss': 0.00545497, 'lr': 0.0001198, 'params': 197319, 'time_iter': 0.10184, 'accuracy': 0.99916, 'f1': 0.99916, 'auc': 1.0}\n",
      "val: {'epoch': 36, 'time_epoch': 2.43014, 'loss': 0.21546933, 'lr': 0, 'params': 197319, 'time_iter': 0.05171, 'accuracy': 0.9664, 'f1': 0.96705, 'auc': 0.99502}\n",
      "test: {'epoch': 36, 'time_epoch': 2.37202, 'loss': 0.19850745, 'lr': 0, 'params': 197319, 'time_iter': 0.05047, 'accuracy': 0.9651, 'f1': 0.96452, 'auc': 0.99676}\n",
      "> Epoch 36: took 42.9s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0137 train_accuracy: 0.9968\tval_loss: 0.1811 val_accuracy: 0.9691\ttest_loss: 0.1871 test_accuracy: 0.9651\n",
      "train: {'epoch': 37, 'time_epoch': 37.49396, 'eta': 263.42224, 'eta_hours': 0.07317, 'loss': 0.00830646, 'lr': 9.549e-05, 'params': 197319, 'time_iter': 0.10052, 'accuracy': 0.99815, 'f1': 0.99814, 'auc': 1.0}\n",
      "val: {'epoch': 37, 'time_epoch': 2.55, 'loss': 0.20809034, 'lr': 0, 'params': 197319, 'time_iter': 0.05426, 'accuracy': 0.96909, 'f1': 0.96986, 'auc': 0.99499}\n",
      "test: {'epoch': 37, 'time_epoch': 2.43636, 'loss': 0.21339801, 'lr': 0, 'params': 197319, 'time_iter': 0.05184, 'accuracy': 0.96242, 'f1': 0.96149, 'auc': 0.99662}\n",
      "> Epoch 37: took 42.6s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0137 train_accuracy: 0.9968\tval_loss: 0.1811 val_accuracy: 0.9691\ttest_loss: 0.1871 test_accuracy: 0.9651\n",
      "train: {'epoch': 38, 'time_epoch': 37.65919, 'eta': 225.79471, 'eta_hours': 0.06272, 'loss': 0.00304922, 'lr': 7.368e-05, 'params': 197319, 'time_iter': 0.10096, 'accuracy': 0.9995, 'f1': 0.99949, 'auc': 1.0}\n",
      "val: {'epoch': 38, 'time_epoch': 2.30949, 'loss': 0.19887093, 'lr': 0, 'params': 197319, 'time_iter': 0.04914, 'accuracy': 0.96774, 'f1': 0.9685, 'auc': 0.99537}\n",
      "test: {'epoch': 38, 'time_epoch': 2.32245, 'loss': 0.21065312, 'lr': 0, 'params': 197319, 'time_iter': 0.04941, 'accuracy': 0.96644, 'f1': 0.96527, 'auc': 0.99674}\n",
      "> Epoch 38: took 42.4s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0137 train_accuracy: 0.9968\tval_loss: 0.1811 val_accuracy: 0.9691\ttest_loss: 0.1871 test_accuracy: 0.9651\n",
      "train: {'epoch': 39, 'time_epoch': 37.87973, 'eta': 188.19317, 'eta_hours': 0.05228, 'loss': 0.00347671, 'lr': 5.45e-05, 'params': 197319, 'time_iter': 0.10155, 'accuracy': 0.9995, 'f1': 0.99949, 'auc': 1.0}\n",
      "val: {'epoch': 39, 'time_epoch': 2.32503, 'loss': 0.19833761, 'lr': 0, 'params': 197319, 'time_iter': 0.04947, 'accuracy': 0.96774, 'f1': 0.96848, 'auc': 0.99472}\n",
      "test: {'epoch': 39, 'time_epoch': 2.37504, 'loss': 0.20205017, 'lr': 0, 'params': 197319, 'time_iter': 0.05053, 'accuracy': 0.96242, 'f1': 0.96145, 'auc': 0.99689}\n",
      "> Epoch 39: took 42.7s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0137 train_accuracy: 0.9968\tval_loss: 0.1811 val_accuracy: 0.9691\ttest_loss: 0.1871 test_accuracy: 0.9651\n",
      "train: {'epoch': 40, 'time_epoch': 37.71987, 'eta': 150.56246, 'eta_hours': 0.04182, 'loss': 0.00389309, 'lr': 3.806e-05, 'params': 197319, 'time_iter': 0.10113, 'accuracy': 0.99933, 'f1': 0.99934, 'auc': 1.0}\n",
      "val: {'epoch': 40, 'time_epoch': 2.4621, 'loss': 0.20053236, 'lr': 0, 'params': 197319, 'time_iter': 0.05239, 'accuracy': 0.97177, 'f1': 0.97243, 'auc': 0.99385}\n",
      "test: {'epoch': 40, 'time_epoch': 2.47568, 'loss': 0.21084553, 'lr': 0, 'params': 197319, 'time_iter': 0.05267, 'accuracy': 0.96242, 'f1': 0.96156, 'auc': 0.99713}\n",
      "> Epoch 40: took 42.7s (avg 42.5s) | Best so far: epoch 40\ttrain_loss: 0.0039 train_accuracy: 0.9993\tval_loss: 0.2005 val_accuracy: 0.9718\ttest_loss: 0.2108 test_accuracy: 0.9624\n",
      "train: {'epoch': 41, 'time_epoch': 38.07158, 'eta': 112.95263, 'eta_hours': 0.03138, 'loss': 0.00479828, 'lr': 2.447e-05, 'params': 197319, 'time_iter': 0.10207, 'accuracy': 0.99933, 'f1': 0.99933, 'auc': 1.0}\n",
      "val: {'epoch': 41, 'time_epoch': 2.38688, 'loss': 0.19407093, 'lr': 0, 'params': 197319, 'time_iter': 0.05078, 'accuracy': 0.97177, 'f1': 0.97233, 'auc': 0.99519}\n",
      "test: {'epoch': 41, 'time_epoch': 2.38066, 'loss': 0.20985705, 'lr': 0, 'params': 197319, 'time_iter': 0.05065, 'accuracy': 0.9651, 'f1': 0.96396, 'auc': 0.99683}\n",
      "> Epoch 41: took 42.9s (avg 42.5s) | Best so far: epoch 40\ttrain_loss: 0.0039 train_accuracy: 0.9993\tval_loss: 0.2005 val_accuracy: 0.9718\ttest_loss: 0.2108 test_accuracy: 0.9624\n",
      "train: {'epoch': 42, 'time_epoch': 38.48506, 'eta': 75.34055, 'eta_hours': 0.02093, 'loss': 0.00189501, 'lr': 1.382e-05, 'params': 197319, 'time_iter': 0.10318, 'accuracy': 0.99983, 'f1': 0.99984, 'auc': 1.0}\n",
      "val: {'epoch': 42, 'time_epoch': 2.39048, 'loss': 0.1958686, 'lr': 0, 'params': 197319, 'time_iter': 0.05086, 'accuracy': 0.96774, 'f1': 0.96848, 'auc': 0.99549}\n",
      "test: {'epoch': 42, 'time_epoch': 2.41662, 'loss': 0.21568999, 'lr': 0, 'params': 197319, 'time_iter': 0.05142, 'accuracy': 0.96242, 'f1': 0.96162, 'auc': 0.99744}\n",
      "> Epoch 42: took 43.4s (avg 42.5s) | Best so far: epoch 40\ttrain_loss: 0.0039 train_accuracy: 0.9993\tval_loss: 0.2005 val_accuracy: 0.9718\ttest_loss: 0.2108 test_accuracy: 0.9624\n",
      "train: {'epoch': 43, 'time_epoch': 38.47795, 'eta': 37.68863, 'eta_hours': 0.01047, 'loss': 0.00171234, 'lr': 6.16e-06, 'params': 197319, 'time_iter': 0.10316, 'accuracy': 0.99966, 'f1': 0.99966, 'auc': 1.0}\n",
      "val: {'epoch': 43, 'time_epoch': 2.63433, 'loss': 0.1900614, 'lr': 0, 'params': 197319, 'time_iter': 0.05605, 'accuracy': 0.97177, 'f1': 0.97242, 'auc': 0.99535}\n",
      "test: {'epoch': 43, 'time_epoch': 2.29239, 'loss': 0.22142423, 'lr': 0, 'params': 197319, 'time_iter': 0.04877, 'accuracy': 0.96242, 'f1': 0.96159, 'auc': 0.99734}\n",
      "> Epoch 43: took 43.5s (avg 42.5s) | Best so far: epoch 40\ttrain_loss: 0.0039 train_accuracy: 0.9993\tval_loss: 0.2005 val_accuracy: 0.9718\ttest_loss: 0.2108 test_accuracy: 0.9624\n",
      "train: {'epoch': 44, 'time_epoch': 38.11011, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.00133509, 'lr': 1.54e-06, 'params': 197319, 'time_iter': 0.10217, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 44, 'time_epoch': 2.28679, 'loss': 0.19779833, 'lr': 0, 'params': 197319, 'time_iter': 0.04866, 'accuracy': 0.96909, 'f1': 0.96974, 'auc': 0.99455}\n",
      "test: {'epoch': 44, 'time_epoch': 2.58144, 'loss': 0.21287832, 'lr': 0, 'params': 197319, 'time_iter': 0.05492, 'accuracy': 0.96242, 'f1': 0.96149, 'auc': 0.99693}\n",
      "> Epoch 44: took 43.1s (avg 42.5s) | Best so far: epoch 40\ttrain_loss: 0.0039 train_accuracy: 0.9993\tval_loss: 0.2005 val_accuracy: 0.9718\ttest_loss: 0.2108 test_accuracy: 0.9624\n",
      "Avg time per epoch: 42.53s\n",
      "Total train loop time: 0.53h\n",
      "Task done, results saved in results\\neural-Act\\0\n",
      "40\n",
      "{'epoch': 40, 'time_epoch': 2.47568, 'loss': 0.21084553, 'lr': 0, 'params': 197319, 'time_iter': 0.05267, 'accuracy': 0.96242, 'f1': 0.96156, 'auc': 0.99713}\n",
      "{'epoch': 40, 'time_epoch': 37.71987, 'eta': 150.56246, 'eta_hours': 0.04182, 'loss': 0.00389309, 'lr': 3.806e-05, 'params': 197319, 'time_iter': 0.10113, 'accuracy': 0.99933, 'f1': 0.99934, 'auc': 1.0}\n",
      "{'epoch': 40, 'time_epoch': 2.4621, 'loss': 0.20053236, 'lr': 0, 'params': 197319, 'time_iter': 0.05239, 'accuracy': 0.97177, 'f1': 0.97243, 'auc': 0.99385}\n",
      "Results aggregated across runs saved in results\\neural-Act\\agg\n",
      "[*] All done: 2024-02-27 15:56:53.656601\n"
     ]
    }
   ],
   "source": [
    "%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False  #Exphormer dropout 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee9b2b78-8d9e-4ab6-be23-5842d37ec5b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-27 16:31:18.738329\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 7\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [05:32<00:00, 22.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:05:47.44\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [01:43<00:00, 71.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:51.31\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=400, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.6, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.6, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.6, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.6, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.6, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.6, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.6, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.6, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.6, inplace=False)\n",
      "      )\n",
      "      (3): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.6, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.6, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.6, inplace=False)\n",
      "      )\n",
      "      (4): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.6, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.6, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.6, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.3\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.6\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 5\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 75\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 197319\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 37.85872, 'eta': 2801.54513, 'eta_hours': 0.77821, 'loss': 1.95071595, 'lr': 0.0, 'params': 197319, 'time_iter': 0.1015, 'accuracy': 0.14478, 'f1': 0.05866, 'auc': 0.48729}\n",
      "...computing epoch stats took: 0.12s\n",
      "val: {'epoch': 0, 'time_epoch': 2.41407, 'loss': 1.94900316, 'lr': 0, 'params': 197319, 'time_iter': 0.05136, 'accuracy': 0.15591, 'f1': 0.07201, 'auc': 0.49374}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 0, 'time_epoch': 2.39342, 'loss': 1.95803753, 'lr': 0, 'params': 197319, 'time_iter': 0.05092, 'accuracy': 0.11007, 'f1': 0.06386, 'auc': 0.49216}\n",
      "...computing epoch stats took: 0.03s\n",
      "> Epoch 0: took 42.9s (avg 42.9s) | Best so far: epoch 0\ttrain_loss: 1.9507 train_accuracy: 0.1448\tval_loss: 1.9490 val_accuracy: 0.1559\ttest_loss: 1.9580 test_accuracy: 0.1101\n",
      "train: {'epoch': 1, 'time_epoch': 35.57599, 'eta': 2680.36688, 'eta_hours': 0.74455, 'loss': 1.73865033, 'lr': 0.0002, 'params': 197319, 'time_iter': 0.09538, 'accuracy': 0.5571, 'f1': 0.5571, 'auc': 0.86079}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 1, 'time_epoch': 2.21215, 'loss': 1.57771465, 'lr': 0, 'params': 197319, 'time_iter': 0.04707, 'accuracy': 0.71102, 'f1': 0.70879, 'auc': 0.94919}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 2.21582, 'loss': 1.57990353, 'lr': 0, 'params': 197319, 'time_iter': 0.04715, 'accuracy': 0.71409, 'f1': 0.71351, 'auc': 0.95499}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 1: took 40.1s (avg 41.5s) | Best so far: epoch 1\ttrain_loss: 1.7387 train_accuracy: 0.5571\tval_loss: 1.5777 val_accuracy: 0.7110\ttest_loss: 1.5799 test_accuracy: 0.7141\n",
      "train: {'epoch': 2, 'time_epoch': 35.83397, 'eta': 2622.4482, 'eta_hours': 0.72846, 'loss': 1.35871142, 'lr': 0.0004, 'params': 197319, 'time_iter': 0.09607, 'accuracy': 0.80047, 'f1': 0.79766, 'auc': 0.95893}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 2, 'time_epoch': 2.21066, 'loss': 1.20087755, 'lr': 0, 'params': 197319, 'time_iter': 0.04704, 'accuracy': 0.8414, 'f1': 0.84721, 'auc': 0.97553}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 2.20249, 'loss': 1.20183092, 'lr': 0, 'params': 197319, 'time_iter': 0.04686, 'accuracy': 0.84564, 'f1': 0.85077, 'auc': 0.97452}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 2: took 40.3s (avg 41.1s) | Best so far: epoch 2\ttrain_loss: 1.3587 train_accuracy: 0.8005\tval_loss: 1.2009 val_accuracy: 0.8414\ttest_loss: 1.2018 test_accuracy: 0.8456\n",
      "train: {'epoch': 3, 'time_epoch': 36.58487, 'eta': 2588.90038, 'eta_hours': 0.71914, 'loss': 0.98310784, 'lr': 0.0006, 'params': 197319, 'time_iter': 0.09808, 'accuracy': 0.87235, 'f1': 0.87133, 'auc': 0.97854}\n",
      "val: {'epoch': 3, 'time_epoch': 2.27487, 'loss': 0.76791872, 'lr': 0, 'params': 197319, 'time_iter': 0.0484, 'accuracy': 0.9207, 'f1': 0.9229, 'auc': 0.98945}\n",
      "test: {'epoch': 3, 'time_epoch': 2.44126, 'loss': 0.7637288, 'lr': 0, 'params': 197319, 'time_iter': 0.05194, 'accuracy': 0.9396, 'f1': 0.93819, 'auc': 0.98951}\n",
      "> Epoch 3: took 41.4s (avg 41.2s) | Best so far: epoch 3\ttrain_loss: 0.9831 train_accuracy: 0.8723\tval_loss: 0.7679 val_accuracy: 0.9207\ttest_loss: 0.7637 test_accuracy: 0.9396\n",
      "train: {'epoch': 4, 'time_epoch': 38.20278, 'eta': 2576.78854, 'eta_hours': 0.71577, 'loss': 0.68113384, 'lr': 0.0008, 'params': 197319, 'time_iter': 0.10242, 'accuracy': 0.89536, 'f1': 0.8947, 'auc': 0.98386}\n",
      "val: {'epoch': 4, 'time_epoch': 2.35984, 'loss': 0.59459193, 'lr': 0, 'params': 197319, 'time_iter': 0.05021, 'accuracy': 0.88978, 'f1': 0.8921, 'auc': 0.98811}\n",
      "test: {'epoch': 4, 'time_epoch': 2.40562, 'loss': 0.55741282, 'lr': 0, 'params': 197319, 'time_iter': 0.05118, 'accuracy': 0.91544, 'f1': 0.91565, 'auc': 0.98958}\n",
      "> Epoch 4: took 43.1s (avg 41.5s) | Best so far: epoch 3\ttrain_loss: 0.9831 train_accuracy: 0.8723\tval_loss: 0.7679 val_accuracy: 0.9207\ttest_loss: 0.7637 test_accuracy: 0.9396\n",
      "train: {'epoch': 5, 'time_epoch': 37.68959, 'eta': 2550.07807, 'eta_hours': 0.70836, 'loss': 0.5035414, 'lr': 0.001, 'params': 197319, 'time_iter': 0.10104, 'accuracy': 0.90611, 'f1': 0.90585, 'auc': 0.98679}\n",
      "val: {'epoch': 5, 'time_epoch': 2.38508, 'loss': 0.50163142, 'lr': 0, 'params': 197319, 'time_iter': 0.05075, 'accuracy': 0.88844, 'f1': 0.88973, 'auc': 0.98558}\n",
      "test: {'epoch': 5, 'time_epoch': 2.60468, 'loss': 0.48718536, 'lr': 0, 'params': 197319, 'time_iter': 0.05542, 'accuracy': 0.88725, 'f1': 0.88455, 'auc': 0.98804}\n",
      "> Epoch 5: took 42.8s (avg 41.7s) | Best so far: epoch 3\ttrain_loss: 0.9831 train_accuracy: 0.8723\tval_loss: 0.7679 val_accuracy: 0.9207\ttest_loss: 0.7637 test_accuracy: 0.9396\n",
      "train: {'epoch': 6, 'time_epoch': 37.81361, 'eta': 2521.43545, 'eta_hours': 0.7004, 'loss': 0.39008281, 'lr': 0.0009995, 'params': 197319, 'time_iter': 0.10138, 'accuracy': 0.91636, 'f1': 0.91611, 'auc': 0.98943}\n",
      "val: {'epoch': 6, 'time_epoch': 2.38226, 'loss': 0.41336696, 'lr': 0, 'params': 197319, 'time_iter': 0.05069, 'accuracy': 0.88978, 'f1': 0.89592, 'auc': 0.98983}\n",
      "test: {'epoch': 6, 'time_epoch': 2.49238, 'loss': 0.40419938, 'lr': 0, 'params': 197319, 'time_iter': 0.05303, 'accuracy': 0.8953, 'f1': 0.89993, 'auc': 0.99153}\n",
      "> Epoch 6: took 42.8s (avg 41.9s) | Best so far: epoch 3\ttrain_loss: 0.9831 train_accuracy: 0.8723\tval_loss: 0.7679 val_accuracy: 0.9207\ttest_loss: 0.7637 test_accuracy: 0.9396\n",
      "train: {'epoch': 7, 'time_epoch': 37.46132, 'eta': 2487.54959, 'eta_hours': 0.69099, 'loss': 0.30553167, 'lr': 0.00099799, 'params': 197319, 'time_iter': 0.10043, 'accuracy': 0.93567, 'f1': 0.93528, 'auc': 0.99167}\n",
      "val: {'epoch': 7, 'time_epoch': 2.40058, 'loss': 0.28691042, 'lr': 0, 'params': 197319, 'time_iter': 0.05108, 'accuracy': 0.93683, 'f1': 0.93793, 'auc': 0.99308}\n",
      "test: {'epoch': 7, 'time_epoch': 2.47228, 'loss': 0.28294808, 'lr': 0, 'params': 197319, 'time_iter': 0.0526, 'accuracy': 0.94094, 'f1': 0.94066, 'auc': 0.99351}\n",
      "> Epoch 7: took 42.4s (avg 42.0s) | Best so far: epoch 7\ttrain_loss: 0.3055 train_accuracy: 0.9357\tval_loss: 0.2869 val_accuracy: 0.9368\ttest_loss: 0.2829 test_accuracy: 0.9409\n",
      "train: {'epoch': 8, 'time_epoch': 37.34718, 'eta': 2452.03222, 'eta_hours': 0.68112, 'loss': 0.2532144, 'lr': 0.00099547, 'params': 197319, 'time_iter': 0.10013, 'accuracy': 0.93954, 'f1': 0.93928, 'auc': 0.9943}\n",
      "val: {'epoch': 8, 'time_epoch': 2.27903, 'loss': 0.29269776, 'lr': 0, 'params': 197319, 'time_iter': 0.04849, 'accuracy': 0.93011, 'f1': 0.93199, 'auc': 0.99238}\n",
      "test: {'epoch': 8, 'time_epoch': 2.60942, 'loss': 0.26613253, 'lr': 0, 'params': 197319, 'time_iter': 0.05552, 'accuracy': 0.93826, 'f1': 0.93901, 'auc': 0.99265}\n",
      "> Epoch 8: took 42.3s (avg 42.0s) | Best so far: epoch 7\ttrain_loss: 0.3055 train_accuracy: 0.9357\tval_loss: 0.2869 val_accuracy: 0.9368\ttest_loss: 0.2829 test_accuracy: 0.9409\n",
      "train: {'epoch': 9, 'time_epoch': 37.61158, 'eta': 2417.86743, 'eta_hours': 0.67163, 'loss': 0.19997128, 'lr': 0.00099196, 'params': 197319, 'time_iter': 0.10084, 'accuracy': 0.95532, 'f1': 0.95516, 'auc': 0.9954}\n",
      "val: {'epoch': 9, 'time_epoch': 2.34559, 'loss': 0.25000013, 'lr': 0, 'params': 197319, 'time_iter': 0.04991, 'accuracy': 0.93683, 'f1': 0.93815, 'auc': 0.99494}\n",
      "test: {'epoch': 9, 'time_epoch': 2.42296, 'loss': 0.23022831, 'lr': 0, 'params': 197319, 'time_iter': 0.05155, 'accuracy': 0.94631, 'f1': 0.94676, 'auc': 0.99608}\n",
      "> Epoch 9: took 42.5s (avg 42.0s) | Best so far: epoch 7\ttrain_loss: 0.3055 train_accuracy: 0.9357\tval_loss: 0.2869 val_accuracy: 0.9368\ttest_loss: 0.2829 test_accuracy: 0.9409\n",
      "train: {'epoch': 10, 'time_epoch': 37.67985, 'eta': 2383.47321, 'eta_hours': 0.66208, 'loss': 0.2052087, 'lr': 0.00098746, 'params': 197319, 'time_iter': 0.10102, 'accuracy': 0.94945, 'f1': 0.94932, 'auc': 0.99495}\n",
      "val: {'epoch': 10, 'time_epoch': 2.3712, 'loss': 0.21158347, 'lr': 0, 'params': 197319, 'time_iter': 0.05045, 'accuracy': 0.94892, 'f1': 0.95017, 'auc': 0.99545}\n",
      "test: {'epoch': 10, 'time_epoch': 2.39938, 'loss': 0.18134957, 'lr': 0, 'params': 197319, 'time_iter': 0.05105, 'accuracy': 0.9557, 'f1': 0.95408, 'auc': 0.99639}\n",
      "> Epoch 10: took 42.5s (avg 42.1s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 11, 'time_epoch': 37.32154, 'eta': 2346.65026, 'eta_hours': 0.65185, 'loss': 0.16657615, 'lr': 0.00098198, 'params': 197319, 'time_iter': 0.10006, 'accuracy': 0.95852, 'f1': 0.9583, 'auc': 0.99711}\n",
      "val: {'epoch': 11, 'time_epoch': 2.36946, 'loss': 0.22040607, 'lr': 0, 'params': 197319, 'time_iter': 0.05041, 'accuracy': 0.93817, 'f1': 0.94054, 'auc': 0.99636}\n",
      "test: {'epoch': 11, 'time_epoch': 2.68388, 'loss': 0.21886048, 'lr': 0, 'params': 197319, 'time_iter': 0.0571, 'accuracy': 0.94228, 'f1': 0.94227, 'auc': 0.99466}\n",
      "> Epoch 11: took 42.5s (avg 42.1s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 12, 'time_epoch': 37.64688, 'eta': 2311.30221, 'eta_hours': 0.64203, 'loss': 0.16567877, 'lr': 0.00097553, 'params': 197319, 'time_iter': 0.10093, 'accuracy': 0.95516, 'f1': 0.95501, 'auc': 0.99719}\n",
      "val: {'epoch': 12, 'time_epoch': 2.28127, 'loss': 0.18840853, 'lr': 0, 'params': 197319, 'time_iter': 0.04854, 'accuracy': 0.94758, 'f1': 0.94853, 'auc': 0.99693}\n",
      "test: {'epoch': 12, 'time_epoch': 2.40221, 'loss': 0.17759571, 'lr': 0, 'params': 197319, 'time_iter': 0.05111, 'accuracy': 0.95168, 'f1': 0.95108, 'auc': 0.99531}\n",
      "> Epoch 12: took 42.4s (avg 42.1s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 13, 'time_epoch': 38.18307, 'eta': 2277.96203, 'eta_hours': 0.63277, 'loss': 0.14364371, 'lr': 0.00096812, 'params': 197319, 'time_iter': 0.10237, 'accuracy': 0.96087, 'f1': 0.96076, 'auc': 0.99766}\n",
      "val: {'epoch': 13, 'time_epoch': 2.33629, 'loss': 0.22270538, 'lr': 0, 'params': 197319, 'time_iter': 0.04971, 'accuracy': 0.94489, 'f1': 0.94747, 'auc': 0.99511}\n",
      "test: {'epoch': 13, 'time_epoch': 2.44679, 'loss': 0.19591925, 'lr': 0, 'params': 197319, 'time_iter': 0.05206, 'accuracy': 0.94362, 'f1': 0.94389, 'auc': 0.99734}\n",
      "> Epoch 13: took 43.1s (avg 42.2s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 14, 'time_epoch': 38.03234, 'eta': 2243.37319, 'eta_hours': 0.62316, 'loss': 0.14012865, 'lr': 0.00095976, 'params': 197319, 'time_iter': 0.10196, 'accuracy': 0.96355, 'f1': 0.9635, 'auc': 0.99772}\n",
      "val: {'epoch': 14, 'time_epoch': 2.30362, 'loss': 0.40244229, 'lr': 0, 'params': 197319, 'time_iter': 0.04901, 'accuracy': 0.89785, 'f1': 0.90299, 'auc': 0.99225}\n",
      "test: {'epoch': 14, 'time_epoch': 2.58587, 'loss': 0.38726537, 'lr': 0, 'params': 197319, 'time_iter': 0.05502, 'accuracy': 0.88859, 'f1': 0.89896, 'auc': 0.99522}\n",
      "> Epoch 14: took 43.0s (avg 42.3s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 15, 'time_epoch': 37.76288, 'eta': 2207.36028, 'eta_hours': 0.61316, 'loss': 0.14100237, 'lr': 0.00095048, 'params': 197319, 'time_iter': 0.10124, 'accuracy': 0.95835, 'f1': 0.95823, 'auc': 0.99781}\n",
      "val: {'epoch': 15, 'time_epoch': 2.31522, 'loss': 0.32073224, 'lr': 0, 'params': 197319, 'time_iter': 0.04926, 'accuracy': 0.90591, 'f1': 0.90753, 'auc': 0.99224}\n",
      "test: {'epoch': 15, 'time_epoch': 2.3975, 'loss': 0.29432466, 'lr': 0, 'params': 197319, 'time_iter': 0.05101, 'accuracy': 0.92081, 'f1': 0.9215, 'auc': 0.99394}\n",
      "> Epoch 15: took 42.6s (avg 42.3s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 16, 'time_epoch': 38.06129, 'eta': 2172.1596, 'eta_hours': 0.60338, 'loss': 0.14159783, 'lr': 0.0009403, 'params': 197319, 'time_iter': 0.10204, 'accuracy': 0.95868, 'f1': 0.95868, 'auc': 0.99748}\n",
      "val: {'epoch': 16, 'time_epoch': 2.32824, 'loss': 0.31452005, 'lr': 0, 'params': 197319, 'time_iter': 0.04954, 'accuracy': 0.91801, 'f1': 0.92273, 'auc': 0.99477}\n",
      "test: {'epoch': 16, 'time_epoch': 2.48764, 'loss': 0.34624568, 'lr': 0, 'params': 197319, 'time_iter': 0.05293, 'accuracy': 0.9047, 'f1': 0.91142, 'auc': 0.99472}\n",
      "> Epoch 16: took 43.0s (avg 42.3s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 17, 'time_epoch': 37.4508, 'eta': 2134.70786, 'eta_hours': 0.59297, 'loss': 0.13584012, 'lr': 0.00092922, 'params': 197319, 'time_iter': 0.1004, 'accuracy': 0.96305, 'f1': 0.96296, 'auc': 0.99791}\n",
      "val: {'epoch': 17, 'time_epoch': 2.35581, 'loss': 0.18673798, 'lr': 0, 'params': 197319, 'time_iter': 0.05012, 'accuracy': 0.94758, 'f1': 0.94911, 'auc': 0.99643}\n",
      "test: {'epoch': 17, 'time_epoch': 2.52095, 'loss': 0.21520824, 'lr': 0, 'params': 197319, 'time_iter': 0.05364, 'accuracy': 0.94765, 'f1': 0.94651, 'auc': 0.99607}\n",
      "> Epoch 17: took 42.4s (avg 42.3s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 18, 'time_epoch': 37.25929, 'eta': 2096.69178, 'eta_hours': 0.58241, 'loss': 0.1372548, 'lr': 0.00091729, 'params': 197319, 'time_iter': 0.09989, 'accuracy': 0.9612, 'f1': 0.96107, 'auc': 0.99733}\n",
      "val: {'epoch': 18, 'time_epoch': 2.33355, 'loss': 0.24056298, 'lr': 0, 'params': 197319, 'time_iter': 0.04965, 'accuracy': 0.92742, 'f1': 0.93073, 'auc': 0.99576}\n",
      "test: {'epoch': 18, 'time_epoch': 2.39177, 'loss': 0.25037173, 'lr': 0, 'params': 197319, 'time_iter': 0.05089, 'accuracy': 0.93289, 'f1': 0.93528, 'auc': 0.99639}\n",
      "> Epoch 18: took 42.1s (avg 42.3s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 19, 'time_epoch': 37.56162, 'eta': 2059.58276, 'eta_hours': 0.57211, 'loss': 0.15254805, 'lr': 0.00090451, 'params': 197319, 'time_iter': 0.1007, 'accuracy': 0.9565, 'f1': 0.9563, 'auc': 0.99704}\n",
      "val: {'epoch': 19, 'time_epoch': 2.39349, 'loss': 0.27624676, 'lr': 0, 'params': 197319, 'time_iter': 0.05093, 'accuracy': 0.92473, 'f1': 0.92694, 'auc': 0.99397}\n",
      "test: {'epoch': 19, 'time_epoch': 2.41975, 'loss': 0.2859248, 'lr': 0, 'params': 197319, 'time_iter': 0.05148, 'accuracy': 0.93423, 'f1': 0.933, 'auc': 0.99356}\n",
      "> Epoch 19: took 42.5s (avg 42.3s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 20, 'time_epoch': 37.5638, 'eta': 2022.43626, 'eta_hours': 0.56179, 'loss': 0.12653255, 'lr': 0.00089092, 'params': 197319, 'time_iter': 0.10071, 'accuracy': 0.96339, 'f1': 0.96338, 'auc': 0.99814}\n",
      "val: {'epoch': 20, 'time_epoch': 2.24863, 'loss': 0.26169952, 'lr': 0, 'params': 197319, 'time_iter': 0.04784, 'accuracy': 0.93145, 'f1': 0.9333, 'auc': 0.99454}\n",
      "test: {'epoch': 20, 'time_epoch': 2.36655, 'loss': 0.24713791, 'lr': 0, 'params': 197319, 'time_iter': 0.05035, 'accuracy': 0.94094, 'f1': 0.94091, 'auc': 0.99458}\n",
      "> Epoch 20: took 42.3s (avg 42.3s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 21, 'time_epoch': 38.1328, 'eta': 1986.62258, 'eta_hours': 0.55184, 'loss': 0.1279972, 'lr': 0.00087654, 'params': 197319, 'time_iter': 0.10223, 'accuracy': 0.96322, 'f1': 0.96316, 'auc': 0.99792}\n",
      "val: {'epoch': 21, 'time_epoch': 2.47746, 'loss': 0.31795492, 'lr': 0, 'params': 197319, 'time_iter': 0.05271, 'accuracy': 0.91667, 'f1': 0.92116, 'auc': 0.99256}\n",
      "test: {'epoch': 21, 'time_epoch': 2.44984, 'loss': 0.3037842, 'lr': 0, 'params': 197319, 'time_iter': 0.05212, 'accuracy': 0.92081, 'f1': 0.92496, 'auc': 0.99422}\n",
      "> Epoch 21: took 43.2s (avg 42.4s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 22, 'time_epoch': 38.27589, 'eta': 1950.93076, 'eta_hours': 0.54193, 'loss': 0.14772944, 'lr': 0.0008614, 'params': 197319, 'time_iter': 0.10262, 'accuracy': 0.95784, 'f1': 0.95778, 'auc': 0.99753}\n",
      "val: {'epoch': 22, 'time_epoch': 2.34866, 'loss': 0.39590243, 'lr': 0, 'params': 197319, 'time_iter': 0.04997, 'accuracy': 0.91129, 'f1': 0.91353, 'auc': 0.99015}\n",
      "test: {'epoch': 22, 'time_epoch': 2.39307, 'loss': 0.33950485, 'lr': 0, 'params': 197319, 'time_iter': 0.05092, 'accuracy': 0.91141, 'f1': 0.91222, 'auc': 0.992}\n",
      "> Epoch 22: took 43.1s (avg 42.4s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 23, 'time_epoch': 38.42501, 'eta': 1915.34047, 'eta_hours': 0.53204, 'loss': 0.13009995, 'lr': 0.00084553, 'params': 197319, 'time_iter': 0.10302, 'accuracy': 0.96288, 'f1': 0.9628, 'auc': 0.99827}\n",
      "val: {'epoch': 23, 'time_epoch': 2.25107, 'loss': 0.27263077, 'lr': 0, 'params': 197319, 'time_iter': 0.0479, 'accuracy': 0.92742, 'f1': 0.93017, 'auc': 0.99431}\n",
      "test: {'epoch': 23, 'time_epoch': 2.66814, 'loss': 0.26040719, 'lr': 0, 'params': 197319, 'time_iter': 0.05677, 'accuracy': 0.93423, 'f1': 0.93475, 'auc': 0.99535}\n",
      "> Epoch 23: took 43.4s (avg 42.4s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 24, 'time_epoch': 37.92752, 'eta': 1878.52842, 'eta_hours': 0.52181, 'loss': 0.09573762, 'lr': 0.00082897, 'params': 197319, 'time_iter': 0.10168, 'accuracy': 0.97162, 'f1': 0.97155, 'auc': 0.99865}\n",
      "val: {'epoch': 24, 'time_epoch': 2.35304, 'loss': 0.24452479, 'lr': 0, 'params': 197319, 'time_iter': 0.05006, 'accuracy': 0.94758, 'f1': 0.94876, 'auc': 0.9948}\n",
      "test: {'epoch': 24, 'time_epoch': 2.41838, 'loss': 0.23196825, 'lr': 0, 'params': 197319, 'time_iter': 0.05145, 'accuracy': 0.94765, 'f1': 0.94694, 'auc': 0.99552}\n",
      "> Epoch 24: took 42.8s (avg 42.4s) | Best so far: epoch 10\ttrain_loss: 0.2052 train_accuracy: 0.9495\tval_loss: 0.2116 val_accuracy: 0.9489\ttest_loss: 0.1813 test_accuracy: 0.9557\n",
      "train: {'epoch': 25, 'time_epoch': 37.53449, 'eta': 1840.88986, 'eta_hours': 0.51136, 'loss': 0.09119839, 'lr': 0.00081174, 'params': 197319, 'time_iter': 0.10063, 'accuracy': 0.97565, 'f1': 0.97561, 'auc': 0.99895}\n",
      "val: {'epoch': 25, 'time_epoch': 2.36015, 'loss': 0.22293419, 'lr': 0, 'params': 197319, 'time_iter': 0.05022, 'accuracy': 0.95027, 'f1': 0.95161, 'auc': 0.99399}\n",
      "test: {'epoch': 25, 'time_epoch': 2.56352, 'loss': 0.2182085, 'lr': 0, 'params': 197319, 'time_iter': 0.05454, 'accuracy': 0.95034, 'f1': 0.94959, 'auc': 0.99587}\n",
      "> Epoch 25: took 42.5s (avg 42.4s) | Best so far: epoch 25\ttrain_loss: 0.0912 train_accuracy: 0.9757\tval_loss: 0.2229 val_accuracy: 0.9503\ttest_loss: 0.2182 test_accuracy: 0.9503\n",
      "train: {'epoch': 26, 'time_epoch': 37.51508, 'eta': 1803.22449, 'eta_hours': 0.5009, 'loss': 0.07511086, 'lr': 0.00079389, 'params': 197319, 'time_iter': 0.10058, 'accuracy': 0.97867, 'f1': 0.97862, 'auc': 0.9992}\n",
      "val: {'epoch': 26, 'time_epoch': 2.26483, 'loss': 0.26968659, 'lr': 0, 'params': 197319, 'time_iter': 0.04819, 'accuracy': 0.93683, 'f1': 0.93827, 'auc': 0.99345}\n",
      "test: {'epoch': 26, 'time_epoch': 2.50838, 'loss': 0.2737745, 'lr': 0, 'params': 197319, 'time_iter': 0.05337, 'accuracy': 0.93691, 'f1': 0.93676, 'auc': 0.99439}\n",
      "> Epoch 26: took 42.4s (avg 42.4s) | Best so far: epoch 25\ttrain_loss: 0.0912 train_accuracy: 0.9757\tval_loss: 0.2229 val_accuracy: 0.9503\ttest_loss: 0.2182 test_accuracy: 0.9503\n",
      "train: {'epoch': 27, 'time_epoch': 37.77748, 'eta': 1766.01033, 'eta_hours': 0.49056, 'loss': 0.1015157, 'lr': 0.00077545, 'params': 197319, 'time_iter': 0.10128, 'accuracy': 0.97397, 'f1': 0.97398, 'auc': 0.99883}\n",
      "val: {'epoch': 27, 'time_epoch': 2.32658, 'loss': 0.2329569, 'lr': 0, 'params': 197319, 'time_iter': 0.0495, 'accuracy': 0.94624, 'f1': 0.9472, 'auc': 0.99582}\n",
      "test: {'epoch': 27, 'time_epoch': 2.39039, 'loss': 0.25705259, 'lr': 0, 'params': 197319, 'time_iter': 0.05086, 'accuracy': 0.9396, 'f1': 0.94034, 'auc': 0.99458}\n",
      "> Epoch 27: took 42.6s (avg 42.4s) | Best so far: epoch 25\ttrain_loss: 0.0912 train_accuracy: 0.9757\tval_loss: 0.2229 val_accuracy: 0.9503\ttest_loss: 0.2182 test_accuracy: 0.9503\n",
      "train: {'epoch': 28, 'time_epoch': 37.54833, 'eta': 1728.39383, 'eta_hours': 0.48011, 'loss': 0.08780034, 'lr': 0.00075645, 'params': 197319, 'time_iter': 0.10067, 'accuracy': 0.97699, 'f1': 0.97695, 'auc': 0.99901}\n",
      "val: {'epoch': 28, 'time_epoch': 2.35485, 'loss': 0.21960042, 'lr': 0, 'params': 197319, 'time_iter': 0.0501, 'accuracy': 0.94355, 'f1': 0.94466, 'auc': 0.99582}\n",
      "test: {'epoch': 28, 'time_epoch': 2.36952, 'loss': 0.2524542, 'lr': 0, 'params': 197319, 'time_iter': 0.05042, 'accuracy': 0.93826, 'f1': 0.9383, 'auc': 0.99658}\n",
      "> Epoch 28: took 42.4s (avg 42.4s) | Best so far: epoch 25\ttrain_loss: 0.0912 train_accuracy: 0.9757\tval_loss: 0.2229 val_accuracy: 0.9503\ttest_loss: 0.2182 test_accuracy: 0.9503\n",
      "train: {'epoch': 29, 'time_epoch': 37.37815, 'eta': 1690.52661, 'eta_hours': 0.46959, 'loss': 0.0805243, 'lr': 0.00073693, 'params': 197319, 'time_iter': 0.10021, 'accuracy': 0.97615, 'f1': 0.97608, 'auc': 0.99923}\n",
      "val: {'epoch': 29, 'time_epoch': 2.24402, 'loss': 0.29198509, 'lr': 0, 'params': 197319, 'time_iter': 0.04775, 'accuracy': 0.94086, 'f1': 0.94205, 'auc': 0.99481}\n",
      "test: {'epoch': 29, 'time_epoch': 2.45263, 'loss': 0.24425566, 'lr': 0, 'params': 197319, 'time_iter': 0.05218, 'accuracy': 0.94497, 'f1': 0.94407, 'auc': 0.99626}\n",
      "> Epoch 29: took 42.2s (avg 42.4s) | Best so far: epoch 25\ttrain_loss: 0.0912 train_accuracy: 0.9757\tval_loss: 0.2229 val_accuracy: 0.9503\ttest_loss: 0.2182 test_accuracy: 0.9503\n",
      "train: {'epoch': 30, 'time_epoch': 38.56864, 'eta': 1654.38067, 'eta_hours': 0.45955, 'loss': 0.08280596, 'lr': 0.00071694, 'params': 197319, 'time_iter': 0.1034, 'accuracy': 0.97699, 'f1': 0.97696, 'auc': 0.9992}\n",
      "val: {'epoch': 30, 'time_epoch': 2.30355, 'loss': 0.19859399, 'lr': 0, 'params': 197319, 'time_iter': 0.04901, 'accuracy': 0.95161, 'f1': 0.95285, 'auc': 0.9972}\n",
      "test: {'epoch': 30, 'time_epoch': 2.5065, 'loss': 0.23644542, 'lr': 0, 'params': 197319, 'time_iter': 0.05333, 'accuracy': 0.94228, 'f1': 0.94234, 'auc': 0.99649}\n",
      "> Epoch 30: took 43.5s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 31, 'time_epoch': 38.09212, 'eta': 1617.44298, 'eta_hours': 0.44929, 'loss': 0.08836366, 'lr': 0.00069651, 'params': 197319, 'time_iter': 0.10212, 'accuracy': 0.9743, 'f1': 0.97429, 'auc': 0.99903}\n",
      "val: {'epoch': 31, 'time_epoch': 2.287, 'loss': 0.30412157, 'lr': 0, 'params': 197319, 'time_iter': 0.04866, 'accuracy': 0.93011, 'f1': 0.93078, 'auc': 0.99471}\n",
      "test: {'epoch': 31, 'time_epoch': 2.37473, 'loss': 0.31488399, 'lr': 0, 'params': 197319, 'time_iter': 0.05053, 'accuracy': 0.92752, 'f1': 0.92736, 'auc': 0.99304}\n",
      "> Epoch 31: took 42.8s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 32, 'time_epoch': 37.78054, 'eta': 1580.03878, 'eta_hours': 0.4389, 'loss': 0.09187495, 'lr': 0.00067569, 'params': 197319, 'time_iter': 0.10129, 'accuracy': 0.97514, 'f1': 0.97515, 'auc': 0.99902}\n",
      "val: {'epoch': 32, 'time_epoch': 2.30054, 'loss': 0.21130704, 'lr': 0, 'params': 197319, 'time_iter': 0.04895, 'accuracy': 0.94624, 'f1': 0.94768, 'auc': 0.99623}\n",
      "test: {'epoch': 32, 'time_epoch': 2.87475, 'loss': 0.2723525, 'lr': 0, 'params': 197319, 'time_iter': 0.06116, 'accuracy': 0.93289, 'f1': 0.93358, 'auc': 0.99636}\n",
      "> Epoch 32: took 43.0s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 33, 'time_epoch': 37.77823, 'eta': 1542.60965, 'eta_hours': 0.4285, 'loss': 0.08063162, 'lr': 0.00065451, 'params': 197319, 'time_iter': 0.10128, 'accuracy': 0.97749, 'f1': 0.9775, 'auc': 0.99915}\n",
      "val: {'epoch': 33, 'time_epoch': 2.29754, 'loss': 0.22326922, 'lr': 0, 'params': 197319, 'time_iter': 0.04888, 'accuracy': 0.94489, 'f1': 0.94629, 'auc': 0.99727}\n",
      "test: {'epoch': 33, 'time_epoch': 2.41742, 'loss': 0.24862777, 'lr': 0, 'params': 197319, 'time_iter': 0.05143, 'accuracy': 0.94497, 'f1': 0.94551, 'auc': 0.99546}\n",
      "> Epoch 33: took 42.6s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 34, 'time_epoch': 37.69619, 'eta': 1505.06681, 'eta_hours': 0.41807, 'loss': 0.065542, 'lr': 0.00063302, 'params': 197319, 'time_iter': 0.10106, 'accuracy': 0.98253, 'f1': 0.98246, 'auc': 0.99956}\n",
      "val: {'epoch': 34, 'time_epoch': 2.27711, 'loss': 0.21248414, 'lr': 0, 'params': 197319, 'time_iter': 0.04845, 'accuracy': 0.9422, 'f1': 0.94321, 'auc': 0.99726}\n",
      "test: {'epoch': 34, 'time_epoch': 2.44208, 'loss': 0.24818293, 'lr': 0, 'params': 197319, 'time_iter': 0.05196, 'accuracy': 0.94094, 'f1': 0.94035, 'auc': 0.99488}\n",
      "> Epoch 34: took 42.5s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 35, 'time_epoch': 37.49863, 'eta': 1467.30143, 'eta_hours': 0.40758, 'loss': 0.06342183, 'lr': 0.00061126, 'params': 197319, 'time_iter': 0.10053, 'accuracy': 0.98236, 'f1': 0.98239, 'auc': 0.99955}\n",
      "val: {'epoch': 35, 'time_epoch': 2.35295, 'loss': 0.24334483, 'lr': 0, 'params': 197319, 'time_iter': 0.05006, 'accuracy': 0.93414, 'f1': 0.93568, 'auc': 0.99681}\n",
      "test: {'epoch': 35, 'time_epoch': 2.70246, 'loss': 0.27741421, 'lr': 0, 'params': 197319, 'time_iter': 0.0575, 'accuracy': 0.93557, 'f1': 0.93602, 'auc': 0.99684}\n",
      "> Epoch 35: took 42.6s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 36, 'time_epoch': 37.66592, 'eta': 1429.72228, 'eta_hours': 0.39715, 'loss': 0.06412006, 'lr': 0.00058928, 'params': 197319, 'time_iter': 0.10098, 'accuracy': 0.98169, 'f1': 0.98162, 'auc': 0.99954}\n",
      "val: {'epoch': 36, 'time_epoch': 2.32453, 'loss': 0.33752156, 'lr': 0, 'params': 197319, 'time_iter': 0.04946, 'accuracy': 0.92339, 'f1': 0.92471, 'auc': 0.99285}\n",
      "test: {'epoch': 36, 'time_epoch': 2.42653, 'loss': 0.32658613, 'lr': 0, 'params': 197319, 'time_iter': 0.05163, 'accuracy': 0.92483, 'f1': 0.92525, 'auc': 0.99434}\n",
      "> Epoch 36: took 42.5s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 37, 'time_epoch': 38.08063, 'eta': 1392.54236, 'eta_hours': 0.38682, 'loss': 0.06378239, 'lr': 0.00056712, 'params': 197319, 'time_iter': 0.10209, 'accuracy': 0.9822, 'f1': 0.98223, 'auc': 0.99948}\n",
      "val: {'epoch': 37, 'time_epoch': 2.35005, 'loss': 0.21446397, 'lr': 0, 'params': 197319, 'time_iter': 0.05, 'accuracy': 0.95027, 'f1': 0.95136, 'auc': 0.99484}\n",
      "test: {'epoch': 37, 'time_epoch': 2.55142, 'loss': 0.22827034, 'lr': 0, 'params': 197319, 'time_iter': 0.05429, 'accuracy': 0.95436, 'f1': 0.95437, 'auc': 0.99558}\n",
      "> Epoch 37: took 43.1s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 38, 'time_epoch': 37.86502, 'eta': 1355.11722, 'eta_hours': 0.37642, 'loss': 0.05339095, 'lr': 0.00054482, 'params': 197319, 'time_iter': 0.10151, 'accuracy': 0.98455, 'f1': 0.98447, 'auc': 0.99972}\n",
      "val: {'epoch': 38, 'time_epoch': 2.32545, 'loss': 0.23338969, 'lr': 0, 'params': 197319, 'time_iter': 0.04948, 'accuracy': 0.94892, 'f1': 0.95016, 'auc': 0.9952}\n",
      "test: {'epoch': 38, 'time_epoch': 2.53468, 'loss': 0.25275544, 'lr': 0, 'params': 197319, 'time_iter': 0.05393, 'accuracy': 0.94497, 'f1': 0.94519, 'auc': 0.99526}\n",
      "> Epoch 38: took 42.8s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 39, 'time_epoch': 37.99468, 'eta': 1317.78354, 'eta_hours': 0.36605, 'loss': 0.06616691, 'lr': 0.00052243, 'params': 197319, 'time_iter': 0.10186, 'accuracy': 0.98287, 'f1': 0.98281, 'auc': 0.99952}\n",
      "val: {'epoch': 39, 'time_epoch': 2.38941, 'loss': 0.31446431, 'lr': 0, 'params': 197319, 'time_iter': 0.05084, 'accuracy': 0.93011, 'f1': 0.93193, 'auc': 0.99464}\n",
      "test: {'epoch': 39, 'time_epoch': 2.45123, 'loss': 0.31715268, 'lr': 0, 'params': 197319, 'time_iter': 0.05215, 'accuracy': 0.93154, 'f1': 0.92997, 'auc': 0.99576}\n",
      "> Epoch 39: took 42.9s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 40, 'time_epoch': 37.78659, 'eta': 1280.24506, 'eta_hours': 0.35562, 'loss': 0.06571038, 'lr': 0.0005, 'params': 197319, 'time_iter': 0.1013, 'accuracy': 0.98085, 'f1': 0.98087, 'auc': 0.99961}\n",
      "val: {'epoch': 40, 'time_epoch': 2.34361, 'loss': 0.33805119, 'lr': 0, 'params': 197319, 'time_iter': 0.04986, 'accuracy': 0.9207, 'f1': 0.92197, 'auc': 0.99574}\n",
      "test: {'epoch': 40, 'time_epoch': 2.47754, 'loss': 0.30769643, 'lr': 0, 'params': 197319, 'time_iter': 0.05271, 'accuracy': 0.93154, 'f1': 0.93042, 'auc': 0.99655}\n",
      "> Epoch 40: took 42.7s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 41, 'time_epoch': 37.61983, 'eta': 1242.56374, 'eta_hours': 0.34516, 'loss': 0.0550576, 'lr': 0.00047757, 'params': 197319, 'time_iter': 0.10086, 'accuracy': 0.98589, 'f1': 0.98585, 'auc': 0.99959}\n",
      "val: {'epoch': 41, 'time_epoch': 2.29619, 'loss': 0.25012735, 'lr': 0, 'params': 197319, 'time_iter': 0.04886, 'accuracy': 0.94355, 'f1': 0.94516, 'auc': 0.99608}\n",
      "test: {'epoch': 41, 'time_epoch': 2.56052, 'loss': 0.30152908, 'lr': 0, 'params': 197319, 'time_iter': 0.05448, 'accuracy': 0.93691, 'f1': 0.93594, 'auc': 0.99709}\n",
      "> Epoch 41: took 42.6s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 42, 'time_epoch': 38.02444, 'eta': 1205.18639, 'eta_hours': 0.33477, 'loss': 0.04096517, 'lr': 0.00045518, 'params': 197319, 'time_iter': 0.10194, 'accuracy': 0.9869, 'f1': 0.9869, 'auc': 0.99985}\n",
      "val: {'epoch': 42, 'time_epoch': 2.21716, 'loss': 0.24391984, 'lr': 0, 'params': 197319, 'time_iter': 0.04717, 'accuracy': 0.94758, 'f1': 0.94859, 'auc': 0.99636}\n",
      "test: {'epoch': 42, 'time_epoch': 2.30742, 'loss': 0.27869227, 'lr': 0, 'params': 197319, 'time_iter': 0.04909, 'accuracy': 0.94094, 'f1': 0.9401, 'auc': 0.99664}\n",
      "> Epoch 42: took 42.6s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 43, 'time_epoch': 36.47255, 'eta': 1166.68623, 'eta_hours': 0.32408, 'loss': 0.03754731, 'lr': 0.00043288, 'params': 197319, 'time_iter': 0.09778, 'accuracy': 0.98875, 'f1': 0.98871, 'auc': 0.99986}\n",
      "val: {'epoch': 43, 'time_epoch': 2.3025, 'loss': 0.2330303, 'lr': 0, 'params': 197319, 'time_iter': 0.04899, 'accuracy': 0.95027, 'f1': 0.95121, 'auc': 0.99689}\n",
      "test: {'epoch': 43, 'time_epoch': 2.38436, 'loss': 0.22746753, 'lr': 0, 'params': 197319, 'time_iter': 0.05073, 'accuracy': 0.95168, 'f1': 0.95188, 'auc': 0.99557}\n",
      "> Epoch 43: took 41.2s (avg 42.5s) | Best so far: epoch 30\ttrain_loss: 0.0828 train_accuracy: 0.9770\tval_loss: 0.1986 val_accuracy: 0.9516\ttest_loss: 0.2364 test_accuracy: 0.9423\n",
      "train: {'epoch': 44, 'time_epoch': 38.2902, 'eta': 1129.48797, 'eta_hours': 0.31375, 'loss': 0.0369374, 'lr': 0.00041072, 'params': 197319, 'time_iter': 0.10265, 'accuracy': 0.98942, 'f1': 0.98938, 'auc': 0.99978}\n",
      "val: {'epoch': 44, 'time_epoch': 2.25127, 'loss': 0.23798234, 'lr': 0, 'params': 197319, 'time_iter': 0.0479, 'accuracy': 0.95699, 'f1': 0.95807, 'auc': 0.99684}\n",
      "test: {'epoch': 44, 'time_epoch': 2.64259, 'loss': 0.26173192, 'lr': 0, 'params': 197319, 'time_iter': 0.05623, 'accuracy': 0.95034, 'f1': 0.94917, 'auc': 0.99752}\n",
      "> Epoch 44: took 43.3s (avg 42.5s) | Best so far: epoch 44\ttrain_loss: 0.0369 train_accuracy: 0.9894\tval_loss: 0.2380 val_accuracy: 0.9570\ttest_loss: 0.2617 test_accuracy: 0.9503\n",
      "train: {'epoch': 45, 'time_epoch': 37.53473, 'eta': 1091.76595, 'eta_hours': 0.30327, 'loss': 0.02373616, 'lr': 0.00038874, 'params': 197319, 'time_iter': 0.10063, 'accuracy': 0.99278, 'f1': 0.99278, 'auc': 0.99994}\n",
      "val: {'epoch': 45, 'time_epoch': 2.41038, 'loss': 0.23193553, 'lr': 0, 'params': 197319, 'time_iter': 0.05128, 'accuracy': 0.95161, 'f1': 0.95228, 'auc': 0.9977}\n",
      "test: {'epoch': 45, 'time_epoch': 2.44645, 'loss': 0.24785134, 'lr': 0, 'params': 197319, 'time_iter': 0.05205, 'accuracy': 0.95705, 'f1': 0.95662, 'auc': 0.99589}\n",
      "> Epoch 45: took 42.5s (avg 42.5s) | Best so far: epoch 44\ttrain_loss: 0.0369 train_accuracy: 0.9894\tval_loss: 0.2380 val_accuracy: 0.9570\ttest_loss: 0.2617 test_accuracy: 0.9503\n",
      "train: {'epoch': 46, 'time_epoch': 38.11251, 'eta': 1054.39611, 'eta_hours': 0.29289, 'loss': 0.021383, 'lr': 0.00036698, 'params': 197319, 'time_iter': 0.10218, 'accuracy': 0.99328, 'f1': 0.99331, 'auc': 0.99993}\n",
      "val: {'epoch': 46, 'time_epoch': 2.35714, 'loss': 0.29085546, 'lr': 0, 'params': 197319, 'time_iter': 0.05015, 'accuracy': 0.9422, 'f1': 0.94381, 'auc': 0.99664}\n",
      "test: {'epoch': 46, 'time_epoch': 2.40283, 'loss': 0.26999934, 'lr': 0, 'params': 197319, 'time_iter': 0.05112, 'accuracy': 0.95302, 'f1': 0.95323, 'auc': 0.99713}\n",
      "> Epoch 46: took 43.0s (avg 42.5s) | Best so far: epoch 44\ttrain_loss: 0.0369 train_accuracy: 0.9894\tval_loss: 0.2380 val_accuracy: 0.9570\ttest_loss: 0.2617 test_accuracy: 0.9503\n",
      "train: {'epoch': 47, 'time_epoch': 38.17596, 'eta': 1017.03102, 'eta_hours': 0.28251, 'loss': 0.03883528, 'lr': 0.00034549, 'params': 197319, 'time_iter': 0.10235, 'accuracy': 0.98892, 'f1': 0.98889, 'auc': 0.99971}\n",
      "val: {'epoch': 47, 'time_epoch': 2.28008, 'loss': 0.2334649, 'lr': 0, 'params': 197319, 'time_iter': 0.04851, 'accuracy': 0.9543, 'f1': 0.95597, 'auc': 0.99645}\n",
      "test: {'epoch': 47, 'time_epoch': 2.61197, 'loss': 0.22452651, 'lr': 0, 'params': 197319, 'time_iter': 0.05557, 'accuracy': 0.9557, 'f1': 0.95417, 'auc': 0.99716}\n",
      "> Epoch 47: took 43.2s (avg 42.6s) | Best so far: epoch 44\ttrain_loss: 0.0369 train_accuracy: 0.9894\tval_loss: 0.2380 val_accuracy: 0.9570\ttest_loss: 0.2617 test_accuracy: 0.9503\n",
      "train: {'epoch': 48, 'time_epoch': 38.23835, 'eta': 979.66593, 'eta_hours': 0.27213, 'loss': 0.02570061, 'lr': 0.00032431, 'params': 197319, 'time_iter': 0.10252, 'accuracy': 0.99227, 'f1': 0.99227, 'auc': 0.99989}\n",
      "val: {'epoch': 48, 'time_epoch': 2.35961, 'loss': 0.29097923, 'lr': 0, 'params': 197319, 'time_iter': 0.0502, 'accuracy': 0.94489, 'f1': 0.94612, 'auc': 0.99425}\n",
      "test: {'epoch': 48, 'time_epoch': 2.39653, 'loss': 0.30898, 'lr': 0, 'params': 197319, 'time_iter': 0.05099, 'accuracy': 0.94631, 'f1': 0.94657, 'auc': 0.99475}\n",
      "> Epoch 48: took 43.1s (avg 42.6s) | Best so far: epoch 44\ttrain_loss: 0.0369 train_accuracy: 0.9894\tval_loss: 0.2380 val_accuracy: 0.9570\ttest_loss: 0.2617 test_accuracy: 0.9503\n",
      "train: {'epoch': 49, 'time_epoch': 38.04921, 'eta': 942.17135, 'eta_hours': 0.26171, 'loss': 0.01890534, 'lr': 0.00030349, 'params': 197319, 'time_iter': 0.10201, 'accuracy': 0.99446, 'f1': 0.99446, 'auc': 0.99994}\n",
      "val: {'epoch': 49, 'time_epoch': 2.42213, 'loss': 0.26738932, 'lr': 0, 'params': 197319, 'time_iter': 0.05153, 'accuracy': 0.94758, 'f1': 0.94926, 'auc': 0.99493}\n",
      "test: {'epoch': 49, 'time_epoch': 2.56979, 'loss': 0.28530607, 'lr': 0, 'params': 197319, 'time_iter': 0.05468, 'accuracy': 0.95034, 'f1': 0.94957, 'auc': 0.99561}\n",
      "> Epoch 49: took 43.1s (avg 42.6s) | Best so far: epoch 44\ttrain_loss: 0.0369 train_accuracy: 0.9894\tval_loss: 0.2380 val_accuracy: 0.9570\ttest_loss: 0.2617 test_accuracy: 0.9503\n",
      "train: {'epoch': 50, 'time_epoch': 37.60415, 'eta': 904.44558, 'eta_hours': 0.25123, 'loss': 0.01480614, 'lr': 0.00028306, 'params': 197319, 'time_iter': 0.10082, 'accuracy': 0.99614, 'f1': 0.99616, 'auc': 0.99995}\n",
      "val: {'epoch': 50, 'time_epoch': 2.34675, 'loss': 0.20139294, 'lr': 0, 'params': 197319, 'time_iter': 0.04993, 'accuracy': 0.95968, 'f1': 0.96039, 'auc': 0.99587}\n",
      "test: {'epoch': 50, 'time_epoch': 2.54698, 'loss': 0.21892902, 'lr': 0, 'params': 197319, 'time_iter': 0.05419, 'accuracy': 0.96376, 'f1': 0.96279, 'auc': 0.99691}\n",
      "> Epoch 50: took 42.6s (avg 42.6s) | Best so far: epoch 50\ttrain_loss: 0.0148 train_accuracy: 0.9961\tval_loss: 0.2014 val_accuracy: 0.9597\ttest_loss: 0.2189 test_accuracy: 0.9638\n",
      "train: {'epoch': 51, 'time_epoch': 37.29273, 'eta': 866.58674, 'eta_hours': 0.24072, 'loss': 0.01690925, 'lr': 0.00026307, 'params': 197319, 'time_iter': 0.09998, 'accuracy': 0.99597, 'f1': 0.99595, 'auc': 0.99985}\n",
      "val: {'epoch': 51, 'time_epoch': 2.30123, 'loss': 0.26402328, 'lr': 0, 'params': 197319, 'time_iter': 0.04896, 'accuracy': 0.94624, 'f1': 0.94767, 'auc': 0.99648}\n",
      "test: {'epoch': 51, 'time_epoch': 2.47476, 'loss': 0.26914611, 'lr': 0, 'params': 197319, 'time_iter': 0.05265, 'accuracy': 0.94899, 'f1': 0.94817, 'auc': 0.99704}\n",
      "> Epoch 51: took 42.2s (avg 42.6s) | Best so far: epoch 50\ttrain_loss: 0.0148 train_accuracy: 0.9961\tval_loss: 0.2014 val_accuracy: 0.9597\ttest_loss: 0.2189 test_accuracy: 0.9638\n",
      "train: {'epoch': 52, 'time_epoch': 37.608, 'eta': 828.88013, 'eta_hours': 0.23024, 'loss': 0.01242135, 'lr': 0.00024355, 'params': 197319, 'time_iter': 0.10083, 'accuracy': 0.99664, 'f1': 0.99662, 'auc': 0.99999}\n",
      "val: {'epoch': 52, 'time_epoch': 2.31429, 'loss': 0.21856953, 'lr': 0, 'params': 197319, 'time_iter': 0.04924, 'accuracy': 0.96102, 'f1': 0.96182, 'auc': 0.99582}\n",
      "test: {'epoch': 52, 'time_epoch': 2.41744, 'loss': 0.25069653, 'lr': 0, 'params': 197319, 'time_iter': 0.05143, 'accuracy': 0.95302, 'f1': 0.95321, 'auc': 0.99634}\n",
      "> Epoch 52: took 42.4s (avg 42.6s) | Best so far: epoch 52\ttrain_loss: 0.0124 train_accuracy: 0.9966\tval_loss: 0.2186 val_accuracy: 0.9610\ttest_loss: 0.2507 test_accuracy: 0.9530\n",
      "train: {'epoch': 53, 'time_epoch': 37.42302, 'eta': 791.10523, 'eta_hours': 0.21975, 'loss': 0.01213446, 'lr': 0.00022455, 'params': 197319, 'time_iter': 0.10033, 'accuracy': 0.99681, 'f1': 0.99682, 'auc': 0.99992}\n",
      "val: {'epoch': 53, 'time_epoch': 2.24087, 'loss': 0.23866868, 'lr': 0, 'params': 197319, 'time_iter': 0.04768, 'accuracy': 0.95968, 'f1': 0.96056, 'auc': 0.99474}\n",
      "test: {'epoch': 53, 'time_epoch': 2.50969, 'loss': 0.23593913, 'lr': 0, 'params': 197319, 'time_iter': 0.0534, 'accuracy': 0.95973, 'f1': 0.95847, 'auc': 0.99722}\n",
      "> Epoch 53: took 42.2s (avg 42.6s) | Best so far: epoch 52\ttrain_loss: 0.0124 train_accuracy: 0.9966\tval_loss: 0.2186 val_accuracy: 0.9610\ttest_loss: 0.2507 test_accuracy: 0.9530\n",
      "train: {'epoch': 54, 'time_epoch': 37.69005, 'eta': 753.44024, 'eta_hours': 0.20929, 'loss': 0.01081336, 'lr': 0.00020611, 'params': 197319, 'time_iter': 0.10105, 'accuracy': 0.99698, 'f1': 0.99699, 'auc': 0.9999}\n",
      "val: {'epoch': 54, 'time_epoch': 2.30305, 'loss': 0.23489199, 'lr': 0, 'params': 197319, 'time_iter': 0.049, 'accuracy': 0.95968, 'f1': 0.96091, 'auc': 0.99655}\n",
      "test: {'epoch': 54, 'time_epoch': 2.47938, 'loss': 0.24447428, 'lr': 0, 'params': 197319, 'time_iter': 0.05275, 'accuracy': 0.9557, 'f1': 0.95503, 'auc': 0.99753}\n",
      "> Epoch 54: took 42.6s (avg 42.6s) | Best so far: epoch 52\ttrain_loss: 0.0124 train_accuracy: 0.9966\tval_loss: 0.2186 val_accuracy: 0.9610\ttest_loss: 0.2507 test_accuracy: 0.9530\n",
      "train: {'epoch': 55, 'time_epoch': 37.77954, 'eta': 715.80471, 'eta_hours': 0.19883, 'loss': 0.00733872, 'lr': 0.00018826, 'params': 197319, 'time_iter': 0.10129, 'accuracy': 0.99798, 'f1': 0.99797, 'auc': 0.99999}\n",
      "val: {'epoch': 55, 'time_epoch': 2.37837, 'loss': 0.2588556, 'lr': 0, 'params': 197319, 'time_iter': 0.0506, 'accuracy': 0.95027, 'f1': 0.95136, 'auc': 0.99675}\n",
      "test: {'epoch': 55, 'time_epoch': 2.50125, 'loss': 0.24507899, 'lr': 0, 'params': 197319, 'time_iter': 0.05322, 'accuracy': 0.95839, 'f1': 0.95816, 'auc': 0.9977}\n",
      "> Epoch 55: took 42.7s (avg 42.6s) | Best so far: epoch 52\ttrain_loss: 0.0124 train_accuracy: 0.9966\tval_loss: 0.2186 val_accuracy: 0.9610\ttest_loss: 0.2507 test_accuracy: 0.9530\n",
      "train: {'epoch': 56, 'time_epoch': 37.82051, 'eta': 678.17706, 'eta_hours': 0.18838, 'loss': 0.00883755, 'lr': 0.00017103, 'params': 197319, 'time_iter': 0.1014, 'accuracy': 0.99849, 'f1': 0.99849, 'auc': 0.99995}\n",
      "val: {'epoch': 56, 'time_epoch': 2.26223, 'loss': 0.22710242, 'lr': 0, 'params': 197319, 'time_iter': 0.04813, 'accuracy': 0.9543, 'f1': 0.95538, 'auc': 0.99652}\n",
      "test: {'epoch': 56, 'time_epoch': 2.60108, 'loss': 0.26332999, 'lr': 0, 'params': 197319, 'time_iter': 0.05534, 'accuracy': 0.9557, 'f1': 0.95513, 'auc': 0.99643}\n",
      "> Epoch 56: took 42.8s (avg 42.6s) | Best so far: epoch 52\ttrain_loss: 0.0124 train_accuracy: 0.9966\tval_loss: 0.2186 val_accuracy: 0.9610\ttest_loss: 0.2507 test_accuracy: 0.9530\n",
      "train: {'epoch': 57, 'time_epoch': 37.871, 'eta': 640.55757, 'eta_hours': 0.17793, 'loss': 0.00821273, 'lr': 0.00015447, 'params': 197319, 'time_iter': 0.10153, 'accuracy': 0.99782, 'f1': 0.99779, 'auc': 0.99999}\n",
      "val: {'epoch': 57, 'time_epoch': 2.35419, 'loss': 0.27329618, 'lr': 0, 'params': 197319, 'time_iter': 0.05009, 'accuracy': 0.94892, 'f1': 0.95054, 'auc': 0.99675}\n",
      "test: {'epoch': 57, 'time_epoch': 2.48032, 'loss': 0.26267834, 'lr': 0, 'params': 197319, 'time_iter': 0.05277, 'accuracy': 0.95168, 'f1': 0.9517, 'auc': 0.99609}\n",
      "> Epoch 57: took 42.8s (avg 42.6s) | Best so far: epoch 52\ttrain_loss: 0.0124 train_accuracy: 0.9966\tval_loss: 0.2186 val_accuracy: 0.9610\ttest_loss: 0.2507 test_accuracy: 0.9530\n",
      "train: {'epoch': 58, 'time_epoch': 38.07879, 'eta': 602.98589, 'eta_hours': 0.1675, 'loss': 0.00472607, 'lr': 0.0001386, 'params': 197319, 'time_iter': 0.10209, 'accuracy': 0.99832, 'f1': 0.99834, 'auc': 1.0}\n",
      "val: {'epoch': 58, 'time_epoch': 2.26723, 'loss': 0.25062317, 'lr': 0, 'params': 197319, 'time_iter': 0.04824, 'accuracy': 0.95565, 'f1': 0.95653, 'auc': 0.99735}\n",
      "test: {'epoch': 58, 'time_epoch': 2.3694, 'loss': 0.26805125, 'lr': 0, 'params': 197319, 'time_iter': 0.05041, 'accuracy': 0.95302, 'f1': 0.95231, 'auc': 0.99634}\n",
      "> Epoch 58: took 42.8s (avg 42.6s) | Best so far: epoch 52\ttrain_loss: 0.0124 train_accuracy: 0.9966\tval_loss: 0.2186 val_accuracy: 0.9610\ttest_loss: 0.2507 test_accuracy: 0.9530\n",
      "train: {'epoch': 59, 'time_epoch': 37.48655, 'eta': 565.24926, 'eta_hours': 0.15701, 'loss': 0.00580847, 'lr': 0.00012346, 'params': 197319, 'time_iter': 0.1005, 'accuracy': 0.99832, 'f1': 0.99831, 'auc': 1.0}\n",
      "val: {'epoch': 59, 'time_epoch': 2.24304, 'loss': 0.25237024, 'lr': 0, 'params': 197319, 'time_iter': 0.04772, 'accuracy': 0.95296, 'f1': 0.95453, 'auc': 0.99697}\n",
      "test: {'epoch': 59, 'time_epoch': 2.59164, 'loss': 0.26612838, 'lr': 0, 'params': 197319, 'time_iter': 0.05514, 'accuracy': 0.95436, 'f1': 0.95406, 'auc': 0.99737}\n",
      "> Epoch 59: took 42.4s (avg 42.6s) | Best so far: epoch 52\ttrain_loss: 0.0124 train_accuracy: 0.9966\tval_loss: 0.2186 val_accuracy: 0.9610\ttest_loss: 0.2507 test_accuracy: 0.9530\n",
      "train: {'epoch': 60, 'time_epoch': 37.50415, 'eta': 527.52486, 'eta_hours': 0.14653, 'loss': 0.00463229, 'lr': 0.00010908, 'params': 197319, 'time_iter': 0.10055, 'accuracy': 0.99882, 'f1': 0.99882, 'auc': 1.0}\n",
      "val: {'epoch': 60, 'time_epoch': 2.33734, 'loss': 0.26071971, 'lr': 0, 'params': 197319, 'time_iter': 0.04973, 'accuracy': 0.94892, 'f1': 0.95058, 'auc': 0.99649}\n",
      "test: {'epoch': 60, 'time_epoch': 2.35472, 'loss': 0.26222711, 'lr': 0, 'params': 197319, 'time_iter': 0.0501, 'accuracy': 0.95436, 'f1': 0.95346, 'auc': 0.99722}\n",
      "> Epoch 60: took 42.3s (avg 42.6s) | Best so far: epoch 52\ttrain_loss: 0.0124 train_accuracy: 0.9966\tval_loss: 0.2186 val_accuracy: 0.9610\ttest_loss: 0.2507 test_accuracy: 0.9530\n",
      "train: {'epoch': 61, 'time_epoch': 37.98283, 'eta': 489.90794, 'eta_hours': 0.13609, 'loss': 0.00401731, 'lr': 9.549e-05, 'params': 197319, 'time_iter': 0.10183, 'accuracy': 0.99866, 'f1': 0.99865, 'auc': 1.0}\n",
      "val: {'epoch': 61, 'time_epoch': 2.3176, 'loss': 0.22102809, 'lr': 0, 'params': 197319, 'time_iter': 0.04931, 'accuracy': 0.96102, 'f1': 0.96206, 'auc': 0.99697}\n",
      "test: {'epoch': 61, 'time_epoch': 2.44789, 'loss': 0.25208577, 'lr': 0, 'params': 197319, 'time_iter': 0.05208, 'accuracy': 0.95973, 'f1': 0.95899, 'auc': 0.99741}\n",
      "> Epoch 61: took 42.8s (avg 42.6s) | Best so far: epoch 52\ttrain_loss: 0.0124 train_accuracy: 0.9966\tval_loss: 0.2186 val_accuracy: 0.9610\ttest_loss: 0.2507 test_accuracy: 0.9530\n",
      "train: {'epoch': 62, 'time_epoch': 37.33619, 'eta': 452.15623, 'eta_hours': 0.1256, 'loss': 0.00361802, 'lr': 8.271e-05, 'params': 197319, 'time_iter': 0.1001, 'accuracy': 0.99933, 'f1': 0.99931, 'auc': 1.0}\n",
      "val: {'epoch': 62, 'time_epoch': 2.33166, 'loss': 0.22689662, 'lr': 0, 'params': 197319, 'time_iter': 0.04961, 'accuracy': 0.95968, 'f1': 0.96054, 'auc': 0.99775}\n",
      "test: {'epoch': 62, 'time_epoch': 2.85277, 'loss': 0.24890684, 'lr': 0, 'params': 197319, 'time_iter': 0.0607, 'accuracy': 0.96107, 'f1': 0.96048, 'auc': 0.9975}\n",
      "> Epoch 62: took 42.6s (avg 42.6s) | Best so far: epoch 52\ttrain_loss: 0.0124 train_accuracy: 0.9966\tval_loss: 0.2186 val_accuracy: 0.9610\ttest_loss: 0.2507 test_accuracy: 0.9530\n",
      "train: {'epoch': 63, 'time_epoch': 37.52803, 'eta': 414.45048, 'eta_hours': 0.11513, 'loss': 0.00306725, 'lr': 7.078e-05, 'params': 197319, 'time_iter': 0.10061, 'accuracy': 0.99899, 'f1': 0.99898, 'auc': 1.0}\n",
      "val: {'epoch': 63, 'time_epoch': 2.3033, 'loss': 0.23176704, 'lr': 0, 'params': 197319, 'time_iter': 0.04901, 'accuracy': 0.96102, 'f1': 0.96199, 'auc': 0.99767}\n",
      "test: {'epoch': 63, 'time_epoch': 2.32495, 'loss': 0.25913277, 'lr': 0, 'params': 197319, 'time_iter': 0.04947, 'accuracy': 0.95839, 'f1': 0.9581, 'auc': 0.99639}\n",
      "> Epoch 63: took 42.2s (avg 42.6s) | Best so far: epoch 52\ttrain_loss: 0.0124 train_accuracy: 0.9966\tval_loss: 0.2186 val_accuracy: 0.9610\ttest_loss: 0.2507 test_accuracy: 0.9530\n",
      "train: {'epoch': 64, 'time_epoch': 38.08656, 'eta': 376.83612, 'eta_hours': 0.10468, 'loss': 0.00127221, 'lr': 5.97e-05, 'params': 197319, 'time_iter': 0.10211, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "val: {'epoch': 64, 'time_epoch': 2.33179, 'loss': 0.23413024, 'lr': 0, 'params': 197319, 'time_iter': 0.04961, 'accuracy': 0.96371, 'f1': 0.96459, 'auc': 0.99706}\n",
      "test: {'epoch': 64, 'time_epoch': 2.54899, 'loss': 0.26673635, 'lr': 0, 'params': 197319, 'time_iter': 0.05423, 'accuracy': 0.95973, 'f1': 0.95948, 'auc': 0.99628}\n",
      "> Epoch 64: took 43.1s (avg 42.6s) | Best so far: epoch 64\ttrain_loss: 0.0013 train_accuracy: 0.9997\tval_loss: 0.2341 val_accuracy: 0.9637\ttest_loss: 0.2667 test_accuracy: 0.9597\n",
      "train: {'epoch': 65, 'time_epoch': 38.06453, 'eta': 339.20445, 'eta_hours': 0.09422, 'loss': 0.00237644, 'lr': 4.952e-05, 'params': 197319, 'time_iter': 0.10205, 'accuracy': 0.9995, 'f1': 0.9995, 'auc': 1.0}\n",
      "val: {'epoch': 65, 'time_epoch': 2.36007, 'loss': 0.19721815, 'lr': 0, 'params': 197319, 'time_iter': 0.05021, 'accuracy': 0.96371, 'f1': 0.96463, 'auc': 0.99769}\n",
      "test: {'epoch': 65, 'time_epoch': 2.58441, 'loss': 0.26590274, 'lr': 0, 'params': 197319, 'time_iter': 0.05499, 'accuracy': 0.95705, 'f1': 0.95619, 'auc': 0.99649}\n",
      "> Epoch 65: took 43.1s (avg 42.6s) | Best so far: epoch 64\ttrain_loss: 0.0013 train_accuracy: 0.9997\tval_loss: 0.2341 val_accuracy: 0.9637\ttest_loss: 0.2667 test_accuracy: 0.9597\n",
      "train: {'epoch': 66, 'time_epoch': 37.90527, 'eta': 301.54085, 'eta_hours': 0.08376, 'loss': 0.00112491, 'lr': 4.024e-05, 'params': 197319, 'time_iter': 0.10162, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "val: {'epoch': 66, 'time_epoch': 2.3439, 'loss': 0.22521513, 'lr': 0, 'params': 197319, 'time_iter': 0.04987, 'accuracy': 0.95968, 'f1': 0.96062, 'auc': 0.99722}\n",
      "test: {'epoch': 66, 'time_epoch': 2.49036, 'loss': 0.26637511, 'lr': 0, 'params': 197319, 'time_iter': 0.05299, 'accuracy': 0.95973, 'f1': 0.95921, 'auc': 0.99657}\n",
      "> Epoch 66: took 42.8s (avg 42.6s) | Best so far: epoch 64\ttrain_loss: 0.0013 train_accuracy: 0.9997\tval_loss: 0.2341 val_accuracy: 0.9637\ttest_loss: 0.2667 test_accuracy: 0.9597\n",
      "train: {'epoch': 67, 'time_epoch': 37.65986, 'eta': 263.84487, 'eta_hours': 0.07329, 'loss': 0.00083879, 'lr': 3.188e-05, 'params': 197319, 'time_iter': 0.10096, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 67, 'time_epoch': 2.38173, 'loss': 0.21500634, 'lr': 0, 'params': 197319, 'time_iter': 0.05068, 'accuracy': 0.96237, 'f1': 0.96318, 'auc': 0.99782}\n",
      "test: {'epoch': 67, 'time_epoch': 2.39261, 'loss': 0.26609059, 'lr': 0, 'params': 197319, 'time_iter': 0.05091, 'accuracy': 0.96107, 'f1': 0.96079, 'auc': 0.99683}\n",
      "> Epoch 67: took 42.5s (avg 42.6s) | Best so far: epoch 64\ttrain_loss: 0.0013 train_accuracy: 0.9997\tval_loss: 0.2341 val_accuracy: 0.9637\ttest_loss: 0.2667 test_accuracy: 0.9597\n",
      "train: {'epoch': 68, 'time_epoch': 37.64109, 'eta': 226.14831, 'eta_hours': 0.06282, 'loss': 0.00215949, 'lr': 2.447e-05, 'params': 197319, 'time_iter': 0.10091, 'accuracy': 0.99933, 'f1': 0.99933, 'auc': 1.0}\n",
      "val: {'epoch': 68, 'time_epoch': 2.26153, 'loss': 0.21502592, 'lr': 0, 'params': 197319, 'time_iter': 0.04812, 'accuracy': 0.95968, 'f1': 0.96061, 'auc': 0.9979}\n",
      "test: {'epoch': 68, 'time_epoch': 2.70939, 'loss': 0.25199908, 'lr': 0, 'params': 197319, 'time_iter': 0.05765, 'accuracy': 0.95973, 'f1': 0.95923, 'auc': 0.99734}\n",
      "> Epoch 68: took 42.7s (avg 42.6s) | Best so far: epoch 64\ttrain_loss: 0.0013 train_accuracy: 0.9997\tval_loss: 0.2341 val_accuracy: 0.9637\ttest_loss: 0.2667 test_accuracy: 0.9597\n",
      "train: {'epoch': 69, 'time_epoch': 37.56629, 'eta': 188.44799, 'eta_hours': 0.05235, 'loss': 0.00102279, 'lr': 1.802e-05, 'params': 197319, 'time_iter': 0.10071, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "val: {'epoch': 69, 'time_epoch': 2.42483, 'loss': 0.22050846, 'lr': 0, 'params': 197319, 'time_iter': 0.05159, 'accuracy': 0.95968, 'f1': 0.96075, 'auc': 0.99796}\n",
      "test: {'epoch': 69, 'time_epoch': 2.38235, 'loss': 0.25706718, 'lr': 0, 'params': 197319, 'time_iter': 0.05069, 'accuracy': 0.95973, 'f1': 0.95923, 'auc': 0.99758}\n",
      "> Epoch 69: took 42.5s (avg 42.6s) | Best so far: epoch 64\ttrain_loss: 0.0013 train_accuracy: 0.9997\tval_loss: 0.2341 val_accuracy: 0.9637\ttest_loss: 0.2667 test_accuracy: 0.9597\n",
      "train: {'epoch': 70, 'time_epoch': 37.44206, 'eta': 150.74445, 'eta_hours': 0.04187, 'loss': 0.00428626, 'lr': 1.254e-05, 'params': 197319, 'time_iter': 0.10038, 'accuracy': 0.99916, 'f1': 0.99915, 'auc': 0.99997}\n",
      "val: {'epoch': 70, 'time_epoch': 2.32521, 'loss': 0.21243836, 'lr': 0, 'params': 197319, 'time_iter': 0.04947, 'accuracy': 0.95699, 'f1': 0.95824, 'auc': 0.99786}\n",
      "test: {'epoch': 70, 'time_epoch': 2.44913, 'loss': 0.26104997, 'lr': 0, 'params': 197319, 'time_iter': 0.05211, 'accuracy': 0.95839, 'f1': 0.95818, 'auc': 0.99627}\n",
      "> Epoch 70: took 42.3s (avg 42.6s) | Best so far: epoch 64\ttrain_loss: 0.0013 train_accuracy: 0.9997\tval_loss: 0.2341 val_accuracy: 0.9637\ttest_loss: 0.2667 test_accuracy: 0.9597\n",
      "train: {'epoch': 71, 'time_epoch': 37.79884, 'eta': 113.06303, 'eta_hours': 0.03141, 'loss': 0.00077334, 'lr': 8.04e-06, 'params': 197319, 'time_iter': 0.10134, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 71, 'time_epoch': 2.29405, 'loss': 0.22296842, 'lr': 0, 'params': 197319, 'time_iter': 0.04881, 'accuracy': 0.96102, 'f1': 0.96202, 'auc': 0.99759}\n",
      "test: {'epoch': 71, 'time_epoch': 2.6094, 'loss': 0.26733271, 'lr': 0, 'params': 197319, 'time_iter': 0.05552, 'accuracy': 0.95705, 'f1': 0.95676, 'auc': 0.99724}\n",
      "> Epoch 71: took 42.8s (avg 42.6s) | Best so far: epoch 64\ttrain_loss: 0.0013 train_accuracy: 0.9997\tval_loss: 0.2341 val_accuracy: 0.9637\ttest_loss: 0.2667 test_accuracy: 0.9597\n",
      "train: {'epoch': 72, 'time_epoch': 38.04565, 'eta': 75.38516, 'eta_hours': 0.02094, 'loss': 0.00142043, 'lr': 4.53e-06, 'params': 197319, 'time_iter': 0.102, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 72, 'time_epoch': 2.39323, 'loss': 0.20747692, 'lr': 0, 'params': 197319, 'time_iter': 0.05092, 'accuracy': 0.96102, 'f1': 0.96202, 'auc': 0.99776}\n",
      "test: {'epoch': 72, 'time_epoch': 2.39153, 'loss': 0.26064484, 'lr': 0, 'params': 197319, 'time_iter': 0.05088, 'accuracy': 0.95705, 'f1': 0.95688, 'auc': 0.9973}\n",
      "> Epoch 72: took 42.9s (avg 42.6s) | Best so far: epoch 64\ttrain_loss: 0.0013 train_accuracy: 0.9997\tval_loss: 0.2341 val_accuracy: 0.9637\ttest_loss: 0.2667 test_accuracy: 0.9597\n",
      "train: {'epoch': 73, 'time_epoch': 38.91747, 'eta': 37.70913, 'eta_hours': 0.01047, 'loss': 0.00167682, 'lr': 2.01e-06, 'params': 197319, 'time_iter': 0.10434, 'accuracy': 0.9995, 'f1': 0.9995, 'auc': 1.0}\n",
      "val: {'epoch': 73, 'time_epoch': 2.23409, 'loss': 0.2205403, 'lr': 0, 'params': 197319, 'time_iter': 0.04753, 'accuracy': 0.95968, 'f1': 0.96073, 'auc': 0.99783}\n",
      "test: {'epoch': 73, 'time_epoch': 2.31717, 'loss': 0.26391443, 'lr': 0, 'params': 197319, 'time_iter': 0.0493, 'accuracy': 0.95839, 'f1': 0.95793, 'auc': 0.99679}\n",
      "> Epoch 73: took 43.6s (avg 42.6s) | Best so far: epoch 64\ttrain_loss: 0.0013 train_accuracy: 0.9997\tval_loss: 0.2341 val_accuracy: 0.9637\ttest_loss: 0.2667 test_accuracy: 0.9597\n",
      "train: {'epoch': 74, 'time_epoch': 37.75243, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.00139914, 'lr': 5e-07, 'params': 197319, 'time_iter': 0.10121, 'accuracy': 0.99966, 'f1': 0.99966, 'auc': 1.0}\n",
      "val: {'epoch': 74, 'time_epoch': 2.55866, 'loss': 0.21770014, 'lr': 0, 'params': 197319, 'time_iter': 0.05444, 'accuracy': 0.9543, 'f1': 0.9556, 'auc': 0.99783}\n",
      "test: {'epoch': 74, 'time_epoch': 3.0386, 'loss': 0.26131388, 'lr': 0, 'params': 197319, 'time_iter': 0.06465, 'accuracy': 0.96107, 'f1': 0.96055, 'auc': 0.99684}\n",
      "> Epoch 74: took 43.4s (avg 42.6s) | Best so far: epoch 64\ttrain_loss: 0.0013 train_accuracy: 0.9997\tval_loss: 0.2341 val_accuracy: 0.9637\ttest_loss: 0.2667 test_accuracy: 0.9597\n",
      "Avg time per epoch: 42.61s\n",
      "Total train loop time: 0.89h\n",
      "Task done, results saved in results\\neural-Act\\0\n",
      "64\n",
      "{'epoch': 64, 'time_epoch': 2.54899, 'loss': 0.26673635, 'lr': 0, 'params': 197319, 'time_iter': 0.05423, 'accuracy': 0.95973, 'f1': 0.95948, 'auc': 0.99628}\n",
      "{'epoch': 64, 'time_epoch': 38.08656, 'eta': 376.83612, 'eta_hours': 0.10468, 'loss': 0.00127221, 'lr': 5.97e-05, 'params': 197319, 'time_iter': 0.10211, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "{'epoch': 64, 'time_epoch': 2.33179, 'loss': 0.23413024, 'lr': 0, 'params': 197319, 'time_iter': 0.04961, 'accuracy': 0.96371, 'f1': 0.96459, 'auc': 0.99706}\n",
      "Results aggregated across runs saved in results\\neural-Act\\agg\n",
      "[*] All done: 2024-02-27 17:32:24.540049\n"
     ]
    }
   ],
   "source": [
    "#exphormer dropout 0.6 attn dropout 0.3\n",
    "%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779638cd-a083-4db7-bba6-16b2c53ee82d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-27 17:45:52.202496\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 7\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [05:40<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:05:55.97\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [01:49<00:00, 68.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:56.12\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=400, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (3): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (4): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.3\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.3\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 5\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 75\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 197319\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 38.7084, 'eta': 2864.42134, 'eta_hours': 0.79567, 'loss': 1.95119791, 'lr': 0.0, 'params': 197319, 'time_iter': 0.10378, 'accuracy': 0.14192, 'f1': 0.06098, 'auc': 0.48243}\n",
      "...computing epoch stats took: 0.12s\n",
      "val: {'epoch': 0, 'time_epoch': 2.53903, 'loss': 1.95076242, 'lr': 0, 'params': 197319, 'time_iter': 0.05402, 'accuracy': 0.1586, 'f1': 0.07688, 'auc': 0.48508}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 0, 'time_epoch': 2.43018, 'loss': 1.95956455, 'lr': 0, 'params': 197319, 'time_iter': 0.05171, 'accuracy': 0.10872, 'f1': 0.05668, 'auc': 0.48668}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 43.9s (avg 43.9s) | Best so far: epoch 0\ttrain_loss: 1.9512 train_accuracy: 0.1419\tval_loss: 1.9508 val_accuracy: 0.1586\ttest_loss: 1.9596 test_accuracy: 0.1087\n",
      "train: {'epoch': 1, 'time_epoch': 36.80688, 'eta': 2756.30776, 'eta_hours': 0.76564, 'loss': 1.71987253, 'lr': 0.0002, 'params': 197319, 'time_iter': 0.09868, 'accuracy': 0.59288, 'f1': 0.59556, 'auc': 0.87982}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 1, 'time_epoch': 2.38223, 'loss': 1.54435233, 'lr': 0, 'params': 197319, 'time_iter': 0.05069, 'accuracy': 0.78091, 'f1': 0.78125, 'auc': 0.96202}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 2.24659, 'loss': 1.54387398, 'lr': 0, 'params': 197319, 'time_iter': 0.0478, 'accuracy': 0.79463, 'f1': 0.79367, 'auc': 0.96605}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 1: took 41.5s (avg 42.7s) | Best so far: epoch 1\ttrain_loss: 1.7199 train_accuracy: 0.5929\tval_loss: 1.5444 val_accuracy: 0.7809\ttest_loss: 1.5439 test_accuracy: 0.7946\n",
      "train: {'epoch': 2, 'time_epoch': 41.98286, 'eta': 2819.95528, 'eta_hours': 0.78332, 'loss': 1.32794695, 'lr': 0.0004, 'params': 197319, 'time_iter': 0.11255, 'accuracy': 0.84733, 'f1': 0.84537, 'auc': 0.96921}\n",
      "...computing epoch stats took: 0.03s\n",
      "val: {'epoch': 2, 'time_epoch': 2.54408, 'loss': 1.14781699, 'lr': 0, 'params': 197319, 'time_iter': 0.05413, 'accuracy': 0.88441, 'f1': 0.88996, 'auc': 0.98177}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 2, 'time_epoch': 3.4502, 'loss': 1.15448139, 'lr': 0, 'params': 197319, 'time_iter': 0.07341, 'accuracy': 0.87785, 'f1': 0.88156, 'auc': 0.98173}\n",
      "...computing epoch stats took: 0.06s\n",
      "> Epoch 2: took 48.1s (avg 44.5s) | Best so far: epoch 2\ttrain_loss: 1.3279 train_accuracy: 0.8473\tval_loss: 1.1478 val_accuracy: 0.8844\ttest_loss: 1.1545 test_accuracy: 0.8779\n",
      "train: {'epoch': 3, 'time_epoch': 42.07879, 'eta': 2832.49042, 'eta_hours': 0.7868, 'loss': 0.92875141, 'lr': 0.0006, 'params': 197319, 'time_iter': 0.11281, 'accuracy': 0.91031, 'f1': 0.90987, 'auc': 0.98562}\n",
      "val: {'epoch': 3, 'time_epoch': 2.31575, 'loss': 0.76100082, 'lr': 0, 'params': 197319, 'time_iter': 0.04927, 'accuracy': 0.91801, 'f1': 0.91937, 'auc': 0.99003}\n",
      "test: {'epoch': 3, 'time_epoch': 2.9857, 'loss': 0.77764095, 'lr': 0, 'params': 197319, 'time_iter': 0.06353, 'accuracy': 0.89664, 'f1': 0.89725, 'auc': 0.98848}\n",
      "> Epoch 3: took 47.5s (avg 45.2s) | Best so far: epoch 3\ttrain_loss: 0.9288 train_accuracy: 0.9103\tval_loss: 0.7610 val_accuracy: 0.9180\ttest_loss: 0.7776 test_accuracy: 0.8966\n",
      "train: {'epoch': 4, 'time_epoch': 40.0643, 'eta': 2794.97716, 'eta_hours': 0.77638, 'loss': 0.63699753, 'lr': 0.0008, 'params': 197319, 'time_iter': 0.10741, 'accuracy': 0.91367, 'f1': 0.9132, 'auc': 0.9862}\n",
      "val: {'epoch': 4, 'time_epoch': 3.14483, 'loss': 0.50401556, 'lr': 0, 'params': 197319, 'time_iter': 0.06691, 'accuracy': 0.93548, 'f1': 0.93734, 'auc': 0.99097}\n",
      "test: {'epoch': 4, 'time_epoch': 2.62043, 'loss': 0.49606002, 'lr': 0, 'params': 197319, 'time_iter': 0.05575, 'accuracy': 0.93423, 'f1': 0.93642, 'auc': 0.99255}\n",
      "> Epoch 4: took 46.0s (avg 45.4s) | Best so far: epoch 4\ttrain_loss: 0.6370 train_accuracy: 0.9137\tval_loss: 0.5040 val_accuracy: 0.9355\ttest_loss: 0.4961 test_accuracy: 0.9342\n",
      "train: {'epoch': 5, 'time_epoch': 41.95897, 'eta': 2778.40228, 'eta_hours': 0.77178, 'loss': 0.45807004, 'lr': 0.001, 'params': 197319, 'time_iter': 0.11249, 'accuracy': 0.91972, 'f1': 0.91947, 'auc': 0.98742}\n",
      "val: {'epoch': 5, 'time_epoch': 2.44793, 'loss': 0.37403376, 'lr': 0, 'params': 197319, 'time_iter': 0.05208, 'accuracy': 0.93548, 'f1': 0.93653, 'auc': 0.99184}\n",
      "test: {'epoch': 5, 'time_epoch': 3.30789, 'loss': 0.37578436, 'lr': 0, 'params': 197319, 'time_iter': 0.07038, 'accuracy': 0.92752, 'f1': 0.92761, 'auc': 0.9913}\n",
      "> Epoch 5: took 47.8s (avg 45.8s) | Best so far: epoch 4\ttrain_loss: 0.6370 train_accuracy: 0.9137\tval_loss: 0.5040 val_accuracy: 0.9355\ttest_loss: 0.4961 test_accuracy: 0.9342\n",
      "train: {'epoch': 6, 'time_epoch': 39.65345, 'eta': 2732.1783, 'eta_hours': 0.75894, 'loss': 0.33230705, 'lr': 0.0009995, 'params': 197319, 'time_iter': 0.10631, 'accuracy': 0.93719, 'f1': 0.93717, 'auc': 0.99172}\n",
      "val: {'epoch': 6, 'time_epoch': 2.83135, 'loss': 0.34938327, 'lr': 0, 'params': 197319, 'time_iter': 0.06024, 'accuracy': 0.91667, 'f1': 0.91898, 'auc': 0.99281}\n",
      "test: {'epoch': 6, 'time_epoch': 2.30137, 'loss': 0.30298748, 'lr': 0, 'params': 197319, 'time_iter': 0.04897, 'accuracy': 0.92886, 'f1': 0.92789, 'auc': 0.99447}\n",
      "> Epoch 6: took 44.9s (avg 45.7s) | Best so far: epoch 4\ttrain_loss: 0.6370 train_accuracy: 0.9137\tval_loss: 0.5040 val_accuracy: 0.9355\ttest_loss: 0.4961 test_accuracy: 0.9342\n",
      "train: {'epoch': 7, 'time_epoch': 41.8326, 'eta': 2705.84731, 'eta_hours': 0.75162, 'loss': 0.24733023, 'lr': 0.00099799, 'params': 197319, 'time_iter': 0.11215, 'accuracy': 0.95146, 'f1': 0.95149, 'auc': 0.99427}\n",
      "val: {'epoch': 7, 'time_epoch': 2.84715, 'loss': 0.27369266, 'lr': 0, 'params': 197319, 'time_iter': 0.06058, 'accuracy': 0.93952, 'f1': 0.94146, 'auc': 0.99314}\n",
      "test: {'epoch': 7, 'time_epoch': 3.17697, 'loss': 0.26864399, 'lr': 0, 'params': 197319, 'time_iter': 0.0676, 'accuracy': 0.94362, 'f1': 0.94231, 'auc': 0.99325}\n",
      "> Epoch 7: took 48.0s (avg 46.0s) | Best so far: epoch 7\ttrain_loss: 0.2473 train_accuracy: 0.9515\tval_loss: 0.2737 val_accuracy: 0.9395\ttest_loss: 0.2686 test_accuracy: 0.9436\n",
      "train: {'epoch': 8, 'time_epoch': 42.70719, 'eta': 2682.48517, 'eta_hours': 0.74513, 'loss': 0.20944792, 'lr': 0.00099547, 'params': 197319, 'time_iter': 0.1145, 'accuracy': 0.95364, 'f1': 0.95356, 'auc': 0.99578}\n",
      "val: {'epoch': 8, 'time_epoch': 2.24176, 'loss': 0.24198632, 'lr': 0, 'params': 197319, 'time_iter': 0.0477, 'accuracy': 0.94758, 'f1': 0.94873, 'auc': 0.9937}\n",
      "test: {'epoch': 8, 'time_epoch': 2.99558, 'loss': 0.21495339, 'lr': 0, 'params': 197319, 'time_iter': 0.06374, 'accuracy': 0.9557, 'f1': 0.9548, 'auc': 0.99528}\n",
      "> Epoch 8: took 48.0s (avg 46.2s) | Best so far: epoch 8\ttrain_loss: 0.2094 train_accuracy: 0.9536\tval_loss: 0.2420 val_accuracy: 0.9476\ttest_loss: 0.2150 test_accuracy: 0.9557\n",
      "train: {'epoch': 9, 'time_epoch': 42.16309, 'eta': 2651.71739, 'eta_hours': 0.73659, 'loss': 0.16972948, 'lr': 0.00099196, 'params': 197319, 'time_iter': 0.11304, 'accuracy': 0.96389, 'f1': 0.96381, 'auc': 0.99654}\n",
      "val: {'epoch': 9, 'time_epoch': 2.67542, 'loss': 0.18704345, 'lr': 0, 'params': 197319, 'time_iter': 0.05692, 'accuracy': 0.95699, 'f1': 0.95798, 'auc': 0.99579}\n",
      "test: {'epoch': 9, 'time_epoch': 2.35178, 'loss': 0.16299392, 'lr': 0, 'params': 197319, 'time_iter': 0.05004, 'accuracy': 0.96242, 'f1': 0.96252, 'auc': 0.99765}\n",
      "> Epoch 9: took 47.3s (avg 46.3s) | Best so far: epoch 9\ttrain_loss: 0.1697 train_accuracy: 0.9639\tval_loss: 0.1870 val_accuracy: 0.9570\ttest_loss: 0.1630 test_accuracy: 0.9624\n",
      "train: {'epoch': 10, 'time_epoch': 42.75787, 'eta': 2622.33828, 'eta_hours': 0.72843, 'loss': 0.14549504, 'lr': 0.00098746, 'params': 197319, 'time_iter': 0.11463, 'accuracy': 0.96591, 'f1': 0.9658, 'auc': 0.99733}\n",
      "val: {'epoch': 10, 'time_epoch': 3.01051, 'loss': 0.23395215, 'lr': 0, 'params': 197319, 'time_iter': 0.06405, 'accuracy': 0.94086, 'f1': 0.94222, 'auc': 0.99456}\n",
      "test: {'epoch': 10, 'time_epoch': 2.34175, 'loss': 0.24048109, 'lr': 0, 'params': 197319, 'time_iter': 0.04982, 'accuracy': 0.94094, 'f1': 0.9409, 'auc': 0.99525}\n",
      "> Epoch 10: took 48.2s (avg 46.5s) | Best so far: epoch 9\ttrain_loss: 0.1697 train_accuracy: 0.9639\tval_loss: 0.1870 val_accuracy: 0.9570\ttest_loss: 0.1630 test_accuracy: 0.9624\n",
      "train: {'epoch': 11, 'time_epoch': 39.25571, 'eta': 2572.34302, 'eta_hours': 0.71454, 'loss': 0.12642414, 'lr': 0.00098198, 'params': 197319, 'time_iter': 0.10524, 'accuracy': 0.97212, 'f1': 0.97206, 'auc': 0.99802}\n",
      "val: {'epoch': 11, 'time_epoch': 2.2316, 'loss': 0.18802897, 'lr': 0, 'params': 197319, 'time_iter': 0.04748, 'accuracy': 0.95296, 'f1': 0.95355, 'auc': 0.99753}\n",
      "test: {'epoch': 11, 'time_epoch': 2.65058, 'loss': 0.17937277, 'lr': 0, 'params': 197319, 'time_iter': 0.0564, 'accuracy': 0.95973, 'f1': 0.95934, 'auc': 0.9975}\n",
      "> Epoch 11: took 44.2s (avg 46.3s) | Best so far: epoch 9\ttrain_loss: 0.1697 train_accuracy: 0.9639\tval_loss: 0.1870 val_accuracy: 0.9570\ttest_loss: 0.1630 test_accuracy: 0.9624\n",
      "train: {'epoch': 12, 'time_epoch': 41.76135, 'eta': 2535.95, 'eta_hours': 0.70443, 'loss': 0.1144759, 'lr': 0.00097553, 'params': 197319, 'time_iter': 0.11196, 'accuracy': 0.9743, 'f1': 0.97429, 'auc': 0.99792}\n",
      "val: {'epoch': 12, 'time_epoch': 3.27081, 'loss': 0.19749478, 'lr': 0, 'params': 197319, 'time_iter': 0.06959, 'accuracy': 0.95296, 'f1': 0.95396, 'auc': 0.99687}\n",
      "test: {'epoch': 12, 'time_epoch': 2.52707, 'loss': 0.17680363, 'lr': 0, 'params': 197319, 'time_iter': 0.05377, 'accuracy': 0.95034, 'f1': 0.94956, 'auc': 0.99806}\n",
      "> Epoch 12: took 47.7s (avg 46.4s) | Best so far: epoch 9\ttrain_loss: 0.1697 train_accuracy: 0.9639\tval_loss: 0.1870 val_accuracy: 0.9570\ttest_loss: 0.1630 test_accuracy: 0.9624\n",
      "train: {'epoch': 13, 'time_epoch': 40.33816, 'eta': 2492.58902, 'eta_hours': 0.69239, 'loss': 0.09158252, 'lr': 0.00096812, 'params': 197319, 'time_iter': 0.10815, 'accuracy': 0.97733, 'f1': 0.97731, 'auc': 0.99895}\n",
      "val: {'epoch': 13, 'time_epoch': 2.55981, 'loss': 0.18219116, 'lr': 0, 'params': 197319, 'time_iter': 0.05446, 'accuracy': 0.95699, 'f1': 0.95849, 'auc': 0.99633}\n",
      "test: {'epoch': 13, 'time_epoch': 2.33925, 'loss': 0.16868848, 'lr': 0, 'params': 197319, 'time_iter': 0.04977, 'accuracy': 0.96376, 'f1': 0.96337, 'auc': 0.99726}\n",
      "> Epoch 13: took 45.3s (avg 46.3s) | Best so far: epoch 9\ttrain_loss: 0.1697 train_accuracy: 0.9639\tval_loss: 0.1870 val_accuracy: 0.9570\ttest_loss: 0.1630 test_accuracy: 0.9624\n",
      "train: {'epoch': 14, 'time_epoch': 38.43667, 'eta': 2442.02513, 'eta_hours': 0.67834, 'loss': 0.10437748, 'lr': 0.00095976, 'params': 197319, 'time_iter': 0.10305, 'accuracy': 0.9743, 'f1': 0.97425, 'auc': 0.99829}\n",
      "val: {'epoch': 14, 'time_epoch': 2.2882, 'loss': 0.15285678, 'lr': 0, 'params': 197319, 'time_iter': 0.04869, 'accuracy': 0.96371, 'f1': 0.96439, 'auc': 0.9971}\n",
      "test: {'epoch': 14, 'time_epoch': 2.50093, 'loss': 0.1797427, 'lr': 0, 'params': 197319, 'time_iter': 0.05321, 'accuracy': 0.95705, 'f1': 0.95735, 'auc': 0.99623}\n",
      "> Epoch 14: took 43.3s (avg 46.1s) | Best so far: epoch 14\ttrain_loss: 0.1044 train_accuracy: 0.9743\tval_loss: 0.1529 val_accuracy: 0.9637\ttest_loss: 0.1797 test_accuracy: 0.9570\n",
      "train: {'epoch': 15, 'time_epoch': 38.25257, 'eta': 2392.29826, 'eta_hours': 0.66453, 'loss': 0.07407535, 'lr': 0.00095048, 'params': 197319, 'time_iter': 0.10255, 'accuracy': 0.98136, 'f1': 0.98137, 'auc': 0.99917}\n",
      "val: {'epoch': 15, 'time_epoch': 2.36809, 'loss': 0.25740122, 'lr': 0, 'params': 197319, 'time_iter': 0.05038, 'accuracy': 0.93683, 'f1': 0.93637, 'auc': 0.99673}\n",
      "test: {'epoch': 15, 'time_epoch': 2.35546, 'loss': 0.28830321, 'lr': 0, 'params': 197319, 'time_iter': 0.05012, 'accuracy': 0.9396, 'f1': 0.9373, 'auc': 0.99636}\n",
      "> Epoch 15: took 43.0s (avg 45.9s) | Best so far: epoch 14\ttrain_loss: 0.1044 train_accuracy: 0.9743\tval_loss: 0.1529 val_accuracy: 0.9637\ttest_loss: 0.1797 test_accuracy: 0.9570\n",
      "train: {'epoch': 16, 'time_epoch': 38.62831, 'eta': 2345.20324, 'eta_hours': 0.65145, 'loss': 0.09546939, 'lr': 0.0009403, 'params': 197319, 'time_iter': 0.10356, 'accuracy': 0.97665, 'f1': 0.97663, 'auc': 0.9986}\n",
      "val: {'epoch': 16, 'time_epoch': 2.38645, 'loss': 0.18206314, 'lr': 0, 'params': 197319, 'time_iter': 0.05078, 'accuracy': 0.94892, 'f1': 0.94997, 'auc': 0.99813}\n",
      "test: {'epoch': 16, 'time_epoch': 2.38307, 'loss': 0.17242916, 'lr': 0, 'params': 197319, 'time_iter': 0.0507, 'accuracy': 0.9557, 'f1': 0.9556, 'auc': 0.99794}\n",
      "> Epoch 16: took 43.5s (avg 45.8s) | Best so far: epoch 14\ttrain_loss: 0.1044 train_accuracy: 0.9743\tval_loss: 0.1529 val_accuracy: 0.9637\ttest_loss: 0.1797 test_accuracy: 0.9570\n",
      "train: {'epoch': 17, 'time_epoch': 37.77737, 'eta': 2296.35433, 'eta_hours': 0.63788, 'loss': 0.06558487, 'lr': 0.00092922, 'params': 197319, 'time_iter': 0.10128, 'accuracy': 0.98371, 'f1': 0.98365, 'auc': 0.99947}\n",
      "val: {'epoch': 17, 'time_epoch': 2.32847, 'loss': 0.1841228, 'lr': 0, 'params': 197319, 'time_iter': 0.04954, 'accuracy': 0.95565, 'f1': 0.95668, 'auc': 0.99665}\n",
      "test: {'epoch': 17, 'time_epoch': 2.6418, 'loss': 0.18940745, 'lr': 0, 'params': 197319, 'time_iter': 0.05621, 'accuracy': 0.95839, 'f1': 0.9581, 'auc': 0.99734}\n",
      "> Epoch 17: took 42.8s (avg 45.6s) | Best so far: epoch 14\ttrain_loss: 0.1044 train_accuracy: 0.9743\tval_loss: 0.1529 val_accuracy: 0.9637\ttest_loss: 0.1797 test_accuracy: 0.9570\n",
      "train: {'epoch': 18, 'time_epoch': 37.70505, 'eta': 2248.4577, 'eta_hours': 0.62457, 'loss': 0.06654363, 'lr': 0.00091729, 'params': 197319, 'time_iter': 0.10109, 'accuracy': 0.9832, 'f1': 0.98317, 'auc': 0.99937}\n",
      "val: {'epoch': 18, 'time_epoch': 2.56513, 'loss': 0.19851057, 'lr': 0, 'params': 197319, 'time_iter': 0.05458, 'accuracy': 0.95296, 'f1': 0.9538, 'auc': 0.99601}\n",
      "test: {'epoch': 18, 'time_epoch': 2.42786, 'loss': 0.16082005, 'lr': 0, 'params': 197319, 'time_iter': 0.05166, 'accuracy': 0.96376, 'f1': 0.96458, 'auc': 0.99742}\n",
      "> Epoch 18: took 42.8s (avg 45.5s) | Best so far: epoch 14\ttrain_loss: 0.1044 train_accuracy: 0.9743\tval_loss: 0.1529 val_accuracy: 0.9637\ttest_loss: 0.1797 test_accuracy: 0.9570\n",
      "train: {'epoch': 19, 'time_epoch': 37.98595, 'eta': 2202.35269, 'eta_hours': 0.61176, 'loss': 0.07366763, 'lr': 0.00090451, 'params': 197319, 'time_iter': 0.10184, 'accuracy': 0.98186, 'f1': 0.98183, 'auc': 0.99921}\n",
      "val: {'epoch': 19, 'time_epoch': 2.31114, 'loss': 0.17347888, 'lr': 0, 'params': 197319, 'time_iter': 0.04917, 'accuracy': 0.96371, 'f1': 0.96446, 'auc': 0.9972}\n",
      "test: {'epoch': 19, 'time_epoch': 2.3261, 'loss': 0.13507994, 'lr': 0, 'params': 197319, 'time_iter': 0.04949, 'accuracy': 0.97047, 'f1': 0.97019, 'auc': 0.9979}\n",
      "> Epoch 19: took 42.7s (avg 45.3s) | Best so far: epoch 14\ttrain_loss: 0.1044 train_accuracy: 0.9743\tval_loss: 0.1529 val_accuracy: 0.9637\ttest_loss: 0.1797 test_accuracy: 0.9570\n",
      "train: {'epoch': 20, 'time_epoch': 37.45436, 'eta': 2155.65398, 'eta_hours': 0.59879, 'loss': 0.04681448, 'lr': 0.00089092, 'params': 197319, 'time_iter': 0.10041, 'accuracy': 0.98774, 'f1': 0.98775, 'auc': 0.99968}\n",
      "val: {'epoch': 20, 'time_epoch': 2.31651, 'loss': 0.17844766, 'lr': 0, 'params': 197319, 'time_iter': 0.04929, 'accuracy': 0.96102, 'f1': 0.96178, 'auc': 0.99688}\n",
      "test: {'epoch': 20, 'time_epoch': 2.64664, 'loss': 0.19891422, 'lr': 0, 'params': 197319, 'time_iter': 0.05631, 'accuracy': 0.95436, 'f1': 0.95384, 'auc': 0.99746}\n",
      "> Epoch 20: took 42.5s (avg 45.2s) | Best so far: epoch 14\ttrain_loss: 0.1044 train_accuracy: 0.9743\tval_loss: 0.1529 val_accuracy: 0.9637\ttest_loss: 0.1797 test_accuracy: 0.9570\n",
      "train: {'epoch': 21, 'time_epoch': 37.65781, 'eta': 2110.28579, 'eta_hours': 0.58619, 'loss': 0.05613086, 'lr': 0.00087654, 'params': 197319, 'time_iter': 0.10096, 'accuracy': 0.98539, 'f1': 0.98534, 'auc': 0.99953}\n",
      "val: {'epoch': 21, 'time_epoch': 2.39847, 'loss': 0.16270341, 'lr': 0, 'params': 197319, 'time_iter': 0.05103, 'accuracy': 0.95968, 'f1': 0.96104, 'auc': 0.99697}\n",
      "test: {'epoch': 21, 'time_epoch': 2.37966, 'loss': 0.17523444, 'lr': 0, 'params': 197319, 'time_iter': 0.05063, 'accuracy': 0.9651, 'f1': 0.96471, 'auc': 0.99685}\n",
      "> Epoch 21: took 42.5s (avg 45.1s) | Best so far: epoch 14\ttrain_loss: 0.1044 train_accuracy: 0.9743\tval_loss: 0.1529 val_accuracy: 0.9637\ttest_loss: 0.1797 test_accuracy: 0.9570\n",
      "train: {'epoch': 22, 'time_epoch': 38.2057, 'eta': 2066.82679, 'eta_hours': 0.57412, 'loss': 0.05564289, 'lr': 0.0008614, 'params': 197319, 'time_iter': 0.10243, 'accuracy': 0.98539, 'f1': 0.98542, 'auc': 0.99914}\n",
      "val: {'epoch': 22, 'time_epoch': 2.34649, 'loss': 0.26548359, 'lr': 0, 'params': 197319, 'time_iter': 0.04993, 'accuracy': 0.94489, 'f1': 0.94676, 'auc': 0.99376}\n",
      "test: {'epoch': 22, 'time_epoch': 2.31725, 'loss': 0.23728924, 'lr': 0, 'params': 197319, 'time_iter': 0.0493, 'accuracy': 0.95034, 'f1': 0.95045, 'auc': 0.9922}\n",
      "> Epoch 22: took 42.9s (avg 45.0s) | Best so far: epoch 14\ttrain_loss: 0.1044 train_accuracy: 0.9743\tval_loss: 0.1529 val_accuracy: 0.9637\ttest_loss: 0.1797 test_accuracy: 0.9570\n",
      "train: {'epoch': 23, 'time_epoch': 37.42014, 'eta': 2022.13625, 'eta_hours': 0.5617, 'loss': 0.04750456, 'lr': 0.00084553, 'params': 197319, 'time_iter': 0.10032, 'accuracy': 0.98791, 'f1': 0.98787, 'auc': 0.99959}\n",
      "val: {'epoch': 23, 'time_epoch': 2.3846, 'loss': 0.2125634, 'lr': 0, 'params': 197319, 'time_iter': 0.05074, 'accuracy': 0.95565, 'f1': 0.95716, 'auc': 0.99763}\n",
      "test: {'epoch': 23, 'time_epoch': 2.54996, 'loss': 0.16270197, 'lr': 0, 'params': 197319, 'time_iter': 0.05425, 'accuracy': 0.96376, 'f1': 0.96342, 'auc': 0.99624}\n",
      "> Epoch 23: took 42.4s (avg 44.9s) | Best so far: epoch 14\ttrain_loss: 0.1044 train_accuracy: 0.9743\tval_loss: 0.1529 val_accuracy: 0.9637\ttest_loss: 0.1797 test_accuracy: 0.9570\n",
      "train: {'epoch': 24, 'time_epoch': 38.00815, 'eta': 1979.20335, 'eta_hours': 0.54978, 'loss': 0.03927907, 'lr': 0.00082897, 'params': 197319, 'time_iter': 0.1019, 'accuracy': 0.99093, 'f1': 0.99092, 'auc': 0.99978}\n",
      "val: {'epoch': 24, 'time_epoch': 2.80941, 'loss': 0.20962004, 'lr': 0, 'params': 197319, 'time_iter': 0.05977, 'accuracy': 0.95565, 'f1': 0.9566, 'auc': 0.99711}\n",
      "test: {'epoch': 24, 'time_epoch': 2.43313, 'loss': 0.18616497, 'lr': 0, 'params': 197319, 'time_iter': 0.05177, 'accuracy': 0.96107, 'f1': 0.96011, 'auc': 0.99723}\n",
      "> Epoch 24: took 43.3s (avg 44.8s) | Best so far: epoch 14\ttrain_loss: 0.1044 train_accuracy: 0.9743\tval_loss: 0.1529 val_accuracy: 0.9637\ttest_loss: 0.1797 test_accuracy: 0.9570\n",
      "train: {'epoch': 25, 'time_epoch': 39.57416, 'eta': 1939.60061, 'eta_hours': 0.53878, 'loss': 0.03428896, 'lr': 0.00081174, 'params': 197319, 'time_iter': 0.1061, 'accuracy': 0.99211, 'f1': 0.99205, 'auc': 0.99965}\n",
      "val: {'epoch': 25, 'time_epoch': 2.36334, 'loss': 0.14387634, 'lr': 0, 'params': 197319, 'time_iter': 0.05028, 'accuracy': 0.97312, 'f1': 0.97366, 'auc': 0.99787}\n",
      "test: {'epoch': 25, 'time_epoch': 2.47572, 'loss': 0.12394149, 'lr': 0, 'params': 197319, 'time_iter': 0.05267, 'accuracy': 0.97315, 'f1': 0.97272, 'auc': 0.99842}\n",
      "> Epoch 25: took 44.5s (avg 44.8s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 26, 'time_epoch': 38.53164, 'eta': 1898.14661, 'eta_hours': 0.52726, 'loss': 0.02771409, 'lr': 0.00079389, 'params': 197319, 'time_iter': 0.1033, 'accuracy': 0.99362, 'f1': 0.99362, 'auc': 0.99984}\n",
      "val: {'epoch': 26, 'time_epoch': 2.42398, 'loss': 0.24240912, 'lr': 0, 'params': 197319, 'time_iter': 0.05157, 'accuracy': 0.95161, 'f1': 0.95374, 'auc': 0.99525}\n",
      "test: {'epoch': 26, 'time_epoch': 2.34417, 'loss': 0.18986145, 'lr': 0, 'params': 197319, 'time_iter': 0.04988, 'accuracy': 0.95705, 'f1': 0.95608, 'auc': 0.99776}\n",
      "> Epoch 26: took 43.4s (avg 44.8s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 27, 'time_epoch': 38.43653, 'eta': 1856.74172, 'eta_hours': 0.51576, 'loss': 0.04220174, 'lr': 0.00077545, 'params': 197319, 'time_iter': 0.10305, 'accuracy': 0.98908, 'f1': 0.98911, 'auc': 0.99975}\n",
      "val: {'epoch': 27, 'time_epoch': 2.40621, 'loss': 0.24413276, 'lr': 0, 'params': 197319, 'time_iter': 0.0512, 'accuracy': 0.95027, 'f1': 0.95165, 'auc': 0.99482}\n",
      "test: {'epoch': 27, 'time_epoch': 2.45264, 'loss': 0.17191759, 'lr': 0, 'params': 197319, 'time_iter': 0.05218, 'accuracy': 0.96779, 'f1': 0.9669, 'auc': 0.99795}\n",
      "> Epoch 27: took 43.4s (avg 44.7s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 28, 'time_epoch': 38.1284, 'eta': 1815.05278, 'eta_hours': 0.50418, 'loss': 0.0284871, 'lr': 0.00075645, 'params': 197319, 'time_iter': 0.10222, 'accuracy': 0.99328, 'f1': 0.99329, 'auc': 0.99988}\n",
      "val: {'epoch': 28, 'time_epoch': 2.25919, 'loss': 0.22876198, 'lr': 0, 'params': 197319, 'time_iter': 0.04807, 'accuracy': 0.9543, 'f1': 0.9555, 'auc': 0.99561}\n",
      "test: {'epoch': 28, 'time_epoch': 2.32701, 'loss': 0.16152365, 'lr': 0, 'params': 197319, 'time_iter': 0.04951, 'accuracy': 0.96779, 'f1': 0.96775, 'auc': 0.99597}\n",
      "> Epoch 28: took 42.8s (avg 44.6s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 29, 'time_epoch': 37.47575, 'eta': 1772.62223, 'eta_hours': 0.4924, 'loss': 0.03561959, 'lr': 0.00073693, 'params': 197319, 'time_iter': 0.10047, 'accuracy': 0.99026, 'f1': 0.99028, 'auc': 0.99968}\n",
      "val: {'epoch': 29, 'time_epoch': 2.32903, 'loss': 0.20722986, 'lr': 0, 'params': 197319, 'time_iter': 0.04955, 'accuracy': 0.95161, 'f1': 0.95276, 'auc': 0.99623}\n",
      "test: {'epoch': 29, 'time_epoch': 2.35532, 'loss': 0.18994248, 'lr': 0, 'params': 197319, 'time_iter': 0.05011, 'accuracy': 0.96644, 'f1': 0.96606, 'auc': 0.99526}\n",
      "> Epoch 29: took 42.2s (avg 44.6s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 30, 'time_epoch': 38.01239, 'eta': 1731.27304, 'eta_hours': 0.48091, 'loss': 0.02238152, 'lr': 0.00071694, 'params': 197319, 'time_iter': 0.10191, 'accuracy': 0.99395, 'f1': 0.99393, 'auc': 0.99992}\n",
      "val: {'epoch': 30, 'time_epoch': 2.28992, 'loss': 0.1656545, 'lr': 0, 'params': 197319, 'time_iter': 0.04872, 'accuracy': 0.96774, 'f1': 0.96837, 'auc': 0.99722}\n",
      "test: {'epoch': 30, 'time_epoch': 2.52013, 'loss': 0.17680125, 'lr': 0, 'params': 197319, 'time_iter': 0.05362, 'accuracy': 0.96779, 'f1': 0.96819, 'auc': 0.99633}\n",
      "> Epoch 30: took 42.9s (avg 44.5s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 31, 'time_epoch': 37.86424, 'eta': 1689.93331, 'eta_hours': 0.46943, 'loss': 0.02750064, 'lr': 0.00069651, 'params': 197319, 'time_iter': 0.10151, 'accuracy': 0.99227, 'f1': 0.99227, 'auc': 0.99994}\n",
      "val: {'epoch': 31, 'time_epoch': 2.31377, 'loss': 0.26041735, 'lr': 0, 'params': 197319, 'time_iter': 0.04923, 'accuracy': 0.95027, 'f1': 0.95178, 'auc': 0.99675}\n",
      "test: {'epoch': 31, 'time_epoch': 2.3644, 'loss': 0.29409907, 'lr': 0, 'params': 197319, 'time_iter': 0.05031, 'accuracy': 0.93826, 'f1': 0.94065, 'auc': 0.99595}\n",
      "> Epoch 31: took 42.6s (avg 44.4s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 32, 'time_epoch': 38.05829, 'eta': 1649.05119, 'eta_hours': 0.45807, 'loss': 0.0204119, 'lr': 0.00067569, 'params': 197319, 'time_iter': 0.10203, 'accuracy': 0.99513, 'f1': 0.99511, 'auc': 0.99982}\n",
      "val: {'epoch': 32, 'time_epoch': 2.42096, 'loss': 0.18092284, 'lr': 0, 'params': 197319, 'time_iter': 0.05151, 'accuracy': 0.9664, 'f1': 0.96715, 'auc': 0.99645}\n",
      "test: {'epoch': 32, 'time_epoch': 2.5233, 'loss': 0.16367941, 'lr': 0, 'params': 197319, 'time_iter': 0.05369, 'accuracy': 0.97047, 'f1': 0.97044, 'auc': 0.99711}\n",
      "> Epoch 32: took 43.1s (avg 44.4s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 33, 'time_epoch': 38.14206, 'eta': 1608.43619, 'eta_hours': 0.44679, 'loss': 0.01672056, 'lr': 0.00065451, 'params': 197319, 'time_iter': 0.10226, 'accuracy': 0.99647, 'f1': 0.99647, 'auc': 0.99997}\n",
      "val: {'epoch': 33, 'time_epoch': 2.26897, 'loss': 0.27728154, 'lr': 0, 'params': 197319, 'time_iter': 0.04828, 'accuracy': 0.94892, 'f1': 0.94995, 'auc': 0.99606}\n",
      "test: {'epoch': 33, 'time_epoch': 2.54301, 'loss': 0.29791166, 'lr': 0, 'params': 197319, 'time_iter': 0.05411, 'accuracy': 0.95168, 'f1': 0.95161, 'auc': 0.99532}\n",
      "> Epoch 33: took 43.1s (avg 44.4s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 34, 'time_epoch': 38.04249, 'eta': 1567.84872, 'eta_hours': 0.43551, 'loss': 0.01931591, 'lr': 0.00063302, 'params': 197319, 'time_iter': 0.10199, 'accuracy': 0.99479, 'f1': 0.99476, 'auc': 0.99996}\n",
      "val: {'epoch': 34, 'time_epoch': 2.34084, 'loss': 0.19143884, 'lr': 0, 'params': 197319, 'time_iter': 0.04981, 'accuracy': 0.96371, 'f1': 0.96449, 'auc': 0.998}\n",
      "test: {'epoch': 34, 'time_epoch': 2.40783, 'loss': 0.21954186, 'lr': 0, 'params': 197319, 'time_iter': 0.05123, 'accuracy': 0.96242, 'f1': 0.96225, 'auc': 0.99625}\n",
      "> Epoch 34: took 42.9s (avg 44.3s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 35, 'time_epoch': 37.80434, 'eta': 1527.14463, 'eta_hours': 0.42421, 'loss': 0.01415413, 'lr': 0.00061126, 'params': 197319, 'time_iter': 0.10135, 'accuracy': 0.99563, 'f1': 0.99564, 'auc': 0.99991}\n",
      "val: {'epoch': 35, 'time_epoch': 2.37161, 'loss': 0.2202028, 'lr': 0, 'params': 197319, 'time_iter': 0.05046, 'accuracy': 0.96505, 'f1': 0.96599, 'auc': 0.99628}\n",
      "test: {'epoch': 35, 'time_epoch': 2.33937, 'loss': 0.20750381, 'lr': 0, 'params': 197319, 'time_iter': 0.04977, 'accuracy': 0.96242, 'f1': 0.96204, 'auc': 0.99639}\n",
      "> Epoch 35: took 42.6s (avg 44.3s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 36, 'time_epoch': 37.67485, 'eta': 1486.4643, 'eta_hours': 0.41291, 'loss': 0.02399307, 'lr': 0.00058928, 'params': 197319, 'time_iter': 0.101, 'accuracy': 0.99479, 'f1': 0.99476, 'auc': 0.99989}\n",
      "val: {'epoch': 36, 'time_epoch': 2.29438, 'loss': 0.15816953, 'lr': 0, 'params': 197319, 'time_iter': 0.04882, 'accuracy': 0.96505, 'f1': 0.96575, 'auc': 0.99795}\n",
      "test: {'epoch': 36, 'time_epoch': 2.86682, 'loss': 0.1631827, 'lr': 0, 'params': 197319, 'time_iter': 0.061, 'accuracy': 0.96913, 'f1': 0.96882, 'auc': 0.99724}\n",
      "> Epoch 36: took 42.9s (avg 44.2s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 37, 'time_epoch': 37.28061, 'eta': 1445.55829, 'eta_hours': 0.40154, 'loss': 0.01047287, 'lr': 0.00056712, 'params': 197319, 'time_iter': 0.09995, 'accuracy': 0.99748, 'f1': 0.99747, 'auc': 0.99999}\n",
      "val: {'epoch': 37, 'time_epoch': 2.47151, 'loss': 0.23033979, 'lr': 0, 'params': 197319, 'time_iter': 0.05259, 'accuracy': 0.96371, 'f1': 0.96473, 'auc': 0.99607}\n",
      "test: {'epoch': 37, 'time_epoch': 2.32286, 'loss': 0.20227012, 'lr': 0, 'params': 197319, 'time_iter': 0.04942, 'accuracy': 0.96376, 'f1': 0.96255, 'auc': 0.99572}\n",
      "> Epoch 37: took 42.2s (avg 44.2s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 38, 'time_epoch': 37.72955, 'eta': 1405.25259, 'eta_hours': 0.39035, 'loss': 0.01296933, 'lr': 0.00054482, 'params': 197319, 'time_iter': 0.10115, 'accuracy': 0.99714, 'f1': 0.99713, 'auc': 0.99992}\n",
      "val: {'epoch': 38, 'time_epoch': 2.36787, 'loss': 0.27658545, 'lr': 0, 'params': 197319, 'time_iter': 0.05038, 'accuracy': 0.95699, 'f1': 0.95803, 'auc': 0.99407}\n",
      "test: {'epoch': 38, 'time_epoch': 2.32824, 'loss': 0.19754841, 'lr': 0, 'params': 197319, 'time_iter': 0.04954, 'accuracy': 0.96644, 'f1': 0.96678, 'auc': 0.99738}\n",
      "> Epoch 38: took 42.5s (avg 44.1s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 39, 'time_epoch': 37.47064, 'eta': 1364.84916, 'eta_hours': 0.37912, 'loss': 0.02360418, 'lr': 0.00052243, 'params': 197319, 'time_iter': 0.10046, 'accuracy': 0.99496, 'f1': 0.99494, 'auc': 0.9998}\n",
      "val: {'epoch': 39, 'time_epoch': 2.21099, 'loss': 0.25923098, 'lr': 0, 'params': 197319, 'time_iter': 0.04704, 'accuracy': 0.95699, 'f1': 0.95832, 'auc': 0.99536}\n",
      "test: {'epoch': 39, 'time_epoch': 2.37317, 'loss': 0.18846214, 'lr': 0, 'params': 197319, 'time_iter': 0.05049, 'accuracy': 0.97047, 'f1': 0.9699, 'auc': 0.99511}\n",
      "> Epoch 39: took 42.1s (avg 44.1s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 40, 'time_epoch': 37.52415, 'eta': 1324.63317, 'eta_hours': 0.36795, 'loss': 0.01183268, 'lr': 0.0005, 'params': 197319, 'time_iter': 0.1006, 'accuracy': 0.99681, 'f1': 0.99683, 'auc': 0.99999}\n",
      "val: {'epoch': 40, 'time_epoch': 2.31673, 'loss': 0.30713478, 'lr': 0, 'params': 197319, 'time_iter': 0.04929, 'accuracy': 0.95296, 'f1': 0.95477, 'auc': 0.99313}\n",
      "test: {'epoch': 40, 'time_epoch': 2.29311, 'loss': 0.23228776, 'lr': 0, 'params': 197319, 'time_iter': 0.04879, 'accuracy': 0.96242, 'f1': 0.96136, 'auc': 0.99748}\n",
      "> Epoch 40: took 42.2s (avg 44.0s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 41, 'time_epoch': 38.44059, 'eta': 1285.26542, 'eta_hours': 0.35702, 'loss': 0.01161276, 'lr': 0.00047757, 'params': 197319, 'time_iter': 0.10306, 'accuracy': 0.99731, 'f1': 0.99734, 'auc': 0.99997}\n",
      "val: {'epoch': 41, 'time_epoch': 2.63418, 'loss': 0.25746816, 'lr': 0, 'params': 197319, 'time_iter': 0.05605, 'accuracy': 0.96237, 'f1': 0.96351, 'auc': 0.99533}\n",
      "test: {'epoch': 41, 'time_epoch': 2.34768, 'loss': 0.16869317, 'lr': 0, 'params': 197319, 'time_iter': 0.04995, 'accuracy': 0.96644, 'f1': 0.96652, 'auc': 0.99762}\n",
      "> Epoch 41: took 43.5s (avg 44.0s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 42, 'time_epoch': 38.04652, 'eta': 1245.64753, 'eta_hours': 0.34601, 'loss': 0.00660053, 'lr': 0.00045518, 'params': 197319, 'time_iter': 0.102, 'accuracy': 0.99782, 'f1': 0.99781, 'auc': 0.99999}\n",
      "val: {'epoch': 42, 'time_epoch': 2.34089, 'loss': 0.28275023, 'lr': 0, 'params': 197319, 'time_iter': 0.04981, 'accuracy': 0.95968, 'f1': 0.96109, 'auc': 0.99364}\n",
      "test: {'epoch': 42, 'time_epoch': 2.52032, 'loss': 0.25455012, 'lr': 0, 'params': 197319, 'time_iter': 0.05362, 'accuracy': 0.9557, 'f1': 0.95573, 'auc': 0.99443}\n",
      "> Epoch 42: took 43.0s (avg 44.0s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 43, 'time_epoch': 37.90778, 'eta': 1206.00332, 'eta_hours': 0.335, 'loss': 0.00682045, 'lr': 0.00043288, 'params': 197319, 'time_iter': 0.10163, 'accuracy': 0.99899, 'f1': 0.99898, 'auc': 0.99999}\n",
      "val: {'epoch': 43, 'time_epoch': 2.39464, 'loss': 0.29567391, 'lr': 0, 'params': 197319, 'time_iter': 0.05095, 'accuracy': 0.9543, 'f1': 0.95584, 'auc': 0.99634}\n",
      "test: {'epoch': 43, 'time_epoch': 2.31588, 'loss': 0.2164635, 'lr': 0, 'params': 197319, 'time_iter': 0.04927, 'accuracy': 0.97047, 'f1': 0.97032, 'auc': 0.9968}\n",
      "> Epoch 43: took 42.7s (avg 44.0s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 44, 'time_epoch': 38.08426, 'eta': 1166.55394, 'eta_hours': 0.32404, 'loss': 0.0067074, 'lr': 0.00041072, 'params': 197319, 'time_iter': 0.1021, 'accuracy': 0.99815, 'f1': 0.99814, 'auc': 1.0}\n",
      "val: {'epoch': 44, 'time_epoch': 2.36651, 'loss': 0.2648419, 'lr': 0, 'params': 197319, 'time_iter': 0.05035, 'accuracy': 0.96371, 'f1': 0.96429, 'auc': 0.99412}\n",
      "test: {'epoch': 44, 'time_epoch': 2.33534, 'loss': 0.20433478, 'lr': 0, 'params': 197319, 'time_iter': 0.04969, 'accuracy': 0.97181, 'f1': 0.97157, 'auc': 0.99503}\n",
      "> Epoch 44: took 42.9s (avg 44.0s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 45, 'time_epoch': 37.16276, 'eta': 1126.58297, 'eta_hours': 0.31294, 'loss': 0.00771717, 'lr': 0.00038874, 'params': 197319, 'time_iter': 0.09963, 'accuracy': 0.99815, 'f1': 0.99815, 'auc': 0.99997}\n",
      "val: {'epoch': 45, 'time_epoch': 2.24397, 'loss': 0.28134508, 'lr': 0, 'params': 197319, 'time_iter': 0.04774, 'accuracy': 0.95699, 'f1': 0.95828, 'auc': 0.99602}\n",
      "test: {'epoch': 45, 'time_epoch': 2.43666, 'loss': 0.26933047, 'lr': 0, 'params': 197319, 'time_iter': 0.05184, 'accuracy': 0.95839, 'f1': 0.95785, 'auc': 0.99731}\n",
      "> Epoch 45: took 41.9s (avg 43.9s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 46, 'time_epoch': 37.11123, 'eta': 1086.70079, 'eta_hours': 0.30186, 'loss': 0.00664908, 'lr': 0.00036698, 'params': 197319, 'time_iter': 0.09949, 'accuracy': 0.99832, 'f1': 0.99831, 'auc': 0.99998}\n",
      "val: {'epoch': 46, 'time_epoch': 2.48092, 'loss': 0.23770022, 'lr': 0, 'params': 197319, 'time_iter': 0.05279, 'accuracy': 0.96774, 'f1': 0.96852, 'auc': 0.99591}\n",
      "test: {'epoch': 46, 'time_epoch': 2.72309, 'loss': 0.20508309, 'lr': 0, 'params': 197319, 'time_iter': 0.05794, 'accuracy': 0.96779, 'f1': 0.96786, 'auc': 0.99658}\n",
      "> Epoch 46: took 42.4s (avg 43.9s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 47, 'time_epoch': 37.72893, 'eta': 1047.28153, 'eta_hours': 0.29091, 'loss': 0.00853519, 'lr': 0.00034549, 'params': 197319, 'time_iter': 0.10115, 'accuracy': 0.99782, 'f1': 0.9978, 'auc': 0.99997}\n",
      "val: {'epoch': 47, 'time_epoch': 2.33607, 'loss': 0.26923966, 'lr': 0, 'params': 197319, 'time_iter': 0.0497, 'accuracy': 0.95699, 'f1': 0.95779, 'auc': 0.99523}\n",
      "test: {'epoch': 47, 'time_epoch': 2.36688, 'loss': 0.2288883, 'lr': 0, 'params': 197319, 'time_iter': 0.05036, 'accuracy': 0.96376, 'f1': 0.9625, 'auc': 0.99767}\n",
      "> Epoch 47: took 42.5s (avg 43.9s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 48, 'time_epoch': 37.50349, 'eta': 1007.81164, 'eta_hours': 0.27995, 'loss': 0.00628696, 'lr': 0.00032431, 'params': 197319, 'time_iter': 0.10055, 'accuracy': 0.99815, 'f1': 0.99814, 'auc': 0.99999}\n",
      "val: {'epoch': 48, 'time_epoch': 2.32038, 'loss': 0.21936412, 'lr': 0, 'params': 197319, 'time_iter': 0.04937, 'accuracy': 0.96774, 'f1': 0.96809, 'auc': 0.99532}\n",
      "test: {'epoch': 48, 'time_epoch': 2.54236, 'loss': 0.16241027, 'lr': 0, 'params': 197319, 'time_iter': 0.05409, 'accuracy': 0.97315, 'f1': 0.97265, 'auc': 0.99773}\n",
      "> Epoch 48: took 42.5s (avg 43.8s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 49, 'time_epoch': 37.7376, 'eta': 968.53746, 'eta_hours': 0.26904, 'loss': 0.00337102, 'lr': 0.00030349, 'params': 197319, 'time_iter': 0.10117, 'accuracy': 0.99899, 'f1': 0.99898, 'auc': 1.0}\n",
      "val: {'epoch': 49, 'time_epoch': 2.35226, 'loss': 0.28845952, 'lr': 0, 'params': 197319, 'time_iter': 0.05005, 'accuracy': 0.95296, 'f1': 0.95397, 'auc': 0.99622}\n",
      "test: {'epoch': 49, 'time_epoch': 2.44689, 'loss': 0.23730409, 'lr': 0, 'params': 197319, 'time_iter': 0.05206, 'accuracy': 0.96376, 'f1': 0.9628, 'auc': 0.99693}\n",
      "> Epoch 49: took 42.6s (avg 43.8s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 50, 'time_epoch': 38.22155, 'eta': 929.55128, 'eta_hours': 0.25821, 'loss': 0.00220609, 'lr': 0.00028306, 'params': 197319, 'time_iter': 0.10247, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "val: {'epoch': 50, 'time_epoch': 2.3143, 'loss': 0.20027476, 'lr': 0, 'params': 197319, 'time_iter': 0.04924, 'accuracy': 0.97043, 'f1': 0.97127, 'auc': 0.99616}\n",
      "test: {'epoch': 50, 'time_epoch': 2.40632, 'loss': 0.19927969, 'lr': 0, 'params': 197319, 'time_iter': 0.0512, 'accuracy': 0.97047, 'f1': 0.96966, 'auc': 0.99641}\n",
      "> Epoch 50: took 43.0s (avg 43.8s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 51, 'time_epoch': 37.65987, 'eta': 890.34607, 'eta_hours': 0.24732, 'loss': 0.00229181, 'lr': 0.00026307, 'params': 197319, 'time_iter': 0.10096, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 0.99986}\n",
      "val: {'epoch': 51, 'time_epoch': 2.4025, 'loss': 0.23948338, 'lr': 0, 'params': 197319, 'time_iter': 0.05112, 'accuracy': 0.96505, 'f1': 0.96598, 'auc': 0.99651}\n",
      "test: {'epoch': 51, 'time_epoch': 2.51222, 'loss': 0.18569595, 'lr': 0, 'params': 197319, 'time_iter': 0.05345, 'accuracy': 0.96779, 'f1': 0.96707, 'auc': 0.9976}\n",
      "> Epoch 51: took 42.7s (avg 43.8s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 52, 'time_epoch': 37.73667, 'eta': 851.23105, 'eta_hours': 0.23645, 'loss': 0.00120045, 'lr': 0.00024355, 'params': 197319, 'time_iter': 0.10117, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "val: {'epoch': 52, 'time_epoch': 2.44957, 'loss': 0.23474828, 'lr': 0, 'params': 197319, 'time_iter': 0.05212, 'accuracy': 0.96371, 'f1': 0.96466, 'auc': 0.99716}\n",
      "test: {'epoch': 52, 'time_epoch': 2.39357, 'loss': 0.18545559, 'lr': 0, 'params': 197319, 'time_iter': 0.05093, 'accuracy': 0.97181, 'f1': 0.97097, 'auc': 0.99713}\n",
      "> Epoch 52: took 42.7s (avg 43.7s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 53, 'time_epoch': 38.01133, 'eta': 812.2739, 'eta_hours': 0.22563, 'loss': 0.00169042, 'lr': 0.00022455, 'params': 197319, 'time_iter': 0.10191, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 53, 'time_epoch': 2.29835, 'loss': 0.24753581, 'lr': 0, 'params': 197319, 'time_iter': 0.0489, 'accuracy': 0.96371, 'f1': 0.96464, 'auc': 0.99607}\n",
      "test: {'epoch': 53, 'time_epoch': 2.29894, 'loss': 0.20114164, 'lr': 0, 'params': 197319, 'time_iter': 0.04891, 'accuracy': 0.97181, 'f1': 0.97066, 'auc': 0.99694}\n",
      "> Epoch 53: took 42.7s (avg 43.7s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 54, 'time_epoch': 37.59308, 'eta': 773.19905, 'eta_hours': 0.21478, 'loss': 0.00307806, 'lr': 0.00020611, 'params': 197319, 'time_iter': 0.10079, 'accuracy': 0.99933, 'f1': 0.99932, 'auc': 0.99999}\n",
      "val: {'epoch': 54, 'time_epoch': 2.38253, 'loss': 0.26770385, 'lr': 0, 'params': 197319, 'time_iter': 0.05069, 'accuracy': 0.96237, 'f1': 0.96297, 'auc': 0.99509}\n",
      "test: {'epoch': 54, 'time_epoch': 2.33198, 'loss': 0.21859503, 'lr': 0, 'params': 197319, 'time_iter': 0.04962, 'accuracy': 0.96779, 'f1': 0.96807, 'auc': 0.99757}\n",
      "> Epoch 54: took 42.4s (avg 43.7s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 55, 'time_epoch': 37.9004, 'eta': 734.28139, 'eta_hours': 0.20397, 'loss': 0.00272242, 'lr': 0.00018826, 'params': 197319, 'time_iter': 0.10161, 'accuracy': 0.9995, 'f1': 0.99949, 'auc': 1.0}\n",
      "val: {'epoch': 55, 'time_epoch': 2.32617, 'loss': 0.23628433, 'lr': 0, 'params': 197319, 'time_iter': 0.04949, 'accuracy': 0.96909, 'f1': 0.9696, 'auc': 0.996}\n",
      "test: {'epoch': 55, 'time_epoch': 2.38563, 'loss': 0.21512564, 'lr': 0, 'params': 197319, 'time_iter': 0.05076, 'accuracy': 0.96779, 'f1': 0.96743, 'auc': 0.99689}\n",
      "> Epoch 55: took 42.7s (avg 43.7s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 56, 'time_epoch': 37.69158, 'eta': 695.33348, 'eta_hours': 0.19315, 'loss': 0.0004601, 'lr': 0.00017103, 'params': 197319, 'time_iter': 0.10105, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 56, 'time_epoch': 2.26753, 'loss': 0.21323413, 'lr': 0, 'params': 197319, 'time_iter': 0.04825, 'accuracy': 0.97043, 'f1': 0.97131, 'auc': 0.99776}\n",
      "test: {'epoch': 56, 'time_epoch': 2.21673, 'loss': 0.20078589, 'lr': 0, 'params': 197319, 'time_iter': 0.04716, 'accuracy': 0.97181, 'f1': 0.9715, 'auc': 0.99728}\n",
      "> Epoch 56: took 42.3s (avg 43.7s) | Best so far: epoch 25\ttrain_loss: 0.0343 train_accuracy: 0.9921\tval_loss: 0.1439 val_accuracy: 0.9731\ttest_loss: 0.1239 test_accuracy: 0.9731\n",
      "train: {'epoch': 57, 'time_epoch': 36.67943, 'eta': 656.13223, 'eta_hours': 0.18226, 'loss': 0.00024679, 'lr': 0.00015447, 'params': 197319, 'time_iter': 0.09834, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#exphormer dropout 0.3 attn dropout 0.3\n",
    "%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64190bd1-4834-493a-be1b-2fc0f7559bf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-02-27 18:36:33.858154\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 7\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [05:31<00:00, 22.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:05:46.87\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [01:41<00:00, 73.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:48.00\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=400, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.3\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: Exphormer\n",
      "  layers: 5\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 75\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 197319\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 38.30337, 'eta': 2834.44924, 'eta_hours': 0.78735, 'loss': 1.95125421, 'lr': 0.0, 'params': 197319, 'time_iter': 0.10269, 'accuracy': 0.13923, 'f1': 0.05973, 'auc': 0.48162}\n",
      "...computing epoch stats took: 0.11s\n",
      "val: {'epoch': 0, 'time_epoch': 2.37198, 'loss': 1.95126104, 'lr': 0, 'params': 197319, 'time_iter': 0.05047, 'accuracy': 0.15591, 'f1': 0.07638, 'auc': 0.48353}\n",
      "...computing epoch stats took: 0.04s\n",
      "test: {'epoch': 0, 'time_epoch': 2.37006, 'loss': 1.95966625, 'lr': 0, 'params': 197319, 'time_iter': 0.05043, 'accuracy': 0.10738, 'f1': 0.05238, 'auc': 0.48707}\n",
      "...computing epoch stats took: 0.03s\n",
      "> Epoch 0: took 43.2s (avg 43.2s) | Best so far: epoch 0\ttrain_loss: 1.9513 train_accuracy: 0.1392\tval_loss: 1.9513 val_accuracy: 0.1559\ttest_loss: 1.9597 test_accuracy: 0.1074\n",
      "train: {'epoch': 1, 'time_epoch': 35.49351, 'eta': 2693.58598, 'eta_hours': 0.74822, 'loss': 1.71614035, 'lr': 0.0002, 'params': 197319, 'time_iter': 0.09516, 'accuracy': 0.60245, 'f1': 0.6066, 'auc': 0.88517}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 1, 'time_epoch': 2.2213, 'loss': 1.53954694, 'lr': 0, 'params': 197319, 'time_iter': 0.04726, 'accuracy': 0.80242, 'f1': 0.80322, 'auc': 0.96293}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 1, 'time_epoch': 2.17015, 'loss': 1.53690259, 'lr': 0, 'params': 197319, 'time_iter': 0.04617, 'accuracy': 0.78926, 'f1': 0.78876, 'auc': 0.96676}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 1: took 40.0s (avg 41.6s) | Best so far: epoch 1\ttrain_loss: 1.7161 train_accuracy: 0.6025\tval_loss: 1.5395 val_accuracy: 0.8024\ttest_loss: 1.5369 test_accuracy: 0.7893\n",
      "train: {'epoch': 2, 'time_epoch': 35.48477, 'eta': 2622.75949, 'eta_hours': 0.72854, 'loss': 1.3223329, 'lr': 0.0004, 'params': 197319, 'time_iter': 0.09513, 'accuracy': 0.85455, 'f1': 0.85312, 'auc': 0.97283}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 2, 'time_epoch': 2.15509, 'loss': 1.12871133, 'lr': 0, 'params': 197319, 'time_iter': 0.04585, 'accuracy': 0.89919, 'f1': 0.90376, 'auc': 0.98564}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 2, 'time_epoch': 2.17437, 'loss': 1.13945952, 'lr': 0, 'params': 197319, 'time_iter': 0.04626, 'accuracy': 0.89128, 'f1': 0.89116, 'auc': 0.98389}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 2: took 39.9s (avg 41.0s) | Best so far: epoch 2\ttrain_loss: 1.3223 train_accuracy: 0.8546\tval_loss: 1.1287 val_accuracy: 0.8992\ttest_loss: 1.1395 test_accuracy: 0.8913\n",
      "train: {'epoch': 3, 'time_epoch': 35.6661, 'eta': 2572.82239, 'eta_hours': 0.71467, 'loss': 0.91643344, 'lr': 0.0006, 'params': 197319, 'time_iter': 0.09562, 'accuracy': 0.9135, 'f1': 0.91315, 'auc': 0.9854}\n",
      "val: {'epoch': 3, 'time_epoch': 2.1462, 'loss': 0.89848648, 'lr': 0, 'params': 197319, 'time_iter': 0.04566, 'accuracy': 0.8293, 'f1': 0.83287, 'auc': 0.9737}\n",
      "test: {'epoch': 3, 'time_epoch': 2.20289, 'loss': 0.89803548, 'lr': 0, 'params': 197319, 'time_iter': 0.04687, 'accuracy': 0.82685, 'f1': 0.82984, 'auc': 0.97627}\n",
      "> Epoch 3: took 40.1s (avg 40.8s) | Best so far: epoch 2\ttrain_loss: 1.3223 train_accuracy: 0.8546\tval_loss: 1.1287 val_accuracy: 0.8992\ttest_loss: 1.1395 test_accuracy: 0.8913\n",
      "train: {'epoch': 4, 'time_epoch': 36.93158, 'eta': 2546.31045, 'eta_hours': 0.70731, 'loss': 0.63010889, 'lr': 0.0008, 'params': 197319, 'time_iter': 0.09901, 'accuracy': 0.91737, 'f1': 0.91701, 'auc': 0.98601}\n",
      "val: {'epoch': 4, 'time_epoch': 2.32826, 'loss': 0.53301626, 'lr': 0, 'params': 197319, 'time_iter': 0.04954, 'accuracy': 0.91801, 'f1': 0.92084, 'auc': 0.99033}\n",
      "test: {'epoch': 4, 'time_epoch': 2.4868, 'loss': 0.5315414, 'lr': 0, 'params': 197319, 'time_iter': 0.05291, 'accuracy': 0.91409, 'f1': 0.91352, 'auc': 0.9903}\n",
      "> Epoch 4: took 41.8s (avg 41.0s) | Best so far: epoch 4\ttrain_loss: 0.6301 train_accuracy: 0.9174\tval_loss: 0.5330 val_accuracy: 0.9180\ttest_loss: 0.5315 test_accuracy: 0.9141\n",
      "train: {'epoch': 5, 'time_epoch': 37.04225, 'eta': 2517.59806, 'eta_hours': 0.69933, 'loss': 0.44856807, 'lr': 0.001, 'params': 197319, 'time_iter': 0.09931, 'accuracy': 0.92425, 'f1': 0.92395, 'auc': 0.98851}\n",
      "val: {'epoch': 5, 'time_epoch': 2.64523, 'loss': 0.49709394, 'lr': 0, 'params': 197319, 'time_iter': 0.05628, 'accuracy': 0.89247, 'f1': 0.89895, 'auc': 0.98144}\n",
      "test: {'epoch': 5, 'time_epoch': 2.51142, 'loss': 0.51244543, 'lr': 0, 'params': 197319, 'time_iter': 0.05343, 'accuracy': 0.87785, 'f1': 0.88687, 'auc': 0.98199}\n",
      "> Epoch 5: took 42.3s (avg 41.2s) | Best so far: epoch 4\ttrain_loss: 0.6301 train_accuracy: 0.9174\tval_loss: 0.5330 val_accuracy: 0.9180\ttest_loss: 0.5315 test_accuracy: 0.9141\n",
      "train: {'epoch': 6, 'time_epoch': 40.93132, 'eta': 2524.28521, 'eta_hours': 0.70119, 'loss': 0.30952928, 'lr': 0.0009995, 'params': 197319, 'time_iter': 0.10974, 'accuracy': 0.9439, 'f1': 0.9439, 'auc': 0.99283}\n",
      "val: {'epoch': 6, 'time_epoch': 2.57275, 'loss': 0.41629867, 'lr': 0, 'params': 197319, 'time_iter': 0.05474, 'accuracy': 0.88978, 'f1': 0.89078, 'auc': 0.98975}\n",
      "test: {'epoch': 6, 'time_epoch': 2.90147, 'loss': 0.36594705, 'lr': 0, 'params': 197319, 'time_iter': 0.06173, 'accuracy': 0.90872, 'f1': 0.90097, 'auc': 0.9907}\n",
      "> Epoch 6: took 46.5s (avg 42.0s) | Best so far: epoch 4\ttrain_loss: 0.6301 train_accuracy: 0.9174\tval_loss: 0.5330 val_accuracy: 0.9180\ttest_loss: 0.5315 test_accuracy: 0.9141\n",
      "train: {'epoch': 7, 'time_epoch': 41.6764, 'eta': 2525.30784, 'eta_hours': 0.70147, 'loss': 0.24867616, 'lr': 0.00099799, 'params': 197319, 'time_iter': 0.11173, 'accuracy': 0.95297, 'f1': 0.95291, 'auc': 0.9938}\n",
      "val: {'epoch': 7, 'time_epoch': 2.24515, 'loss': 0.21021804, 'lr': 0, 'params': 197319, 'time_iter': 0.04777, 'accuracy': 0.95968, 'f1': 0.96097, 'auc': 0.99525}\n",
      "test: {'epoch': 7, 'time_epoch': 2.42324, 'loss': 0.20783593, 'lr': 0, 'params': 197319, 'time_iter': 0.05156, 'accuracy': 0.96242, 'f1': 0.96218, 'auc': 0.9952}\n",
      "> Epoch 7: took 46.4s (avg 42.5s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 8, 'time_epoch': 36.75456, 'eta': 2480.74829, 'eta_hours': 0.6891, 'loss': 0.21426781, 'lr': 0.00099547, 'params': 197319, 'time_iter': 0.09854, 'accuracy': 0.95499, 'f1': 0.95501, 'auc': 0.9943}\n",
      "val: {'epoch': 8, 'time_epoch': 2.29425, 'loss': 0.2836143, 'lr': 0, 'params': 197319, 'time_iter': 0.04881, 'accuracy': 0.93414, 'f1': 0.93521, 'auc': 0.99322}\n",
      "test: {'epoch': 8, 'time_epoch': 2.31684, 'loss': 0.24605812, 'lr': 0, 'params': 197319, 'time_iter': 0.04929, 'accuracy': 0.94228, 'f1': 0.94066, 'auc': 0.99344}\n",
      "> Epoch 8: took 41.5s (avg 42.4s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 9, 'time_epoch': 36.21114, 'eta': 2434.21747, 'eta_hours': 0.67617, 'loss': 0.16914386, 'lr': 0.00099196, 'params': 197319, 'time_iter': 0.09708, 'accuracy': 0.96271, 'f1': 0.96253, 'auc': 0.99645}\n",
      "val: {'epoch': 9, 'time_epoch': 2.38706, 'loss': 0.18525719, 'lr': 0, 'params': 197319, 'time_iter': 0.05079, 'accuracy': 0.95833, 'f1': 0.95936, 'auc': 0.99593}\n",
      "test: {'epoch': 9, 'time_epoch': 2.28402, 'loss': 0.17145367, 'lr': 0, 'params': 197319, 'time_iter': 0.0486, 'accuracy': 0.96376, 'f1': 0.96372, 'auc': 0.99586}\n",
      "> Epoch 9: took 41.0s (avg 42.3s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 10, 'time_epoch': 36.36677, 'eta': 2390.46848, 'eta_hours': 0.66402, 'loss': 0.1467973, 'lr': 0.00098746, 'params': 197319, 'time_iter': 0.0975, 'accuracy': 0.96876, 'f1': 0.96871, 'auc': 0.99658}\n",
      "val: {'epoch': 10, 'time_epoch': 2.13704, 'loss': 0.20892128, 'lr': 0, 'params': 197319, 'time_iter': 0.04547, 'accuracy': 0.94892, 'f1': 0.95013, 'auc': 0.99598}\n",
      "test: {'epoch': 10, 'time_epoch': 2.27382, 'loss': 0.18645073, 'lr': 0, 'params': 197319, 'time_iter': 0.04838, 'accuracy': 0.95302, 'f1': 0.94994, 'auc': 0.99758}\n",
      "> Epoch 10: took 40.9s (avg 42.1s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 11, 'time_epoch': 36.62937, 'eta': 2349.32848, 'eta_hours': 0.65259, 'loss': 0.11536428, 'lr': 0.00098198, 'params': 197319, 'time_iter': 0.0982, 'accuracy': 0.97313, 'f1': 0.97295, 'auc': 0.99802}\n",
      "val: {'epoch': 11, 'time_epoch': 2.30226, 'loss': 0.1880513, 'lr': 0, 'params': 197319, 'time_iter': 0.04898, 'accuracy': 0.95833, 'f1': 0.95901, 'auc': 0.99497}\n",
      "test: {'epoch': 11, 'time_epoch': 2.28627, 'loss': 0.18685577, 'lr': 0, 'params': 197319, 'time_iter': 0.04864, 'accuracy': 0.9557, 'f1': 0.95467, 'auc': 0.99583}\n",
      "> Epoch 11: took 41.3s (avg 42.1s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 12, 'time_epoch': 36.74233, 'eta': 2309.42115, 'eta_hours': 0.64151, 'loss': 0.10831329, 'lr': 0.00097553, 'params': 197319, 'time_iter': 0.0985, 'accuracy': 0.97615, 'f1': 0.97609, 'auc': 0.99794}\n",
      "val: {'epoch': 12, 'time_epoch': 2.64398, 'loss': 0.30454546, 'lr': 0, 'params': 197319, 'time_iter': 0.05625, 'accuracy': 0.93011, 'f1': 0.93154, 'auc': 0.99354}\n",
      "test: {'epoch': 12, 'time_epoch': 2.56432, 'loss': 0.27982149, 'lr': 0, 'params': 197319, 'time_iter': 0.05456, 'accuracy': 0.93423, 'f1': 0.92788, 'auc': 0.99551}\n",
      "> Epoch 12: took 42.0s (avg 42.1s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 13, 'time_epoch': 37.91605, 'eta': 2275.08002, 'eta_hours': 0.63197, 'loss': 0.1120889, 'lr': 0.00096812, 'params': 197319, 'time_iter': 0.10165, 'accuracy': 0.97464, 'f1': 0.97466, 'auc': 0.9979}\n",
      "val: {'epoch': 13, 'time_epoch': 2.19395, 'loss': 0.20569216, 'lr': 0, 'params': 197319, 'time_iter': 0.04668, 'accuracy': 0.95161, 'f1': 0.95261, 'auc': 0.99423}\n",
      "test: {'epoch': 13, 'time_epoch': 2.28319, 'loss': 0.16330499, 'lr': 0, 'params': 197319, 'time_iter': 0.04858, 'accuracy': 0.9557, 'f1': 0.95453, 'auc': 0.99859}\n",
      "> Epoch 13: took 42.5s (avg 42.1s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 14, 'time_epoch': 36.86683, 'eta': 2236.06537, 'eta_hours': 0.62113, 'loss': 0.09669983, 'lr': 0.00095976, 'params': 197319, 'time_iter': 0.09884, 'accuracy': 0.97682, 'f1': 0.97676, 'auc': 0.99822}\n",
      "val: {'epoch': 14, 'time_epoch': 2.38662, 'loss': 0.21885862, 'lr': 0, 'params': 197319, 'time_iter': 0.05078, 'accuracy': 0.95296, 'f1': 0.95457, 'auc': 0.99299}\n",
      "test: {'epoch': 14, 'time_epoch': 2.27696, 'loss': 0.16022056, 'lr': 0, 'params': 197319, 'time_iter': 0.04845, 'accuracy': 0.9557, 'f1': 0.95509, 'auc': 0.99831}\n",
      "> Epoch 14: took 41.6s (avg 42.1s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 15, 'time_epoch': 36.46085, 'eta': 2195.82214, 'eta_hours': 0.60995, 'loss': 0.08147047, 'lr': 0.00095048, 'params': 197319, 'time_iter': 0.09775, 'accuracy': 0.98085, 'f1': 0.98084, 'auc': 0.9988}\n",
      "val: {'epoch': 15, 'time_epoch': 2.24137, 'loss': 0.26363921, 'lr': 0, 'params': 197319, 'time_iter': 0.04769, 'accuracy': 0.93414, 'f1': 0.93554, 'auc': 0.99479}\n",
      "test: {'epoch': 15, 'time_epoch': 2.25171, 'loss': 0.1941362, 'lr': 0, 'params': 197319, 'time_iter': 0.04791, 'accuracy': 0.9557, 'f1': 0.95564, 'auc': 0.99505}\n",
      "> Epoch 15: took 41.0s (avg 42.0s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 16, 'time_epoch': 36.83759, 'eta': 2157.30924, 'eta_hours': 0.59925, 'loss': 0.0834269, 'lr': 0.0009403, 'params': 197319, 'time_iter': 0.09876, 'accuracy': 0.97917, 'f1': 0.97912, 'auc': 0.99857}\n",
      "val: {'epoch': 16, 'time_epoch': 2.26422, 'loss': 0.22419365, 'lr': 0, 'params': 197319, 'time_iter': 0.04817, 'accuracy': 0.94758, 'f1': 0.94906, 'auc': 0.99558}\n",
      "test: {'epoch': 16, 'time_epoch': 2.25161, 'loss': 0.20135381, 'lr': 0, 'params': 197319, 'time_iter': 0.04791, 'accuracy': 0.94228, 'f1': 0.94306, 'auc': 0.99724}\n",
      "> Epoch 16: took 41.4s (avg 42.0s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 17, 'time_epoch': 37.11113, 'eta': 2119.84871, 'eta_hours': 0.58885, 'loss': 0.0729379, 'lr': 0.00092922, 'params': 197319, 'time_iter': 0.09949, 'accuracy': 0.98119, 'f1': 0.98121, 'auc': 0.99911}\n",
      "val: {'epoch': 17, 'time_epoch': 2.30308, 'loss': 0.32470354, 'lr': 0, 'params': 197319, 'time_iter': 0.049, 'accuracy': 0.92876, 'f1': 0.9301, 'auc': 0.99211}\n",
      "test: {'epoch': 17, 'time_epoch': 2.404, 'loss': 0.21483614, 'lr': 0, 'params': 197319, 'time_iter': 0.05115, 'accuracy': 0.95436, 'f1': 0.95488, 'auc': 0.99359}\n",
      "> Epoch 17: took 41.9s (avg 42.0s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 18, 'time_epoch': 38.57827, 'eta': 2086.74914, 'eta_hours': 0.57965, 'loss': 0.06407137, 'lr': 0.00091729, 'params': 197319, 'time_iter': 0.10343, 'accuracy': 0.98505, 'f1': 0.98508, 'auc': 0.99892}\n",
      "val: {'epoch': 18, 'time_epoch': 2.66215, 'loss': 0.23908304, 'lr': 0, 'params': 197319, 'time_iter': 0.05664, 'accuracy': 0.94624, 'f1': 0.94741, 'auc': 0.99343}\n",
      "test: {'epoch': 18, 'time_epoch': 2.70054, 'loss': 0.21808846, 'lr': 0, 'params': 197319, 'time_iter': 0.05746, 'accuracy': 0.9557, 'f1': 0.95454, 'auc': 0.99302}\n",
      "> Epoch 18: took 44.0s (avg 42.1s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 19, 'time_epoch': 36.56515, 'eta': 2047.56565, 'eta_hours': 0.56877, 'loss': 0.06380842, 'lr': 0.00090451, 'params': 197319, 'time_iter': 0.09803, 'accuracy': 0.9827, 'f1': 0.98272, 'auc': 0.99933}\n",
      "val: {'epoch': 19, 'time_epoch': 2.24943, 'loss': 0.19212592, 'lr': 0, 'params': 197319, 'time_iter': 0.04786, 'accuracy': 0.95565, 'f1': 0.95683, 'auc': 0.99624}\n",
      "test: {'epoch': 19, 'time_epoch': 2.31386, 'loss': 0.15749278, 'lr': 0, 'params': 197319, 'time_iter': 0.04923, 'accuracy': 0.95839, 'f1': 0.95829, 'auc': 0.99775}\n",
      "> Epoch 19: took 41.2s (avg 42.0s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 20, 'time_epoch': 37.554, 'eta': 2011.17426, 'eta_hours': 0.55866, 'loss': 0.0571492, 'lr': 0.00089092, 'params': 197319, 'time_iter': 0.10068, 'accuracy': 0.9864, 'f1': 0.98639, 'auc': 0.99961}\n",
      "val: {'epoch': 20, 'time_epoch': 2.2505, 'loss': 0.25085276, 'lr': 0, 'params': 197319, 'time_iter': 0.04788, 'accuracy': 0.9422, 'f1': 0.94278, 'auc': 0.99337}\n",
      "test: {'epoch': 20, 'time_epoch': 2.89158, 'loss': 0.23359173, 'lr': 0, 'params': 197319, 'time_iter': 0.06152, 'accuracy': 0.94765, 'f1': 0.94574, 'auc': 0.99525}\n",
      "> Epoch 20: took 42.8s (avg 42.1s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 21, 'time_epoch': 37.3938, 'eta': 1974.29124, 'eta_hours': 0.54841, 'loss': 0.03259234, 'lr': 0.00087654, 'params': 197319, 'time_iter': 0.10025, 'accuracy': 0.99244, 'f1': 0.99243, 'auc': 0.99955}\n",
      "val: {'epoch': 21, 'time_epoch': 2.25439, 'loss': 0.21513194, 'lr': 0, 'params': 197319, 'time_iter': 0.04797, 'accuracy': 0.95833, 'f1': 0.95933, 'auc': 0.99478}\n",
      "test: {'epoch': 21, 'time_epoch': 2.21045, 'loss': 0.19690278, 'lr': 0, 'params': 197319, 'time_iter': 0.04703, 'accuracy': 0.96107, 'f1': 0.96058, 'auc': 0.99562}\n",
      "> Epoch 21: took 41.9s (avg 42.1s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 22, 'time_epoch': 36.06467, 'eta': 1934.35883, 'eta_hours': 0.53732, 'loss': 0.04512834, 'lr': 0.0008614, 'params': 197319, 'time_iter': 0.09669, 'accuracy': 0.99043, 'f1': 0.99044, 'auc': 0.99947}\n",
      "val: {'epoch': 22, 'time_epoch': 2.39015, 'loss': 0.27006354, 'lr': 0, 'params': 197319, 'time_iter': 0.05085, 'accuracy': 0.93952, 'f1': 0.94152, 'auc': 0.99581}\n",
      "test: {'epoch': 22, 'time_epoch': 2.28462, 'loss': 0.20746661, 'lr': 0, 'params': 197319, 'time_iter': 0.04861, 'accuracy': 0.9557, 'f1': 0.95423, 'auc': 0.99613}\n",
      "> Epoch 22: took 40.8s (avg 42.0s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 23, 'time_epoch': 37.09644, 'eta': 1896.94124, 'eta_hours': 0.52693, 'loss': 0.04763409, 'lr': 0.00084553, 'params': 197319, 'time_iter': 0.09945, 'accuracy': 0.98858, 'f1': 0.98859, 'auc': 0.99947}\n",
      "val: {'epoch': 23, 'time_epoch': 2.23249, 'loss': 0.26361987, 'lr': 0, 'params': 197319, 'time_iter': 0.0475, 'accuracy': 0.94892, 'f1': 0.95082, 'auc': 0.99505}\n",
      "test: {'epoch': 23, 'time_epoch': 2.27295, 'loss': 0.19969792, 'lr': 0, 'params': 197319, 'time_iter': 0.04836, 'accuracy': 0.95839, 'f1': 0.95725, 'auc': 0.99548}\n",
      "> Epoch 23: took 41.7s (avg 42.0s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 24, 'time_epoch': 37.1588, 'eta': 1859.67407, 'eta_hours': 0.51658, 'loss': 0.04314658, 'lr': 0.00082897, 'params': 197319, 'time_iter': 0.09962, 'accuracy': 0.99076, 'f1': 0.99078, 'auc': 0.99926}\n",
      "val: {'epoch': 24, 'time_epoch': 2.33986, 'loss': 0.25078703, 'lr': 0, 'params': 197319, 'time_iter': 0.04978, 'accuracy': 0.94758, 'f1': 0.94882, 'auc': 0.99514}\n",
      "test: {'epoch': 24, 'time_epoch': 2.36015, 'loss': 0.21151324, 'lr': 0, 'params': 197319, 'time_iter': 0.05022, 'accuracy': 0.95436, 'f1': 0.95397, 'auc': 0.99638}\n",
      "> Epoch 24: took 41.9s (avg 42.0s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 25, 'time_epoch': 38.21772, 'eta': 1824.41089, 'eta_hours': 0.50678, 'loss': 0.0473025, 'lr': 0.00081174, 'params': 197319, 'time_iter': 0.10246, 'accuracy': 0.98774, 'f1': 0.98775, 'auc': 0.99968}\n",
      "val: {'epoch': 25, 'time_epoch': 2.39772, 'loss': 0.21585266, 'lr': 0, 'params': 197319, 'time_iter': 0.05102, 'accuracy': 0.95296, 'f1': 0.95377, 'auc': 0.99334}\n",
      "test: {'epoch': 25, 'time_epoch': 2.69715, 'loss': 0.18999094, 'lr': 0, 'params': 197319, 'time_iter': 0.05739, 'accuracy': 0.95839, 'f1': 0.95716, 'auc': 0.99582}\n",
      "> Epoch 25: took 43.4s (avg 42.0s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 26, 'time_epoch': 37.9055, 'eta': 1788.3738, 'eta_hours': 0.49677, 'loss': 0.03077182, 'lr': 0.00079389, 'params': 197319, 'time_iter': 0.10162, 'accuracy': 0.99227, 'f1': 0.99228, 'auc': 0.99972}\n",
      "val: {'epoch': 26, 'time_epoch': 2.36455, 'loss': 0.20795702, 'lr': 0, 'params': 197319, 'time_iter': 0.05031, 'accuracy': 0.95968, 'f1': 0.96071, 'auc': 0.99648}\n",
      "test: {'epoch': 26, 'time_epoch': 2.37495, 'loss': 0.17874896, 'lr': 0, 'params': 197319, 'time_iter': 0.05053, 'accuracy': 0.96644, 'f1': 0.96655, 'auc': 0.99747}\n",
      "> Epoch 26: took 42.7s (avg 42.1s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 27, 'time_epoch': 37.54044, 'eta': 1751.59047, 'eta_hours': 0.48655, 'loss': 0.03069018, 'lr': 0.00077545, 'params': 197319, 'time_iter': 0.10064, 'accuracy': 0.99194, 'f1': 0.99196, 'auc': 0.99982}\n",
      "val: {'epoch': 27, 'time_epoch': 2.39775, 'loss': 0.23330533, 'lr': 0, 'params': 197319, 'time_iter': 0.05102, 'accuracy': 0.95027, 'f1': 0.95141, 'auc': 0.99539}\n",
      "test: {'epoch': 27, 'time_epoch': 2.30096, 'loss': 0.19046641, 'lr': 0, 'params': 197319, 'time_iter': 0.04896, 'accuracy': 0.95839, 'f1': 0.95771, 'auc': 0.99644}\n",
      "> Epoch 27: took 42.3s (avg 42.1s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 28, 'time_epoch': 39.59675, 'eta': 1718.01665, 'eta_hours': 0.47723, 'loss': 0.03322327, 'lr': 0.00075645, 'params': 197319, 'time_iter': 0.10616, 'accuracy': 0.99143, 'f1': 0.99141, 'auc': 0.9996}\n",
      "val: {'epoch': 28, 'time_epoch': 2.56335, 'loss': 0.2322724, 'lr': 0, 'params': 197319, 'time_iter': 0.05454, 'accuracy': 0.95565, 'f1': 0.9565, 'auc': 0.99451}\n",
      "test: {'epoch': 28, 'time_epoch': 2.71635, 'loss': 0.21684442, 'lr': 0, 'params': 197319, 'time_iter': 0.05779, 'accuracy': 0.96107, 'f1': 0.95896, 'auc': 0.99538}\n",
      "> Epoch 28: took 45.0s (avg 42.2s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 29, 'time_epoch': 38.42624, 'eta': 1682.28554, 'eta_hours': 0.4673, 'loss': 0.04471561, 'lr': 0.00073693, 'params': 197319, 'time_iter': 0.10302, 'accuracy': 0.98925, 'f1': 0.98924, 'auc': 0.9995}\n",
      "val: {'epoch': 29, 'time_epoch': 2.26704, 'loss': 0.25833399, 'lr': 0, 'params': 197319, 'time_iter': 0.04823, 'accuracy': 0.94758, 'f1': 0.94874, 'auc': 0.99655}\n",
      "test: {'epoch': 29, 'time_epoch': 2.36353, 'loss': 0.199998, 'lr': 0, 'params': 197319, 'time_iter': 0.05029, 'accuracy': 0.96107, 'f1': 0.96099, 'auc': 0.99685}\n",
      "> Epoch 29: took 43.1s (avg 42.2s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 30, 'time_epoch': 38.95651, 'eta': 1647.1332, 'eta_hours': 0.45754, 'loss': 0.03017309, 'lr': 0.00071694, 'params': 197319, 'time_iter': 0.10444, 'accuracy': 0.99261, 'f1': 0.99257, 'auc': 0.99973}\n",
      "val: {'epoch': 30, 'time_epoch': 2.55029, 'loss': 0.21410101, 'lr': 0, 'params': 197319, 'time_iter': 0.05426, 'accuracy': 0.95968, 'f1': 0.96085, 'auc': 0.99654}\n",
      "test: {'epoch': 30, 'time_epoch': 2.37686, 'loss': 0.15957448, 'lr': 0, 'params': 197319, 'time_iter': 0.05057, 'accuracy': 0.96376, 'f1': 0.96324, 'auc': 0.99631}\n",
      "> Epoch 30: took 44.0s (avg 42.3s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 31, 'time_epoch': 40.91498, 'eta': 1614.37479, 'eta_hours': 0.44844, 'loss': 0.01902769, 'lr': 0.00069651, 'params': 197319, 'time_iter': 0.10969, 'accuracy': 0.9953, 'f1': 0.9953, 'auc': 0.9999}\n",
      "val: {'epoch': 31, 'time_epoch': 2.43233, 'loss': 0.23326046, 'lr': 0, 'params': 197319, 'time_iter': 0.05175, 'accuracy': 0.95565, 'f1': 0.95679, 'auc': 0.99528}\n",
      "test: {'epoch': 31, 'time_epoch': 2.69777, 'loss': 0.21159897, 'lr': 0, 'params': 197319, 'time_iter': 0.0574, 'accuracy': 0.96107, 'f1': 0.96079, 'auc': 0.99513}\n",
      "> Epoch 31: took 46.1s (avg 42.4s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 32, 'time_epoch': 42.32434, 'eta': 1582.91577, 'eta_hours': 0.4397, 'loss': 0.02562241, 'lr': 0.00067569, 'params': 197319, 'time_iter': 0.11347, 'accuracy': 0.99395, 'f1': 0.99396, 'auc': 0.99984}\n",
      "val: {'epoch': 32, 'time_epoch': 2.67122, 'loss': 0.24884716, 'lr': 0, 'params': 197319, 'time_iter': 0.05683, 'accuracy': 0.95699, 'f1': 0.95825, 'auc': 0.99558}\n",
      "test: {'epoch': 32, 'time_epoch': 3.26418, 'loss': 0.17740285, 'lr': 0, 'params': 197319, 'time_iter': 0.06945, 'accuracy': 0.96242, 'f1': 0.96207, 'auc': 0.99782}\n",
      "> Epoch 32: took 48.4s (avg 42.6s) | Best so far: epoch 7\ttrain_loss: 0.2487 train_accuracy: 0.9530\tval_loss: 0.2102 val_accuracy: 0.9597\ttest_loss: 0.2078 test_accuracy: 0.9624\n",
      "train: {'epoch': 33, 'time_epoch': 43.028, 'eta': 1551.66613, 'eta_hours': 0.43102, 'loss': 0.01080028, 'lr': 0.00065451, 'params': 197319, 'time_iter': 0.11536, 'accuracy': 0.99798, 'f1': 0.99795, 'auc': 0.99998}\n",
      "val: {'epoch': 33, 'time_epoch': 3.33985, 'loss': 0.22041103, 'lr': 0, 'params': 197319, 'time_iter': 0.07106, 'accuracy': 0.96237, 'f1': 0.96299, 'auc': 0.99715}\n",
      "test: {'epoch': 33, 'time_epoch': 2.9791, 'loss': 0.25756282, 'lr': 0, 'params': 197319, 'time_iter': 0.06339, 'accuracy': 0.9557, 'f1': 0.95576, 'auc': 0.99556}\n",
      "> Epoch 33: took 49.4s (avg 42.8s) | Best so far: epoch 33\ttrain_loss: 0.0108 train_accuracy: 0.9980\tval_loss: 0.2204 val_accuracy: 0.9624\ttest_loss: 0.2576 test_accuracy: 0.9557\n",
      "train: {'epoch': 34, 'time_epoch': 39.56481, 'eta': 1515.78553, 'eta_hours': 0.42105, 'loss': 0.02038857, 'lr': 0.00063302, 'params': 197319, 'time_iter': 0.10607, 'accuracy': 0.99563, 'f1': 0.99559, 'auc': 0.99989}\n",
      "val: {'epoch': 34, 'time_epoch': 2.25657, 'loss': 0.18983885, 'lr': 0, 'params': 197319, 'time_iter': 0.04801, 'accuracy': 0.96909, 'f1': 0.96992, 'auc': 0.99648}\n",
      "test: {'epoch': 34, 'time_epoch': 2.2912, 'loss': 0.19032046, 'lr': 0, 'params': 197319, 'time_iter': 0.04875, 'accuracy': 0.96376, 'f1': 0.96367, 'auc': 0.9981}\n",
      "> Epoch 34: took 44.2s (avg 42.8s) | Best so far: epoch 34\ttrain_loss: 0.0204 train_accuracy: 0.9956\tval_loss: 0.1898 val_accuracy: 0.9691\ttest_loss: 0.1903 test_accuracy: 0.9638\n",
      "train: {'epoch': 35, 'time_epoch': 38.47996, 'eta': 1478.52499, 'eta_hours': 0.4107, 'loss': 0.01644028, 'lr': 0.00061126, 'params': 197319, 'time_iter': 0.10316, 'accuracy': 0.99664, 'f1': 0.99665, 'auc': 0.99994}\n",
      "val: {'epoch': 35, 'time_epoch': 2.51154, 'loss': 0.23716713, 'lr': 0, 'params': 197319, 'time_iter': 0.05344, 'accuracy': 0.95968, 'f1': 0.96064, 'auc': 0.99539}\n",
      "test: {'epoch': 35, 'time_epoch': 2.48668, 'loss': 0.20603854, 'lr': 0, 'params': 197319, 'time_iter': 0.05291, 'accuracy': 0.96242, 'f1': 0.96173, 'auc': 0.99723}\n",
      "> Epoch 35: took 43.6s (avg 42.8s) | Best so far: epoch 34\ttrain_loss: 0.0204 train_accuracy: 0.9956\tval_loss: 0.1898 val_accuracy: 0.9691\ttest_loss: 0.1903 test_accuracy: 0.9638\n",
      "train: {'epoch': 36, 'time_epoch': 38.63782, 'eta': 1441.36066, 'eta_hours': 0.40038, 'loss': 0.02822812, 'lr': 0.00058928, 'params': 197319, 'time_iter': 0.10359, 'accuracy': 0.99311, 'f1': 0.99311, 'auc': 0.99977}\n",
      "val: {'epoch': 36, 'time_epoch': 2.90338, 'loss': 0.32516418, 'lr': 0, 'params': 197319, 'time_iter': 0.06177, 'accuracy': 0.94086, 'f1': 0.94339, 'auc': 0.99405}\n",
      "test: {'epoch': 36, 'time_epoch': 2.78823, 'loss': 0.2419473, 'lr': 0, 'params': 197319, 'time_iter': 0.05932, 'accuracy': 0.95973, 'f1': 0.95832, 'auc': 0.99521}\n",
      "> Epoch 36: took 44.4s (avg 42.9s) | Best so far: epoch 34\ttrain_loss: 0.0204 train_accuracy: 0.9956\tval_loss: 0.1898 val_accuracy: 0.9691\ttest_loss: 0.1903 test_accuracy: 0.9638\n",
      "train: {'epoch': 37, 'time_epoch': 38.16704, 'eta': 1403.66039, 'eta_hours': 0.38991, 'loss': 0.01860421, 'lr': 0.00056712, 'params': 197319, 'time_iter': 0.10232, 'accuracy': 0.99496, 'f1': 0.99496, 'auc': 0.99991}\n",
      "val: {'epoch': 37, 'time_epoch': 2.31412, 'loss': 0.22712842, 'lr': 0, 'params': 197319, 'time_iter': 0.04924, 'accuracy': 0.95968, 'f1': 0.96068, 'auc': 0.99618}\n",
      "test: {'epoch': 37, 'time_epoch': 2.28177, 'loss': 0.21194231, 'lr': 0, 'params': 197319, 'time_iter': 0.04855, 'accuracy': 0.95973, 'f1': 0.95915, 'auc': 0.99697}\n",
      "> Epoch 37: took 42.9s (avg 42.9s) | Best so far: epoch 34\ttrain_loss: 0.0204 train_accuracy: 0.9956\tval_loss: 0.1898 val_accuracy: 0.9691\ttest_loss: 0.1903 test_accuracy: 0.9638\n",
      "train: {'epoch': 38, 'time_epoch': 37.47777, 'eta': 1365.29994, 'eta_hours': 0.37925, 'loss': 0.01797924, 'lr': 0.00054482, 'params': 197319, 'time_iter': 0.10048, 'accuracy': 0.99614, 'f1': 0.99611, 'auc': 0.99984}\n",
      "val: {'epoch': 38, 'time_epoch': 2.30751, 'loss': 0.16699083, 'lr': 0, 'params': 197319, 'time_iter': 0.0491, 'accuracy': 0.97043, 'f1': 0.97124, 'auc': 0.99792}\n",
      "test: {'epoch': 38, 'time_epoch': 2.33199, 'loss': 0.16938453, 'lr': 0, 'params': 197319, 'time_iter': 0.04962, 'accuracy': 0.97315, 'f1': 0.97215, 'auc': 0.99758}\n",
      "> Epoch 38: took 42.2s (avg 42.9s) | Best so far: epoch 38\ttrain_loss: 0.0180 train_accuracy: 0.9961\tval_loss: 0.1670 val_accuracy: 0.9704\ttest_loss: 0.1694 test_accuracy: 0.9731\n",
      "train: {'epoch': 39, 'time_epoch': 38.55771, 'eta': 1327.92856, 'eta_hours': 0.36887, 'loss': 0.01188248, 'lr': 0.00052243, 'params': 197319, 'time_iter': 0.10337, 'accuracy': 0.99748, 'f1': 0.99746, 'auc': 0.99995}\n",
      "val: {'epoch': 39, 'time_epoch': 2.28506, 'loss': 0.22362723, 'lr': 0, 'params': 197319, 'time_iter': 0.04862, 'accuracy': 0.95968, 'f1': 0.96035, 'auc': 0.99639}\n",
      "test: {'epoch': 39, 'time_epoch': 2.43933, 'loss': 0.21205113, 'lr': 0, 'params': 197319, 'time_iter': 0.0519, 'accuracy': 0.96913, 'f1': 0.96864, 'auc': 0.99408}\n",
      "> Epoch 39: took 43.4s (avg 42.9s) | Best so far: epoch 38\ttrain_loss: 0.0180 train_accuracy: 0.9961\tval_loss: 0.1670 val_accuracy: 0.9704\ttest_loss: 0.1694 test_accuracy: 0.9731\n",
      "train: {'epoch': 40, 'time_epoch': 37.37685, 'eta': 1289.52006, 'eta_hours': 0.3582, 'loss': 0.01182968, 'lr': 0.0005, 'params': 197319, 'time_iter': 0.10021, 'accuracy': 0.99714, 'f1': 0.99715, 'auc': 0.99999}\n",
      "val: {'epoch': 40, 'time_epoch': 2.29829, 'loss': 0.22744748, 'lr': 0, 'params': 197319, 'time_iter': 0.0489, 'accuracy': 0.96371, 'f1': 0.96443, 'auc': 0.9949}\n",
      "test: {'epoch': 40, 'time_epoch': 2.24441, 'loss': 0.22565301, 'lr': 0, 'params': 197319, 'time_iter': 0.04775, 'accuracy': 0.96242, 'f1': 0.96147, 'auc': 0.99777}\n",
      "> Epoch 40: took 42.0s (avg 42.8s) | Best so far: epoch 38\ttrain_loss: 0.0180 train_accuracy: 0.9961\tval_loss: 0.1670 val_accuracy: 0.9704\ttest_loss: 0.1694 test_accuracy: 0.9731\n",
      "train: {'epoch': 41, 'time_epoch': 37.08823, 'eta': 1250.93392, 'eta_hours': 0.34748, 'loss': 0.00744539, 'lr': 0.00047757, 'params': 197319, 'time_iter': 0.09943, 'accuracy': 0.99832, 'f1': 0.99832, 'auc': 0.99989}\n",
      "val: {'epoch': 41, 'time_epoch': 2.59534, 'loss': 0.25808272, 'lr': 0, 'params': 197319, 'time_iter': 0.05522, 'accuracy': 0.96237, 'f1': 0.96317, 'auc': 0.99644}\n",
      "test: {'epoch': 41, 'time_epoch': 2.36221, 'loss': 0.21530976, 'lr': 0, 'params': 197319, 'time_iter': 0.05026, 'accuracy': 0.96644, 'f1': 0.96569, 'auc': 0.99649}\n",
      "> Epoch 41: took 42.1s (avg 42.8s) | Best so far: epoch 38\ttrain_loss: 0.0180 train_accuracy: 0.9961\tval_loss: 0.1670 val_accuracy: 0.9704\ttest_loss: 0.1694 test_accuracy: 0.9731\n",
      "train: {'epoch': 42, 'time_epoch': 37.32259, 'eta': 1212.59186, 'eta_hours': 0.33683, 'loss': 0.0084056, 'lr': 0.00045518, 'params': 197319, 'time_iter': 0.10006, 'accuracy': 0.99748, 'f1': 0.99749, 'auc': 0.99999}\n",
      "val: {'epoch': 42, 'time_epoch': 2.22495, 'loss': 0.2322561, 'lr': 0, 'params': 197319, 'time_iter': 0.04734, 'accuracy': 0.96237, 'f1': 0.96308, 'auc': 0.99698}\n",
      "test: {'epoch': 42, 'time_epoch': 2.24276, 'loss': 0.21005251, 'lr': 0, 'params': 197319, 'time_iter': 0.04772, 'accuracy': 0.96644, 'f1': 0.96577, 'auc': 0.99709}\n",
      "> Epoch 42: took 41.9s (avg 42.8s) | Best so far: epoch 38\ttrain_loss: 0.0180 train_accuracy: 0.9961\tval_loss: 0.1670 val_accuracy: 0.9704\ttest_loss: 0.1694 test_accuracy: 0.9731\n",
      "train: {'epoch': 43, 'time_epoch': 36.59159, 'eta': 1173.78111, 'eta_hours': 0.32605, 'loss': 0.00511222, 'lr': 0.00043288, 'params': 197319, 'time_iter': 0.0981, 'accuracy': 0.99866, 'f1': 0.99865, 'auc': 1.0}\n",
      "val: {'epoch': 43, 'time_epoch': 2.34136, 'loss': 0.27087447, 'lr': 0, 'params': 197319, 'time_iter': 0.04982, 'accuracy': 0.95699, 'f1': 0.9581, 'auc': 0.99675}\n",
      "test: {'epoch': 43, 'time_epoch': 2.31533, 'loss': 0.19930564, 'lr': 0, 'params': 197319, 'time_iter': 0.04926, 'accuracy': 0.97047, 'f1': 0.97025, 'auc': 0.99509}\n",
      "> Epoch 43: took 41.3s (avg 42.8s) | Best so far: epoch 38\ttrain_loss: 0.0180 train_accuracy: 0.9961\tval_loss: 0.1670 val_accuracy: 0.9704\ttest_loss: 0.1694 test_accuracy: 0.9731\n",
      "train: {'epoch': 44, 'time_epoch': 36.62106, 'eta': 1135.08864, 'eta_hours': 0.3153, 'loss': 0.00979338, 'lr': 0.00041072, 'params': 197319, 'time_iter': 0.09818, 'accuracy': 0.99765, 'f1': 0.99765, 'auc': 0.99992}\n",
      "val: {'epoch': 44, 'time_epoch': 2.23234, 'loss': 0.25518659, 'lr': 0, 'params': 197319, 'time_iter': 0.0475, 'accuracy': 0.95968, 'f1': 0.96066, 'auc': 0.99543}\n",
      "test: {'epoch': 44, 'time_epoch': 2.48688, 'loss': 0.22457046, 'lr': 0, 'params': 197319, 'time_iter': 0.05291, 'accuracy': 0.96376, 'f1': 0.96287, 'auc': 0.99631}\n",
      "> Epoch 44: took 41.4s (avg 42.7s) | Best so far: epoch 38\ttrain_loss: 0.0180 train_accuracy: 0.9961\tval_loss: 0.1670 val_accuracy: 0.9704\ttest_loss: 0.1694 test_accuracy: 0.9731\n",
      "train: {'epoch': 45, 'time_epoch': 37.00948, 'eta': 1096.7311, 'eta_hours': 0.30465, 'loss': 0.00748672, 'lr': 0.00038874, 'params': 197319, 'time_iter': 0.09922, 'accuracy': 0.99782, 'f1': 0.99782, 'auc': 0.99999}\n",
      "val: {'epoch': 45, 'time_epoch': 2.42687, 'loss': 0.25614421, 'lr': 0, 'params': 197319, 'time_iter': 0.05164, 'accuracy': 0.95699, 'f1': 0.95791, 'auc': 0.99595}\n",
      "test: {'epoch': 45, 'time_epoch': 2.40129, 'loss': 0.21471686, 'lr': 0, 'params': 197319, 'time_iter': 0.05109, 'accuracy': 0.96376, 'f1': 0.96319, 'auc': 0.99644}\n",
      "> Epoch 45: took 41.9s (avg 42.7s) | Best so far: epoch 38\ttrain_loss: 0.0180 train_accuracy: 0.9961\tval_loss: 0.1670 val_accuracy: 0.9704\ttest_loss: 0.1694 test_accuracy: 0.9731\n",
      "train: {'epoch': 46, 'time_epoch': 36.90802, 'eta': 1058.37048, 'eta_hours': 0.29399, 'loss': 0.00953853, 'lr': 0.00036698, 'params': 197319, 'time_iter': 0.09895, 'accuracy': 0.99815, 'f1': 0.99815, 'auc': 0.99994}\n",
      "val: {'epoch': 46, 'time_epoch': 2.43294, 'loss': 0.18676125, 'lr': 0, 'params': 197319, 'time_iter': 0.05176, 'accuracy': 0.97177, 'f1': 0.97235, 'auc': 0.99636}\n",
      "test: {'epoch': 46, 'time_epoch': 2.26942, 'loss': 0.22083267, 'lr': 0, 'params': 197319, 'time_iter': 0.04829, 'accuracy': 0.96644, 'f1': 0.96583, 'auc': 0.99851}\n",
      "> Epoch 46: took 41.7s (avg 42.7s) | Best so far: epoch 46\ttrain_loss: 0.0095 train_accuracy: 0.9981\tval_loss: 0.1868 val_accuracy: 0.9718\ttest_loss: 0.2208 test_accuracy: 0.9664\n",
      "train: {'epoch': 47, 'time_epoch': 37.16077, 'eta': 1020.21256, 'eta_hours': 0.28339, 'loss': 0.00473687, 'lr': 0.00034549, 'params': 197319, 'time_iter': 0.09963, 'accuracy': 0.99933, 'f1': 0.99933, 'auc': 0.99991}\n",
      "val: {'epoch': 47, 'time_epoch': 2.30563, 'loss': 0.23058763, 'lr': 0, 'params': 197319, 'time_iter': 0.04906, 'accuracy': 0.96371, 'f1': 0.96463, 'auc': 0.99671}\n",
      "test: {'epoch': 47, 'time_epoch': 2.26823, 'loss': 0.20811139, 'lr': 0, 'params': 197319, 'time_iter': 0.04826, 'accuracy': 0.96913, 'f1': 0.96825, 'auc': 0.99805}\n",
      "> Epoch 47: took 41.8s (avg 42.7s) | Best so far: epoch 46\ttrain_loss: 0.0095 train_accuracy: 0.9981\tval_loss: 0.1868 val_accuracy: 0.9718\ttest_loss: 0.2208 test_accuracy: 0.9664\n",
      "train: {'epoch': 48, 'time_epoch': 37.25495, 'eta': 982.14532, 'eta_hours': 0.27282, 'loss': 0.00450731, 'lr': 0.00032431, 'params': 197319, 'time_iter': 0.09988, 'accuracy': 0.99882, 'f1': 0.99881, 'auc': 1.0}\n",
      "val: {'epoch': 48, 'time_epoch': 2.1972, 'loss': 0.23533068, 'lr': 0, 'params': 197319, 'time_iter': 0.04675, 'accuracy': 0.96505, 'f1': 0.96608, 'auc': 0.99611}\n",
      "test: {'epoch': 48, 'time_epoch': 2.24455, 'loss': 0.26732343, 'lr': 0, 'params': 197319, 'time_iter': 0.04776, 'accuracy': 0.9557, 'f1': 0.95654, 'auc': 0.99699}\n",
      "> Epoch 48: took 41.8s (avg 42.7s) | Best so far: epoch 46\ttrain_loss: 0.0095 train_accuracy: 0.9981\tval_loss: 0.1868 val_accuracy: 0.9718\ttest_loss: 0.2208 test_accuracy: 0.9664\n",
      "train: {'epoch': 49, 'time_epoch': 36.698, 'eta': 943.83209, 'eta_hours': 0.26218, 'loss': 0.0062268, 'lr': 0.00030349, 'params': 197319, 'time_iter': 0.09839, 'accuracy': 0.99866, 'f1': 0.99867, 'auc': 0.99998}\n",
      "val: {'epoch': 49, 'time_epoch': 2.24001, 'loss': 0.24345291, 'lr': 0, 'params': 197319, 'time_iter': 0.04766, 'accuracy': 0.96774, 'f1': 0.96874, 'auc': 0.99644}\n",
      "test: {'epoch': 49, 'time_epoch': 2.58715, 'loss': 0.22901329, 'lr': 0, 'params': 197319, 'time_iter': 0.05505, 'accuracy': 0.96644, 'f1': 0.96548, 'auc': 0.99753}\n",
      "> Epoch 49: took 41.6s (avg 42.6s) | Best so far: epoch 46\ttrain_loss: 0.0095 train_accuracy: 0.9981\tval_loss: 0.1868 val_accuracy: 0.9718\ttest_loss: 0.2208 test_accuracy: 0.9664\n",
      "train: {'epoch': 50, 'time_epoch': 36.87831, 'eta': 905.66705, 'eta_hours': 0.25157, 'loss': 0.00187625, 'lr': 0.00028306, 'params': 197319, 'time_iter': 0.09887, 'accuracy': 0.9995, 'f1': 0.9995, 'auc': 1.0}\n",
      "val: {'epoch': 50, 'time_epoch': 2.22244, 'loss': 0.21304448, 'lr': 0, 'params': 197319, 'time_iter': 0.04729, 'accuracy': 0.96774, 'f1': 0.96849, 'auc': 0.99606}\n",
      "test: {'epoch': 50, 'time_epoch': 2.25631, 'loss': 0.19979559, 'lr': 0, 'params': 197319, 'time_iter': 0.04801, 'accuracy': 0.97181, 'f1': 0.97105, 'auc': 0.99732}\n",
      "> Epoch 50: took 41.4s (avg 42.6s) | Best so far: epoch 46\ttrain_loss: 0.0095 train_accuracy: 0.9981\tval_loss: 0.1868 val_accuracy: 0.9718\ttest_loss: 0.2208 test_accuracy: 0.9664\n",
      "train: {'epoch': 51, 'time_epoch': 37.37549, 'eta': 867.77141, 'eta_hours': 0.24105, 'loss': 0.00411783, 'lr': 0.00026307, 'params': 197319, 'time_iter': 0.1002, 'accuracy': 0.99933, 'f1': 0.99931, 'auc': 0.99998}\n",
      "val: {'epoch': 51, 'time_epoch': 2.37094, 'loss': 0.23017687, 'lr': 0, 'params': 197319, 'time_iter': 0.05045, 'accuracy': 0.97043, 'f1': 0.97124, 'auc': 0.99673}\n",
      "test: {'epoch': 51, 'time_epoch': 2.34763, 'loss': 0.19451362, 'lr': 0, 'params': 197319, 'time_iter': 0.04995, 'accuracy': 0.97047, 'f1': 0.96938, 'auc': 0.99699}\n",
      "> Epoch 51: took 42.2s (avg 42.6s) | Best so far: epoch 46\ttrain_loss: 0.0095 train_accuracy: 0.9981\tval_loss: 0.1868 val_accuracy: 0.9718\ttest_loss: 0.2208 test_accuracy: 0.9664\n",
      "train: {'epoch': 52, 'time_epoch': 37.0471, 'eta': 829.75909, 'eta_hours': 0.23049, 'loss': 0.00085966, 'lr': 0.00024355, 'params': 197319, 'time_iter': 0.09932, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 52, 'time_epoch': 2.25043, 'loss': 0.20891894, 'lr': 0, 'params': 197319, 'time_iter': 0.04788, 'accuracy': 0.97043, 'f1': 0.97121, 'auc': 0.99785}\n",
      "test: {'epoch': 52, 'time_epoch': 2.29281, 'loss': 0.20613536, 'lr': 0, 'params': 197319, 'time_iter': 0.04878, 'accuracy': 0.97047, 'f1': 0.96941, 'auc': 0.99801}\n",
      "> Epoch 52: took 41.7s (avg 42.6s) | Best so far: epoch 46\ttrain_loss: 0.0095 train_accuracy: 0.9981\tval_loss: 0.1868 val_accuracy: 0.9718\ttest_loss: 0.2208 test_accuracy: 0.9664\n",
      "train: {'epoch': 53, 'time_epoch': 36.81903, 'eta': 791.69382, 'eta_hours': 0.21991, 'loss': 0.00206104, 'lr': 0.00022455, 'params': 197319, 'time_iter': 0.09871, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "val: {'epoch': 53, 'time_epoch': 2.23699, 'loss': 0.20181482, 'lr': 0, 'params': 197319, 'time_iter': 0.0476, 'accuracy': 0.97043, 'f1': 0.97115, 'auc': 0.99827}\n",
      "test: {'epoch': 53, 'time_epoch': 2.37522, 'loss': 0.20966037, 'lr': 0, 'params': 197319, 'time_iter': 0.05054, 'accuracy': 0.96913, 'f1': 0.96815, 'auc': 0.99722}\n",
      "> Epoch 53: took 41.5s (avg 42.6s) | Best so far: epoch 46\ttrain_loss: 0.0095 train_accuracy: 0.9981\tval_loss: 0.1868 val_accuracy: 0.9718\ttest_loss: 0.2208 test_accuracy: 0.9664\n",
      "train: {'epoch': 54, 'time_epoch': 36.72693, 'eta': 753.64038, 'eta_hours': 0.20934, 'loss': 0.00089996, 'lr': 0.00020611, 'params': 197319, 'time_iter': 0.09846, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 54, 'time_epoch': 2.25495, 'loss': 0.18874861, 'lr': 0, 'params': 197319, 'time_iter': 0.04798, 'accuracy': 0.97446, 'f1': 0.97502, 'auc': 0.99735}\n",
      "test: {'epoch': 54, 'time_epoch': 2.50971, 'loss': 0.23314522, 'lr': 0, 'params': 197319, 'time_iter': 0.0534, 'accuracy': 0.96644, 'f1': 0.96568, 'auc': 0.99769}\n",
      "> Epoch 54: took 41.6s (avg 42.6s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 55, 'time_epoch': 36.64911, 'eta': 715.60791, 'eta_hours': 0.19878, 'loss': 0.00036357, 'lr': 0.00018826, 'params': 197319, 'time_iter': 0.09825, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 55, 'time_epoch': 2.2305, 'loss': 0.21350991, 'lr': 0, 'params': 197319, 'time_iter': 0.04746, 'accuracy': 0.96371, 'f1': 0.96452, 'auc': 0.99802}\n",
      "test: {'epoch': 55, 'time_epoch': 2.30873, 'loss': 0.23171145, 'lr': 0, 'params': 197319, 'time_iter': 0.04912, 'accuracy': 0.96779, 'f1': 0.96651, 'auc': 0.99737}\n",
      "> Epoch 55: took 41.3s (avg 42.5s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 56, 'time_epoch': 37.0761, 'eta': 677.75881, 'eta_hours': 0.18827, 'loss': 0.00179934, 'lr': 0.00017103, 'params': 197319, 'time_iter': 0.0994, 'accuracy': 0.99983, 'f1': 0.99984, 'auc': 1.0}\n",
      "val: {'epoch': 56, 'time_epoch': 2.55562, 'loss': 0.19563799, 'lr': 0, 'params': 197319, 'time_iter': 0.05437, 'accuracy': 0.96909, 'f1': 0.96966, 'auc': 0.9972}\n",
      "test: {'epoch': 56, 'time_epoch': 2.24999, 'loss': 0.21503995, 'lr': 0, 'params': 197319, 'time_iter': 0.04787, 'accuracy': 0.97181, 'f1': 0.97159, 'auc': 0.99639}\n",
      "> Epoch 56: took 42.0s (avg 42.5s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 57, 'time_epoch': 36.92575, 'eta': 639.89231, 'eta_hours': 0.17775, 'loss': 0.00205103, 'lr': 0.00015447, 'params': 197319, 'time_iter': 0.099, 'accuracy': 0.99983, 'f1': 0.99984, 'auc': 0.99986}\n",
      "val: {'epoch': 57, 'time_epoch': 2.18158, 'loss': 0.19702687, 'lr': 0, 'params': 197319, 'time_iter': 0.04642, 'accuracy': 0.97043, 'f1': 0.97103, 'auc': 0.99726}\n",
      "test: {'epoch': 57, 'time_epoch': 2.22809, 'loss': 0.21224154, 'lr': 0, 'params': 197319, 'time_iter': 0.04741, 'accuracy': 0.97181, 'f1': 0.97085, 'auc': 0.99706}\n",
      "> Epoch 57: took 41.4s (avg 42.5s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 58, 'time_epoch': 37.74532, 'eta': 602.27995, 'eta_hours': 0.1673, 'loss': 0.00026348, 'lr': 0.0001386, 'params': 197319, 'time_iter': 0.10119, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 58, 'time_epoch': 2.17946, 'loss': 0.20683817, 'lr': 0, 'params': 197319, 'time_iter': 0.04637, 'accuracy': 0.9664, 'f1': 0.96706, 'auc': 0.9973}\n",
      "test: {'epoch': 58, 'time_epoch': 2.2825, 'loss': 0.20020746, 'lr': 0, 'params': 197319, 'time_iter': 0.04856, 'accuracy': 0.97315, 'f1': 0.97271, 'auc': 0.99721}\n",
      "> Epoch 58: took 42.3s (avg 42.5s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 59, 'time_epoch': 37.42295, 'eta': 564.58256, 'eta_hours': 0.15683, 'loss': 0.00098798, 'lr': 0.00012346, 'params': 197319, 'time_iter': 0.10033, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "val: {'epoch': 59, 'time_epoch': 2.2889, 'loss': 0.2283693, 'lr': 0, 'params': 197319, 'time_iter': 0.0487, 'accuracy': 0.96505, 'f1': 0.96606, 'auc': 0.99708}\n",
      "test: {'epoch': 59, 'time_epoch': 2.25506, 'loss': 0.22200427, 'lr': 0, 'params': 197319, 'time_iter': 0.04798, 'accuracy': 0.96913, 'f1': 0.96822, 'auc': 0.99682}\n",
      "> Epoch 59: took 42.1s (avg 42.5s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 60, 'time_epoch': 36.4976, 'eta': 526.6818, 'eta_hours': 0.1463, 'loss': 0.00023935, 'lr': 0.00010908, 'params': 197319, 'time_iter': 0.09785, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 60, 'time_epoch': 2.20938, 'loss': 0.22416528, 'lr': 0, 'params': 197319, 'time_iter': 0.04701, 'accuracy': 0.96909, 'f1': 0.96987, 'auc': 0.99698}\n",
      "test: {'epoch': 60, 'time_epoch': 2.33683, 'loss': 0.23603824, 'lr': 0, 'params': 197319, 'time_iter': 0.04972, 'accuracy': 0.97047, 'f1': 0.96973, 'auc': 0.99752}\n",
      "> Epoch 60: took 41.1s (avg 42.5s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 61, 'time_epoch': 36.49071, 'eta': 488.82486, 'eta_hours': 0.13578, 'loss': 0.00022809, 'lr': 9.549e-05, 'params': 197319, 'time_iter': 0.09783, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 61, 'time_epoch': 2.26305, 'loss': 0.23662582, 'lr': 0, 'params': 197319, 'time_iter': 0.04815, 'accuracy': 0.96774, 'f1': 0.96864, 'auc': 0.99718}\n",
      "test: {'epoch': 61, 'time_epoch': 2.25232, 'loss': 0.23044583, 'lr': 0, 'params': 197319, 'time_iter': 0.04792, 'accuracy': 0.96913, 'f1': 0.96846, 'auc': 0.99779}\n",
      "> Epoch 61: took 41.1s (avg 42.5s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 62, 'time_epoch': 36.90288, 'eta': 451.0898, 'eta_hours': 0.1253, 'loss': 0.00021233, 'lr': 8.271e-05, 'params': 197319, 'time_iter': 0.09894, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 62, 'time_epoch': 2.21234, 'loss': 0.23586586, 'lr': 0, 'params': 197319, 'time_iter': 0.04707, 'accuracy': 0.9664, 'f1': 0.96732, 'auc': 0.99734}\n",
      "test: {'epoch': 62, 'time_epoch': 2.26742, 'loss': 0.22142082, 'lr': 0, 'params': 197319, 'time_iter': 0.04824, 'accuracy': 0.96913, 'f1': 0.9683, 'auc': 0.99771}\n",
      "> Epoch 62: took 41.5s (avg 42.4s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 63, 'time_epoch': 36.84629, 'eta': 413.37102, 'eta_hours': 0.11483, 'loss': 0.00020653, 'lr': 7.078e-05, 'params': 197319, 'time_iter': 0.09878, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 63, 'time_epoch': 2.21902, 'loss': 0.22772966, 'lr': 0, 'params': 197319, 'time_iter': 0.04721, 'accuracy': 0.97043, 'f1': 0.97114, 'auc': 0.99711}\n",
      "test: {'epoch': 63, 'time_epoch': 2.35552, 'loss': 0.23103391, 'lr': 0, 'params': 197319, 'time_iter': 0.05012, 'accuracy': 0.96913, 'f1': 0.9683, 'auc': 0.99788}\n",
      "> Epoch 63: took 41.5s (avg 42.4s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 64, 'time_epoch': 36.78279, 'eta': 375.66931, 'eta_hours': 0.10435, 'loss': 0.00019871, 'lr': 5.97e-05, 'params': 197319, 'time_iter': 0.09861, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 64, 'time_epoch': 2.16614, 'loss': 0.22510114, 'lr': 0, 'params': 197319, 'time_iter': 0.04609, 'accuracy': 0.96909, 'f1': 0.96986, 'auc': 0.99704}\n",
      "test: {'epoch': 64, 'time_epoch': 2.52691, 'loss': 0.23625282, 'lr': 0, 'params': 197319, 'time_iter': 0.05376, 'accuracy': 0.97047, 'f1': 0.96977, 'auc': 0.99758}\n",
      "> Epoch 64: took 41.6s (avg 42.4s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 65, 'time_epoch': 37.15813, 'eta': 338.04663, 'eta_hours': 0.0939, 'loss': 0.0018329, 'lr': 4.952e-05, 'params': 197319, 'time_iter': 0.09962, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 0.99996}\n",
      "val: {'epoch': 65, 'time_epoch': 2.16312, 'loss': 0.22396028, 'lr': 0, 'params': 197319, 'time_iter': 0.04602, 'accuracy': 0.96909, 'f1': 0.96986, 'auc': 0.99714}\n",
      "test: {'epoch': 65, 'time_epoch': 2.21136, 'loss': 0.218459, 'lr': 0, 'params': 197319, 'time_iter': 0.04705, 'accuracy': 0.97047, 'f1': 0.96977, 'auc': 0.99757}\n",
      "> Epoch 65: took 41.6s (avg 42.4s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 66, 'time_epoch': 36.9726, 'eta': 300.41567, 'eta_hours': 0.08345, 'loss': 0.00020491, 'lr': 4.024e-05, 'params': 197319, 'time_iter': 0.09912, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 66, 'time_epoch': 2.35451, 'loss': 0.24051522, 'lr': 0, 'params': 197319, 'time_iter': 0.0501, 'accuracy': 0.96774, 'f1': 0.9687, 'auc': 0.99685}\n",
      "test: {'epoch': 66, 'time_epoch': 2.27592, 'loss': 0.23322533, 'lr': 0, 'params': 197319, 'time_iter': 0.04842, 'accuracy': 0.97047, 'f1': 0.96953, 'auc': 0.99734}\n",
      "> Epoch 66: took 41.7s (avg 42.4s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 67, 'time_epoch': 36.52916, 'eta': 262.75842, 'eta_hours': 0.07299, 'loss': 0.00018512, 'lr': 3.188e-05, 'params': 197319, 'time_iter': 0.09793, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 67, 'time_epoch': 2.15298, 'loss': 0.25936032, 'lr': 0, 'params': 197319, 'time_iter': 0.04581, 'accuracy': 0.9664, 'f1': 0.96732, 'auc': 0.99694}\n",
      "test: {'epoch': 67, 'time_epoch': 2.19634, 'loss': 0.23258332, 'lr': 0, 'params': 197319, 'time_iter': 0.04673, 'accuracy': 0.97047, 'f1': 0.96953, 'auc': 0.99724}\n",
      "> Epoch 67: took 41.0s (avg 42.4s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 68, 'time_epoch': 37.24434, 'eta': 225.19606, 'eta_hours': 0.06255, 'loss': 0.00018093, 'lr': 2.447e-05, 'params': 197319, 'time_iter': 0.09985, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 68, 'time_epoch': 2.20474, 'loss': 0.25508094, 'lr': 0, 'params': 197319, 'time_iter': 0.04691, 'accuracy': 0.96774, 'f1': 0.9687, 'auc': 0.99702}\n",
      "test: {'epoch': 68, 'time_epoch': 2.25993, 'loss': 0.23848762, 'lr': 0, 'params': 197319, 'time_iter': 0.04808, 'accuracy': 0.97047, 'f1': 0.96965, 'auc': 0.99762}\n",
      "> Epoch 68: took 41.8s (avg 42.4s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 69, 'time_epoch': 36.62979, 'eta': 187.5989, 'eta_hours': 0.05211, 'loss': 0.00018116, 'lr': 1.802e-05, 'params': 197319, 'time_iter': 0.0982, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 69, 'time_epoch': 2.28073, 'loss': 0.26121352, 'lr': 0, 'params': 197319, 'time_iter': 0.04853, 'accuracy': 0.96774, 'f1': 0.9687, 'auc': 0.99713}\n",
      "test: {'epoch': 69, 'time_epoch': 2.4733, 'loss': 0.23166324, 'lr': 0, 'params': 197319, 'time_iter': 0.05262, 'accuracy': 0.97047, 'f1': 0.96965, 'auc': 0.99736}\n",
      "> Epoch 69: took 41.5s (avg 42.3s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 70, 'time_epoch': 36.50479, 'eta': 150.02193, 'eta_hours': 0.04167, 'loss': 0.00201948, 'lr': 1.254e-05, 'params': 197319, 'time_iter': 0.09787, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 0.99991}\n",
      "val: {'epoch': 70, 'time_epoch': 2.20654, 'loss': 0.2414762, 'lr': 0, 'params': 197319, 'time_iter': 0.04695, 'accuracy': 0.96774, 'f1': 0.9687, 'auc': 0.99749}\n",
      "test: {'epoch': 70, 'time_epoch': 2.28444, 'loss': 0.24156303, 'lr': 0, 'params': 197319, 'time_iter': 0.04861, 'accuracy': 0.97047, 'f1': 0.96965, 'auc': 0.99725}\n",
      "> Epoch 70: took 41.1s (avg 42.3s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 71, 'time_epoch': 36.92307, 'eta': 112.49218, 'eta_hours': 0.03125, 'loss': 0.00017552, 'lr': 8.04e-06, 'params': 197319, 'time_iter': 0.09899, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 71, 'time_epoch': 2.60032, 'loss': 0.24857821, 'lr': 0, 'params': 197319, 'time_iter': 0.05533, 'accuracy': 0.96774, 'f1': 0.96864, 'auc': 0.99672}\n",
      "test: {'epoch': 71, 'time_epoch': 2.34275, 'loss': 0.24092714, 'lr': 0, 'params': 197319, 'time_iter': 0.04985, 'accuracy': 0.97047, 'f1': 0.96965, 'auc': 0.99735}\n",
      "> Epoch 71: took 42.0s (avg 42.3s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 72, 'time_epoch': 36.90635, 'eta': 74.9786, 'eta_hours': 0.02083, 'loss': 0.00039345, 'lr': 4.53e-06, 'params': 197319, 'time_iter': 0.09894, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 72, 'time_epoch': 2.20292, 'loss': 0.24805169, 'lr': 0, 'params': 197319, 'time_iter': 0.04687, 'accuracy': 0.9664, 'f1': 0.96732, 'auc': 0.99709}\n",
      "test: {'epoch': 72, 'time_epoch': 2.27126, 'loss': 0.24040105, 'lr': 0, 'params': 197319, 'time_iter': 0.04832, 'accuracy': 0.97047, 'f1': 0.96965, 'auc': 0.99737}\n",
      "> Epoch 72: took 41.5s (avg 42.3s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 73, 'time_epoch': 36.41093, 'eta': 37.47473, 'eta_hours': 0.01041, 'loss': 0.0001746, 'lr': 2.01e-06, 'params': 197319, 'time_iter': 0.09762, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 73, 'time_epoch': 2.27716, 'loss': 0.25313644, 'lr': 0, 'params': 197319, 'time_iter': 0.04845, 'accuracy': 0.96774, 'f1': 0.9687, 'auc': 0.99662}\n",
      "test: {'epoch': 73, 'time_epoch': 2.28553, 'loss': 0.23072041, 'lr': 0, 'params': 197319, 'time_iter': 0.04863, 'accuracy': 0.97047, 'f1': 0.96965, 'auc': 0.99737}\n",
      "> Epoch 73: took 41.1s (avg 42.3s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "train: {'epoch': 74, 'time_epoch': 37.0006, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.00017461, 'lr': 5e-07, 'params': 197319, 'time_iter': 0.0992, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 74, 'time_epoch': 2.22968, 'loss': 0.25497838, 'lr': 0, 'params': 197319, 'time_iter': 0.04744, 'accuracy': 0.96774, 'f1': 0.9687, 'auc': 0.99707}\n",
      "test: {'epoch': 74, 'time_epoch': 2.52885, 'loss': 0.23386139, 'lr': 0, 'params': 197319, 'time_iter': 0.05381, 'accuracy': 0.97047, 'f1': 0.96965, 'auc': 0.99783}\n",
      "> Epoch 74: took 41.9s (avg 42.3s) | Best so far: epoch 54\ttrain_loss: 0.0009 train_accuracy: 0.9998\tval_loss: 0.1887 val_accuracy: 0.9745\ttest_loss: 0.2331 test_accuracy: 0.9664\n",
      "Avg time per epoch: 42.29s\n",
      "Total train loop time: 0.88h\n",
      "Task done, results saved in results\\neural-Act\\0\n",
      "54\n",
      "{'epoch': 54, 'time_epoch': 2.50971, 'loss': 0.23314522, 'lr': 0, 'params': 197319, 'time_iter': 0.0534, 'accuracy': 0.96644, 'f1': 0.96568, 'auc': 0.99769}\n",
      "{'epoch': 54, 'time_epoch': 36.72693, 'eta': 753.64038, 'eta_hours': 0.20934, 'loss': 0.00089996, 'lr': 0.00020611, 'params': 197319, 'time_iter': 0.09846, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "{'epoch': 54, 'time_epoch': 2.25495, 'loss': 0.18874861, 'lr': 0, 'params': 197319, 'time_iter': 0.04798, 'accuracy': 0.97446, 'f1': 0.97502, 'auc': 0.99735}\n",
      "Results aggregated across runs saved in results\\neural-Act\\agg\n",
      "[*] All done: 2024-02-27 19:37:10.321943\n"
     ]
    }
   ],
   "source": [
    "#exphormer dropout 0.1 attn dropout 0.3\n",
    "%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2eaef7-2a94-49c9-86f7-1125dfc75fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-03 00:42:36.279139\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 7\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [03:19<00:00, 37.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:03:20.87\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [00:46<00:00, 158.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:00:48.48\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=400, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.3\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.3\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: CustomGatedGCN+Exphormer\n",
      "  layers: 3\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 75\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 195018\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 38.60514, 'eta': 2856.78038, 'eta_hours': 0.79355, 'loss': 1.95314814, 'lr': 0.0, 'params': 195018, 'time_iter': 0.1035, 'accuracy': 0.12932, 'f1': 0.09101, 'auc': 0.49971}\n",
      "...computing epoch stats took: 0.23s\n",
      "val: {'epoch': 0, 'time_epoch': 2.38176, 'loss': 1.94798094, 'lr': 0, 'params': 195018, 'time_iter': 0.05068, 'accuracy': 0.13978, 'f1': 0.08839, 'auc': 0.51266}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 0, 'time_epoch': 2.38048, 'loss': 1.94917123, 'lr': 0, 'params': 195018, 'time_iter': 0.05065, 'accuracy': 0.13154, 'f1': 0.08375, 'auc': 0.47455}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 0: took 43.6s (avg 43.6s) | Best so far: epoch 0\ttrain_loss: 1.9531 train_accuracy: 0.1293\tval_loss: 1.9480 val_accuracy: 0.1398\ttest_loss: 1.9492 test_accuracy: 0.1315\n",
      "train: {'epoch': 1, 'time_epoch': 37.76162, 'eta': 2787.38657, 'eta_hours': 0.77427, 'loss': 1.72816659, 'lr': 0.0002, 'params': 195018, 'time_iter': 0.10124, 'accuracy': 0.58935, 'f1': 0.57704, 'auc': 0.89095}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 1, 'time_epoch': 2.28233, 'loss': 1.55805121, 'lr': 0, 'params': 195018, 'time_iter': 0.04856, 'accuracy': 0.74597, 'f1': 0.74309, 'auc': 0.95891}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 2.30245, 'loss': 1.54584677, 'lr': 0, 'params': 195018, 'time_iter': 0.04899, 'accuracy': 0.76779, 'f1': 0.74723, 'auc': 0.96473}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 42.4s (avg 43.0s) | Best so far: epoch 1\ttrain_loss: 1.7282 train_accuracy: 0.5894\tval_loss: 1.5581 val_accuracy: 0.7460\ttest_loss: 1.5458 test_accuracy: 0.7678\n",
      "train: {'epoch': 2, 'time_epoch': 38.38148, 'eta': 2753.95762, 'eta_hours': 0.76499, 'loss': 1.33150042, 'lr': 0.0004, 'params': 195018, 'time_iter': 0.1029, 'accuracy': 0.84397, 'f1': 0.84273, 'auc': 0.97305}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 2.36221, 'loss': 1.14993262, 'lr': 0, 'params': 195018, 'time_iter': 0.05026, 'accuracy': 0.8629, 'f1': 0.86403, 'auc': 0.98498}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 2.3046, 'loss': 1.14255414, 'lr': 0, 'params': 195018, 'time_iter': 0.04903, 'accuracy': 0.86174, 'f1': 0.85755, 'auc': 0.98819}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 43.1s (avg 43.0s) | Best so far: epoch 2\ttrain_loss: 1.3315 train_accuracy: 0.8440\tval_loss: 1.1499 val_accuracy: 0.8629\ttest_loss: 1.1426 test_accuracy: 0.8617\n",
      "train: {'epoch': 3, 'time_epoch': 38.17516, 'eta': 2714.39024, 'eta_hours': 0.754, 'loss': 0.91323658, 'lr': 0.0006, 'params': 195018, 'time_iter': 0.10235, 'accuracy': 0.91434, 'f1': 0.9138, 'auc': 0.98601}\n",
      "val: {'epoch': 3, 'time_epoch': 2.29237, 'loss': 0.82832864, 'lr': 0, 'params': 195018, 'time_iter': 0.04877, 'accuracy': 0.85618, 'f1': 0.86108, 'auc': 0.98972}\n",
      "test: {'epoch': 3, 'time_epoch': 2.27944, 'loss': 0.82758528, 'lr': 0, 'params': 195018, 'time_iter': 0.0485, 'accuracy': 0.84966, 'f1': 0.84938, 'auc': 0.98974}\n",
      "> Epoch 3: took 42.8s (avg 43.0s) | Best so far: epoch 2\ttrain_loss: 1.3315 train_accuracy: 0.8440\tval_loss: 1.1499 val_accuracy: 0.8629\ttest_loss: 1.1426 test_accuracy: 0.8617\n",
      "train: {'epoch': 4, 'time_epoch': 39.11633, 'eta': 2688.55615, 'eta_hours': 0.74682, 'loss': 0.58550668, 'lr': 0.0008, 'params': 195018, 'time_iter': 0.10487, 'accuracy': 0.93383, 'f1': 0.9335, 'auc': 0.99134}\n",
      "val: {'epoch': 4, 'time_epoch': 2.46697, 'loss': 0.49033213, 'lr': 0, 'params': 195018, 'time_iter': 0.05249, 'accuracy': 0.9328, 'f1': 0.93422, 'auc': 0.99081}\n",
      "test: {'epoch': 4, 'time_epoch': 2.45783, 'loss': 0.46588189, 'lr': 0, 'params': 195018, 'time_iter': 0.05229, 'accuracy': 0.93691, 'f1': 0.93778, 'auc': 0.99427}\n",
      "> Epoch 4: took 44.1s (avg 43.2s) | Best so far: epoch 4\ttrain_loss: 0.5855 train_accuracy: 0.9338\tval_loss: 0.4903 val_accuracy: 0.9328\ttest_loss: 0.4659 test_accuracy: 0.9369\n",
      "train: {'epoch': 5, 'time_epoch': 39.09766, 'eta': 2658.07998, 'eta_hours': 0.73836, 'loss': 0.40457616, 'lr': 0.001, 'params': 195018, 'time_iter': 0.10482, 'accuracy': 0.93467, 'f1': 0.93442, 'auc': 0.99229}\n",
      "val: {'epoch': 5, 'time_epoch': 2.38807, 'loss': 0.35071106, 'lr': 0, 'params': 195018, 'time_iter': 0.05081, 'accuracy': 0.93414, 'f1': 0.93581, 'auc': 0.99605}\n",
      "test: {'epoch': 5, 'time_epoch': 2.41944, 'loss': 0.30887839, 'lr': 0, 'params': 195018, 'time_iter': 0.05148, 'accuracy': 0.95168, 'f1': 0.95182, 'auc': 0.99558}\n",
      "> Epoch 5: took 43.9s (avg 43.3s) | Best so far: epoch 5\ttrain_loss: 0.4046 train_accuracy: 0.9347\tval_loss: 0.3507 val_accuracy: 0.9341\ttest_loss: 0.3089 test_accuracy: 0.9517\n",
      "train: {'epoch': 6, 'time_epoch': 38.51207, 'eta': 2619.45193, 'eta_hours': 0.72763, 'loss': 0.26807933, 'lr': 0.0009995, 'params': 195018, 'time_iter': 0.10325, 'accuracy': 0.95146, 'f1': 0.95132, 'auc': 0.99603}\n",
      "val: {'epoch': 6, 'time_epoch': 2.28388, 'loss': 0.3034365, 'lr': 0, 'params': 195018, 'time_iter': 0.04859, 'accuracy': 0.9328, 'f1': 0.93428, 'auc': 0.99582}\n",
      "test: {'epoch': 6, 'time_epoch': 2.31845, 'loss': 0.314593, 'lr': 0, 'params': 195018, 'time_iter': 0.04933, 'accuracy': 0.92349, 'f1': 0.92496, 'auc': 0.99362}\n",
      "> Epoch 6: took 43.1s (avg 43.3s) | Best so far: epoch 5\ttrain_loss: 0.4046 train_accuracy: 0.9347\tval_loss: 0.3507 val_accuracy: 0.9341\ttest_loss: 0.3089 test_accuracy: 0.9517\n",
      "train: {'epoch': 7, 'time_epoch': 38.98346, 'eta': 2584.8007, 'eta_hours': 0.718, 'loss': 0.1932348, 'lr': 0.00099799, 'params': 195018, 'time_iter': 0.10451, 'accuracy': 0.96423, 'f1': 0.96414, 'auc': 0.99742}\n",
      "val: {'epoch': 7, 'time_epoch': 2.40201, 'loss': 0.2693111, 'lr': 0, 'params': 195018, 'time_iter': 0.05111, 'accuracy': 0.9328, 'f1': 0.93435, 'auc': 0.99513}\n",
      "test: {'epoch': 7, 'time_epoch': 2.46834, 'loss': 0.21779989, 'lr': 0, 'params': 195018, 'time_iter': 0.05252, 'accuracy': 0.94228, 'f1': 0.94192, 'auc': 0.99661}\n",
      "> Epoch 7: took 43.9s (avg 43.4s) | Best so far: epoch 5\ttrain_loss: 0.4046 train_accuracy: 0.9347\tval_loss: 0.3507 val_accuracy: 0.9341\ttest_loss: 0.3089 test_accuracy: 0.9517\n",
      "train: {'epoch': 8, 'time_epoch': 38.64015, 'eta': 2546.66917, 'eta_hours': 0.70741, 'loss': 0.16115204, 'lr': 0.00099547, 'params': 195018, 'time_iter': 0.10359, 'accuracy': 0.96523, 'f1': 0.96518, 'auc': 0.99785}\n",
      "val: {'epoch': 8, 'time_epoch': 2.33525, 'loss': 0.19871816, 'lr': 0, 'params': 195018, 'time_iter': 0.04969, 'accuracy': 0.9543, 'f1': 0.95551, 'auc': 0.99507}\n",
      "test: {'epoch': 8, 'time_epoch': 2.37408, 'loss': 0.1675062, 'lr': 0, 'params': 195018, 'time_iter': 0.05051, 'accuracy': 0.96644, 'f1': 0.96649, 'auc': 0.99497}\n",
      "> Epoch 8: took 43.4s (avg 43.4s) | Best so far: epoch 8\ttrain_loss: 0.1612 train_accuracy: 0.9652\tval_loss: 0.1987 val_accuracy: 0.9543\ttest_loss: 0.1675 test_accuracy: 0.9664\n",
      "train: {'epoch': 9, 'time_epoch': 38.52943, 'eta': 2507.71624, 'eta_hours': 0.69659, 'loss': 0.12440801, 'lr': 0.00099196, 'params': 195018, 'time_iter': 0.1033, 'accuracy': 0.97346, 'f1': 0.97344, 'auc': 0.99861}\n",
      "val: {'epoch': 9, 'time_epoch': 2.29572, 'loss': 0.2682374, 'lr': 0, 'params': 195018, 'time_iter': 0.04885, 'accuracy': 0.9328, 'f1': 0.93448, 'auc': 0.99419}\n",
      "test: {'epoch': 9, 'time_epoch': 2.31061, 'loss': 0.28658498, 'lr': 0, 'params': 195018, 'time_iter': 0.04916, 'accuracy': 0.92483, 'f1': 0.92242, 'auc': 0.99326}\n",
      "> Epoch 9: took 43.2s (avg 43.4s) | Best so far: epoch 8\ttrain_loss: 0.1612 train_accuracy: 0.9652\tval_loss: 0.1987 val_accuracy: 0.9543\ttest_loss: 0.1675 test_accuracy: 0.9664\n",
      "train: {'epoch': 10, 'time_epoch': 38.23539, 'eta': 2467.12951, 'eta_hours': 0.68531, 'loss': 0.10281151, 'lr': 0.00098746, 'params': 195018, 'time_iter': 0.10251, 'accuracy': 0.97716, 'f1': 0.97719, 'auc': 0.99891}\n",
      "val: {'epoch': 10, 'time_epoch': 2.36068, 'loss': 0.22195239, 'lr': 0, 'params': 195018, 'time_iter': 0.05023, 'accuracy': 0.94624, 'f1': 0.94568, 'auc': 0.9949}\n",
      "test: {'epoch': 10, 'time_epoch': 2.39063, 'loss': 0.24908165, 'lr': 0, 'params': 195018, 'time_iter': 0.05086, 'accuracy': 0.93423, 'f1': 0.9346, 'auc': 0.99537}\n",
      "> Epoch 10: took 43.0s (avg 43.3s) | Best so far: epoch 8\ttrain_loss: 0.1612 train_accuracy: 0.9652\tval_loss: 0.1987 val_accuracy: 0.9543\ttest_loss: 0.1675 test_accuracy: 0.9664\n",
      "train: {'epoch': 11, 'time_epoch': 38.3267, 'eta': 2427.41409, 'eta_hours': 0.67428, 'loss': 0.09628335, 'lr': 0.00098198, 'params': 195018, 'time_iter': 0.10275, 'accuracy': 0.97632, 'f1': 0.9763, 'auc': 0.99938}\n",
      "val: {'epoch': 11, 'time_epoch': 2.39176, 'loss': 0.24772677, 'lr': 0, 'params': 195018, 'time_iter': 0.05089, 'accuracy': 0.93414, 'f1': 0.93471, 'auc': 0.99587}\n",
      "test: {'epoch': 11, 'time_epoch': 2.36414, 'loss': 0.30511399, 'lr': 0, 'params': 195018, 'time_iter': 0.0503, 'accuracy': 0.91678, 'f1': 0.9181, 'auc': 0.9957}\n",
      "> Epoch 11: took 43.1s (avg 43.3s) | Best so far: epoch 8\ttrain_loss: 0.1612 train_accuracy: 0.9652\tval_loss: 0.1987 val_accuracy: 0.9543\ttest_loss: 0.1675 test_accuracy: 0.9664\n",
      "train: {'epoch': 12, 'time_epoch': 38.6065, 'eta': 2389.24672, 'eta_hours': 0.66368, 'loss': 0.07270673, 'lr': 0.00097553, 'params': 195018, 'time_iter': 0.1035, 'accuracy': 0.98253, 'f1': 0.98249, 'auc': 0.99958}\n",
      "val: {'epoch': 12, 'time_epoch': 2.34504, 'loss': 0.15148501, 'lr': 0, 'params': 195018, 'time_iter': 0.04989, 'accuracy': 0.96237, 'f1': 0.96308, 'auc': 0.99695}\n",
      "test: {'epoch': 12, 'time_epoch': 2.34059, 'loss': 0.14710903, 'lr': 0, 'params': 195018, 'time_iter': 0.0498, 'accuracy': 0.96779, 'f1': 0.9682, 'auc': 0.9977}\n",
      "> Epoch 12: took 43.3s (avg 43.3s) | Best so far: epoch 12\ttrain_loss: 0.0727 train_accuracy: 0.9825\tval_loss: 0.1515 val_accuracy: 0.9624\ttest_loss: 0.1471 test_accuracy: 0.9678\n",
      "train: {'epoch': 13, 'time_epoch': 38.96617, 'eta': 2352.58375, 'eta_hours': 0.6535, 'loss': 0.06664235, 'lr': 0.00096812, 'params': 195018, 'time_iter': 0.10447, 'accuracy': 0.98388, 'f1': 0.98383, 'auc': 0.99958}\n",
      "val: {'epoch': 13, 'time_epoch': 2.44886, 'loss': 0.21994669, 'lr': 0, 'params': 195018, 'time_iter': 0.0521, 'accuracy': 0.94489, 'f1': 0.94684, 'auc': 0.9945}\n",
      "test: {'epoch': 13, 'time_epoch': 2.50318, 'loss': 0.186265, 'lr': 0, 'params': 195018, 'time_iter': 0.05326, 'accuracy': 0.95168, 'f1': 0.9531, 'auc': 0.99643}\n",
      "> Epoch 13: took 44.0s (avg 43.4s) | Best so far: epoch 12\ttrain_loss: 0.0727 train_accuracy: 0.9825\tval_loss: 0.1515 val_accuracy: 0.9624\ttest_loss: 0.1471 test_accuracy: 0.9678\n",
      "train: {'epoch': 14, 'time_epoch': 38.9971, 'eta': 2315.73743, 'eta_hours': 0.64326, 'loss': 0.06830687, 'lr': 0.00095976, 'params': 195018, 'time_iter': 0.10455, 'accuracy': 0.98404, 'f1': 0.98399, 'auc': 0.99938}\n",
      "val: {'epoch': 14, 'time_epoch': 2.38598, 'loss': 0.16162321, 'lr': 0, 'params': 195018, 'time_iter': 0.05077, 'accuracy': 0.96237, 'f1': 0.96304, 'auc': 0.99779}\n",
      "test: {'epoch': 14, 'time_epoch': 2.54399, 'loss': 0.17960178, 'lr': 0, 'params': 195018, 'time_iter': 0.05413, 'accuracy': 0.95839, 'f1': 0.95878, 'auc': 0.99799}\n",
      "> Epoch 14: took 44.0s (avg 43.4s) | Best so far: epoch 12\ttrain_loss: 0.0727 train_accuracy: 0.9825\tval_loss: 0.1515 val_accuracy: 0.9624\ttest_loss: 0.1471 test_accuracy: 0.9678\n",
      "train: {'epoch': 15, 'time_epoch': 39.16295, 'eta': 2279.23383, 'eta_hours': 0.63312, 'loss': 0.05048899, 'lr': 0.00095048, 'params': 195018, 'time_iter': 0.10499, 'accuracy': 0.98774, 'f1': 0.98774, 'auc': 0.99961}\n",
      "val: {'epoch': 15, 'time_epoch': 2.41845, 'loss': 0.15132122, 'lr': 0, 'params': 195018, 'time_iter': 0.05146, 'accuracy': 0.95968, 'f1': 0.96033, 'auc': 0.99699}\n",
      "test: {'epoch': 15, 'time_epoch': 2.56884, 'loss': 0.13363355, 'lr': 0, 'params': 195018, 'time_iter': 0.05466, 'accuracy': 0.96913, 'f1': 0.96896, 'auc': 0.99817}\n",
      "> Epoch 15: took 44.2s (avg 43.4s) | Best so far: epoch 12\ttrain_loss: 0.0727 train_accuracy: 0.9825\tval_loss: 0.1515 val_accuracy: 0.9624\ttest_loss: 0.1471 test_accuracy: 0.9678\n",
      "train: {'epoch': 16, 'time_epoch': 39.2522, 'eta': 2242.72186, 'eta_hours': 0.62298, 'loss': 0.05988284, 'lr': 0.0009403, 'params': 195018, 'time_iter': 0.10523, 'accuracy': 0.98472, 'f1': 0.98465, 'auc': 0.99955}\n",
      "val: {'epoch': 16, 'time_epoch': 2.369, 'loss': 0.12571512, 'lr': 0, 'params': 195018, 'time_iter': 0.0504, 'accuracy': 0.9664, 'f1': 0.96699, 'auc': 0.99845}\n",
      "test: {'epoch': 16, 'time_epoch': 2.44496, 'loss': 0.13146124, 'lr': 0, 'params': 195018, 'time_iter': 0.05202, 'accuracy': 0.9651, 'f1': 0.96479, 'auc': 0.99908}\n",
      "> Epoch 16: took 44.1s (avg 43.5s) | Best so far: epoch 16\ttrain_loss: 0.0599 train_accuracy: 0.9847\tval_loss: 0.1257 val_accuracy: 0.9664\ttest_loss: 0.1315 test_accuracy: 0.9651\n",
      "train: {'epoch': 17, 'time_epoch': 39.40601, 'eta': 2206.39248, 'eta_hours': 0.61289, 'loss': 0.03898998, 'lr': 0.00092922, 'params': 195018, 'time_iter': 0.10565, 'accuracy': 0.98959, 'f1': 0.98956, 'auc': 0.99988}\n",
      "val: {'epoch': 17, 'time_epoch': 2.62604, 'loss': 0.14374178, 'lr': 0, 'params': 195018, 'time_iter': 0.05587, 'accuracy': 0.96505, 'f1': 0.96565, 'auc': 0.99783}\n",
      "test: {'epoch': 17, 'time_epoch': 2.40465, 'loss': 0.16428606, 'lr': 0, 'params': 195018, 'time_iter': 0.05116, 'accuracy': 0.96376, 'f1': 0.96344, 'auc': 0.99824}\n",
      "> Epoch 17: took 44.5s (avg 43.5s) | Best so far: epoch 16\ttrain_loss: 0.0599 train_accuracy: 0.9847\tval_loss: 0.1257 val_accuracy: 0.9664\ttest_loss: 0.1315 test_accuracy: 0.9651\n",
      "train: {'epoch': 18, 'time_epoch': 43.49113, 'eta': 2181.7796, 'eta_hours': 0.60605, 'loss': 0.04414244, 'lr': 0.00091729, 'params': 195018, 'time_iter': 0.1166, 'accuracy': 0.98959, 'f1': 0.98958, 'auc': 0.99964}\n",
      "val: {'epoch': 18, 'time_epoch': 2.608, 'loss': 0.15680447, 'lr': 0, 'params': 195018, 'time_iter': 0.05549, 'accuracy': 0.96371, 'f1': 0.96477, 'auc': 0.99805}\n",
      "test: {'epoch': 18, 'time_epoch': 3.08416, 'loss': 0.15125308, 'lr': 0, 'params': 195018, 'time_iter': 0.06562, 'accuracy': 0.96644, 'f1': 0.96616, 'auc': 0.99712}\n",
      "> Epoch 18: took 49.3s (avg 43.8s) | Best so far: epoch 16\ttrain_loss: 0.0599 train_accuracy: 0.9847\tval_loss: 0.1257 val_accuracy: 0.9664\ttest_loss: 0.1315 test_accuracy: 0.9651\n",
      "train: {'epoch': 19, 'time_epoch': 46.64392, 'eta': 2163.94908, 'eta_hours': 0.6011, 'loss': 0.03056137, 'lr': 0.00090451, 'params': 195018, 'time_iter': 0.12505, 'accuracy': 0.99227, 'f1': 0.99227, 'auc': 0.99985}\n",
      "val: {'epoch': 19, 'time_epoch': 2.98151, 'loss': 0.14894016, 'lr': 0, 'params': 195018, 'time_iter': 0.06344, 'accuracy': 0.96505, 'f1': 0.96638, 'auc': 0.99838}\n",
      "test: {'epoch': 19, 'time_epoch': 2.99685, 'loss': 0.22984943, 'lr': 0, 'params': 195018, 'time_iter': 0.06376, 'accuracy': 0.94765, 'f1': 0.94982, 'auc': 0.99735}\n",
      "> Epoch 19: took 52.7s (avg 44.3s) | Best so far: epoch 16\ttrain_loss: 0.0599 train_accuracy: 0.9847\tval_loss: 0.1257 val_accuracy: 0.9664\ttest_loss: 0.1315 test_accuracy: 0.9651\n",
      "train: {'epoch': 20, 'time_epoch': 47.05128, 'eta': 2144.4219, 'eta_hours': 0.59567, 'loss': 0.03479583, 'lr': 0.00089092, 'params': 195018, 'time_iter': 0.12614, 'accuracy': 0.99059, 'f1': 0.99059, 'auc': 0.99986}\n",
      "val: {'epoch': 20, 'time_epoch': 2.86631, 'loss': 0.19713142, 'lr': 0, 'params': 195018, 'time_iter': 0.06099, 'accuracy': 0.95699, 'f1': 0.95762, 'auc': 0.99583}\n",
      "test: {'epoch': 20, 'time_epoch': 2.8878, 'loss': 0.16451444, 'lr': 0, 'params': 195018, 'time_iter': 0.06144, 'accuracy': 0.9651, 'f1': 0.96475, 'auc': 0.99735}\n",
      "> Epoch 20: took 52.9s (avg 44.7s) | Best so far: epoch 16\ttrain_loss: 0.0599 train_accuracy: 0.9847\tval_loss: 0.1257 val_accuracy: 0.9664\ttest_loss: 0.1315 test_accuracy: 0.9651\n",
      "train: {'epoch': 21, 'time_epoch': 46.04195, 'eta': 2119.96097, 'eta_hours': 0.58888, 'loss': 0.03627319, 'lr': 0.00087654, 'params': 195018, 'time_iter': 0.12344, 'accuracy': 0.99059, 'f1': 0.99055, 'auc': 0.99981}\n",
      "val: {'epoch': 21, 'time_epoch': 2.87156, 'loss': 0.17342815, 'lr': 0, 'params': 195018, 'time_iter': 0.0611, 'accuracy': 0.95833, 'f1': 0.9591, 'auc': 0.99727}\n",
      "test: {'epoch': 21, 'time_epoch': 2.95932, 'loss': 0.16461688, 'lr': 0, 'params': 195018, 'time_iter': 0.06296, 'accuracy': 0.96242, 'f1': 0.96223, 'auc': 0.9989}\n",
      "> Epoch 21: took 51.9s (avg 45.0s) | Best so far: epoch 16\ttrain_loss: 0.0599 train_accuracy: 0.9847\tval_loss: 0.1257 val_accuracy: 0.9664\ttest_loss: 0.1315 test_accuracy: 0.9651\n",
      "train: {'epoch': 22, 'time_epoch': 46.82522, 'eta': 2095.39431, 'eta_hours': 0.58205, 'loss': 0.03175531, 'lr': 0.0008614, 'params': 195018, 'time_iter': 0.12554, 'accuracy': 0.99143, 'f1': 0.99144, 'auc': 0.99979}\n",
      "val: {'epoch': 22, 'time_epoch': 2.73302, 'loss': 0.14941893, 'lr': 0, 'params': 195018, 'time_iter': 0.05815, 'accuracy': 0.96505, 'f1': 0.96544, 'auc': 0.99873}\n",
      "test: {'epoch': 22, 'time_epoch': 2.41855, 'loss': 0.16840072, 'lr': 0, 'params': 195018, 'time_iter': 0.05146, 'accuracy': 0.96242, 'f1': 0.96287, 'auc': 0.99819}\n",
      "> Epoch 22: took 52.0s (avg 45.3s) | Best so far: epoch 16\ttrain_loss: 0.0599 train_accuracy: 0.9847\tval_loss: 0.1257 val_accuracy: 0.9664\ttest_loss: 0.1315 test_accuracy: 0.9651\n",
      "train: {'epoch': 23, 'time_epoch': 39.6955, 'eta': 2053.82211, 'eta_hours': 0.57051, 'loss': 0.02906822, 'lr': 0.00084553, 'params': 195018, 'time_iter': 0.10642, 'accuracy': 0.99177, 'f1': 0.99175, 'auc': 0.99992}\n",
      "val: {'epoch': 23, 'time_epoch': 2.3447, 'loss': 0.15706843, 'lr': 0, 'params': 195018, 'time_iter': 0.04989, 'accuracy': 0.96505, 'f1': 0.96609, 'auc': 0.99761}\n",
      "test: {'epoch': 23, 'time_epoch': 2.33242, 'loss': 0.15717075, 'lr': 0, 'params': 195018, 'time_iter': 0.04963, 'accuracy': 0.96644, 'f1': 0.96579, 'auc': 0.999}\n",
      "> Epoch 23: took 44.4s (avg 45.3s) | Best so far: epoch 16\ttrain_loss: 0.0599 train_accuracy: 0.9847\tval_loss: 0.1257 val_accuracy: 0.9664\ttest_loss: 0.1315 test_accuracy: 0.9651\n",
      "train: {'epoch': 24, 'time_epoch': 41.9005, 'eta': 2016.81004, 'eta_hours': 0.56023, 'loss': 0.02111605, 'lr': 0.00082897, 'params': 195018, 'time_iter': 0.11233, 'accuracy': 0.99429, 'f1': 0.99427, 'auc': 0.99996}\n",
      "val: {'epoch': 24, 'time_epoch': 2.82579, 'loss': 0.14956624, 'lr': 0, 'params': 195018, 'time_iter': 0.06012, 'accuracy': 0.9664, 'f1': 0.96724, 'auc': 0.99707}\n",
      "test: {'epoch': 24, 'time_epoch': 2.98131, 'loss': 0.15080118, 'lr': 0, 'params': 195018, 'time_iter': 0.06343, 'accuracy': 0.96913, 'f1': 0.96846, 'auc': 0.99903}\n",
      "> Epoch 24: took 47.8s (avg 45.4s) | Best so far: epoch 16\ttrain_loss: 0.0599 train_accuracy: 0.9847\tval_loss: 0.1257 val_accuracy: 0.9664\ttest_loss: 0.1315 test_accuracy: 0.9651\n",
      "train: {'epoch': 25, 'time_epoch': 45.42596, 'eta': 1986.06608, 'eta_hours': 0.55169, 'loss': 0.02084039, 'lr': 0.00081174, 'params': 195018, 'time_iter': 0.12179, 'accuracy': 0.99412, 'f1': 0.99412, 'auc': 0.99996}\n",
      "val: {'epoch': 25, 'time_epoch': 2.87215, 'loss': 0.1603052, 'lr': 0, 'params': 195018, 'time_iter': 0.06111, 'accuracy': 0.96237, 'f1': 0.96342, 'auc': 0.99796}\n",
      "test: {'epoch': 25, 'time_epoch': 2.93472, 'loss': 0.16598058, 'lr': 0, 'params': 195018, 'time_iter': 0.06244, 'accuracy': 0.97047, 'f1': 0.96923, 'auc': 0.99741}\n",
      "> Epoch 25: took 51.3s (avg 45.6s) | Best so far: epoch 16\ttrain_loss: 0.0599 train_accuracy: 0.9847\tval_loss: 0.1257 val_accuracy: 0.9664\ttest_loss: 0.1315 test_accuracy: 0.9651\n",
      "train: {'epoch': 26, 'time_epoch': 44.65385, 'eta': 1952.86191, 'eta_hours': 0.54246, 'loss': 0.02006048, 'lr': 0.00079389, 'params': 195018, 'time_iter': 0.11972, 'accuracy': 0.99496, 'f1': 0.99497, 'auc': 0.99996}\n",
      "val: {'epoch': 26, 'time_epoch': 2.90523, 'loss': 0.17014524, 'lr': 0, 'params': 195018, 'time_iter': 0.06181, 'accuracy': 0.96371, 'f1': 0.96453, 'auc': 0.99742}\n",
      "test: {'epoch': 26, 'time_epoch': 2.95167, 'loss': 0.16882944, 'lr': 0, 'params': 195018, 'time_iter': 0.0628, 'accuracy': 0.96913, 'f1': 0.96932, 'auc': 0.99867}\n",
      "> Epoch 26: took 50.6s (avg 45.8s) | Best so far: epoch 16\ttrain_loss: 0.0599 train_accuracy: 0.9847\tval_loss: 0.1257 val_accuracy: 0.9664\ttest_loss: 0.1315 test_accuracy: 0.9651\n",
      "train: {'epoch': 27, 'time_epoch': 44.21428, 'eta': 1918.10207, 'eta_hours': 0.53281, 'loss': 0.01782701, 'lr': 0.00077545, 'params': 195018, 'time_iter': 0.11854, 'accuracy': 0.99479, 'f1': 0.99477, 'auc': 0.99994}\n",
      "val: {'epoch': 27, 'time_epoch': 2.2803, 'loss': 0.12366112, 'lr': 0, 'params': 195018, 'time_iter': 0.04852, 'accuracy': 0.97312, 'f1': 0.97409, 'auc': 0.99786}\n",
      "test: {'epoch': 27, 'time_epoch': 2.30624, 'loss': 0.14771811, 'lr': 0, 'params': 195018, 'time_iter': 0.04907, 'accuracy': 0.96779, 'f1': 0.96763, 'auc': 0.99837}\n",
      "> Epoch 27: took 48.8s (avg 45.9s) | Best so far: epoch 27\ttrain_loss: 0.0178 train_accuracy: 0.9948\tval_loss: 0.1237 val_accuracy: 0.9731\ttest_loss: 0.1477 test_accuracy: 0.9678\n",
      "train: {'epoch': 28, 'time_epoch': 38.18587, 'eta': 1873.12789, 'eta_hours': 0.52031, 'loss': 0.01127699, 'lr': 0.00075645, 'params': 195018, 'time_iter': 0.10237, 'accuracy': 0.99698, 'f1': 0.99697, 'auc': 0.99996}\n",
      "val: {'epoch': 28, 'time_epoch': 2.26839, 'loss': 0.13843943, 'lr': 0, 'params': 195018, 'time_iter': 0.04826, 'accuracy': 0.97446, 'f1': 0.97492, 'auc': 0.99708}\n",
      "test: {'epoch': 28, 'time_epoch': 2.29838, 'loss': 0.16792491, 'lr': 0, 'params': 195018, 'time_iter': 0.0489, 'accuracy': 0.97047, 'f1': 0.97009, 'auc': 0.99788}\n",
      "> Epoch 28: took 42.8s (avg 45.8s) | Best so far: epoch 28\ttrain_loss: 0.0113 train_accuracy: 0.9970\tval_loss: 0.1384 val_accuracy: 0.9745\ttest_loss: 0.1679 test_accuracy: 0.9705\n",
      "train: {'epoch': 29, 'time_epoch': 39.27734, 'eta': 1830.24348, 'eta_hours': 0.5084, 'loss': 0.00981746, 'lr': 0.00073693, 'params': 195018, 'time_iter': 0.1053, 'accuracy': 0.99782, 'f1': 0.9978, 'auc': 0.99998}\n",
      "val: {'epoch': 29, 'time_epoch': 2.29704, 'loss': 0.17315056, 'lr': 0, 'params': 195018, 'time_iter': 0.04887, 'accuracy': 0.96371, 'f1': 0.96443, 'auc': 0.99833}\n",
      "test: {'epoch': 29, 'time_epoch': 2.31525, 'loss': 0.16206664, 'lr': 0, 'params': 195018, 'time_iter': 0.04926, 'accuracy': 0.96376, 'f1': 0.96383, 'auc': 0.99834}\n",
      "> Epoch 29: took 43.9s (avg 45.7s) | Best so far: epoch 28\ttrain_loss: 0.0113 train_accuracy: 0.9970\tval_loss: 0.1384 val_accuracy: 0.9745\ttest_loss: 0.1679 test_accuracy: 0.9705\n",
      "train: {'epoch': 30, 'time_epoch': 38.54014, 'eta': 1786.54542, 'eta_hours': 0.49626, 'loss': 0.01203102, 'lr': 0.00071694, 'params': 195018, 'time_iter': 0.10332, 'accuracy': 0.99698, 'f1': 0.99698, 'auc': 0.99998}\n",
      "val: {'epoch': 30, 'time_epoch': 2.3722, 'loss': 0.14607959, 'lr': 0, 'params': 195018, 'time_iter': 0.05047, 'accuracy': 0.97312, 'f1': 0.9739, 'auc': 0.99887}\n",
      "test: {'epoch': 30, 'time_epoch': 2.36275, 'loss': 0.16741822, 'lr': 0, 'params': 195018, 'time_iter': 0.05027, 'accuracy': 0.96913, 'f1': 0.9693, 'auc': 0.99842}\n",
      "> Epoch 30: took 43.3s (avg 45.7s) | Best so far: epoch 28\ttrain_loss: 0.0113 train_accuracy: 0.9970\tval_loss: 0.1384 val_accuracy: 0.9745\ttest_loss: 0.1679 test_accuracy: 0.9705\n",
      "train: {'epoch': 31, 'time_epoch': 38.94434, 'eta': 1743.71288, 'eta_hours': 0.48436, 'loss': 0.02303115, 'lr': 0.00069651, 'params': 195018, 'time_iter': 0.10441, 'accuracy': 0.99278, 'f1': 0.99276, 'auc': 0.99994}\n",
      "val: {'epoch': 31, 'time_epoch': 2.35442, 'loss': 0.22489698, 'lr': 0, 'params': 195018, 'time_iter': 0.05009, 'accuracy': 0.94624, 'f1': 0.94794, 'auc': 0.99645}\n",
      "test: {'epoch': 31, 'time_epoch': 2.3595, 'loss': 0.22858587, 'lr': 0, 'params': 195018, 'time_iter': 0.0502, 'accuracy': 0.95034, 'f1': 0.94942, 'auc': 0.99777}\n",
      "> Epoch 31: took 43.7s (avg 45.6s) | Best so far: epoch 28\ttrain_loss: 0.0113 train_accuracy: 0.9970\tval_loss: 0.1384 val_accuracy: 0.9745\ttest_loss: 0.1679 test_accuracy: 0.9705\n",
      "train: {'epoch': 32, 'time_epoch': 38.77639, 'eta': 1700.90223, 'eta_hours': 0.47247, 'loss': 0.01621653, 'lr': 0.00067569, 'params': 195018, 'time_iter': 0.10396, 'accuracy': 0.99563, 'f1': 0.99562, 'auc': 0.99995}\n",
      "val: {'epoch': 32, 'time_epoch': 2.29672, 'loss': 0.15141044, 'lr': 0, 'params': 195018, 'time_iter': 0.04887, 'accuracy': 0.97177, 'f1': 0.97222, 'auc': 0.99739}\n",
      "test: {'epoch': 32, 'time_epoch': 2.31227, 'loss': 0.12491413, 'lr': 0, 'params': 195018, 'time_iter': 0.0492, 'accuracy': 0.97584, 'f1': 0.97532, 'auc': 0.99929}\n",
      "> Epoch 32: took 43.4s (avg 45.5s) | Best so far: epoch 28\ttrain_loss: 0.0113 train_accuracy: 0.9970\tval_loss: 0.1384 val_accuracy: 0.9745\ttest_loss: 0.1679 test_accuracy: 0.9705\n",
      "train: {'epoch': 33, 'time_epoch': 38.91121, 'eta': 1658.49148, 'eta_hours': 0.46069, 'loss': 0.00821402, 'lr': 0.00065451, 'params': 195018, 'time_iter': 0.10432, 'accuracy': 0.99782, 'f1': 0.99781, 'auc': 0.99999}\n",
      "val: {'epoch': 33, 'time_epoch': 2.42882, 'loss': 0.16074292, 'lr': 0, 'params': 195018, 'time_iter': 0.05168, 'accuracy': 0.96909, 'f1': 0.96992, 'auc': 0.99725}\n",
      "test: {'epoch': 33, 'time_epoch': 2.45061, 'loss': 0.1754058, 'lr': 0, 'params': 195018, 'time_iter': 0.05214, 'accuracy': 0.9651, 'f1': 0.96549, 'auc': 0.99888}\n",
      "> Epoch 33: took 43.8s (avg 45.5s) | Best so far: epoch 28\ttrain_loss: 0.0113 train_accuracy: 0.9970\tval_loss: 0.1384 val_accuracy: 0.9745\ttest_loss: 0.1679 test_accuracy: 0.9705\n",
      "train: {'epoch': 34, 'time_epoch': 38.62095, 'eta': 1615.94896, 'eta_hours': 0.44887, 'loss': 0.01223508, 'lr': 0.00063302, 'params': 195018, 'time_iter': 0.10354, 'accuracy': 0.99698, 'f1': 0.99695, 'auc': 0.99996}\n",
      "val: {'epoch': 34, 'time_epoch': 2.39074, 'loss': 0.16321944, 'lr': 0, 'params': 195018, 'time_iter': 0.05087, 'accuracy': 0.97177, 'f1': 0.97259, 'auc': 0.9967}\n",
      "test: {'epoch': 34, 'time_epoch': 2.39183, 'loss': 0.17200029, 'lr': 0, 'params': 195018, 'time_iter': 0.05089, 'accuracy': 0.96107, 'f1': 0.96149, 'auc': 0.99841}\n",
      "> Epoch 34: took 43.4s (avg 45.4s) | Best so far: epoch 28\ttrain_loss: 0.0113 train_accuracy: 0.9970\tval_loss: 0.1384 val_accuracy: 0.9745\ttest_loss: 0.1679 test_accuracy: 0.9705\n",
      "train: {'epoch': 35, 'time_epoch': 39.51752, 'eta': 1574.5956, 'eta_hours': 0.43739, 'loss': 0.00945409, 'lr': 0.00061126, 'params': 195018, 'time_iter': 0.10595, 'accuracy': 0.99765, 'f1': 0.99762, 'auc': 0.99999}\n",
      "val: {'epoch': 35, 'time_epoch': 2.35948, 'loss': 0.10125417, 'lr': 0, 'params': 195018, 'time_iter': 0.0502, 'accuracy': 0.97849, 'f1': 0.97878, 'auc': 0.99826}\n",
      "test: {'epoch': 35, 'time_epoch': 2.36558, 'loss': 0.15779826, 'lr': 0, 'params': 195018, 'time_iter': 0.05033, 'accuracy': 0.96779, 'f1': 0.96743, 'auc': 0.99876}\n",
      "> Epoch 35: took 44.3s (avg 45.4s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 36, 'time_epoch': 38.63177, 'eta': 1532.43179, 'eta_hours': 0.42568, 'loss': 0.00282307, 'lr': 0.00058928, 'params': 195018, 'time_iter': 0.10357, 'accuracy': 0.9995, 'f1': 0.99949, 'auc': 1.0}\n",
      "val: {'epoch': 36, 'time_epoch': 2.37593, 'loss': 0.1414843, 'lr': 0, 'params': 195018, 'time_iter': 0.05055, 'accuracy': 0.9664, 'f1': 0.96684, 'auc': 0.99835}\n",
      "test: {'epoch': 36, 'time_epoch': 2.37653, 'loss': 0.17549195, 'lr': 0, 'params': 195018, 'time_iter': 0.05056, 'accuracy': 0.9651, 'f1': 0.96571, 'auc': 0.99867}\n",
      "> Epoch 36: took 43.4s (avg 45.3s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 37, 'time_epoch': 39.00332, 'eta': 1490.81564, 'eta_hours': 0.41412, 'loss': 0.00463714, 'lr': 0.00056712, 'params': 195018, 'time_iter': 0.10457, 'accuracy': 0.99882, 'f1': 0.99882, 'auc': 1.0}\n",
      "val: {'epoch': 37, 'time_epoch': 2.35358, 'loss': 0.14198516, 'lr': 0, 'params': 195018, 'time_iter': 0.05008, 'accuracy': 0.96774, 'f1': 0.96873, 'auc': 0.99735}\n",
      "test: {'epoch': 37, 'time_epoch': 2.46776, 'loss': 0.19225411, 'lr': 0, 'params': 195018, 'time_iter': 0.05251, 'accuracy': 0.96107, 'f1': 0.96117, 'auc': 0.99852}\n",
      "> Epoch 37: took 43.9s (avg 45.3s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 38, 'time_epoch': 41.51734, 'eta': 1451.65412, 'eta_hours': 0.40324, 'loss': 0.0057846, 'lr': 0.00054482, 'params': 195018, 'time_iter': 0.11131, 'accuracy': 0.99849, 'f1': 0.99849, 'auc': 1.0}\n",
      "val: {'epoch': 38, 'time_epoch': 2.60354, 'loss': 0.14392035, 'lr': 0, 'params': 195018, 'time_iter': 0.05539, 'accuracy': 0.97715, 'f1': 0.97761, 'auc': 0.99785}\n",
      "test: {'epoch': 38, 'time_epoch': 2.50992, 'loss': 0.17378559, 'lr': 0, 'params': 195018, 'time_iter': 0.0534, 'accuracy': 0.9651, 'f1': 0.9655, 'auc': 0.99796}\n",
      "> Epoch 38: took 46.7s (avg 45.3s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 39, 'time_epoch': 41.09477, 'eta': 1412.00506, 'eta_hours': 0.39222, 'loss': 0.00946454, 'lr': 0.00052243, 'params': 195018, 'time_iter': 0.11017, 'accuracy': 0.99782, 'f1': 0.9978, 'auc': 0.99996}\n",
      "val: {'epoch': 39, 'time_epoch': 2.50884, 'loss': 0.14658349, 'lr': 0, 'params': 195018, 'time_iter': 0.05338, 'accuracy': 0.96909, 'f1': 0.9697, 'auc': 0.99679}\n",
      "test: {'epoch': 39, 'time_epoch': 2.62992, 'loss': 0.16618767, 'lr': 0, 'params': 195018, 'time_iter': 0.05596, 'accuracy': 0.96644, 'f1': 0.96605, 'auc': 0.99735}\n",
      "> Epoch 39: took 46.3s (avg 45.4s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 40, 'time_epoch': 41.79705, 'eta': 1372.86785, 'eta_hours': 0.38135, 'loss': 0.00675083, 'lr': 0.0005, 'params': 195018, 'time_iter': 0.11206, 'accuracy': 0.99782, 'f1': 0.99781, 'auc': 1.0}\n",
      "val: {'epoch': 40, 'time_epoch': 2.48736, 'loss': 0.13534534, 'lr': 0, 'params': 195018, 'time_iter': 0.05292, 'accuracy': 0.97312, 'f1': 0.97392, 'auc': 0.99697}\n",
      "test: {'epoch': 40, 'time_epoch': 2.48992, 'loss': 0.14214413, 'lr': 0, 'params': 195018, 'time_iter': 0.05298, 'accuracy': 0.97315, 'f1': 0.97277, 'auc': 0.99927}\n",
      "> Epoch 40: took 46.8s (avg 45.4s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 41, 'time_epoch': 41.50181, 'eta': 1333.37202, 'eta_hours': 0.37038, 'loss': 0.00381952, 'lr': 0.00047757, 'params': 195018, 'time_iter': 0.11126, 'accuracy': 0.99882, 'f1': 0.99882, 'auc': 1.0}\n",
      "val: {'epoch': 41, 'time_epoch': 2.62884, 'loss': 0.18678103, 'lr': 0, 'params': 195018, 'time_iter': 0.05593, 'accuracy': 0.96774, 'f1': 0.96843, 'auc': 0.99795}\n",
      "test: {'epoch': 41, 'time_epoch': 2.54872, 'loss': 0.16738438, 'lr': 0, 'params': 195018, 'time_iter': 0.05423, 'accuracy': 0.96242, 'f1': 0.96144, 'auc': 0.99896}\n",
      "> Epoch 41: took 46.7s (avg 45.4s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 42, 'time_epoch': 41.74477, 'eta': 1293.96368, 'eta_hours': 0.35943, 'loss': 0.00505319, 'lr': 0.00045518, 'params': 195018, 'time_iter': 0.11192, 'accuracy': 0.99882, 'f1': 0.99883, 'auc': 0.99999}\n",
      "val: {'epoch': 42, 'time_epoch': 2.50489, 'loss': 0.13068333, 'lr': 0, 'params': 195018, 'time_iter': 0.0533, 'accuracy': 0.97446, 'f1': 0.9749, 'auc': 0.99764}\n",
      "test: {'epoch': 42, 'time_epoch': 2.51936, 'loss': 0.14912317, 'lr': 0, 'params': 195018, 'time_iter': 0.0536, 'accuracy': 0.97315, 'f1': 0.97286, 'auc': 0.99924}\n",
      "> Epoch 42: took 46.8s (avg 45.5s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 43, 'time_epoch': 41.81569, 'eta': 1254.49912, 'eta_hours': 0.34847, 'loss': 0.00337702, 'lr': 0.00043288, 'params': 195018, 'time_iter': 0.11211, 'accuracy': 0.99899, 'f1': 0.99899, 'auc': 1.0}\n",
      "val: {'epoch': 43, 'time_epoch': 2.66873, 'loss': 0.20983519, 'lr': 0, 'params': 195018, 'time_iter': 0.05678, 'accuracy': 0.96909, 'f1': 0.96985, 'auc': 0.99576}\n",
      "test: {'epoch': 43, 'time_epoch': 2.62016, 'loss': 0.17548596, 'lr': 0, 'params': 195018, 'time_iter': 0.05575, 'accuracy': 0.96107, 'f1': 0.96179, 'auc': 0.99885}\n",
      "> Epoch 43: took 47.2s (avg 45.5s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 44, 'time_epoch': 42.88579, 'eta': 1215.64346, 'eta_hours': 0.33768, 'loss': 0.00250992, 'lr': 0.00041072, 'params': 195018, 'time_iter': 0.11498, 'accuracy': 0.99899, 'f1': 0.99898, 'auc': 1.0}\n",
      "val: {'epoch': 44, 'time_epoch': 2.69017, 'loss': 0.1611046, 'lr': 0, 'params': 195018, 'time_iter': 0.05724, 'accuracy': 0.97446, 'f1': 0.97466, 'auc': 0.99757}\n",
      "test: {'epoch': 44, 'time_epoch': 2.5299, 'loss': 0.1487553, 'lr': 0, 'params': 195018, 'time_iter': 0.05383, 'accuracy': 0.97047, 'f1': 0.97012, 'auc': 0.99904}\n",
      "> Epoch 44: took 48.2s (avg 45.6s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 45, 'time_epoch': 42.03456, 'eta': 1176.07593, 'eta_hours': 0.32669, 'loss': 0.00103186, 'lr': 0.00038874, 'params': 195018, 'time_iter': 0.11269, 'accuracy': 0.99966, 'f1': 0.99966, 'auc': 1.0}\n",
      "val: {'epoch': 45, 'time_epoch': 2.5595, 'loss': 0.15405067, 'lr': 0, 'params': 195018, 'time_iter': 0.05446, 'accuracy': 0.97177, 'f1': 0.97231, 'auc': 0.99753}\n",
      "test: {'epoch': 45, 'time_epoch': 2.37035, 'loss': 0.14435316, 'lr': 0, 'params': 195018, 'time_iter': 0.05043, 'accuracy': 0.97584, 'f1': 0.97559, 'auc': 0.99916}\n",
      "> Epoch 45: took 47.0s (avg 45.6s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 46, 'time_epoch': 42.12852, 'eta': 1136.45939, 'eta_hours': 0.31568, 'loss': 0.000519, 'lr': 0.00036698, 'params': 195018, 'time_iter': 0.11295, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 46, 'time_epoch': 2.54648, 'loss': 0.17042239, 'lr': 0, 'params': 195018, 'time_iter': 0.05418, 'accuracy': 0.97043, 'f1': 0.97102, 'auc': 0.99707}\n",
      "test: {'epoch': 46, 'time_epoch': 2.56047, 'loss': 0.15191338, 'lr': 0, 'params': 195018, 'time_iter': 0.05448, 'accuracy': 0.97315, 'f1': 0.97238, 'auc': 0.99889}\n",
      "> Epoch 46: took 47.3s (avg 45.6s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 47, 'time_epoch': 42.74174, 'eta': 1097.08313, 'eta_hours': 0.30475, 'loss': 0.00423133, 'lr': 0.00034549, 'params': 195018, 'time_iter': 0.11459, 'accuracy': 0.99899, 'f1': 0.99897, 'auc': 0.99999}\n",
      "val: {'epoch': 47, 'time_epoch': 2.75, 'loss': 0.14802511, 'lr': 0, 'params': 195018, 'time_iter': 0.05851, 'accuracy': 0.97312, 'f1': 0.97362, 'auc': 0.99863}\n",
      "test: {'epoch': 47, 'time_epoch': 2.69489, 'loss': 0.15638008, 'lr': 0, 'params': 195018, 'time_iter': 0.05734, 'accuracy': 0.96779, 'f1': 0.96679, 'auc': 0.99887}\n",
      "> Epoch 47: took 48.2s (avg 45.7s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 48, 'time_epoch': 41.92798, 'eta': 1057.13771, 'eta_hours': 0.29365, 'loss': 0.00227757, 'lr': 0.00032431, 'params': 195018, 'time_iter': 0.11241, 'accuracy': 0.9995, 'f1': 0.99949, 'auc': 1.0}\n",
      "val: {'epoch': 48, 'time_epoch': 2.74518, 'loss': 0.17822532, 'lr': 0, 'params': 195018, 'time_iter': 0.05841, 'accuracy': 0.9664, 'f1': 0.96693, 'auc': 0.99777}\n",
      "test: {'epoch': 48, 'time_epoch': 2.77756, 'loss': 0.19104816, 'lr': 0, 'params': 195018, 'time_iter': 0.0591, 'accuracy': 0.9651, 'f1': 0.96431, 'auc': 0.99909}\n",
      "> Epoch 48: took 47.5s (avg 45.7s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 49, 'time_epoch': 42.2305, 'eta': 1017.26424, 'eta_hours': 0.28257, 'loss': 0.0049319, 'lr': 0.00030349, 'params': 195018, 'time_iter': 0.11322, 'accuracy': 0.99916, 'f1': 0.99916, 'auc': 0.99991}\n",
      "val: {'epoch': 49, 'time_epoch': 2.93268, 'loss': 0.15811579, 'lr': 0, 'params': 195018, 'time_iter': 0.0624, 'accuracy': 0.97312, 'f1': 0.97343, 'auc': 0.9975}\n",
      "test: {'epoch': 49, 'time_epoch': 2.6286, 'loss': 0.15159454, 'lr': 0, 'params': 195018, 'time_iter': 0.05593, 'accuracy': 0.96779, 'f1': 0.96795, 'auc': 0.99929}\n",
      "> Epoch 49: took 47.8s (avg 45.8s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 50, 'time_epoch': 42.86794, 'eta': 977.59832, 'eta_hours': 0.27156, 'loss': 0.0018087, 'lr': 0.00028306, 'params': 195018, 'time_iter': 0.11493, 'accuracy': 0.9995, 'f1': 0.9995, 'auc': 1.0}\n",
      "val: {'epoch': 50, 'time_epoch': 2.5995, 'loss': 0.15966565, 'lr': 0, 'params': 195018, 'time_iter': 0.05531, 'accuracy': 0.96774, 'f1': 0.96838, 'auc': 0.99817}\n",
      "test: {'epoch': 50, 'time_epoch': 2.6261, 'loss': 0.15769683, 'lr': 0, 'params': 195018, 'time_iter': 0.05587, 'accuracy': 0.97181, 'f1': 0.97129, 'auc': 0.99873}\n",
      "> Epoch 50: took 48.1s (avg 45.8s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 51, 'time_epoch': 43.34281, 'eta': 938.01928, 'eta_hours': 0.26056, 'loss': 0.00308079, 'lr': 0.00026307, 'params': 195018, 'time_iter': 0.1162, 'accuracy': 0.99933, 'f1': 0.99932, 'auc': 0.99999}\n",
      "val: {'epoch': 51, 'time_epoch': 2.82055, 'loss': 0.15191696, 'lr': 0, 'params': 195018, 'time_iter': 0.06001, 'accuracy': 0.97446, 'f1': 0.97503, 'auc': 0.99796}\n",
      "test: {'epoch': 51, 'time_epoch': 2.81501, 'loss': 0.14383326, 'lr': 0, 'params': 195018, 'time_iter': 0.05989, 'accuracy': 0.97181, 'f1': 0.97105, 'auc': 0.99897}\n",
      "> Epoch 51: took 49.0s (avg 45.9s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 52, 'time_epoch': 44.28471, 'eta': 898.68918, 'eta_hours': 0.24964, 'loss': 0.00183751, 'lr': 0.00024355, 'params': 195018, 'time_iter': 0.11873, 'accuracy': 0.9995, 'f1': 0.9995, 'auc': 1.0}\n",
      "val: {'epoch': 52, 'time_epoch': 2.89195, 'loss': 0.15469846, 'lr': 0, 'params': 195018, 'time_iter': 0.06153, 'accuracy': 0.97446, 'f1': 0.97491, 'auc': 0.99696}\n",
      "test: {'epoch': 52, 'time_epoch': 2.71816, 'loss': 0.1643445, 'lr': 0, 'params': 195018, 'time_iter': 0.05783, 'accuracy': 0.96779, 'f1': 0.96688, 'auc': 0.99871}\n",
      "> Epoch 52: took 50.0s (avg 45.9s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 53, 'time_epoch': 43.32533, 'eta': 858.80249, 'eta_hours': 0.23856, 'loss': 0.00151713, 'lr': 0.00022455, 'params': 195018, 'time_iter': 0.11615, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 53, 'time_epoch': 2.53332, 'loss': 0.15607176, 'lr': 0, 'params': 195018, 'time_iter': 0.0539, 'accuracy': 0.97177, 'f1': 0.97209, 'auc': 0.99809}\n",
      "test: {'epoch': 53, 'time_epoch': 2.64902, 'loss': 0.17089126, 'lr': 0, 'params': 195018, 'time_iter': 0.05636, 'accuracy': 0.97181, 'f1': 0.97177, 'auc': 0.99854}\n",
      "> Epoch 53: took 48.6s (avg 46.0s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 54, 'time_epoch': 42.08512, 'eta': 818.33978, 'eta_hours': 0.22732, 'loss': 0.00063414, 'lr': 0.00020611, 'params': 195018, 'time_iter': 0.11283, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 54, 'time_epoch': 2.64305, 'loss': 0.16298904, 'lr': 0, 'params': 195018, 'time_iter': 0.05624, 'accuracy': 0.97312, 'f1': 0.9735, 'auc': 0.99807}\n",
      "test: {'epoch': 54, 'time_epoch': 2.81019, 'loss': 0.17951822, 'lr': 0, 'params': 195018, 'time_iter': 0.05979, 'accuracy': 0.96779, 'f1': 0.96757, 'auc': 0.99874}\n",
      "> Epoch 54: took 47.6s (avg 46.0s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 55, 'time_epoch': 43.25906, 'eta': 778.21742, 'eta_hours': 0.21617, 'loss': 0.0009334, 'lr': 0.00018826, 'params': 195018, 'time_iter': 0.11598, 'accuracy': 0.9995, 'f1': 0.9995, 'auc': 1.0}\n",
      "val: {'epoch': 55, 'time_epoch': 2.73395, 'loss': 0.20895018, 'lr': 0, 'params': 195018, 'time_iter': 0.05817, 'accuracy': 0.96505, 'f1': 0.96563, 'auc': 0.99646}\n",
      "test: {'epoch': 55, 'time_epoch': 2.6342, 'loss': 0.20511786, 'lr': 0, 'params': 195018, 'time_iter': 0.05605, 'accuracy': 0.96644, 'f1': 0.965, 'auc': 0.99819}\n",
      "> Epoch 55: took 48.7s (avg 46.1s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 56, 'time_epoch': 43.47827, 'eta': 738.05423, 'eta_hours': 0.20502, 'loss': 0.00045418, 'lr': 0.00017103, 'params': 195018, 'time_iter': 0.11656, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 56, 'time_epoch': 2.74986, 'loss': 0.17527619, 'lr': 0, 'params': 195018, 'time_iter': 0.05851, 'accuracy': 0.97043, 'f1': 0.97121, 'auc': 0.9972}\n",
      "test: {'epoch': 56, 'time_epoch': 2.58003, 'loss': 0.17720736, 'lr': 0, 'params': 195018, 'time_iter': 0.05489, 'accuracy': 0.96779, 'f1': 0.96711, 'auc': 0.99883}\n",
      "> Epoch 56: took 48.9s (avg 46.1s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 57, 'time_epoch': 43.14793, 'eta': 697.6799, 'eta_hours': 0.1938, 'loss': 0.00032678, 'lr': 0.00015447, 'params': 195018, 'time_iter': 0.11568, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 57, 'time_epoch': 2.8199, 'loss': 0.16199638, 'lr': 0, 'params': 195018, 'time_iter': 0.06, 'accuracy': 0.97446, 'f1': 0.97477, 'auc': 0.99814}\n",
      "test: {'epoch': 57, 'time_epoch': 2.61014, 'loss': 0.15602072, 'lr': 0, 'params': 195018, 'time_iter': 0.05553, 'accuracy': 0.96913, 'f1': 0.96858, 'auc': 0.99892}\n",
      "> Epoch 57: took 48.7s (avg 46.2s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 58, 'time_epoch': 43.2991, 'eta': 657.25254, 'eta_hours': 0.18257, 'loss': 0.0013149, 'lr': 0.0001386, 'params': 195018, 'time_iter': 0.11608, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 58, 'time_epoch': 2.6825, 'loss': 0.15411716, 'lr': 0, 'params': 195018, 'time_iter': 0.05707, 'accuracy': 0.97312, 'f1': 0.97344, 'auc': 0.99823}\n",
      "test: {'epoch': 58, 'time_epoch': 2.69656, 'loss': 0.15525355, 'lr': 0, 'params': 195018, 'time_iter': 0.05737, 'accuracy': 0.96913, 'f1': 0.96901, 'auc': 0.99921}\n",
      "> Epoch 58: took 48.7s (avg 46.2s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 59, 'time_epoch': 43.18726, 'eta': 616.70151, 'eta_hours': 0.17131, 'loss': 0.00023695, 'lr': 0.00012346, 'params': 195018, 'time_iter': 0.11578, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 59, 'time_epoch': 2.62519, 'loss': 0.15689218, 'lr': 0, 'params': 195018, 'time_iter': 0.05586, 'accuracy': 0.97312, 'f1': 0.97344, 'auc': 0.99821}\n",
      "test: {'epoch': 59, 'time_epoch': 2.94043, 'loss': 0.15627527, 'lr': 0, 'params': 195018, 'time_iter': 0.06256, 'accuracy': 0.97315, 'f1': 0.97279, 'auc': 0.99934}\n",
      "> Epoch 59: took 48.8s (avg 46.3s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 60, 'time_epoch': 43.04124, 'eta': 576.03052, 'eta_hours': 0.16001, 'loss': 0.00097153, 'lr': 0.00010908, 'params': 195018, 'time_iter': 0.11539, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 60, 'time_epoch': 2.31424, 'loss': 0.15105263, 'lr': 0, 'params': 195018, 'time_iter': 0.04924, 'accuracy': 0.97312, 'f1': 0.9736, 'auc': 0.9982}\n",
      "test: {'epoch': 60, 'time_epoch': 2.59858, 'loss': 0.15410172, 'lr': 0, 'params': 195018, 'time_iter': 0.05529, 'accuracy': 0.97181, 'f1': 0.97097, 'auc': 0.99908}\n",
      "> Epoch 60: took 48.0s (avg 46.3s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 61, 'time_epoch': 42.91162, 'eta': 535.25589, 'eta_hours': 0.14868, 'loss': 0.00021609, 'lr': 9.549e-05, 'params': 195018, 'time_iter': 0.11504, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 61, 'time_epoch': 2.48989, 'loss': 0.1545125, 'lr': 0, 'params': 195018, 'time_iter': 0.05298, 'accuracy': 0.97177, 'f1': 0.97216, 'auc': 0.99825}\n",
      "test: {'epoch': 61, 'time_epoch': 2.58418, 'loss': 0.15430543, 'lr': 0, 'params': 195018, 'time_iter': 0.05498, 'accuracy': 0.9745, 'f1': 0.97409, 'auc': 0.99901}\n",
      "> Epoch 61: took 48.0s (avg 46.3s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 62, 'time_epoch': 43.04117, 'eta': 494.43811, 'eta_hours': 0.13734, 'loss': 0.00022462, 'lr': 8.271e-05, 'params': 195018, 'time_iter': 0.11539, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 62, 'time_epoch': 2.55862, 'loss': 0.15505199, 'lr': 0, 'params': 195018, 'time_iter': 0.05444, 'accuracy': 0.97446, 'f1': 0.97482, 'auc': 0.99823}\n",
      "test: {'epoch': 62, 'time_epoch': 2.83324, 'loss': 0.15632916, 'lr': 0, 'params': 195018, 'time_iter': 0.06028, 'accuracy': 0.97181, 'f1': 0.97129, 'auc': 0.99911}\n",
      "> Epoch 62: took 48.5s (avg 46.3s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 63, 'time_epoch': 42.60427, 'eta': 453.47574, 'eta_hours': 0.12597, 'loss': 0.00151786, 'lr': 7.078e-05, 'params': 195018, 'time_iter': 0.11422, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 63, 'time_epoch': 2.55482, 'loss': 0.14724445, 'lr': 0, 'params': 195018, 'time_iter': 0.05436, 'accuracy': 0.97581, 'f1': 0.97626, 'auc': 0.99825}\n",
      "test: {'epoch': 63, 'time_epoch': 2.57334, 'loss': 0.15682478, 'lr': 0, 'params': 195018, 'time_iter': 0.05475, 'accuracy': 0.97047, 'f1': 0.97029, 'auc': 0.99917}\n",
      "> Epoch 63: took 47.8s (avg 46.4s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 64, 'time_epoch': 42.10165, 'eta': 412.38553, 'eta_hours': 0.11455, 'loss': 0.00024852, 'lr': 5.97e-05, 'params': 195018, 'time_iter': 0.11287, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 64, 'time_epoch': 2.67619, 'loss': 0.15683952, 'lr': 0, 'params': 195018, 'time_iter': 0.05694, 'accuracy': 0.97581, 'f1': 0.97623, 'auc': 0.99828}\n",
      "test: {'epoch': 64, 'time_epoch': 2.81377, 'loss': 0.15854383, 'lr': 0, 'params': 195018, 'time_iter': 0.05987, 'accuracy': 0.97315, 'f1': 0.97245, 'auc': 0.99916}\n",
      "> Epoch 64: took 47.7s (avg 46.4s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 65, 'time_epoch': 43.31121, 'eta': 371.42962, 'eta_hours': 0.10317, 'loss': 0.00165425, 'lr': 4.952e-05, 'params': 195018, 'time_iter': 0.11612, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 65, 'time_epoch': 2.87068, 'loss': 0.14913498, 'lr': 0, 'params': 195018, 'time_iter': 0.06108, 'accuracy': 0.97715, 'f1': 0.97756, 'auc': 0.99821}\n",
      "test: {'epoch': 65, 'time_epoch': 2.90151, 'loss': 0.1627845, 'lr': 0, 'params': 195018, 'time_iter': 0.06173, 'accuracy': 0.97315, 'f1': 0.97242, 'auc': 0.99927}\n",
      "> Epoch 65: took 49.1s (avg 46.4s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 66, 'time_epoch': 44.53509, 'eta': 330.54953, 'eta_hours': 0.09182, 'loss': 0.00019385, 'lr': 4.024e-05, 'params': 195018, 'time_iter': 0.1194, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 66, 'time_epoch': 2.62043, 'loss': 0.15004438, 'lr': 0, 'params': 195018, 'time_iter': 0.05575, 'accuracy': 0.97581, 'f1': 0.97627, 'auc': 0.99827}\n",
      "test: {'epoch': 66, 'time_epoch': 2.55364, 'loss': 0.15860631, 'lr': 0, 'params': 195018, 'time_iter': 0.05433, 'accuracy': 0.9745, 'f1': 0.9737, 'auc': 0.99918}\n",
      "> Epoch 66: took 49.8s (avg 46.5s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 67, 'time_epoch': 43.95587, 'eta': 289.50231, 'eta_hours': 0.08042, 'loss': 0.00018924, 'lr': 3.188e-05, 'params': 195018, 'time_iter': 0.11784, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 67, 'time_epoch': 2.48904, 'loss': 0.16257066, 'lr': 0, 'params': 195018, 'time_iter': 0.05296, 'accuracy': 0.97446, 'f1': 0.97499, 'auc': 0.99819}\n",
      "test: {'epoch': 67, 'time_epoch': 2.9149, 'loss': 0.15437871, 'lr': 0, 'params': 195018, 'time_iter': 0.06202, 'accuracy': 0.97047, 'f1': 0.96978, 'auc': 0.99925}\n",
      "> Epoch 67: took 49.4s (avg 46.5s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 68, 'time_epoch': 42.46879, 'eta': 248.24147, 'eta_hours': 0.06896, 'loss': 0.0001806, 'lr': 2.447e-05, 'params': 195018, 'time_iter': 0.11386, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 68, 'time_epoch': 2.4595, 'loss': 0.14271454, 'lr': 0, 'params': 195018, 'time_iter': 0.05233, 'accuracy': 0.97581, 'f1': 0.97627, 'auc': 0.99831}\n",
      "test: {'epoch': 68, 'time_epoch': 2.55321, 'loss': 0.15544177, 'lr': 0, 'params': 195018, 'time_iter': 0.05432, 'accuracy': 0.97315, 'f1': 0.97241, 'auc': 0.99915}\n",
      "> Epoch 68: took 47.5s (avg 46.5s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 69, 'time_epoch': 41.08083, 'eta': 206.84698, 'eta_hours': 0.05746, 'loss': 0.00173231, 'lr': 1.802e-05, 'params': 195018, 'time_iter': 0.11014, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 69, 'time_epoch': 2.51416, 'loss': 0.15071101, 'lr': 0, 'params': 195018, 'time_iter': 0.05349, 'accuracy': 0.97581, 'f1': 0.9762, 'auc': 0.99816}\n",
      "test: {'epoch': 69, 'time_epoch': 2.79511, 'loss': 0.15748502, 'lr': 0, 'params': 195018, 'time_iter': 0.05947, 'accuracy': 0.97181, 'f1': 0.97163, 'auc': 0.99918}\n",
      "> Epoch 69: took 46.4s (avg 46.5s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 70, 'time_epoch': 41.51178, 'eta': 165.48561, 'eta_hours': 0.04597, 'loss': 0.00021977, 'lr': 1.254e-05, 'params': 195018, 'time_iter': 0.11129, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 70, 'time_epoch': 2.51089, 'loss': 0.14645621, 'lr': 0, 'params': 195018, 'time_iter': 0.05342, 'accuracy': 0.97581, 'f1': 0.97619, 'auc': 0.9983}\n",
      "test: {'epoch': 70, 'time_epoch': 2.6499, 'loss': 0.15856897, 'lr': 0, 'params': 195018, 'time_iter': 0.05638, 'accuracy': 0.9745, 'f1': 0.97363, 'auc': 0.99912}\n",
      "> Epoch 70: took 46.7s (avg 46.5s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 71, 'time_epoch': 41.83249, 'eta': 124.13342, 'eta_hours': 0.03448, 'loss': 0.00017508, 'lr': 8.04e-06, 'params': 195018, 'time_iter': 0.11215, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 71, 'time_epoch': 2.47828, 'loss': 0.15183868, 'lr': 0, 'params': 195018, 'time_iter': 0.05273, 'accuracy': 0.97446, 'f1': 0.97491, 'auc': 0.99836}\n",
      "test: {'epoch': 71, 'time_epoch': 2.56277, 'loss': 0.15790754, 'lr': 0, 'params': 195018, 'time_iter': 0.05453, 'accuracy': 0.97315, 'f1': 0.97243, 'auc': 0.99907}\n",
      "> Epoch 71: took 46.9s (avg 46.5s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 72, 'time_epoch': 43.27357, 'eta': 82.80755, 'eta_hours': 0.023, 'loss': 0.00017451, 'lr': 4.53e-06, 'params': 195018, 'time_iter': 0.11601, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 72, 'time_epoch': 2.41227, 'loss': 0.13912558, 'lr': 0, 'params': 195018, 'time_iter': 0.05132, 'accuracy': 0.97715, 'f1': 0.97756, 'auc': 0.99826}\n",
      "test: {'epoch': 72, 'time_epoch': 2.66549, 'loss': 0.15454128, 'lr': 0, 'params': 195018, 'time_iter': 0.05671, 'accuracy': 0.9745, 'f1': 0.97363, 'auc': 0.99916}\n",
      "> Epoch 72: took 48.4s (avg 46.6s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 73, 'time_epoch': 43.79695, 'eta': 41.43612, 'eta_hours': 0.01151, 'loss': 0.00017379, 'lr': 2.01e-06, 'params': 195018, 'time_iter': 0.11742, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 73, 'time_epoch': 2.61698, 'loss': 0.14550658, 'lr': 0, 'params': 195018, 'time_iter': 0.05568, 'accuracy': 0.97715, 'f1': 0.97756, 'auc': 0.99833}\n",
      "test: {'epoch': 73, 'time_epoch': 2.82218, 'loss': 0.16312946, 'lr': 0, 'params': 195018, 'time_iter': 0.06005, 'accuracy': 0.97315, 'f1': 0.97243, 'auc': 0.99915}\n",
      "> Epoch 73: took 49.3s (avg 46.6s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "train: {'epoch': 74, 'time_epoch': 43.05218, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.00017685, 'lr': 5e-07, 'params': 195018, 'time_iter': 0.11542, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 74, 'time_epoch': 2.7783, 'loss': 0.14099439, 'lr': 0, 'params': 195018, 'time_iter': 0.05911, 'accuracy': 0.97581, 'f1': 0.97618, 'auc': 0.99829}\n",
      "test: {'epoch': 74, 'time_epoch': 2.77997, 'loss': 0.15149494, 'lr': 0, 'params': 195018, 'time_iter': 0.05915, 'accuracy': 0.97181, 'f1': 0.97124, 'auc': 0.99911}\n",
      "> Epoch 74: took 48.7s (avg 46.6s) | Best so far: epoch 35\ttrain_loss: 0.0095 train_accuracy: 0.9977\tval_loss: 0.1013 val_accuracy: 0.9785\ttest_loss: 0.1578 test_accuracy: 0.9678\n",
      "Avg time per epoch: 46.63s\n",
      "Total train loop time: 0.97h\n",
      "Task done, results saved in results\\neural-Act\\0\n",
      "35\n",
      "{'epoch': 35, 'time_epoch': 2.36558, 'loss': 0.15779826, 'lr': 0, 'params': 195018, 'time_iter': 0.05033, 'accuracy': 0.96779, 'f1': 0.96743, 'auc': 0.99876}\n",
      "{'epoch': 35, 'time_epoch': 39.51752, 'eta': 1574.5956, 'eta_hours': 0.43739, 'loss': 0.00945409, 'lr': 0.00061126, 'params': 195018, 'time_iter': 0.10595, 'accuracy': 0.99765, 'f1': 0.99762, 'auc': 0.99999}\n",
      "{'epoch': 35, 'time_epoch': 2.35948, 'loss': 0.10125417, 'lr': 0, 'params': 195018, 'time_iter': 0.0502, 'accuracy': 0.97849, 'f1': 0.97878, 'auc': 0.99826}\n",
      "Results aggregated across runs saved in results\\neural-Act\\agg\n",
      "[*] All done: 2024-03-03 01:45:07.727912\n"
     ]
    }
   ],
   "source": [
    "#CustomGatedGCN+Exphormer dropout 0.3 attn dropout 0.3\n",
    "%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86faad40-7160-4907-81ae-835e020ba4dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-03 01:48:31.428645\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 7\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [03:48<00:00, 32.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:03:51.10\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [00:58<00:00, 126.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:00.86\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=400, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.5\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: CustomGatedGCN+Exphormer\n",
      "  layers: 3\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 75\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 195018\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 42.52701, 'eta': 3146.99856, 'eta_hours': 0.87417, 'loss': 1.95332376, 'lr': 0.0, 'params': 195018, 'time_iter': 0.11401, 'accuracy': 0.13084, 'f1': 0.09133, 'auc': 0.50006}\n",
      "...computing epoch stats took: 0.18s\n",
      "val: {'epoch': 0, 'time_epoch': 2.62269, 'loss': 1.94766249, 'lr': 0, 'params': 195018, 'time_iter': 0.0558, 'accuracy': 0.14113, 'f1': 0.08972, 'auc': 0.51275}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 0, 'time_epoch': 2.80006, 'loss': 1.94955251, 'lr': 0, 'params': 195018, 'time_iter': 0.05958, 'accuracy': 0.13557, 'f1': 0.08282, 'auc': 0.47465}\n",
      "...computing epoch stats took: 0.03s\n",
      "> Epoch 0: took 48.2s (avg 48.2s) | Best so far: epoch 0\ttrain_loss: 1.9533 train_accuracy: 0.1308\tval_loss: 1.9477 val_accuracy: 0.1411\ttest_loss: 1.9496 test_accuracy: 0.1356\n",
      "train: {'epoch': 1, 'time_epoch': 39.93768, 'eta': 3009.961, 'eta_hours': 0.8361, 'loss': 1.72585922, 'lr': 0.0002, 'params': 195018, 'time_iter': 0.10707, 'accuracy': 0.59405, 'f1': 0.58412, 'auc': 0.89351}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 1, 'time_epoch': 2.37152, 'loss': 1.55338115, 'lr': 0, 'params': 195018, 'time_iter': 0.05046, 'accuracy': 0.76747, 'f1': 0.76924, 'auc': 0.96314}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 2.54685, 'loss': 1.54370647, 'lr': 0, 'params': 195018, 'time_iter': 0.05419, 'accuracy': 0.79597, 'f1': 0.78923, 'auc': 0.96823}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 1: took 44.9s (avg 46.6s) | Best so far: epoch 1\ttrain_loss: 1.7259 train_accuracy: 0.5940\tval_loss: 1.5534 val_accuracy: 0.7675\ttest_loss: 1.5437 test_accuracy: 0.7960\n",
      "train: {'epoch': 2, 'time_epoch': 40.40542, 'eta': 2948.88242, 'eta_hours': 0.81913, 'loss': 1.32677665, 'lr': 0.0004, 'params': 195018, 'time_iter': 0.10833, 'accuracy': 0.85673, 'f1': 0.85555, 'auc': 0.97618}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 2.59, 'loss': 1.14407507, 'lr': 0, 'params': 195018, 'time_iter': 0.05511, 'accuracy': 0.85887, 'f1': 0.85859, 'auc': 0.98607}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 2.62021, 'loss': 1.13381493, 'lr': 0, 'params': 195018, 'time_iter': 0.05575, 'accuracy': 0.86577, 'f1': 0.86431, 'auc': 0.9882}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 2: took 45.7s (avg 46.3s) | Best so far: epoch 2\ttrain_loss: 1.3268 train_accuracy: 0.8567\tval_loss: 1.1441 val_accuracy: 0.8589\ttest_loss: 1.1338 test_accuracy: 0.8658\n",
      "train: {'epoch': 3, 'time_epoch': 41.7213, 'eta': 2921.49739, 'eta_hours': 0.81153, 'loss': 0.90856688, 'lr': 0.0006, 'params': 195018, 'time_iter': 0.11185, 'accuracy': 0.91669, 'f1': 0.91625, 'auc': 0.98627}\n",
      "val: {'epoch': 3, 'time_epoch': 2.45922, 'loss': 0.75543052, 'lr': 0, 'params': 195018, 'time_iter': 0.05232, 'accuracy': 0.90726, 'f1': 0.90908, 'auc': 0.9927}\n",
      "test: {'epoch': 3, 'time_epoch': 2.59219, 'loss': 0.76005698, 'lr': 0, 'params': 195018, 'time_iter': 0.05515, 'accuracy': 0.89799, 'f1': 0.90122, 'auc': 0.99118}\n",
      "> Epoch 3: took 46.8s (avg 46.4s) | Best so far: epoch 3\ttrain_loss: 0.9086 train_accuracy: 0.9167\tval_loss: 0.7554 val_accuracy: 0.9073\ttest_loss: 0.7601 test_accuracy: 0.8980\n",
      "train: {'epoch': 4, 'time_epoch': 42.72386, 'eta': 2902.4137, 'eta_hours': 0.80623, 'loss': 0.58245649, 'lr': 0.0008, 'params': 195018, 'time_iter': 0.11454, 'accuracy': 0.93719, 'f1': 0.93692, 'auc': 0.99157}\n",
      "val: {'epoch': 4, 'time_epoch': 2.63046, 'loss': 0.47391306, 'lr': 0, 'params': 195018, 'time_iter': 0.05597, 'accuracy': 0.93952, 'f1': 0.94098, 'auc': 0.99148}\n",
      "test: {'epoch': 4, 'time_epoch': 2.65134, 'loss': 0.44209386, 'lr': 0, 'params': 195018, 'time_iter': 0.05641, 'accuracy': 0.95034, 'f1': 0.9496, 'auc': 0.99293}\n",
      "> Epoch 4: took 48.1s (avg 46.7s) | Best so far: epoch 4\ttrain_loss: 0.5825 train_accuracy: 0.9372\tval_loss: 0.4739 val_accuracy: 0.9395\ttest_loss: 0.4421 test_accuracy: 0.9503\n",
      "train: {'epoch': 5, 'time_epoch': 41.64399, 'eta': 2863.03137, 'eta_hours': 0.79529, 'loss': 0.38825844, 'lr': 0.001, 'params': 195018, 'time_iter': 0.11165, 'accuracy': 0.94222, 'f1': 0.94195, 'auc': 0.99318}\n",
      "val: {'epoch': 5, 'time_epoch': 2.6003, 'loss': 0.29531958, 'lr': 0, 'params': 195018, 'time_iter': 0.05533, 'accuracy': 0.9543, 'f1': 0.95532, 'auc': 0.9968}\n",
      "test: {'epoch': 5, 'time_epoch': 2.68392, 'loss': 0.28224547, 'lr': 0, 'params': 195018, 'time_iter': 0.0571, 'accuracy': 0.96376, 'f1': 0.96424, 'auc': 0.99557}\n",
      "> Epoch 5: took 47.0s (avg 46.8s) | Best so far: epoch 5\ttrain_loss: 0.3883 train_accuracy: 0.9422\tval_loss: 0.2953 val_accuracy: 0.9543\ttest_loss: 0.2822 test_accuracy: 0.9638\n",
      "train: {'epoch': 6, 'time_epoch': 41.8455, 'eta': 2824.96044, 'eta_hours': 0.78471, 'loss': 0.25544845, 'lr': 0.0009995, 'params': 195018, 'time_iter': 0.11219, 'accuracy': 0.957, 'f1': 0.95684, 'auc': 0.9964}\n",
      "val: {'epoch': 6, 'time_epoch': 2.66863, 'loss': 0.42598895, 'lr': 0, 'params': 195018, 'time_iter': 0.05678, 'accuracy': 0.87903, 'f1': 0.88829, 'auc': 0.99042}\n",
      "test: {'epoch': 6, 'time_epoch': 2.67373, 'loss': 0.40384664, 'lr': 0, 'params': 195018, 'time_iter': 0.05689, 'accuracy': 0.89933, 'f1': 0.90573, 'auc': 0.98826}\n",
      "> Epoch 6: took 47.3s (avg 46.8s) | Best so far: epoch 5\ttrain_loss: 0.3883 train_accuracy: 0.9422\tval_loss: 0.2953 val_accuracy: 0.9543\ttest_loss: 0.2822 test_accuracy: 0.9638\n",
      "train: {'epoch': 7, 'time_epoch': 43.08806, 'eta': 2796.35227, 'eta_hours': 0.77676, 'loss': 0.19756048, 'lr': 0.00099799, 'params': 195018, 'time_iter': 0.11552, 'accuracy': 0.96339, 'f1': 0.96331, 'auc': 0.99684}\n",
      "val: {'epoch': 7, 'time_epoch': 2.5302, 'loss': 0.26509066, 'lr': 0, 'params': 195018, 'time_iter': 0.05383, 'accuracy': 0.94086, 'f1': 0.94171, 'auc': 0.99433}\n",
      "test: {'epoch': 7, 'time_epoch': 2.62547, 'loss': 0.22153983, 'lr': 0, 'params': 195018, 'time_iter': 0.05586, 'accuracy': 0.95168, 'f1': 0.95183, 'auc': 0.9934}\n",
      "> Epoch 7: took 48.3s (avg 47.0s) | Best so far: epoch 5\ttrain_loss: 0.3883 train_accuracy: 0.9422\tval_loss: 0.2953 val_accuracy: 0.9543\ttest_loss: 0.2822 test_accuracy: 0.9638\n",
      "train: {'epoch': 8, 'time_epoch': 42.00664, 'eta': 2756.59596, 'eta_hours': 0.76572, 'loss': 0.1635268, 'lr': 0.00099547, 'params': 195018, 'time_iter': 0.11262, 'accuracy': 0.9654, 'f1': 0.96532, 'auc': 0.99796}\n",
      "val: {'epoch': 8, 'time_epoch': 2.69516, 'loss': 0.25049892, 'lr': 0, 'params': 195018, 'time_iter': 0.05734, 'accuracy': 0.92876, 'f1': 0.93155, 'auc': 0.99636}\n",
      "test: {'epoch': 8, 'time_epoch': 2.57679, 'loss': 0.23326575, 'lr': 0, 'params': 195018, 'time_iter': 0.05483, 'accuracy': 0.93154, 'f1': 0.93216, 'auc': 0.99405}\n",
      "> Epoch 8: took 47.3s (avg 47.1s) | Best so far: epoch 5\ttrain_loss: 0.3883 train_accuracy: 0.9422\tval_loss: 0.2953 val_accuracy: 0.9543\ttest_loss: 0.2822 test_accuracy: 0.9638\n",
      "train: {'epoch': 9, 'time_epoch': 43.71693, 'eta': 2727.50649, 'eta_hours': 0.75764, 'loss': 0.12058584, 'lr': 0.00099196, 'params': 195018, 'time_iter': 0.1172, 'accuracy': 0.97598, 'f1': 0.97592, 'auc': 0.99859}\n",
      "val: {'epoch': 9, 'time_epoch': 2.715, 'loss': 0.17322708, 'lr': 0, 'params': 195018, 'time_iter': 0.05777, 'accuracy': 0.96102, 'f1': 0.96153, 'auc': 0.99621}\n",
      "test: {'epoch': 9, 'time_epoch': 2.73638, 'loss': 0.17947671, 'lr': 0, 'params': 195018, 'time_iter': 0.05822, 'accuracy': 0.95436, 'f1': 0.95382, 'auc': 0.99824}\n",
      "> Epoch 9: took 49.2s (avg 47.3s) | Best so far: epoch 9\ttrain_loss: 0.1206 train_accuracy: 0.9760\tval_loss: 0.1732 val_accuracy: 0.9610\ttest_loss: 0.1795 test_accuracy: 0.9544\n",
      "train: {'epoch': 10, 'time_epoch': 43.84377, 'eta': 2696.49544, 'eta_hours': 0.74903, 'loss': 0.0923905, 'lr': 0.00098746, 'params': 195018, 'time_iter': 0.11754, 'accuracy': 0.97934, 'f1': 0.97935, 'auc': 0.99933}\n",
      "val: {'epoch': 10, 'time_epoch': 2.45169, 'loss': 0.29533338, 'lr': 0, 'params': 195018, 'time_iter': 0.05216, 'accuracy': 0.93011, 'f1': 0.9341, 'auc': 0.9908}\n",
      "test: {'epoch': 10, 'time_epoch': 2.66522, 'loss': 0.3645694, 'lr': 0, 'params': 195018, 'time_iter': 0.05671, 'accuracy': 0.9047, 'f1': 0.91122, 'auc': 0.9903}\n",
      "> Epoch 10: took 49.0s (avg 47.4s) | Best so far: epoch 9\ttrain_loss: 0.1206 train_accuracy: 0.9760\tval_loss: 0.1732 val_accuracy: 0.9610\ttest_loss: 0.1795 test_accuracy: 0.9544\n",
      "train: {'epoch': 11, 'time_epoch': 42.69611, 'eta': 2657.32039, 'eta_hours': 0.73814, 'loss': 0.08828903, 'lr': 0.00098198, 'params': 195018, 'time_iter': 0.11447, 'accuracy': 0.9785, 'f1': 0.9784, 'auc': 0.99928}\n",
      "val: {'epoch': 11, 'time_epoch': 2.57505, 'loss': 0.18016552, 'lr': 0, 'params': 195018, 'time_iter': 0.05479, 'accuracy': 0.9543, 'f1': 0.95522, 'auc': 0.99771}\n",
      "test: {'epoch': 11, 'time_epoch': 2.68891, 'loss': 0.17854931, 'lr': 0, 'params': 195018, 'time_iter': 0.05721, 'accuracy': 0.95973, 'f1': 0.96012, 'auc': 0.99619}\n",
      "> Epoch 11: took 48.0s (avg 47.5s) | Best so far: epoch 9\ttrain_loss: 0.1206 train_accuracy: 0.9760\tval_loss: 0.1732 val_accuracy: 0.9610\ttest_loss: 0.1795 test_accuracy: 0.9544\n",
      "train: {'epoch': 12, 'time_epoch': 43.16697, 'eta': 2619.8493, 'eta_hours': 0.72774, 'loss': 0.07063381, 'lr': 0.00097553, 'params': 195018, 'time_iter': 0.11573, 'accuracy': 0.98404, 'f1': 0.98397, 'auc': 0.99966}\n",
      "val: {'epoch': 12, 'time_epoch': 2.56954, 'loss': 0.13706202, 'lr': 0, 'params': 195018, 'time_iter': 0.05467, 'accuracy': 0.96237, 'f1': 0.96272, 'auc': 0.99903}\n",
      "test: {'epoch': 12, 'time_epoch': 2.58066, 'loss': 0.1714533, 'lr': 0, 'params': 195018, 'time_iter': 0.05491, 'accuracy': 0.9557, 'f1': 0.95443, 'auc': 0.99839}\n",
      "> Epoch 12: took 48.4s (avg 47.6s) | Best so far: epoch 12\ttrain_loss: 0.0706 train_accuracy: 0.9840\tval_loss: 0.1371 val_accuracy: 0.9624\ttest_loss: 0.1715 test_accuracy: 0.9557\n",
      "train: {'epoch': 13, 'time_epoch': 42.92956, 'eta': 2580.53005, 'eta_hours': 0.71681, 'loss': 0.05671476, 'lr': 0.00096812, 'params': 195018, 'time_iter': 0.11509, 'accuracy': 0.98673, 'f1': 0.98673, 'auc': 0.99966}\n",
      "val: {'epoch': 13, 'time_epoch': 2.62917, 'loss': 0.33094551, 'lr': 0, 'params': 195018, 'time_iter': 0.05594, 'accuracy': 0.91935, 'f1': 0.92318, 'auc': 0.99025}\n",
      "test: {'epoch': 13, 'time_epoch': 2.6252, 'loss': 0.30363185, 'lr': 0, 'params': 195018, 'time_iter': 0.05586, 'accuracy': 0.92215, 'f1': 0.9221, 'auc': 0.99452}\n",
      "> Epoch 13: took 48.2s (avg 47.6s) | Best so far: epoch 12\ttrain_loss: 0.0706 train_accuracy: 0.9840\tval_loss: 0.1371 val_accuracy: 0.9624\ttest_loss: 0.1715 test_accuracy: 0.9557\n",
      "train: {'epoch': 14, 'time_epoch': 43.42345, 'eta': 2542.70498, 'eta_hours': 0.70631, 'loss': 0.06573044, 'lr': 0.00095976, 'params': 195018, 'time_iter': 0.11642, 'accuracy': 0.9832, 'f1': 0.98321, 'auc': 0.99923}\n",
      "val: {'epoch': 14, 'time_epoch': 2.51331, 'loss': 0.11648942, 'lr': 0, 'params': 195018, 'time_iter': 0.05347, 'accuracy': 0.97312, 'f1': 0.97369, 'auc': 0.99746}\n",
      "test: {'epoch': 14, 'time_epoch': 2.61125, 'loss': 0.1541057, 'lr': 0, 'params': 195018, 'time_iter': 0.05556, 'accuracy': 0.96242, 'f1': 0.96243, 'auc': 0.99683}\n",
      "> Epoch 14: took 48.6s (avg 47.7s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 15, 'time_epoch': 42.06857, 'eta': 2499.184, 'eta_hours': 0.69422, 'loss': 0.05195546, 'lr': 0.00095048, 'params': 195018, 'time_iter': 0.11278, 'accuracy': 0.98707, 'f1': 0.98705, 'auc': 0.99956}\n",
      "val: {'epoch': 15, 'time_epoch': 2.58443, 'loss': 0.26161595, 'lr': 0, 'params': 195018, 'time_iter': 0.05499, 'accuracy': 0.9422, 'f1': 0.94507, 'auc': 0.9951}\n",
      "test: {'epoch': 15, 'time_epoch': 2.58965, 'loss': 0.23328619, 'lr': 0, 'params': 195018, 'time_iter': 0.0551, 'accuracy': 0.9396, 'f1': 0.9401, 'auc': 0.997}\n",
      "> Epoch 15: took 47.3s (avg 47.6s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 16, 'time_epoch': 42.14425, 'eta': 2456.09209, 'eta_hours': 0.68225, 'loss': 0.04753712, 'lr': 0.0009403, 'params': 195018, 'time_iter': 0.11299, 'accuracy': 0.98791, 'f1': 0.98787, 'auc': 0.99974}\n",
      "val: {'epoch': 16, 'time_epoch': 2.46608, 'loss': 0.18249159, 'lr': 0, 'params': 195018, 'time_iter': 0.05247, 'accuracy': 0.9543, 'f1': 0.95474, 'auc': 0.99742}\n",
      "test: {'epoch': 16, 'time_epoch': 2.72222, 'loss': 0.18787887, 'lr': 0, 'params': 195018, 'time_iter': 0.05792, 'accuracy': 0.95705, 'f1': 0.95626, 'auc': 0.99781}\n",
      "> Epoch 16: took 47.4s (avg 47.6s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 17, 'time_epoch': 43.79833, 'eta': 2418.34342, 'eta_hours': 0.67176, 'loss': 0.04350925, 'lr': 0.00092922, 'params': 195018, 'time_iter': 0.11742, 'accuracy': 0.98925, 'f1': 0.98924, 'auc': 0.99969}\n",
      "val: {'epoch': 17, 'time_epoch': 2.69449, 'loss': 0.12099929, 'lr': 0, 'params': 195018, 'time_iter': 0.05733, 'accuracy': 0.97177, 'f1': 0.97225, 'auc': 0.99856}\n",
      "test: {'epoch': 17, 'time_epoch': 2.71906, 'loss': 0.13586281, 'lr': 0, 'params': 195018, 'time_iter': 0.05785, 'accuracy': 0.9651, 'f1': 0.96485, 'auc': 0.99812}\n",
      "> Epoch 17: took 49.3s (avg 47.7s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 18, 'time_epoch': 43.65251, 'eta': 2379.52814, 'eta_hours': 0.66098, 'loss': 0.03587233, 'lr': 0.00091729, 'params': 195018, 'time_iter': 0.11703, 'accuracy': 0.99227, 'f1': 0.99228, 'auc': 0.99959}\n",
      "val: {'epoch': 18, 'time_epoch': 2.58323, 'loss': 0.17747763, 'lr': 0, 'params': 195018, 'time_iter': 0.05496, 'accuracy': 0.95699, 'f1': 0.95791, 'auc': 0.99626}\n",
      "test: {'epoch': 18, 'time_epoch': 2.61716, 'loss': 0.14231894, 'lr': 0, 'params': 195018, 'time_iter': 0.05568, 'accuracy': 0.96779, 'f1': 0.96727, 'auc': 0.99701}\n",
      "> Epoch 18: took 48.9s (avg 47.8s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 19, 'time_epoch': 43.15046, 'eta': 2338.84849, 'eta_hours': 0.64968, 'loss': 0.03285329, 'lr': 0.00090451, 'params': 195018, 'time_iter': 0.11568, 'accuracy': 0.9911, 'f1': 0.99108, 'auc': 0.99986}\n",
      "val: {'epoch': 19, 'time_epoch': 2.62254, 'loss': 0.19961026, 'lr': 0, 'params': 195018, 'time_iter': 0.0558, 'accuracy': 0.94892, 'f1': 0.9502, 'auc': 0.99694}\n",
      "test: {'epoch': 19, 'time_epoch': 2.5582, 'loss': 0.17990891, 'lr': 0, 'params': 195018, 'time_iter': 0.05443, 'accuracy': 0.95168, 'f1': 0.94994, 'auc': 0.99787}\n",
      "> Epoch 19: took 48.4s (avg 47.8s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 20, 'time_epoch': 41.63428, 'eta': 2294.03479, 'eta_hours': 0.63723, 'loss': 0.03262349, 'lr': 0.00089092, 'params': 195018, 'time_iter': 0.11162, 'accuracy': 0.99059, 'f1': 0.99051, 'auc': 0.99982}\n",
      "val: {'epoch': 20, 'time_epoch': 2.53882, 'loss': 0.14627279, 'lr': 0, 'params': 195018, 'time_iter': 0.05402, 'accuracy': 0.96505, 'f1': 0.96612, 'auc': 0.99869}\n",
      "test: {'epoch': 20, 'time_epoch': 2.53873, 'loss': 0.15882964, 'lr': 0, 'params': 195018, 'time_iter': 0.05402, 'accuracy': 0.96376, 'f1': 0.96382, 'auc': 0.99711}\n",
      "> Epoch 20: took 46.8s (avg 47.8s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 21, 'time_epoch': 41.89736, 'eta': 2250.14392, 'eta_hours': 0.62504, 'loss': 0.03389357, 'lr': 0.00087654, 'params': 195018, 'time_iter': 0.11233, 'accuracy': 0.99211, 'f1': 0.9921, 'auc': 0.99977}\n",
      "val: {'epoch': 21, 'time_epoch': 2.56441, 'loss': 0.19612888, 'lr': 0, 'params': 195018, 'time_iter': 0.05456, 'accuracy': 0.95699, 'f1': 0.9576, 'auc': 0.99643}\n",
      "test: {'epoch': 21, 'time_epoch': 2.75408, 'loss': 0.20793995, 'lr': 0, 'params': 195018, 'time_iter': 0.0586, 'accuracy': 0.9557, 'f1': 0.95482, 'auc': 0.99729}\n",
      "> Epoch 21: took 47.3s (avg 47.7s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 22, 'time_epoch': 41.98987, 'eta': 2206.63554, 'eta_hours': 0.61295, 'loss': 0.02841033, 'lr': 0.0008614, 'params': 195018, 'time_iter': 0.11257, 'accuracy': 0.99177, 'f1': 0.99178, 'auc': 0.99992}\n",
      "val: {'epoch': 22, 'time_epoch': 2.60658, 'loss': 0.1451436, 'lr': 0, 'params': 195018, 'time_iter': 0.05546, 'accuracy': 0.97043, 'f1': 0.97097, 'auc': 0.9962}\n",
      "test: {'epoch': 22, 'time_epoch': 2.61382, 'loss': 0.15252542, 'lr': 0, 'params': 195018, 'time_iter': 0.05561, 'accuracy': 0.96644, 'f1': 0.96546, 'auc': 0.99811}\n",
      "> Epoch 22: took 47.3s (avg 47.7s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 23, 'time_epoch': 42.61282, 'eta': 2164.57748, 'eta_hours': 0.60127, 'loss': 0.03121671, 'lr': 0.00084553, 'params': 195018, 'time_iter': 0.11424, 'accuracy': 0.99143, 'f1': 0.99145, 'auc': 0.99991}\n",
      "val: {'epoch': 23, 'time_epoch': 2.52073, 'loss': 0.19138809, 'lr': 0, 'params': 195018, 'time_iter': 0.05363, 'accuracy': 0.95296, 'f1': 0.95399, 'auc': 0.9986}\n",
      "test: {'epoch': 23, 'time_epoch': 2.68106, 'loss': 0.22501764, 'lr': 0, 'params': 195018, 'time_iter': 0.05704, 'accuracy': 0.9557, 'f1': 0.95639, 'auc': 0.99601}\n",
      "> Epoch 23: took 47.9s (avg 47.7s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 24, 'time_epoch': 44.81894, 'eta': 2126.88728, 'eta_hours': 0.5908, 'loss': 0.02316601, 'lr': 0.00082897, 'params': 195018, 'time_iter': 0.12016, 'accuracy': 0.99379, 'f1': 0.99377, 'auc': 0.99996}\n",
      "val: {'epoch': 24, 'time_epoch': 2.99862, 'loss': 0.11912184, 'lr': 0, 'params': 195018, 'time_iter': 0.0638, 'accuracy': 0.96774, 'f1': 0.96829, 'auc': 0.99903}\n",
      "test: {'epoch': 24, 'time_epoch': 2.77839, 'loss': 0.16494407, 'lr': 0, 'params': 195018, 'time_iter': 0.05911, 'accuracy': 0.96242, 'f1': 0.96191, 'auc': 0.99836}\n",
      "> Epoch 24: took 50.7s (avg 47.8s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 25, 'time_epoch': 44.02782, 'eta': 2087.15775, 'eta_hours': 0.57977, 'loss': 0.02322895, 'lr': 0.00081174, 'params': 195018, 'time_iter': 0.11804, 'accuracy': 0.99395, 'f1': 0.99393, 'auc': 0.99994}\n",
      "val: {'epoch': 25, 'time_epoch': 2.5821, 'loss': 0.13427598, 'lr': 0, 'params': 195018, 'time_iter': 0.05494, 'accuracy': 0.97177, 'f1': 0.97224, 'auc': 0.99877}\n",
      "test: {'epoch': 25, 'time_epoch': 2.77755, 'loss': 0.16271173, 'lr': 0, 'params': 195018, 'time_iter': 0.0591, 'accuracy': 0.9651, 'f1': 0.96402, 'auc': 0.99749}\n",
      "> Epoch 25: took 49.4s (avg 47.9s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 26, 'time_epoch': 44.08794, 'eta': 2047.21672, 'eta_hours': 0.56867, 'loss': 0.0183078, 'lr': 0.00079389, 'params': 195018, 'time_iter': 0.1182, 'accuracy': 0.99597, 'f1': 0.99597, 'auc': 0.99992}\n",
      "val: {'epoch': 26, 'time_epoch': 2.67843, 'loss': 0.13494378, 'lr': 0, 'params': 195018, 'time_iter': 0.05699, 'accuracy': 0.97312, 'f1': 0.97357, 'auc': 0.99774}\n",
      "test: {'epoch': 26, 'time_epoch': 2.58632, 'loss': 0.16223327, 'lr': 0, 'params': 195018, 'time_iter': 0.05503, 'accuracy': 0.97047, 'f1': 0.97022, 'auc': 0.99732}\n",
      "> Epoch 26: took 49.4s (avg 48.0s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 27, 'time_epoch': 43.49798, 'eta': 2005.98919, 'eta_hours': 0.55722, 'loss': 0.01529262, 'lr': 0.00077545, 'params': 195018, 'time_iter': 0.11662, 'accuracy': 0.99597, 'f1': 0.99593, 'auc': 0.99995}\n",
      "val: {'epoch': 27, 'time_epoch': 2.65283, 'loss': 0.18786352, 'lr': 0, 'params': 195018, 'time_iter': 0.05644, 'accuracy': 0.96237, 'f1': 0.963, 'auc': 0.99648}\n",
      "test: {'epoch': 27, 'time_epoch': 2.69969, 'loss': 0.20994535, 'lr': 0, 'params': 195018, 'time_iter': 0.05744, 'accuracy': 0.95705, 'f1': 0.95543, 'auc': 0.99624}\n",
      "> Epoch 27: took 48.9s (avg 48.0s) | Best so far: epoch 14\ttrain_loss: 0.0657 train_accuracy: 0.9832\tval_loss: 0.1165 val_accuracy: 0.9731\ttest_loss: 0.1541 test_accuracy: 0.9624\n",
      "train: {'epoch': 28, 'time_epoch': 41.86516, 'eta': 1962.01507, 'eta_hours': 0.545, 'loss': 0.01473367, 'lr': 0.00075645, 'params': 195018, 'time_iter': 0.11224, 'accuracy': 0.99563, 'f1': 0.99564, 'auc': 0.99998}\n",
      "val: {'epoch': 28, 'time_epoch': 2.64571, 'loss': 0.1065044, 'lr': 0, 'params': 195018, 'time_iter': 0.05629, 'accuracy': 0.97984, 'f1': 0.98014, 'auc': 0.99788}\n",
      "test: {'epoch': 28, 'time_epoch': 2.62144, 'loss': 0.14547547, 'lr': 0, 'params': 195018, 'time_iter': 0.05578, 'accuracy': 0.9745, 'f1': 0.97423, 'auc': 0.998}\n",
      "> Epoch 28: took 47.2s (avg 48.0s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 29, 'time_epoch': 41.77219, 'eta': 1918.04211, 'eta_hours': 0.53279, 'loss': 0.01264602, 'lr': 0.00073693, 'params': 195018, 'time_iter': 0.11199, 'accuracy': 0.99681, 'f1': 0.99678, 'auc': 0.99998}\n",
      "val: {'epoch': 29, 'time_epoch': 2.57908, 'loss': 0.13688747, 'lr': 0, 'params': 195018, 'time_iter': 0.05487, 'accuracy': 0.97581, 'f1': 0.97594, 'auc': 0.99805}\n",
      "test: {'epoch': 29, 'time_epoch': 2.62186, 'loss': 0.23559713, 'lr': 0, 'params': 195018, 'time_iter': 0.05578, 'accuracy': 0.95168, 'f1': 0.95255, 'auc': 0.99825}\n",
      "> Epoch 29: took 47.0s (avg 47.9s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 30, 'time_epoch': 41.85545, 'eta': 1874.3293, 'eta_hours': 0.52065, 'loss': 0.0072008, 'lr': 0.00071694, 'params': 195018, 'time_iter': 0.11221, 'accuracy': 0.99765, 'f1': 0.99765, 'auc': 0.99999}\n",
      "val: {'epoch': 30, 'time_epoch': 2.65259, 'loss': 0.15002394, 'lr': 0, 'params': 195018, 'time_iter': 0.05644, 'accuracy': 0.97312, 'f1': 0.97385, 'auc': 0.998}\n",
      "test: {'epoch': 30, 'time_epoch': 2.60453, 'loss': 0.17340807, 'lr': 0, 'params': 195018, 'time_iter': 0.05542, 'accuracy': 0.9651, 'f1': 0.96305, 'auc': 0.99715}\n",
      "> Epoch 30: took 47.2s (avg 47.9s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 31, 'time_epoch': 42.09826, 'eta': 1831.05886, 'eta_hours': 0.50863, 'loss': 0.00757612, 'lr': 0.00069651, 'params': 195018, 'time_iter': 0.11286, 'accuracy': 0.99866, 'f1': 0.99864, 'auc': 0.99999}\n",
      "val: {'epoch': 31, 'time_epoch': 2.49915, 'loss': 0.13289743, 'lr': 0, 'params': 195018, 'time_iter': 0.05317, 'accuracy': 0.97043, 'f1': 0.97123, 'auc': 0.99749}\n",
      "test: {'epoch': 31, 'time_epoch': 2.70713, 'loss': 0.18720954, 'lr': 0, 'params': 195018, 'time_iter': 0.0576, 'accuracy': 0.9651, 'f1': 0.96394, 'auc': 0.99758}\n",
      "> Epoch 31: took 47.4s (avg 47.9s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 32, 'time_epoch': 41.58376, 'eta': 1787.20463, 'eta_hours': 0.49645, 'loss': 0.02717681, 'lr': 0.00067569, 'params': 195018, 'time_iter': 0.11148, 'accuracy': 0.99227, 'f1': 0.99226, 'auc': 0.99982}\n",
      "val: {'epoch': 32, 'time_epoch': 2.64885, 'loss': 0.15016691, 'lr': 0, 'params': 195018, 'time_iter': 0.05636, 'accuracy': 0.96505, 'f1': 0.96562, 'auc': 0.99799}\n",
      "test: {'epoch': 32, 'time_epoch': 2.5449, 'loss': 0.17295465, 'lr': 0, 'params': 195018, 'time_iter': 0.05415, 'accuracy': 0.97181, 'f1': 0.97133, 'auc': 0.99734}\n",
      "> Epoch 32: took 46.8s (avg 47.9s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 33, 'time_epoch': 42.8862, 'eta': 1745.05456, 'eta_hours': 0.48474, 'loss': 0.01594151, 'lr': 0.00065451, 'params': 195018, 'time_iter': 0.11498, 'accuracy': 0.99563, 'f1': 0.99562, 'auc': 0.99997}\n",
      "val: {'epoch': 33, 'time_epoch': 2.61908, 'loss': 0.2219346, 'lr': 0, 'params': 195018, 'time_iter': 0.05573, 'accuracy': 0.96102, 'f1': 0.96172, 'auc': 0.99771}\n",
      "test: {'epoch': 33, 'time_epoch': 2.77147, 'loss': 0.24109694, 'lr': 0, 'params': 195018, 'time_iter': 0.05897, 'accuracy': 0.9557, 'f1': 0.95377, 'auc': 0.99671}\n",
      "> Epoch 33: took 48.3s (avg 47.9s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 34, 'time_epoch': 44.464, 'eta': 1704.66562, 'eta_hours': 0.47352, 'loss': 0.01366764, 'lr': 0.00063302, 'params': 195018, 'time_iter': 0.11921, 'accuracy': 0.99597, 'f1': 0.99594, 'auc': 0.99997}\n",
      "val: {'epoch': 34, 'time_epoch': 2.78506, 'loss': 0.12640003, 'lr': 0, 'params': 195018, 'time_iter': 0.05926, 'accuracy': 0.97446, 'f1': 0.97492, 'auc': 0.99908}\n",
      "test: {'epoch': 34, 'time_epoch': 2.6884, 'loss': 0.17681631, 'lr': 0, 'params': 195018, 'time_iter': 0.0572, 'accuracy': 0.96644, 'f1': 0.96635, 'auc': 0.99762}\n",
      "> Epoch 34: took 50.0s (avg 47.9s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 35, 'time_epoch': 42.00248, 'eta': 1661.38363, 'eta_hours': 0.4615, 'loss': 0.00616362, 'lr': 0.00061126, 'params': 195018, 'time_iter': 0.11261, 'accuracy': 0.99832, 'f1': 0.99832, 'auc': 1.0}\n",
      "val: {'epoch': 35, 'time_epoch': 2.87851, 'loss': 0.14383744, 'lr': 0, 'params': 195018, 'time_iter': 0.06124, 'accuracy': 0.97446, 'f1': 0.9747, 'auc': 0.99859}\n",
      "test: {'epoch': 35, 'time_epoch': 2.52213, 'loss': 0.20775955, 'lr': 0, 'params': 195018, 'time_iter': 0.05366, 'accuracy': 0.96644, 'f1': 0.96629, 'auc': 0.99507}\n",
      "> Epoch 35: took 47.5s (avg 47.9s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 36, 'time_epoch': 41.69073, 'eta': 1617.85063, 'eta_hours': 0.4494, 'loss': 0.00162336, 'lr': 0.00058928, 'params': 195018, 'time_iter': 0.11177, 'accuracy': 0.99983, 'f1': 0.99984, 'auc': 1.0}\n",
      "val: {'epoch': 36, 'time_epoch': 2.65571, 'loss': 0.14575449, 'lr': 0, 'params': 195018, 'time_iter': 0.0565, 'accuracy': 0.97446, 'f1': 0.97536, 'auc': 0.99831}\n",
      "test: {'epoch': 36, 'time_epoch': 2.53418, 'loss': 0.18711826, 'lr': 0, 'params': 195018, 'time_iter': 0.05392, 'accuracy': 0.96913, 'f1': 0.9689, 'auc': 0.9958}\n",
      "> Epoch 36: took 46.9s (avg 47.9s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 37, 'time_epoch': 41.72913, 'eta': 1574.45199, 'eta_hours': 0.43735, 'loss': 0.00885217, 'lr': 0.00056712, 'params': 195018, 'time_iter': 0.11187, 'accuracy': 0.99782, 'f1': 0.99782, 'auc': 0.99996}\n",
      "val: {'epoch': 37, 'time_epoch': 2.63719, 'loss': 0.15620818, 'lr': 0, 'params': 195018, 'time_iter': 0.05611, 'accuracy': 0.96774, 'f1': 0.9688, 'auc': 0.99819}\n",
      "test: {'epoch': 37, 'time_epoch': 2.4554, 'loss': 0.19871453, 'lr': 0, 'params': 195018, 'time_iter': 0.05224, 'accuracy': 0.96644, 'f1': 0.96506, 'auc': 0.99825}\n",
      "> Epoch 37: took 46.9s (avg 47.9s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 38, 'time_epoch': 41.78747, 'eta': 1531.19282, 'eta_hours': 0.42533, 'loss': 0.00716828, 'lr': 0.00054482, 'params': 195018, 'time_iter': 0.11203, 'accuracy': 0.99782, 'f1': 0.9978, 'auc': 0.99999}\n",
      "val: {'epoch': 38, 'time_epoch': 2.51291, 'loss': 0.11380455, 'lr': 0, 'params': 195018, 'time_iter': 0.05347, 'accuracy': 0.97715, 'f1': 0.97767, 'auc': 0.99919}\n",
      "test: {'epoch': 38, 'time_epoch': 2.52515, 'loss': 0.17504686, 'lr': 0, 'params': 195018, 'time_iter': 0.05373, 'accuracy': 0.97047, 'f1': 0.96972, 'auc': 0.9983}\n",
      "> Epoch 38: took 46.9s (avg 47.8s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 39, 'time_epoch': 41.69908, 'eta': 1487.92988, 'eta_hours': 0.41331, 'loss': 0.00190014, 'lr': 0.00052243, 'params': 195018, 'time_iter': 0.11179, 'accuracy': 0.9995, 'f1': 0.99949, 'auc': 1.0}\n",
      "val: {'epoch': 39, 'time_epoch': 2.51127, 'loss': 0.12852385, 'lr': 0, 'params': 195018, 'time_iter': 0.05343, 'accuracy': 0.97581, 'f1': 0.97641, 'auc': 0.99913}\n",
      "test: {'epoch': 39, 'time_epoch': 2.6473, 'loss': 0.18654682, 'lr': 0, 'params': 195018, 'time_iter': 0.05633, 'accuracy': 0.9651, 'f1': 0.96433, 'auc': 0.99854}\n",
      "> Epoch 39: took 46.9s (avg 47.8s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 40, 'time_epoch': 42.53711, 'eta': 1445.43819, 'eta_hours': 0.40151, 'loss': 0.00313561, 'lr': 0.0005, 'params': 195018, 'time_iter': 0.11404, 'accuracy': 0.99916, 'f1': 0.99916, 'auc': 0.99998}\n",
      "val: {'epoch': 40, 'time_epoch': 2.62472, 'loss': 0.14348683, 'lr': 0, 'params': 195018, 'time_iter': 0.05585, 'accuracy': 0.97581, 'f1': 0.97631, 'auc': 0.9986}\n",
      "test: {'epoch': 40, 'time_epoch': 2.66806, 'loss': 0.18029456, 'lr': 0, 'params': 195018, 'time_iter': 0.05677, 'accuracy': 0.96913, 'f1': 0.96827, 'auc': 0.99683}\n",
      "> Epoch 40: took 47.9s (avg 47.8s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 41, 'time_epoch': 41.90437, 'eta': 1402.44718, 'eta_hours': 0.38957, 'loss': 0.00449692, 'lr': 0.00047757, 'params': 195018, 'time_iter': 0.11234, 'accuracy': 0.99866, 'f1': 0.99868, 'auc': 1.0}\n",
      "val: {'epoch': 41, 'time_epoch': 2.6413, 'loss': 0.17851434, 'lr': 0, 'params': 195018, 'time_iter': 0.0562, 'accuracy': 0.96774, 'f1': 0.96842, 'auc': 0.99713}\n",
      "test: {'epoch': 41, 'time_epoch': 2.66446, 'loss': 0.24072846, 'lr': 0, 'params': 195018, 'time_iter': 0.05669, 'accuracy': 0.95705, 'f1': 0.95605, 'auc': 0.99561}\n",
      "> Epoch 41: took 47.3s (avg 47.8s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 42, 'time_epoch': 41.61024, 'eta': 1359.28783, 'eta_hours': 0.37758, 'loss': 0.01065352, 'lr': 0.00045518, 'params': 195018, 'time_iter': 0.11156, 'accuracy': 0.99765, 'f1': 0.99764, 'auc': 0.99998}\n",
      "val: {'epoch': 42, 'time_epoch': 2.48143, 'loss': 0.14058229, 'lr': 0, 'params': 195018, 'time_iter': 0.0528, 'accuracy': 0.97312, 'f1': 0.97363, 'auc': 0.9984}\n",
      "test: {'epoch': 42, 'time_epoch': 2.54191, 'loss': 0.20563909, 'lr': 0, 'params': 195018, 'time_iter': 0.05408, 'accuracy': 0.9651, 'f1': 0.96406, 'auc': 0.99629}\n",
      "> Epoch 42: took 46.7s (avg 47.8s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 43, 'time_epoch': 39.88642, 'eta': 1314.98438, 'eta_hours': 0.36527, 'loss': 0.00332734, 'lr': 0.00043288, 'params': 195018, 'time_iter': 0.10693, 'accuracy': 0.99916, 'f1': 0.99917, 'auc': 1.0}\n",
      "val: {'epoch': 43, 'time_epoch': 2.38577, 'loss': 0.16158544, 'lr': 0, 'params': 195018, 'time_iter': 0.05076, 'accuracy': 0.97177, 'f1': 0.97236, 'auc': 0.99836}\n",
      "test: {'epoch': 43, 'time_epoch': 2.39074, 'loss': 0.17334472, 'lr': 0, 'params': 195018, 'time_iter': 0.05087, 'accuracy': 0.96913, 'f1': 0.96879, 'auc': 0.99896}\n",
      "> Epoch 43: took 44.7s (avg 47.7s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 44, 'time_epoch': 39.22265, 'eta': 1270.43473, 'eta_hours': 0.3529, 'loss': 0.00154959, 'lr': 0.00041072, 'params': 195018, 'time_iter': 0.10515, 'accuracy': 0.99966, 'f1': 0.99966, 'auc': 1.0}\n",
      "val: {'epoch': 44, 'time_epoch': 2.31121, 'loss': 0.13799433, 'lr': 0, 'params': 195018, 'time_iter': 0.04917, 'accuracy': 0.97446, 'f1': 0.97471, 'auc': 0.99934}\n",
      "test: {'epoch': 44, 'time_epoch': 2.34046, 'loss': 0.19988578, 'lr': 0, 'params': 195018, 'time_iter': 0.0498, 'accuracy': 0.9651, 'f1': 0.96439, 'auc': 0.99763}\n",
      "> Epoch 44: took 43.9s (avg 47.6s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 45, 'time_epoch': 38.99215, 'eta': 1225.97137, 'eta_hours': 0.34055, 'loss': 0.00481078, 'lr': 0.00038874, 'params': 195018, 'time_iter': 0.10454, 'accuracy': 0.99899, 'f1': 0.99898, 'auc': 1.0}\n",
      "val: {'epoch': 45, 'time_epoch': 2.35556, 'loss': 0.16126245, 'lr': 0, 'params': 195018, 'time_iter': 0.05012, 'accuracy': 0.97043, 'f1': 0.97108, 'auc': 0.99899}\n",
      "test: {'epoch': 45, 'time_epoch': 2.41634, 'loss': 0.21003368, 'lr': 0, 'params': 195018, 'time_iter': 0.05141, 'accuracy': 0.96644, 'f1': 0.96566, 'auc': 0.99881}\n",
      "> Epoch 45: took 43.8s (avg 47.5s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 46, 'time_epoch': 41.72434, 'eta': 1183.36851, 'eta_hours': 0.32871, 'loss': 0.00521191, 'lr': 0.00036698, 'params': 195018, 'time_iter': 0.11186, 'accuracy': 0.99882, 'f1': 0.99882, 'auc': 1.0}\n",
      "val: {'epoch': 46, 'time_epoch': 2.70429, 'loss': 0.1963978, 'lr': 0, 'params': 195018, 'time_iter': 0.05754, 'accuracy': 0.96505, 'f1': 0.96585, 'auc': 0.99768}\n",
      "test: {'epoch': 46, 'time_epoch': 2.65219, 'loss': 0.17410354, 'lr': 0, 'params': 195018, 'time_iter': 0.05643, 'accuracy': 0.97181, 'f1': 0.97085, 'auc': 0.99804}\n",
      "> Epoch 46: took 47.1s (avg 47.5s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 47, 'time_epoch': 42.36072, 'eta': 1141.16023, 'eta_hours': 0.31699, 'loss': 0.00563186, 'lr': 0.00034549, 'params': 195018, 'time_iter': 0.11357, 'accuracy': 0.99866, 'f1': 0.99864, 'auc': 0.99999}\n",
      "val: {'epoch': 47, 'time_epoch': 2.70331, 'loss': 0.16878531, 'lr': 0, 'params': 195018, 'time_iter': 0.05752, 'accuracy': 0.97177, 'f1': 0.97209, 'auc': 0.99836}\n",
      "test: {'epoch': 47, 'time_epoch': 2.77065, 'loss': 0.18919665, 'lr': 0, 'params': 195018, 'time_iter': 0.05895, 'accuracy': 0.96644, 'f1': 0.96546, 'auc': 0.99833}\n",
      "> Epoch 47: took 47.9s (avg 47.5s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 48, 'time_epoch': 42.64334, 'eta': 1099.09568, 'eta_hours': 0.3053, 'loss': 0.00214904, 'lr': 0.00032431, 'params': 195018, 'time_iter': 0.11433, 'accuracy': 0.99916, 'f1': 0.99916, 'auc': 1.0}\n",
      "val: {'epoch': 48, 'time_epoch': 2.8325, 'loss': 0.16371441, 'lr': 0, 'params': 195018, 'time_iter': 0.06027, 'accuracy': 0.97043, 'f1': 0.97087, 'auc': 0.99792}\n",
      "test: {'epoch': 48, 'time_epoch': 2.71648, 'loss': 0.17248132, 'lr': 0, 'params': 195018, 'time_iter': 0.0578, 'accuracy': 0.9745, 'f1': 0.97339, 'auc': 0.99808}\n",
      "> Epoch 48: took 48.2s (avg 47.6s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 49, 'time_epoch': 43.3354, 'eta': 1057.35402, 'eta_hours': 0.29371, 'loss': 0.00464266, 'lr': 0.00030349, 'params': 195018, 'time_iter': 0.11618, 'accuracy': 0.99933, 'f1': 0.99931, 'auc': 0.99986}\n",
      "val: {'epoch': 49, 'time_epoch': 2.80426, 'loss': 0.12188321, 'lr': 0, 'params': 195018, 'time_iter': 0.05967, 'accuracy': 0.97581, 'f1': 0.97609, 'auc': 0.99893}\n",
      "test: {'epoch': 49, 'time_epoch': 2.55601, 'loss': 0.17946904, 'lr': 0, 'params': 195018, 'time_iter': 0.05438, 'accuracy': 0.96913, 'f1': 0.96887, 'auc': 0.99865}\n",
      "> Epoch 49: took 48.8s (avg 47.6s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 50, 'time_epoch': 42.56097, 'eta': 1015.18542, 'eta_hours': 0.282, 'loss': 0.00248724, 'lr': 0.00028306, 'params': 195018, 'time_iter': 0.1141, 'accuracy': 0.99916, 'f1': 0.99916, 'auc': 1.0}\n",
      "val: {'epoch': 50, 'time_epoch': 2.61842, 'loss': 0.15730864, 'lr': 0, 'params': 195018, 'time_iter': 0.05571, 'accuracy': 0.97312, 'f1': 0.9735, 'auc': 0.99877}\n",
      "test: {'epoch': 50, 'time_epoch': 2.6805, 'loss': 0.18895899, 'lr': 0, 'params': 195018, 'time_iter': 0.05703, 'accuracy': 0.96376, 'f1': 0.96432, 'auc': 0.99873}\n",
      "> Epoch 50: took 47.9s (avg 47.6s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 51, 'time_epoch': 42.00411, 'eta': 972.75542, 'eta_hours': 0.27021, 'loss': 0.0010033, 'lr': 0.00026307, 'params': 195018, 'time_iter': 0.11261, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 51, 'time_epoch': 2.65328, 'loss': 0.16117285, 'lr': 0, 'params': 195018, 'time_iter': 0.05645, 'accuracy': 0.97312, 'f1': 0.9737, 'auc': 0.99898}\n",
      "test: {'epoch': 51, 'time_epoch': 2.54933, 'loss': 0.16566612, 'lr': 0, 'params': 195018, 'time_iter': 0.05424, 'accuracy': 0.97047, 'f1': 0.97061, 'auc': 0.99868}\n",
      "> Epoch 51: took 47.3s (avg 47.6s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 52, 'time_epoch': 42.2729, 'eta': 930.45307, 'eta_hours': 0.25846, 'loss': 0.0003557, 'lr': 0.00024355, 'params': 195018, 'time_iter': 0.11333, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 52, 'time_epoch': 2.74665, 'loss': 0.16177345, 'lr': 0, 'params': 195018, 'time_iter': 0.05844, 'accuracy': 0.97312, 'f1': 0.97358, 'auc': 0.99909}\n",
      "test: {'epoch': 52, 'time_epoch': 2.64207, 'loss': 0.17213972, 'lr': 0, 'params': 195018, 'time_iter': 0.05621, 'accuracy': 0.96913, 'f1': 0.96879, 'auc': 0.99885}\n",
      "> Epoch 52: took 47.7s (avg 47.6s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 53, 'time_epoch': 43.33797, 'eta': 888.566, 'eta_hours': 0.24682, 'loss': 0.00029996, 'lr': 0.00022455, 'params': 195018, 'time_iter': 0.11619, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 53, 'time_epoch': 2.53581, 'loss': 0.1501804, 'lr': 0, 'params': 195018, 'time_iter': 0.05395, 'accuracy': 0.97446, 'f1': 0.97492, 'auc': 0.99934}\n",
      "test: {'epoch': 53, 'time_epoch': 2.80567, 'loss': 0.17216994, 'lr': 0, 'params': 195018, 'time_iter': 0.0597, 'accuracy': 0.97181, 'f1': 0.97168, 'auc': 0.99893}\n",
      "> Epoch 53: took 48.7s (avg 47.6s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 54, 'time_epoch': 41.81106, 'eta': 846.07093, 'eta_hours': 0.23502, 'loss': 0.00028168, 'lr': 0.00020611, 'params': 195018, 'time_iter': 0.11209, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 54, 'time_epoch': 2.6004, 'loss': 0.15505797, 'lr': 0, 'params': 195018, 'time_iter': 0.05533, 'accuracy': 0.97446, 'f1': 0.97491, 'auc': 0.99866}\n",
      "test: {'epoch': 54, 'time_epoch': 2.70549, 'loss': 0.17244086, 'lr': 0, 'params': 195018, 'time_iter': 0.05756, 'accuracy': 0.96644, 'f1': 0.96646, 'auc': 0.99901}\n",
      "> Epoch 54: took 47.2s (avg 47.6s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 55, 'time_epoch': 43.32235, 'eta': 804.11305, 'eta_hours': 0.22336, 'loss': 0.00026786, 'lr': 0.00018826, 'params': 195018, 'time_iter': 0.11615, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 55, 'time_epoch': 2.61503, 'loss': 0.15011327, 'lr': 0, 'params': 195018, 'time_iter': 0.05564, 'accuracy': 0.97581, 'f1': 0.97625, 'auc': 0.99906}\n",
      "test: {'epoch': 55, 'time_epoch': 2.72695, 'loss': 0.18322222, 'lr': 0, 'params': 195018, 'time_iter': 0.05802, 'accuracy': 0.96913, 'f1': 0.96907, 'auc': 0.99897}\n",
      "> Epoch 55: took 48.7s (avg 47.6s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 56, 'time_epoch': 43.33068, 'eta': 762.10993, 'eta_hours': 0.2117, 'loss': 0.00028643, 'lr': 0.00017103, 'params': 195018, 'time_iter': 0.11617, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 56, 'time_epoch': 2.64284, 'loss': 0.16002848, 'lr': 0, 'params': 195018, 'time_iter': 0.05623, 'accuracy': 0.97715, 'f1': 0.9775, 'auc': 0.99851}\n",
      "test: {'epoch': 56, 'time_epoch': 2.78314, 'loss': 0.19303925, 'lr': 0, 'params': 195018, 'time_iter': 0.05922, 'accuracy': 0.96779, 'f1': 0.96761, 'auc': 0.99874}\n",
      "> Epoch 56: took 48.8s (avg 47.6s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 57, 'time_epoch': 43.24902, 'eta': 720.03709, 'eta_hours': 0.20001, 'loss': 0.00058429, 'lr': 0.00015447, 'params': 195018, 'time_iter': 0.11595, 'accuracy': 0.99983, 'f1': 0.99984, 'auc': 1.0}\n",
      "val: {'epoch': 57, 'time_epoch': 2.89576, 'loss': 0.14280076, 'lr': 0, 'params': 195018, 'time_iter': 0.06161, 'accuracy': 0.97715, 'f1': 0.97764, 'auc': 0.99859}\n",
      "test: {'epoch': 57, 'time_epoch': 2.68754, 'loss': 0.19089352, 'lr': 0, 'params': 195018, 'time_iter': 0.05718, 'accuracy': 0.96913, 'f1': 0.96904, 'auc': 0.99883}\n",
      "> Epoch 57: took 48.9s (avg 47.7s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 58, 'time_epoch': 43.90739, 'eta': 678.10292, 'eta_hours': 0.18836, 'loss': 0.00143783, 'lr': 0.0001386, 'params': 195018, 'time_iter': 0.11771, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 58, 'time_epoch': 2.73598, 'loss': 0.14346022, 'lr': 0, 'params': 195018, 'time_iter': 0.05821, 'accuracy': 0.97715, 'f1': 0.97752, 'auc': 0.99894}\n",
      "test: {'epoch': 58, 'time_epoch': 2.84865, 'loss': 0.18717049, 'lr': 0, 'params': 195018, 'time_iter': 0.06061, 'accuracy': 0.96913, 'f1': 0.96888, 'auc': 0.99869}\n",
      "> Epoch 58: took 49.5s (avg 47.7s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 59, 'time_epoch': 43.73077, 'eta': 636.05882, 'eta_hours': 0.17668, 'loss': 0.00034941, 'lr': 0.00012346, 'params': 195018, 'time_iter': 0.11724, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 59, 'time_epoch': 2.52571, 'loss': 0.1571849, 'lr': 0, 'params': 195018, 'time_iter': 0.05374, 'accuracy': 0.97849, 'f1': 0.97885, 'auc': 0.99861}\n",
      "test: {'epoch': 59, 'time_epoch': 2.59603, 'loss': 0.20533005, 'lr': 0, 'params': 195018, 'time_iter': 0.05523, 'accuracy': 0.96644, 'f1': 0.96656, 'auc': 0.99748}\n",
      "> Epoch 59: took 48.9s (avg 47.7s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 60, 'time_epoch': 43.00749, 'eta': 593.79342, 'eta_hours': 0.16494, 'loss': 0.00048526, 'lr': 0.00010908, 'params': 195018, 'time_iter': 0.1153, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 60, 'time_epoch': 2.73817, 'loss': 0.13963735, 'lr': 0, 'params': 195018, 'time_iter': 0.05826, 'accuracy': 0.97849, 'f1': 0.97898, 'auc': 0.99895}\n",
      "test: {'epoch': 60, 'time_epoch': 2.64576, 'loss': 0.19879895, 'lr': 0, 'params': 195018, 'time_iter': 0.05629, 'accuracy': 0.97047, 'f1': 0.97022, 'auc': 0.99813}\n",
      "> Epoch 60: took 48.5s (avg 47.7s) | Best so far: epoch 28\ttrain_loss: 0.0147 train_accuracy: 0.9956\tval_loss: 0.1065 val_accuracy: 0.9798\ttest_loss: 0.1455 test_accuracy: 0.9745\n",
      "train: {'epoch': 61, 'time_epoch': 41.73938, 'eta': 551.23819, 'eta_hours': 0.15312, 'loss': 0.00022633, 'lr': 9.549e-05, 'params': 195018, 'time_iter': 0.1119, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 61, 'time_epoch': 2.67582, 'loss': 0.13350881, 'lr': 0, 'params': 195018, 'time_iter': 0.05693, 'accuracy': 0.98118, 'f1': 0.98164, 'auc': 0.99908}\n",
      "test: {'epoch': 61, 'time_epoch': 2.58209, 'loss': 0.18886283, 'lr': 0, 'params': 195018, 'time_iter': 0.05494, 'accuracy': 0.96913, 'f1': 0.96892, 'auc': 0.99833}\n",
      "> Epoch 61: took 47.1s (avg 47.7s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 62, 'time_epoch': 42.44356, 'eta': 508.84299, 'eta_hours': 0.14135, 'loss': 0.00035371, 'lr': 8.271e-05, 'params': 195018, 'time_iter': 0.11379, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 62, 'time_epoch': 2.78799, 'loss': 0.12657454, 'lr': 0, 'params': 195018, 'time_iter': 0.05932, 'accuracy': 0.98118, 'f1': 0.98152, 'auc': 0.99949}\n",
      "test: {'epoch': 62, 'time_epoch': 2.68878, 'loss': 0.19707455, 'lr': 0, 'params': 195018, 'time_iter': 0.05721, 'accuracy': 0.97315, 'f1': 0.9733, 'auc': 0.99803}\n",
      "> Epoch 62: took 48.0s (avg 47.7s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 63, 'time_epoch': 43.29626, 'eta': 466.59284, 'eta_hours': 0.12961, 'loss': 0.00171299, 'lr': 7.078e-05, 'params': 195018, 'time_iter': 0.11608, 'accuracy': 0.99983, 'f1': 0.99984, 'auc': 1.0}\n",
      "val: {'epoch': 63, 'time_epoch': 2.88005, 'loss': 0.15990514, 'lr': 0, 'params': 195018, 'time_iter': 0.06128, 'accuracy': 0.97715, 'f1': 0.97746, 'auc': 0.99895}\n",
      "test: {'epoch': 63, 'time_epoch': 2.90321, 'loss': 0.18084006, 'lr': 0, 'params': 195018, 'time_iter': 0.06177, 'accuracy': 0.97047, 'f1': 0.9703, 'auc': 0.99881}\n",
      "> Epoch 63: took 49.1s (avg 47.7s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 64, 'time_epoch': 45.52055, 'eta': 424.65269, 'eta_hours': 0.11796, 'loss': 0.00020414, 'lr': 5.97e-05, 'params': 195018, 'time_iter': 0.12204, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 64, 'time_epoch': 2.74029, 'loss': 0.15860201, 'lr': 0, 'params': 195018, 'time_iter': 0.0583, 'accuracy': 0.97581, 'f1': 0.97631, 'auc': 0.99898}\n",
      "test: {'epoch': 64, 'time_epoch': 2.47491, 'loss': 0.18640934, 'lr': 0, 'params': 195018, 'time_iter': 0.05266, 'accuracy': 0.96644, 'f1': 0.96638, 'auc': 0.99862}\n",
      "> Epoch 64: took 50.8s (avg 47.8s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 65, 'time_epoch': 44.00506, 'eta': 382.3974, 'eta_hours': 0.10622, 'loss': 0.0010878, 'lr': 4.952e-05, 'params': 195018, 'time_iter': 0.11798, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "val: {'epoch': 65, 'time_epoch': 2.80886, 'loss': 0.16367827, 'lr': 0, 'params': 195018, 'time_iter': 0.05976, 'accuracy': 0.97581, 'f1': 0.97631, 'auc': 0.999}\n",
      "test: {'epoch': 65, 'time_epoch': 2.62369, 'loss': 0.18547041, 'lr': 0, 'params': 195018, 'time_iter': 0.05582, 'accuracy': 0.96913, 'f1': 0.969, 'auc': 0.99888}\n",
      "> Epoch 65: took 49.5s (avg 47.8s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 66, 'time_epoch': 43.78203, 'eta': 340.06324, 'eta_hours': 0.09446, 'loss': 0.00109534, 'lr': 4.024e-05, 'params': 195018, 'time_iter': 0.11738, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 66, 'time_epoch': 2.64951, 'loss': 0.15481736, 'lr': 0, 'params': 195018, 'time_iter': 0.05637, 'accuracy': 0.97849, 'f1': 0.97903, 'auc': 0.99904}\n",
      "test: {'epoch': 66, 'time_epoch': 2.83399, 'loss': 0.19238192, 'lr': 0, 'params': 195018, 'time_iter': 0.0603, 'accuracy': 0.96913, 'f1': 0.96887, 'auc': 0.99867}\n",
      "> Epoch 66: took 49.3s (avg 47.8s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 67, 'time_epoch': 43.97666, 'eta': 297.70653, 'eta_hours': 0.0827, 'loss': 0.00022, 'lr': 3.188e-05, 'params': 195018, 'time_iter': 0.1179, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 67, 'time_epoch': 2.95364, 'loss': 0.15732766, 'lr': 0, 'params': 195018, 'time_iter': 0.06284, 'accuracy': 0.97446, 'f1': 0.97502, 'auc': 0.99877}\n",
      "test: {'epoch': 67, 'time_epoch': 2.62871, 'loss': 0.19559483, 'lr': 0, 'params': 195018, 'time_iter': 0.05593, 'accuracy': 0.9745, 'f1': 0.97427, 'auc': 0.99833}\n",
      "> Epoch 67: took 49.6s (avg 47.9s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 68, 'time_epoch': 42.78356, 'eta': 255.19912, 'eta_hours': 0.07089, 'loss': 0.00018199, 'lr': 2.447e-05, 'params': 195018, 'time_iter': 0.1147, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 68, 'time_epoch': 2.5781, 'loss': 0.15467692, 'lr': 0, 'params': 195018, 'time_iter': 0.05485, 'accuracy': 0.97715, 'f1': 0.97765, 'auc': 0.99904}\n",
      "test: {'epoch': 68, 'time_epoch': 2.68163, 'loss': 0.20053361, 'lr': 0, 'params': 195018, 'time_iter': 0.05706, 'accuracy': 0.96913, 'f1': 0.9689, 'auc': 0.99855}\n",
      "> Epoch 68: took 48.1s (avg 47.9s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 69, 'time_epoch': 42.55909, 'eta': 212.66778, 'eta_hours': 0.05907, 'loss': 0.00206464, 'lr': 1.802e-05, 'params': 195018, 'time_iter': 0.1141, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 0.99989}\n",
      "val: {'epoch': 69, 'time_epoch': 2.46886, 'loss': 0.15459529, 'lr': 0, 'params': 195018, 'time_iter': 0.05253, 'accuracy': 0.97446, 'f1': 0.97495, 'auc': 0.99875}\n",
      "test: {'epoch': 69, 'time_epoch': 2.4614, 'loss': 0.19604476, 'lr': 0, 'params': 195018, 'time_iter': 0.05237, 'accuracy': 0.97047, 'f1': 0.97058, 'auc': 0.99874}\n",
      "> Epoch 69: took 47.5s (avg 47.9s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 70, 'time_epoch': 43.42993, 'eta': 170.18472, 'eta_hours': 0.04727, 'loss': 0.00019833, 'lr': 1.254e-05, 'params': 195018, 'time_iter': 0.11643, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 70, 'time_epoch': 2.7281, 'loss': 0.14861509, 'lr': 0, 'params': 195018, 'time_iter': 0.05804, 'accuracy': 0.97715, 'f1': 0.97763, 'auc': 0.99932}\n",
      "test: {'epoch': 70, 'time_epoch': 2.64699, 'loss': 0.20552134, 'lr': 0, 'params': 195018, 'time_iter': 0.05632, 'accuracy': 0.96913, 'f1': 0.96887, 'auc': 0.99826}\n",
      "> Epoch 70: took 48.9s (avg 47.9s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 71, 'time_epoch': 44.06887, 'eta': 127.70199, 'eta_hours': 0.03547, 'loss': 0.00017818, 'lr': 8.04e-06, 'params': 195018, 'time_iter': 0.11815, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 71, 'time_epoch': 2.67902, 'loss': 0.1476055, 'lr': 0, 'params': 195018, 'time_iter': 0.057, 'accuracy': 0.97715, 'f1': 0.97765, 'auc': 0.99909}\n",
      "test: {'epoch': 71, 'time_epoch': 2.83519, 'loss': 0.21112716, 'lr': 0, 'params': 195018, 'time_iter': 0.06032, 'accuracy': 0.96779, 'f1': 0.96758, 'auc': 0.99849}\n",
      "> Epoch 71: took 49.7s (avg 47.9s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 72, 'time_epoch': 43.50077, 'eta': 85.16023, 'eta_hours': 0.02366, 'loss': 0.00017869, 'lr': 4.53e-06, 'params': 195018, 'time_iter': 0.11662, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 72, 'time_epoch': 2.63383, 'loss': 0.15710411, 'lr': 0, 'params': 195018, 'time_iter': 0.05604, 'accuracy': 0.97581, 'f1': 0.97628, 'auc': 0.99898}\n",
      "test: {'epoch': 72, 'time_epoch': 2.71402, 'loss': 0.19409617, 'lr': 0, 'params': 195018, 'time_iter': 0.05775, 'accuracy': 0.97047, 'f1': 0.97018, 'auc': 0.99872}\n",
      "> Epoch 72: took 48.9s (avg 47.9s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 73, 'time_epoch': 42.0759, 'eta': 42.5733, 'eta_hours': 0.01183, 'loss': 0.00020228, 'lr': 2.01e-06, 'params': 195018, 'time_iter': 0.1128, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 73, 'time_epoch': 2.60386, 'loss': 0.15487932, 'lr': 0, 'params': 195018, 'time_iter': 0.0554, 'accuracy': 0.97849, 'f1': 0.97903, 'auc': 0.99896}\n",
      "test: {'epoch': 73, 'time_epoch': 2.91443, 'loss': 0.19884429, 'lr': 0, 'params': 195018, 'time_iter': 0.06201, 'accuracy': 0.96779, 'f1': 0.96758, 'auc': 0.99881}\n",
      "> Epoch 73: took 47.7s (avg 47.9s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "train: {'epoch': 74, 'time_epoch': 43.12858, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.00022758, 'lr': 5e-07, 'params': 195018, 'time_iter': 0.11563, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 74, 'time_epoch': 2.64415, 'loss': 0.15079661, 'lr': 0, 'params': 195018, 'time_iter': 0.05626, 'accuracy': 0.97715, 'f1': 0.97756, 'auc': 0.99906}\n",
      "test: {'epoch': 74, 'time_epoch': 2.807, 'loss': 0.20353054, 'lr': 0, 'params': 195018, 'time_iter': 0.05972, 'accuracy': 0.97047, 'f1': 0.97018, 'auc': 0.99874}\n",
      "> Epoch 74: took 48.6s (avg 47.9s) | Best so far: epoch 61\ttrain_loss: 0.0002 train_accuracy: 1.0000\tval_loss: 0.1335 val_accuracy: 0.9812\ttest_loss: 0.1889 test_accuracy: 0.9691\n",
      "Avg time per epoch: 47.92s\n",
      "Total train loop time: 1.00h\n",
      "Task done, results saved in results\\neural-Act\\0\n",
      "61\n",
      "{'epoch': 61, 'time_epoch': 2.58209, 'loss': 0.18886283, 'lr': 0, 'params': 195018, 'time_iter': 0.05494, 'accuracy': 0.96913, 'f1': 0.96892, 'auc': 0.99833}\n",
      "{'epoch': 61, 'time_epoch': 41.73938, 'eta': 551.23819, 'eta_hours': 0.15312, 'loss': 0.00022633, 'lr': 9.549e-05, 'params': 195018, 'time_iter': 0.1119, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "{'epoch': 61, 'time_epoch': 2.67582, 'loss': 0.13350881, 'lr': 0, 'params': 195018, 'time_iter': 0.05693, 'accuracy': 0.98118, 'f1': 0.98164, 'auc': 0.99908}\n",
      "Results aggregated across runs saved in results\\neural-Act\\agg\n",
      "[*] All done: 2024-03-03 02:53:22.919173\n"
     ]
    }
   ],
   "source": [
    "#CustomGatedGCN+Exphormer dropout 0.1 attn dropout 0.5\n",
    "%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b40ad43a-206d-4197-9509-fb25ac4a26c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-03 03:10:07.764115\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 7\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [04:00<00:00, 30.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:04:02.72\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [01:25<00:00, 87.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:01:27.49\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=400, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=4\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.5\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.3\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: CustomGatedGCN+Exphormer\n",
      "  layers: 3\n",
      "  n_heads: 4\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 80\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 195018\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 44.99662, 'eta': 3554.73307, 'eta_hours': 0.98743, 'loss': 1.95312805, 'lr': 0.0, 'params': 195018, 'time_iter': 0.12063, 'accuracy': 0.13033, 'f1': 0.0916, 'auc': 0.49981}\n",
      "...computing epoch stats took: 0.31s\n",
      "val: {'epoch': 0, 'time_epoch': 2.57729, 'loss': 1.94799195, 'lr': 0, 'params': 195018, 'time_iter': 0.05484, 'accuracy': 0.13978, 'f1': 0.08917, 'auc': 0.51272}\n",
      "...computing epoch stats took: 0.02s\n",
      "test: {'epoch': 0, 'time_epoch': 2.68027, 'loss': 1.94916268, 'lr': 0, 'params': 195018, 'time_iter': 0.05703, 'accuracy': 0.13154, 'f1': 0.08374, 'auc': 0.4746}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 0: took 50.6s (avg 50.6s) | Best so far: epoch 0\ttrain_loss: 1.9531 train_accuracy: 0.1303\tval_loss: 1.9480 val_accuracy: 0.1398\ttest_loss: 1.9492 test_accuracy: 0.1315\n",
      "train: {'epoch': 1, 'time_epoch': 43.59102, 'eta': 3454.91808, 'eta_hours': 0.9597, 'loss': 1.72754798, 'lr': 0.0002, 'params': 195018, 'time_iter': 0.11687, 'accuracy': 0.58868, 'f1': 0.5767, 'auc': 0.89158}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 1, 'time_epoch': 2.72026, 'loss': 1.55585121, 'lr': 0, 'params': 195018, 'time_iter': 0.05788, 'accuracy': 0.74866, 'f1': 0.74788, 'auc': 0.96078}\n",
      "...computing epoch stats took: 0.03s\n",
      "test: {'epoch': 1, 'time_epoch': 2.67735, 'loss': 1.54409102, 'lr': 0, 'params': 195018, 'time_iter': 0.05696, 'accuracy': 0.78255, 'f1': 0.77157, 'auc': 0.96587}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 49.1s (avg 49.8s) | Best so far: epoch 1\ttrain_loss: 1.7275 train_accuracy: 0.5887\tval_loss: 1.5559 val_accuracy: 0.7487\ttest_loss: 1.5441 test_accuracy: 0.7825\n",
      "train: {'epoch': 2, 'time_epoch': 42.32939, 'eta': 3360.20394, 'eta_hours': 0.93339, 'loss': 1.32998406, 'lr': 0.0004, 'params': 195018, 'time_iter': 0.11348, 'accuracy': 0.848, 'f1': 0.84708, 'auc': 0.97351}\n",
      "...computing epoch stats took: 0.01s\n",
      "val: {'epoch': 2, 'time_epoch': 2.44366, 'loss': 1.15040508, 'lr': 0, 'params': 195018, 'time_iter': 0.05199, 'accuracy': 0.8629, 'f1': 0.86315, 'auc': 0.98258}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 2.6104, 'loss': 1.1376928, 'lr': 0, 'params': 195018, 'time_iter': 0.05554, 'accuracy': 0.86443, 'f1': 0.8635, 'auc': 0.98553}\n",
      "...computing epoch stats took: 0.02s\n",
      "> Epoch 2: took 47.4s (avg 49.0s) | Best so far: epoch 2\ttrain_loss: 1.3300 train_accuracy: 0.8480\tval_loss: 1.1504 val_accuracy: 0.8629\ttest_loss: 1.1377 test_accuracy: 0.8644\n",
      "train: {'epoch': 3, 'time_epoch': 42.89758, 'eta': 3302.47775, 'eta_hours': 0.91735, 'loss': 0.91269724, 'lr': 0.0006, 'params': 195018, 'time_iter': 0.11501, 'accuracy': 0.913, 'f1': 0.91228, 'auc': 0.98604}\n",
      "val: {'epoch': 3, 'time_epoch': 2.56306, 'loss': 0.79183806, 'lr': 0, 'params': 195018, 'time_iter': 0.05453, 'accuracy': 0.87903, 'f1': 0.88142, 'auc': 0.99221}\n",
      "test: {'epoch': 3, 'time_epoch': 2.83906, 'loss': 0.79427323, 'lr': 0, 'params': 195018, 'time_iter': 0.06041, 'accuracy': 0.87383, 'f1': 0.8713, 'auc': 0.99081}\n",
      "> Epoch 3: took 48.4s (avg 48.9s) | Best so far: epoch 3\ttrain_loss: 0.9127 train_accuracy: 0.9130\tval_loss: 0.7918 val_accuracy: 0.8790\ttest_loss: 0.7943 test_accuracy: 0.8738\n",
      "train: {'epoch': 4, 'time_epoch': 43.85544, 'eta': 3265.05094, 'eta_hours': 0.90696, 'loss': 0.58625107, 'lr': 0.0008, 'params': 195018, 'time_iter': 0.11757, 'accuracy': 0.935, 'f1': 0.93481, 'auc': 0.99145}\n",
      "val: {'epoch': 4, 'time_epoch': 2.98661, 'loss': 0.48479179, 'lr': 0, 'params': 195018, 'time_iter': 0.06354, 'accuracy': 0.93011, 'f1': 0.93252, 'auc': 0.99266}\n",
      "test: {'epoch': 4, 'time_epoch': 2.83004, 'loss': 0.45879552, 'lr': 0, 'params': 195018, 'time_iter': 0.06021, 'accuracy': 0.94631, 'f1': 0.94665, 'auc': 0.99415}\n",
      "> Epoch 4: took 49.7s (avg 49.0s) | Best so far: epoch 4\ttrain_loss: 0.5863 train_accuracy: 0.9350\tval_loss: 0.4848 val_accuracy: 0.9301\ttest_loss: 0.4588 test_accuracy: 0.9463\n",
      "train: {'epoch': 5, 'time_epoch': 42.11472, 'eta': 3204.0123, 'eta_hours': 0.89, 'loss': 0.39937859, 'lr': 0.001, 'params': 195018, 'time_iter': 0.11291, 'accuracy': 0.93735, 'f1': 0.93707, 'auc': 0.99241}\n",
      "val: {'epoch': 5, 'time_epoch': 2.59483, 'loss': 0.32558879, 'lr': 0, 'params': 195018, 'time_iter': 0.05521, 'accuracy': 0.9422, 'f1': 0.94476, 'auc': 0.99613}\n",
      "test: {'epoch': 5, 'time_epoch': 2.57503, 'loss': 0.33457544, 'lr': 0, 'params': 195018, 'time_iter': 0.05479, 'accuracy': 0.9396, 'f1': 0.94149, 'auc': 0.9945}\n",
      "> Epoch 5: took 47.3s (avg 48.8s) | Best so far: epoch 5\ttrain_loss: 0.3994 train_accuracy: 0.9374\tval_loss: 0.3256 val_accuracy: 0.9422\ttest_loss: 0.3346 test_accuracy: 0.9396\n",
      "train: {'epoch': 6, 'time_epoch': 43.52787, 'eta': 3163.11761, 'eta_hours': 0.87864, 'loss': 0.25792577, 'lr': 0.00099956, 'params': 195018, 'time_iter': 0.1167, 'accuracy': 0.957, 'f1': 0.95691, 'auc': 0.99593}\n",
      "val: {'epoch': 6, 'time_epoch': 2.70234, 'loss': 0.4129623, 'lr': 0, 'params': 195018, 'time_iter': 0.0575, 'accuracy': 0.8871, 'f1': 0.89195, 'auc': 0.99395}\n",
      "test: {'epoch': 6, 'time_epoch': 2.7115, 'loss': 0.33718196, 'lr': 0, 'params': 195018, 'time_iter': 0.05769, 'accuracy': 0.91141, 'f1': 0.9143, 'auc': 0.99592}\n",
      "> Epoch 6: took 49.0s (avg 48.8s) | Best so far: epoch 5\ttrain_loss: 0.3994 train_accuracy: 0.9374\tval_loss: 0.3256 val_accuracy: 0.9422\ttest_loss: 0.3346 test_accuracy: 0.9396\n",
      "train: {'epoch': 7, 'time_epoch': 43.21929, 'eta': 3118.78743, 'eta_hours': 0.86633, 'loss': 0.19443414, 'lr': 0.00099825, 'params': 195018, 'time_iter': 0.11587, 'accuracy': 0.96439, 'f1': 0.96432, 'auc': 0.99729}\n",
      "val: {'epoch': 7, 'time_epoch': 2.71161, 'loss': 0.27653285, 'lr': 0, 'params': 195018, 'time_iter': 0.05769, 'accuracy': 0.9328, 'f1': 0.93393, 'auc': 0.99336}\n",
      "test: {'epoch': 7, 'time_epoch': 2.67011, 'loss': 0.22855794, 'lr': 0, 'params': 195018, 'time_iter': 0.05681, 'accuracy': 0.94765, 'f1': 0.94567, 'auc': 0.99683}\n",
      "> Epoch 7: took 48.7s (avg 48.8s) | Best so far: epoch 5\ttrain_loss: 0.3994 train_accuracy: 0.9374\tval_loss: 0.3256 val_accuracy: 0.9422\ttest_loss: 0.3346 test_accuracy: 0.9396\n",
      "train: {'epoch': 8, 'time_epoch': 42.98656, 'eta': 3072.86811, 'eta_hours': 0.85357, 'loss': 0.15044001, 'lr': 0.00099606, 'params': 195018, 'time_iter': 0.11525, 'accuracy': 0.9691, 'f1': 0.96901, 'auc': 0.99826}\n",
      "val: {'epoch': 8, 'time_epoch': 2.98713, 'loss': 0.25729225, 'lr': 0, 'params': 195018, 'time_iter': 0.06356, 'accuracy': 0.9328, 'f1': 0.93327, 'auc': 0.99363}\n",
      "test: {'epoch': 8, 'time_epoch': 2.73516, 'loss': 0.27094614, 'lr': 0, 'params': 195018, 'time_iter': 0.05819, 'accuracy': 0.92483, 'f1': 0.92636, 'auc': 0.99548}\n",
      "> Epoch 8: took 48.8s (avg 48.8s) | Best so far: epoch 5\ttrain_loss: 0.3994 train_accuracy: 0.9374\tval_loss: 0.3256 val_accuracy: 0.9422\ttest_loss: 0.3346 test_accuracy: 0.9396\n",
      "train: {'epoch': 9, 'time_epoch': 43.55186, 'eta': 3031.49245, 'eta_hours': 0.84208, 'loss': 0.12988222, 'lr': 0.000993, 'params': 195018, 'time_iter': 0.11676, 'accuracy': 0.97262, 'f1': 0.97262, 'auc': 0.99821}\n",
      "val: {'epoch': 9, 'time_epoch': 2.5644, 'loss': 0.17276799, 'lr': 0, 'params': 195018, 'time_iter': 0.05456, 'accuracy': 0.95699, 'f1': 0.95823, 'auc': 0.99632}\n",
      "test: {'epoch': 9, 'time_epoch': 2.77142, 'loss': 0.20614341, 'lr': 0, 'params': 195018, 'time_iter': 0.05897, 'accuracy': 0.94899, 'f1': 0.9498, 'auc': 0.99461}\n",
      "> Epoch 9: took 48.9s (avg 48.8s) | Best so far: epoch 9\ttrain_loss: 0.1299 train_accuracy: 0.9726\tval_loss: 0.1728 val_accuracy: 0.9570\ttest_loss: 0.2061 test_accuracy: 0.9490\n",
      "train: {'epoch': 10, 'time_epoch': 43.56458, 'eta': 2989.80094, 'eta_hours': 0.8305, 'loss': 0.10453011, 'lr': 0.00098907, 'params': 195018, 'time_iter': 0.1168, 'accuracy': 0.97615, 'f1': 0.97619, 'auc': 0.99911}\n",
      "val: {'epoch': 10, 'time_epoch': 2.57112, 'loss': 0.22842402, 'lr': 0, 'params': 195018, 'time_iter': 0.0547, 'accuracy': 0.94624, 'f1': 0.94689, 'auc': 0.99466}\n",
      "test: {'epoch': 10, 'time_epoch': 2.70359, 'loss': 0.24359586, 'lr': 0, 'params': 195018, 'time_iter': 0.05752, 'accuracy': 0.9396, 'f1': 0.93947, 'auc': 0.99667}\n",
      "> Epoch 10: took 48.9s (avg 48.8s) | Best so far: epoch 9\ttrain_loss: 0.1299 train_accuracy: 0.9726\tval_loss: 0.1728 val_accuracy: 0.9570\ttest_loss: 0.2061 test_accuracy: 0.9490\n",
      "train: {'epoch': 11, 'time_epoch': 43.13468, 'eta': 2945.36115, 'eta_hours': 0.81816, 'loss': 0.09160926, 'lr': 0.00098429, 'params': 195018, 'time_iter': 0.11564, 'accuracy': 0.97951, 'f1': 0.97943, 'auc': 0.99907}\n",
      "val: {'epoch': 11, 'time_epoch': 2.86987, 'loss': 0.15680543, 'lr': 0, 'params': 195018, 'time_iter': 0.06106, 'accuracy': 0.95296, 'f1': 0.95415, 'auc': 0.99753}\n",
      "test: {'epoch': 11, 'time_epoch': 2.80497, 'loss': 0.14855665, 'lr': 0, 'params': 195018, 'time_iter': 0.05968, 'accuracy': 0.96242, 'f1': 0.96303, 'auc': 0.99776}\n",
      "> Epoch 11: took 48.9s (avg 48.8s) | Best so far: epoch 9\ttrain_loss: 0.1299 train_accuracy: 0.9726\tval_loss: 0.1728 val_accuracy: 0.9570\ttest_loss: 0.2061 test_accuracy: 0.9490\n",
      "train: {'epoch': 12, 'time_epoch': 43.91921, 'eta': 2905.16546, 'eta_hours': 0.80699, 'loss': 0.08347151, 'lr': 0.00097866, 'params': 195018, 'time_iter': 0.11775, 'accuracy': 0.97934, 'f1': 0.97931, 'auc': 0.99923}\n",
      "val: {'epoch': 12, 'time_epoch': 2.76515, 'loss': 0.14507273, 'lr': 0, 'params': 195018, 'time_iter': 0.05883, 'accuracy': 0.9664, 'f1': 0.96724, 'auc': 0.99747}\n",
      "test: {'epoch': 12, 'time_epoch': 2.6857, 'loss': 0.13500541, 'lr': 0, 'params': 195018, 'time_iter': 0.05714, 'accuracy': 0.96644, 'f1': 0.96664, 'auc': 0.99766}\n",
      "> Epoch 12: took 49.4s (avg 48.9s) | Best so far: epoch 12\ttrain_loss: 0.0835 train_accuracy: 0.9793\tval_loss: 0.1451 val_accuracy: 0.9664\ttest_loss: 0.1350 test_accuracy: 0.9664\n",
      "train: {'epoch': 13, 'time_epoch': 43.37954, 'eta': 2861.89369, 'eta_hours': 0.79497, 'loss': 0.06552416, 'lr': 0.00097219, 'params': 195018, 'time_iter': 0.1163, 'accuracy': 0.98404, 'f1': 0.98402, 'auc': 0.99925}\n",
      "val: {'epoch': 13, 'time_epoch': 2.73523, 'loss': 0.20221263, 'lr': 0, 'params': 195018, 'time_iter': 0.0582, 'accuracy': 0.94624, 'f1': 0.94931, 'auc': 0.99582}\n",
      "test: {'epoch': 13, 'time_epoch': 2.68764, 'loss': 0.19144069, 'lr': 0, 'params': 195018, 'time_iter': 0.05718, 'accuracy': 0.94765, 'f1': 0.94976, 'auc': 0.99635}\n",
      "> Epoch 13: took 48.9s (avg 48.9s) | Best so far: epoch 12\ttrain_loss: 0.0835 train_accuracy: 0.9793\tval_loss: 0.1451 val_accuracy: 0.9664\ttest_loss: 0.1350 test_accuracy: 0.9664\n",
      "train: {'epoch': 14, 'time_epoch': 43.47681, 'eta': 2819.02908, 'eta_hours': 0.78306, 'loss': 0.06391114, 'lr': 0.00096489, 'params': 195018, 'time_iter': 0.11656, 'accuracy': 0.98421, 'f1': 0.98417, 'auc': 0.9995}\n",
      "val: {'epoch': 14, 'time_epoch': 2.66146, 'loss': 0.1422879, 'lr': 0, 'params': 195018, 'time_iter': 0.05663, 'accuracy': 0.96102, 'f1': 0.96171, 'auc': 0.99822}\n",
      "test: {'epoch': 14, 'time_epoch': 2.60012, 'loss': 0.13889819, 'lr': 0, 'params': 195018, 'time_iter': 0.05532, 'accuracy': 0.9651, 'f1': 0.96465, 'auc': 0.9977}\n",
      "> Epoch 14: took 48.8s (avg 48.9s) | Best so far: epoch 12\ttrain_loss: 0.0835 train_accuracy: 0.9793\tval_loss: 0.1451 val_accuracy: 0.9664\ttest_loss: 0.1350 test_accuracy: 0.9664\n",
      "train: {'epoch': 15, 'time_epoch': 43.04755, 'eta': 2774.3709, 'eta_hours': 0.77066, 'loss': 0.05091342, 'lr': 0.00095677, 'params': 195018, 'time_iter': 0.11541, 'accuracy': 0.98841, 'f1': 0.98843, 'auc': 0.99954}\n",
      "val: {'epoch': 15, 'time_epoch': 2.6258, 'loss': 0.21898431, 'lr': 0, 'params': 195018, 'time_iter': 0.05587, 'accuracy': 0.95161, 'f1': 0.95284, 'auc': 0.9943}\n",
      "test: {'epoch': 15, 'time_epoch': 2.83492, 'loss': 0.15032062, 'lr': 0, 'params': 195018, 'time_iter': 0.06032, 'accuracy': 0.96107, 'f1': 0.9601, 'auc': 0.99808}\n",
      "> Epoch 15: took 48.6s (avg 48.8s) | Best so far: epoch 12\ttrain_loss: 0.0835 train_accuracy: 0.9793\tval_loss: 0.1451 val_accuracy: 0.9664\ttest_loss: 0.1350 test_accuracy: 0.9664\n",
      "train: {'epoch': 16, 'time_epoch': 44.06777, 'eta': 2733.68301, 'eta_hours': 0.75936, 'loss': 0.04688394, 'lr': 0.00094786, 'params': 195018, 'time_iter': 0.11814, 'accuracy': 0.9874, 'f1': 0.98737, 'auc': 0.99977}\n",
      "val: {'epoch': 16, 'time_epoch': 2.6501, 'loss': 0.17521787, 'lr': 0, 'params': 195018, 'time_iter': 0.05639, 'accuracy': 0.95968, 'f1': 0.95995, 'auc': 0.99723}\n",
      "test: {'epoch': 16, 'time_epoch': 2.70007, 'loss': 0.17480917, 'lr': 0, 'params': 195018, 'time_iter': 0.05745, 'accuracy': 0.9557, 'f1': 0.95564, 'auc': 0.99828}\n",
      "> Epoch 16: took 49.5s (avg 48.9s) | Best so far: epoch 12\ttrain_loss: 0.0835 train_accuracy: 0.9793\tval_loss: 0.1451 val_accuracy: 0.9664\ttest_loss: 0.1350 test_accuracy: 0.9664\n",
      "train: {'epoch': 17, 'time_epoch': 42.90351, 'eta': 2688.60936, 'eta_hours': 0.74684, 'loss': 0.04234747, 'lr': 0.00093815, 'params': 195018, 'time_iter': 0.11502, 'accuracy': 0.98959, 'f1': 0.98958, 'auc': 0.99975}\n",
      "val: {'epoch': 17, 'time_epoch': 2.66159, 'loss': 0.18089667, 'lr': 0, 'params': 195018, 'time_iter': 0.05663, 'accuracy': 0.96237, 'f1': 0.96315, 'auc': 0.99622}\n",
      "test: {'epoch': 17, 'time_epoch': 2.60854, 'loss': 0.16652843, 'lr': 0, 'params': 195018, 'time_iter': 0.0555, 'accuracy': 0.96107, 'f1': 0.96086, 'auc': 0.99788}\n",
      "> Epoch 17: took 48.2s (avg 48.8s) | Best so far: epoch 12\ttrain_loss: 0.0835 train_accuracy: 0.9793\tval_loss: 0.1451 val_accuracy: 0.9664\ttest_loss: 0.1350 test_accuracy: 0.9664\n",
      "train: {'epoch': 18, 'time_epoch': 43.71017, 'eta': 2646.35394, 'eta_hours': 0.7351, 'loss': 0.04660843, 'lr': 0.00092768, 'params': 195018, 'time_iter': 0.11719, 'accuracy': 0.9874, 'f1': 0.98743, 'auc': 0.99969}\n",
      "val: {'epoch': 18, 'time_epoch': 2.77628, 'loss': 0.14853764, 'lr': 0, 'params': 195018, 'time_iter': 0.05907, 'accuracy': 0.96237, 'f1': 0.96315, 'auc': 0.99843}\n",
      "test: {'epoch': 18, 'time_epoch': 2.76232, 'loss': 0.13266177, 'lr': 0, 'params': 195018, 'time_iter': 0.05877, 'accuracy': 0.9651, 'f1': 0.96484, 'auc': 0.99789}\n",
      "> Epoch 18: took 49.3s (avg 48.9s) | Best so far: epoch 12\ttrain_loss: 0.0835 train_accuracy: 0.9793\tval_loss: 0.1451 val_accuracy: 0.9664\ttest_loss: 0.1350 test_accuracy: 0.9664\n",
      "train: {'epoch': 19, 'time_epoch': 43.49617, 'eta': 2603.31106, 'eta_hours': 0.72314, 'loss': 0.04264593, 'lr': 0.00091646, 'params': 195018, 'time_iter': 0.11661, 'accuracy': 0.98892, 'f1': 0.98888, 'auc': 0.9997}\n",
      "val: {'epoch': 19, 'time_epoch': 2.72564, 'loss': 0.28524237, 'lr': 0, 'params': 195018, 'time_iter': 0.05799, 'accuracy': 0.93145, 'f1': 0.93406, 'auc': 0.99671}\n",
      "test: {'epoch': 19, 'time_epoch': 3.00751, 'loss': 0.26237675, 'lr': 0, 'params': 195018, 'time_iter': 0.06399, 'accuracy': 0.9396, 'f1': 0.93952, 'auc': 0.99449}\n",
      "> Epoch 19: took 49.3s (avg 48.9s) | Best so far: epoch 12\ttrain_loss: 0.0835 train_accuracy: 0.9793\tval_loss: 0.1451 val_accuracy: 0.9664\ttest_loss: 0.1350 test_accuracy: 0.9664\n",
      "train: {'epoch': 20, 'time_epoch': 43.6374, 'eta': 2560.62179, 'eta_hours': 0.71128, 'loss': 0.04019662, 'lr': 0.00090451, 'params': 195018, 'time_iter': 0.11699, 'accuracy': 0.98858, 'f1': 0.98854, 'auc': 0.99984}\n",
      "val: {'epoch': 20, 'time_epoch': 2.61283, 'loss': 0.16226848, 'lr': 0, 'params': 195018, 'time_iter': 0.05559, 'accuracy': 0.95968, 'f1': 0.95997, 'auc': 0.99787}\n",
      "test: {'epoch': 20, 'time_epoch': 2.87617, 'loss': 0.1394801, 'lr': 0, 'params': 195018, 'time_iter': 0.0612, 'accuracy': 0.96644, 'f1': 0.96698, 'auc': 0.99777}\n",
      "> Epoch 20: took 49.2s (avg 48.9s) | Best so far: epoch 12\ttrain_loss: 0.0835 train_accuracy: 0.9793\tval_loss: 0.1451 val_accuracy: 0.9664\ttest_loss: 0.1350 test_accuracy: 0.9664\n",
      "train: {'epoch': 21, 'time_epoch': 43.07347, 'eta': 2516.35959, 'eta_hours': 0.69899, 'loss': 0.03120988, 'lr': 0.00089185, 'params': 195018, 'time_iter': 0.11548, 'accuracy': 0.99177, 'f1': 0.99172, 'auc': 0.9999}\n",
      "val: {'epoch': 21, 'time_epoch': 2.67994, 'loss': 0.19233814, 'lr': 0, 'params': 195018, 'time_iter': 0.05702, 'accuracy': 0.95296, 'f1': 0.95428, 'auc': 0.9977}\n",
      "test: {'epoch': 21, 'time_epoch': 2.72089, 'loss': 0.14522224, 'lr': 0, 'params': 195018, 'time_iter': 0.05789, 'accuracy': 0.9651, 'f1': 0.96461, 'auc': 0.99836}\n",
      "> Epoch 21: took 48.5s (avg 48.9s) | Best so far: epoch 12\ttrain_loss: 0.0835 train_accuracy: 0.9793\tval_loss: 0.1451 val_accuracy: 0.9664\ttest_loss: 0.1350 test_accuracy: 0.9664\n",
      "train: {'epoch': 22, 'time_epoch': 42.68739, 'eta': 2471.24396, 'eta_hours': 0.68646, 'loss': 0.02727137, 'lr': 0.0008785, 'params': 195018, 'time_iter': 0.11444, 'accuracy': 0.99227, 'f1': 0.99227, 'auc': 0.99989}\n",
      "val: {'epoch': 22, 'time_epoch': 2.82272, 'loss': 0.13130465, 'lr': 0, 'params': 195018, 'time_iter': 0.06006, 'accuracy': 0.97177, 'f1': 0.9724, 'auc': 0.99855}\n",
      "test: {'epoch': 22, 'time_epoch': 2.58248, 'loss': 0.15345125, 'lr': 0, 'params': 195018, 'time_iter': 0.05495, 'accuracy': 0.96913, 'f1': 0.97001, 'auc': 0.99811}\n",
      "> Epoch 22: took 48.1s (avg 48.8s) | Best so far: epoch 22\ttrain_loss: 0.0273 train_accuracy: 0.9923\tval_loss: 0.1313 val_accuracy: 0.9718\ttest_loss: 0.1535 test_accuracy: 0.9691\n",
      "train: {'epoch': 23, 'time_epoch': 43.31824, 'eta': 2427.80266, 'eta_hours': 0.67439, 'loss': 0.0318147, 'lr': 0.00086448, 'params': 195018, 'time_iter': 0.11613, 'accuracy': 0.99059, 'f1': 0.99059, 'auc': 0.99989}\n",
      "val: {'epoch': 23, 'time_epoch': 2.91574, 'loss': 0.12063558, 'lr': 0, 'params': 195018, 'time_iter': 0.06204, 'accuracy': 0.96774, 'f1': 0.96807, 'auc': 0.9977}\n",
      "test: {'epoch': 23, 'time_epoch': 2.64525, 'loss': 0.17549531, 'lr': 0, 'params': 195018, 'time_iter': 0.05628, 'accuracy': 0.95973, 'f1': 0.9594, 'auc': 0.99739}\n",
      "> Epoch 23: took 49.0s (avg 48.9s) | Best so far: epoch 22\ttrain_loss: 0.0273 train_accuracy: 0.9923\tval_loss: 0.1313 val_accuracy: 0.9718\ttest_loss: 0.1535 test_accuracy: 0.9691\n",
      "train: {'epoch': 24, 'time_epoch': 42.65143, 'eta': 2382.90423, 'eta_hours': 0.66192, 'loss': 0.02032987, 'lr': 0.00084983, 'params': 195018, 'time_iter': 0.11435, 'accuracy': 0.99395, 'f1': 0.9939, 'auc': 0.99996}\n",
      "val: {'epoch': 24, 'time_epoch': 2.78103, 'loss': 0.15220152, 'lr': 0, 'params': 195018, 'time_iter': 0.05917, 'accuracy': 0.96909, 'f1': 0.96985, 'auc': 0.99733}\n",
      "test: {'epoch': 24, 'time_epoch': 2.70928, 'loss': 0.17578768, 'lr': 0, 'params': 195018, 'time_iter': 0.05764, 'accuracy': 0.96644, 'f1': 0.96546, 'auc': 0.99815}\n",
      "> Epoch 24: took 48.2s (avg 48.8s) | Best so far: epoch 22\ttrain_loss: 0.0273 train_accuracy: 0.9923\tval_loss: 0.1313 val_accuracy: 0.9718\ttest_loss: 0.1535 test_accuracy: 0.9691\n",
      "train: {'epoch': 25, 'time_epoch': 42.50078, 'eta': 2337.86576, 'eta_hours': 0.64941, 'loss': 0.02279083, 'lr': 0.00083457, 'params': 195018, 'time_iter': 0.11394, 'accuracy': 0.99362, 'f1': 0.99361, 'auc': 0.99993}\n",
      "val: {'epoch': 25, 'time_epoch': 2.74179, 'loss': 0.13123636, 'lr': 0, 'params': 195018, 'time_iter': 0.05834, 'accuracy': 0.97177, 'f1': 0.97211, 'auc': 0.99803}\n",
      "test: {'epoch': 25, 'time_epoch': 2.7351, 'loss': 0.14430456, 'lr': 0, 'params': 195018, 'time_iter': 0.05819, 'accuracy': 0.97047, 'f1': 0.96937, 'auc': 0.99799}\n",
      "> Epoch 25: took 48.0s (avg 48.8s) | Best so far: epoch 22\ttrain_loss: 0.0273 train_accuracy: 0.9923\tval_loss: 0.1313 val_accuracy: 0.9718\ttest_loss: 0.1535 test_accuracy: 0.9691\n",
      "train: {'epoch': 26, 'time_epoch': 45.04404, 'eta': 2298.00758, 'eta_hours': 0.63834, 'loss': 0.01971751, 'lr': 0.00081871, 'params': 195018, 'time_iter': 0.12076, 'accuracy': 0.99379, 'f1': 0.99379, 'auc': 0.99996}\n",
      "val: {'epoch': 26, 'time_epoch': 3.00611, 'loss': 0.17582555, 'lr': 0, 'params': 195018, 'time_iter': 0.06396, 'accuracy': 0.95968, 'f1': 0.9602, 'auc': 0.998}\n",
      "test: {'epoch': 26, 'time_epoch': 2.86404, 'loss': 0.19458583, 'lr': 0, 'params': 195018, 'time_iter': 0.06094, 'accuracy': 0.95705, 'f1': 0.95757, 'auc': 0.99824}\n",
      "> Epoch 26: took 51.0s (avg 48.9s) | Best so far: epoch 22\ttrain_loss: 0.0273 train_accuracy: 0.9923\tval_loss: 0.1313 val_accuracy: 0.9718\ttest_loss: 0.1535 test_accuracy: 0.9691\n",
      "train: {'epoch': 27, 'time_epoch': 43.07096, 'eta': 2254.1147, 'eta_hours': 0.62614, 'loss': 0.0174567, 'lr': 0.0008023, 'params': 195018, 'time_iter': 0.11547, 'accuracy': 0.99496, 'f1': 0.99498, 'auc': 0.99996}\n",
      "val: {'epoch': 27, 'time_epoch': 2.59256, 'loss': 0.21129488, 'lr': 0, 'params': 195018, 'time_iter': 0.05516, 'accuracy': 0.95833, 'f1': 0.95959, 'auc': 0.9955}\n",
      "test: {'epoch': 27, 'time_epoch': 2.61965, 'loss': 0.24576895, 'lr': 0, 'params': 195018, 'time_iter': 0.05574, 'accuracy': 0.95168, 'f1': 0.95296, 'auc': 0.99718}\n",
      "> Epoch 27: took 48.3s (avg 48.9s) | Best so far: epoch 22\ttrain_loss: 0.0273 train_accuracy: 0.9923\tval_loss: 0.1313 val_accuracy: 0.9718\ttest_loss: 0.1535 test_accuracy: 0.9691\n",
      "train: {'epoch': 28, 'time_epoch': 43.87253, 'eta': 2211.68815, 'eta_hours': 0.61436, 'loss': 0.01681682, 'lr': 0.00078536, 'params': 195018, 'time_iter': 0.11762, 'accuracy': 0.99463, 'f1': 0.99462, 'auc': 0.99996}\n",
      "val: {'epoch': 28, 'time_epoch': 2.65734, 'loss': 0.11301065, 'lr': 0, 'params': 195018, 'time_iter': 0.05654, 'accuracy': 0.97849, 'f1': 0.97888, 'auc': 0.99905}\n",
      "test: {'epoch': 28, 'time_epoch': 2.55831, 'loss': 0.15991149, 'lr': 0, 'params': 195018, 'time_iter': 0.05443, 'accuracy': 0.9651, 'f1': 0.96455, 'auc': 0.99826}\n",
      "> Epoch 28: took 49.2s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 29, 'time_epoch': 44.37592, 'eta': 2170.00418, 'eta_hours': 0.60278, 'loss': 0.01835479, 'lr': 0.00076791, 'params': 195018, 'time_iter': 0.11897, 'accuracy': 0.99463, 'f1': 0.99462, 'auc': 0.99993}\n",
      "val: {'epoch': 29, 'time_epoch': 2.96484, 'loss': 0.16786962, 'lr': 0, 'params': 195018, 'time_iter': 0.06308, 'accuracy': 0.96371, 'f1': 0.96438, 'auc': 0.99886}\n",
      "test: {'epoch': 29, 'time_epoch': 2.90482, 'loss': 0.1593799, 'lr': 0, 'params': 195018, 'time_iter': 0.0618, 'accuracy': 0.96644, 'f1': 0.96672, 'auc': 0.99834}\n",
      "> Epoch 29: took 50.3s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 30, 'time_epoch': 44.46991, 'eta': 2128.29511, 'eta_hours': 0.59119, 'loss': 0.01180675, 'lr': 0.00075, 'params': 195018, 'time_iter': 0.11922, 'accuracy': 0.99647, 'f1': 0.99649, 'auc': 0.99998}\n",
      "val: {'epoch': 30, 'time_epoch': 2.81986, 'loss': 0.13562289, 'lr': 0, 'params': 195018, 'time_iter': 0.06, 'accuracy': 0.97312, 'f1': 0.97373, 'auc': 0.99791}\n",
      "test: {'epoch': 30, 'time_epoch': 2.80539, 'loss': 0.16295144, 'lr': 0, 'params': 195018, 'time_iter': 0.05969, 'accuracy': 0.9651, 'f1': 0.96424, 'auc': 0.99813}\n",
      "> Epoch 30: took 50.1s (avg 49.0s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 31, 'time_epoch': 44.46758, 'eta': 2086.40999, 'eta_hours': 0.57956, 'loss': 0.00712504, 'lr': 0.00073165, 'params': 195018, 'time_iter': 0.11922, 'accuracy': 0.99832, 'f1': 0.99832, 'auc': 0.99999}\n",
      "val: {'epoch': 31, 'time_epoch': 2.56013, 'loss': 0.14378395, 'lr': 0, 'params': 195018, 'time_iter': 0.05447, 'accuracy': 0.97446, 'f1': 0.97514, 'auc': 0.99682}\n",
      "test: {'epoch': 31, 'time_epoch': 2.54045, 'loss': 0.12105128, 'lr': 0, 'params': 195018, 'time_iter': 0.05405, 'accuracy': 0.97852, 'f1': 0.97852, 'auc': 0.99852}\n",
      "> Epoch 31: took 49.6s (avg 49.0s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 32, 'time_epoch': 42.43755, 'eta': 2041.47711, 'eta_hours': 0.56708, 'loss': 0.01835322, 'lr': 0.00071289, 'params': 195018, 'time_iter': 0.11377, 'accuracy': 0.99513, 'f1': 0.99511, 'auc': 0.99993}\n",
      "val: {'epoch': 32, 'time_epoch': 2.80098, 'loss': 0.119513, 'lr': 0, 'params': 195018, 'time_iter': 0.0596, 'accuracy': 0.97312, 'f1': 0.97373, 'auc': 0.99929}\n",
      "test: {'epoch': 32, 'time_epoch': 2.44985, 'loss': 0.15370232, 'lr': 0, 'params': 195018, 'time_iter': 0.05212, 'accuracy': 0.97047, 'f1': 0.9703, 'auc': 0.99789}\n",
      "> Epoch 32: took 47.8s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 33, 'time_epoch': 43.48895, 'eta': 1998.11349, 'eta_hours': 0.55503, 'loss': 0.01799571, 'lr': 0.00069376, 'params': 195018, 'time_iter': 0.11659, 'accuracy': 0.99513, 'f1': 0.99514, 'auc': 0.99992}\n",
      "val: {'epoch': 33, 'time_epoch': 2.88153, 'loss': 0.14171567, 'lr': 0, 'params': 195018, 'time_iter': 0.06131, 'accuracy': 0.96909, 'f1': 0.96947, 'auc': 0.99865}\n",
      "test: {'epoch': 33, 'time_epoch': 2.6698, 'loss': 0.15919633, 'lr': 0, 'params': 195018, 'time_iter': 0.0568, 'accuracy': 0.96779, 'f1': 0.9673, 'auc': 0.99871}\n",
      "> Epoch 33: took 49.1s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 34, 'time_epoch': 43.58657, 'eta': 1954.86823, 'eta_hours': 0.54302, 'loss': 0.00660709, 'lr': 0.00067429, 'params': 195018, 'time_iter': 0.11685, 'accuracy': 0.99832, 'f1': 0.99834, 'auc': 0.99996}\n",
      "val: {'epoch': 34, 'time_epoch': 2.52774, 'loss': 0.12230665, 'lr': 0, 'params': 195018, 'time_iter': 0.05378, 'accuracy': 0.97581, 'f1': 0.97653, 'auc': 0.99882}\n",
      "test: {'epoch': 34, 'time_epoch': 2.56485, 'loss': 0.14536408, 'lr': 0, 'params': 195018, 'time_iter': 0.05457, 'accuracy': 0.97315, 'f1': 0.9728, 'auc': 0.99855}\n",
      "> Epoch 34: took 48.7s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 35, 'time_epoch': 43.31931, 'eta': 1911.27734, 'eta_hours': 0.53091, 'loss': 0.00938664, 'lr': 0.00065451, 'params': 195018, 'time_iter': 0.11614, 'accuracy': 0.99765, 'f1': 0.99765, 'auc': 0.99999}\n",
      "val: {'epoch': 35, 'time_epoch': 2.54493, 'loss': 0.12716231, 'lr': 0, 'params': 195018, 'time_iter': 0.05415, 'accuracy': 0.97446, 'f1': 0.97527, 'auc': 0.99869}\n",
      "test: {'epoch': 35, 'time_epoch': 2.59991, 'loss': 0.14441904, 'lr': 0, 'params': 195018, 'time_iter': 0.05532, 'accuracy': 0.97047, 'f1': 0.96983, 'auc': 0.99813}\n",
      "> Epoch 35: took 48.5s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 36, 'time_epoch': 43.82115, 'eta': 1868.28436, 'eta_hours': 0.51897, 'loss': 0.00833468, 'lr': 0.00063446, 'params': 195018, 'time_iter': 0.11748, 'accuracy': 0.99798, 'f1': 0.99798, 'auc': 0.99999}\n",
      "val: {'epoch': 36, 'time_epoch': 2.52925, 'loss': 0.18018248, 'lr': 0, 'params': 195018, 'time_iter': 0.05381, 'accuracy': 0.96909, 'f1': 0.97001, 'auc': 0.99725}\n",
      "test: {'epoch': 36, 'time_epoch': 2.71508, 'loss': 0.13713859, 'lr': 0, 'params': 195018, 'time_iter': 0.05777, 'accuracy': 0.97315, 'f1': 0.97211, 'auc': 0.99766}\n",
      "> Epoch 36: took 49.1s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 37, 'time_epoch': 44.41941, 'eta': 1825.90903, 'eta_hours': 0.5072, 'loss': 0.01194381, 'lr': 0.00061418, 'params': 195018, 'time_iter': 0.11909, 'accuracy': 0.99698, 'f1': 0.99697, 'auc': 0.99986}\n",
      "val: {'epoch': 37, 'time_epoch': 2.65716, 'loss': 0.16885543, 'lr': 0, 'params': 195018, 'time_iter': 0.05654, 'accuracy': 0.96909, 'f1': 0.96986, 'auc': 0.99798}\n",
      "test: {'epoch': 37, 'time_epoch': 2.66913, 'loss': 0.16358336, 'lr': 0, 'params': 195018, 'time_iter': 0.05679, 'accuracy': 0.96644, 'f1': 0.96598, 'auc': 0.99811}\n",
      "> Epoch 37: took 49.8s (avg 49.0s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 38, 'time_epoch': 42.71304, 'eta': 1781.63499, 'eta_hours': 0.4949, 'loss': 0.00821114, 'lr': 0.00059369, 'params': 195018, 'time_iter': 0.11451, 'accuracy': 0.99815, 'f1': 0.99815, 'auc': 0.99999}\n",
      "val: {'epoch': 38, 'time_epoch': 2.67217, 'loss': 0.14369545, 'lr': 0, 'params': 195018, 'time_iter': 0.05685, 'accuracy': 0.96909, 'f1': 0.96996, 'auc': 0.99744}\n",
      "test: {'epoch': 38, 'time_epoch': 2.65058, 'loss': 0.16576606, 'lr': 0, 'params': 195018, 'time_iter': 0.0564, 'accuracy': 0.96779, 'f1': 0.96702, 'auc': 0.99911}\n",
      "> Epoch 38: took 48.1s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 39, 'time_epoch': 43.22987, 'eta': 1737.95583, 'eta_hours': 0.48277, 'loss': 0.00823024, 'lr': 0.00057304, 'params': 195018, 'time_iter': 0.1159, 'accuracy': 0.99782, 'f1': 0.9978, 'auc': 0.99998}\n",
      "val: {'epoch': 39, 'time_epoch': 2.59057, 'loss': 0.13677753, 'lr': 0, 'params': 195018, 'time_iter': 0.05512, 'accuracy': 0.97446, 'f1': 0.97494, 'auc': 0.99757}\n",
      "test: {'epoch': 39, 'time_epoch': 2.84635, 'loss': 0.15407712, 'lr': 0, 'params': 195018, 'time_iter': 0.06056, 'accuracy': 0.97315, 'f1': 0.97184, 'auc': 0.99905}\n",
      "> Epoch 39: took 48.7s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 40, 'time_epoch': 44.8032, 'eta': 1695.79518, 'eta_hours': 0.47105, 'loss': 0.00506936, 'lr': 0.00055226, 'params': 195018, 'time_iter': 0.12012, 'accuracy': 0.99849, 'f1': 0.99848, 'auc': 1.0}\n",
      "val: {'epoch': 40, 'time_epoch': 2.87761, 'loss': 0.15290951, 'lr': 0, 'params': 195018, 'time_iter': 0.06123, 'accuracy': 0.96774, 'f1': 0.96785, 'auc': 0.99809}\n",
      "test: {'epoch': 40, 'time_epoch': 2.69515, 'loss': 0.19606836, 'lr': 0, 'params': 195018, 'time_iter': 0.05734, 'accuracy': 0.96107, 'f1': 0.96122, 'auc': 0.99834}\n",
      "> Epoch 40: took 50.4s (avg 49.0s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 41, 'time_epoch': 43.52131, 'eta': 1652.34888, 'eta_hours': 0.45899, 'loss': 0.00997704, 'lr': 0.0005314, 'params': 195018, 'time_iter': 0.11668, 'accuracy': 0.99714, 'f1': 0.99712, 'auc': 0.99998}\n",
      "val: {'epoch': 41, 'time_epoch': 2.76504, 'loss': 0.15168147, 'lr': 0, 'params': 195018, 'time_iter': 0.05883, 'accuracy': 0.97043, 'f1': 0.97071, 'auc': 0.99841}\n",
      "test: {'epoch': 41, 'time_epoch': 2.72009, 'loss': 0.17502255, 'lr': 0, 'params': 195018, 'time_iter': 0.05787, 'accuracy': 0.96779, 'f1': 0.96766, 'auc': 0.99864}\n",
      "> Epoch 41: took 49.1s (avg 49.0s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 42, 'time_epoch': 43.15748, 'eta': 1608.58603, 'eta_hours': 0.44683, 'loss': 0.00713144, 'lr': 0.00051047, 'params': 195018, 'time_iter': 0.1157, 'accuracy': 0.99849, 'f1': 0.99848, 'auc': 0.99999}\n",
      "val: {'epoch': 42, 'time_epoch': 2.96342, 'loss': 0.16407387, 'lr': 0, 'params': 195018, 'time_iter': 0.06305, 'accuracy': 0.96909, 'f1': 0.96973, 'auc': 0.99858}\n",
      "test: {'epoch': 42, 'time_epoch': 2.90543, 'loss': 0.21699824, 'lr': 0, 'params': 195018, 'time_iter': 0.06182, 'accuracy': 0.96242, 'f1': 0.96185, 'auc': 0.99825}\n",
      "> Epoch 42: took 49.1s (avg 49.0s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 43, 'time_epoch': 43.92605, 'eta': 1565.47954, 'eta_hours': 0.43486, 'loss': 0.00226656, 'lr': 0.00048953, 'params': 195018, 'time_iter': 0.11776, 'accuracy': 0.9995, 'f1': 0.99949, 'auc': 1.0}\n",
      "val: {'epoch': 43, 'time_epoch': 2.69295, 'loss': 0.13394814, 'lr': 0, 'params': 195018, 'time_iter': 0.0573, 'accuracy': 0.97581, 'f1': 0.97634, 'auc': 0.99916}\n",
      "test: {'epoch': 43, 'time_epoch': 2.71012, 'loss': 0.14588405, 'lr': 0, 'params': 195018, 'time_iter': 0.05766, 'accuracy': 0.97047, 'f1': 0.97083, 'auc': 0.99883}\n",
      "> Epoch 43: took 49.4s (avg 49.0s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 44, 'time_epoch': 43.42911, 'eta': 1521.9501, 'eta_hours': 0.42276, 'loss': 0.00122957, 'lr': 0.0004686, 'params': 195018, 'time_iter': 0.11643, 'accuracy': 0.99966, 'f1': 0.99966, 'auc': 1.0}\n",
      "val: {'epoch': 44, 'time_epoch': 2.81349, 'loss': 0.16559808, 'lr': 0, 'params': 195018, 'time_iter': 0.05986, 'accuracy': 0.97177, 'f1': 0.97253, 'auc': 0.99839}\n",
      "test: {'epoch': 44, 'time_epoch': 2.82854, 'loss': 0.17886921, 'lr': 0, 'params': 195018, 'time_iter': 0.06018, 'accuracy': 0.96242, 'f1': 0.96177, 'auc': 0.99843}\n",
      "> Epoch 44: took 49.1s (avg 49.0s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 45, 'time_epoch': 42.85204, 'eta': 1477.99849, 'eta_hours': 0.41056, 'loss': 0.00288753, 'lr': 0.00044774, 'params': 195018, 'time_iter': 0.11488, 'accuracy': 0.99933, 'f1': 0.99932, 'auc': 1.0}\n",
      "val: {'epoch': 45, 'time_epoch': 2.66742, 'loss': 0.19381782, 'lr': 0, 'params': 195018, 'time_iter': 0.05675, 'accuracy': 0.9664, 'f1': 0.96722, 'auc': 0.99753}\n",
      "test: {'epoch': 45, 'time_epoch': 2.8688, 'loss': 0.21332182, 'lr': 0, 'params': 195018, 'time_iter': 0.06104, 'accuracy': 0.96107, 'f1': 0.96125, 'auc': 0.99816}\n",
      "> Epoch 45: took 48.5s (avg 49.0s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 46, 'time_epoch': 42.57585, 'eta': 1433.89976, 'eta_hours': 0.39831, 'loss': 0.00441705, 'lr': 0.00042696, 'params': 195018, 'time_iter': 0.11414, 'accuracy': 0.99882, 'f1': 0.9988, 'auc': 1.0}\n",
      "val: {'epoch': 46, 'time_epoch': 2.65433, 'loss': 0.11959175, 'lr': 0, 'params': 195018, 'time_iter': 0.05648, 'accuracy': 0.97446, 'f1': 0.97501, 'auc': 0.99847}\n",
      "test: {'epoch': 46, 'time_epoch': 2.72998, 'loss': 0.1651222, 'lr': 0, 'params': 195018, 'time_iter': 0.05808, 'accuracy': 0.97181, 'f1': 0.97188, 'auc': 0.99853}\n",
      "> Epoch 46: took 48.0s (avg 49.0s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 47, 'time_epoch': 42.52229, 'eta': 1389.82877, 'eta_hours': 0.38606, 'loss': 0.00580149, 'lr': 0.00040631, 'params': 195018, 'time_iter': 0.114, 'accuracy': 0.99866, 'f1': 0.99863, 'auc': 1.0}\n",
      "val: {'epoch': 47, 'time_epoch': 2.65816, 'loss': 0.13655814, 'lr': 0, 'params': 195018, 'time_iter': 0.05656, 'accuracy': 0.97581, 'f1': 0.97618, 'auc': 0.99847}\n",
      "test: {'epoch': 47, 'time_epoch': 2.4814, 'loss': 0.17403483, 'lr': 0, 'params': 195018, 'time_iter': 0.0528, 'accuracy': 0.96779, 'f1': 0.9675, 'auc': 0.99765}\n",
      "> Epoch 47: took 47.7s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 48, 'time_epoch': 43.06728, 'eta': 1346.16579, 'eta_hours': 0.37393, 'loss': 0.00223451, 'lr': 0.00038582, 'params': 195018, 'time_iter': 0.11546, 'accuracy': 0.99966, 'f1': 0.99966, 'auc': 1.0}\n",
      "val: {'epoch': 48, 'time_epoch': 2.49615, 'loss': 0.14117832, 'lr': 0, 'params': 195018, 'time_iter': 0.05311, 'accuracy': 0.97849, 'f1': 0.97904, 'auc': 0.99842}\n",
      "test: {'epoch': 48, 'time_epoch': 3.0163, 'loss': 0.17024066, 'lr': 0, 'params': 195018, 'time_iter': 0.06418, 'accuracy': 0.97047, 'f1': 0.96964, 'auc': 0.99725}\n",
      "> Epoch 48: took 48.6s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 49, 'time_epoch': 42.82232, 'eta': 1302.37965, 'eta_hours': 0.36177, 'loss': 0.00336024, 'lr': 0.00036554, 'params': 195018, 'time_iter': 0.11481, 'accuracy': 0.99916, 'f1': 0.99914, 'auc': 0.99998}\n",
      "val: {'epoch': 49, 'time_epoch': 2.50878, 'loss': 0.1642213, 'lr': 0, 'params': 195018, 'time_iter': 0.05338, 'accuracy': 0.96774, 'f1': 0.96808, 'auc': 0.99835}\n",
      "test: {'epoch': 49, 'time_epoch': 2.98981, 'loss': 0.15858543, 'lr': 0, 'params': 195018, 'time_iter': 0.06361, 'accuracy': 0.97584, 'f1': 0.97589, 'auc': 0.99855}\n",
      "> Epoch 49: took 48.4s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 50, 'time_epoch': 43.36605, 'eta': 1258.9405, 'eta_hours': 0.34971, 'loss': 0.00215177, 'lr': 0.00034549, 'params': 195018, 'time_iter': 0.11626, 'accuracy': 0.9995, 'f1': 0.9995, 'auc': 1.0}\n",
      "val: {'epoch': 50, 'time_epoch': 2.45963, 'loss': 0.15030925, 'lr': 0, 'params': 195018, 'time_iter': 0.05233, 'accuracy': 0.97581, 'f1': 0.97619, 'auc': 0.99815}\n",
      "test: {'epoch': 50, 'time_epoch': 2.64395, 'loss': 0.17368242, 'lr': 0, 'params': 195018, 'time_iter': 0.05625, 'accuracy': 0.96779, 'f1': 0.96792, 'auc': 0.99845}\n",
      "> Epoch 50: took 48.5s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 51, 'time_epoch': 43.19202, 'eta': 1215.41045, 'eta_hours': 0.33761, 'loss': 0.00280796, 'lr': 0.00032571, 'params': 195018, 'time_iter': 0.1158, 'accuracy': 0.99899, 'f1': 0.99898, 'auc': 1.0}\n",
      "val: {'epoch': 51, 'time_epoch': 2.63348, 'loss': 0.13363227, 'lr': 0, 'params': 195018, 'time_iter': 0.05603, 'accuracy': 0.97581, 'f1': 0.97628, 'auc': 0.99776}\n",
      "test: {'epoch': 51, 'time_epoch': 2.62903, 'loss': 0.14014428, 'lr': 0, 'params': 195018, 'time_iter': 0.05594, 'accuracy': 0.9745, 'f1': 0.97461, 'auc': 0.99902}\n",
      "> Epoch 51: took 48.5s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 52, 'time_epoch': 43.40857, 'eta': 1172.00347, 'eta_hours': 0.32556, 'loss': 0.00043461, 'lr': 0.00030624, 'params': 195018, 'time_iter': 0.11638, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 52, 'time_epoch': 2.63999, 'loss': 0.12186152, 'lr': 0, 'params': 195018, 'time_iter': 0.05617, 'accuracy': 0.97715, 'f1': 0.97738, 'auc': 0.99908}\n",
      "test: {'epoch': 52, 'time_epoch': 2.46385, 'loss': 0.1533425, 'lr': 0, 'params': 195018, 'time_iter': 0.05242, 'accuracy': 0.9745, 'f1': 0.97442, 'auc': 0.99855}\n",
      "> Epoch 52: took 48.6s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 53, 'time_epoch': 43.47209, 'eta': 1128.62701, 'eta_hours': 0.31351, 'loss': 0.0003813, 'lr': 0.00028711, 'params': 195018, 'time_iter': 0.11655, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 53, 'time_epoch': 2.67113, 'loss': 0.14842724, 'lr': 0, 'params': 195018, 'time_iter': 0.05683, 'accuracy': 0.97581, 'f1': 0.97624, 'auc': 0.99794}\n",
      "test: {'epoch': 53, 'time_epoch': 2.54007, 'loss': 0.19775985, 'lr': 0, 'params': 195018, 'time_iter': 0.05404, 'accuracy': 0.96779, 'f1': 0.96759, 'auc': 0.99902}\n",
      "> Epoch 53: took 48.7s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 54, 'time_epoch': 43.66885, 'eta': 1085.33652, 'eta_hours': 0.30148, 'loss': 0.00031433, 'lr': 0.00026835, 'params': 195018, 'time_iter': 0.11707, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 54, 'time_epoch': 2.73445, 'loss': 0.13591845, 'lr': 0, 'params': 195018, 'time_iter': 0.05818, 'accuracy': 0.97581, 'f1': 0.9762, 'auc': 0.99837}\n",
      "test: {'epoch': 54, 'time_epoch': 2.96484, 'loss': 0.18450172, 'lr': 0, 'params': 195018, 'time_iter': 0.06308, 'accuracy': 0.97047, 'f1': 0.97045, 'auc': 0.99873}\n",
      "> Epoch 54: took 49.4s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 55, 'time_epoch': 43.49992, 'eta': 1041.96011, 'eta_hours': 0.28943, 'loss': 0.00039909, 'lr': 0.00025, 'params': 195018, 'time_iter': 0.11662, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 55, 'time_epoch': 2.5629, 'loss': 0.14093026, 'lr': 0, 'params': 195018, 'time_iter': 0.05453, 'accuracy': 0.97581, 'f1': 0.9764, 'auc': 0.99806}\n",
      "test: {'epoch': 55, 'time_epoch': 3.03716, 'loss': 0.19866855, 'lr': 0, 'params': 195018, 'time_iter': 0.06462, 'accuracy': 0.96779, 'f1': 0.96769, 'auc': 0.99871}\n",
      "> Epoch 55: took 49.2s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 56, 'time_epoch': 43.68697, 'eta': 998.65485, 'eta_hours': 0.2774, 'loss': 0.0002726, 'lr': 0.00023209, 'params': 195018, 'time_iter': 0.11712, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 56, 'time_epoch': 2.74036, 'loss': 0.12506745, 'lr': 0, 'params': 195018, 'time_iter': 0.05831, 'accuracy': 0.97849, 'f1': 0.97889, 'auc': 0.99837}\n",
      "test: {'epoch': 56, 'time_epoch': 2.63975, 'loss': 0.18683569, 'lr': 0, 'params': 195018, 'time_iter': 0.05616, 'accuracy': 0.96913, 'f1': 0.96925, 'auc': 0.99858}\n",
      "> Epoch 56: took 49.1s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 57, 'time_epoch': 44.33152, 'eta': 955.5809, 'eta_hours': 0.26544, 'loss': 0.00026228, 'lr': 0.00021464, 'params': 195018, 'time_iter': 0.11885, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 57, 'time_epoch': 2.70863, 'loss': 0.14472831, 'lr': 0, 'params': 195018, 'time_iter': 0.05763, 'accuracy': 0.97446, 'f1': 0.97504, 'auc': 0.99811}\n",
      "test: {'epoch': 57, 'time_epoch': 2.77699, 'loss': 0.18326541, 'lr': 0, 'params': 195018, 'time_iter': 0.05908, 'accuracy': 0.96913, 'f1': 0.96911, 'auc': 0.9989}\n",
      "> Epoch 57: took 49.9s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 58, 'time_epoch': 44.7475, 'eta': 912.61239, 'eta_hours': 0.2535, 'loss': 0.00144642, 'lr': 0.0001977, 'params': 195018, 'time_iter': 0.11997, 'accuracy': 0.99983, 'f1': 0.99982, 'auc': 1.0}\n",
      "val: {'epoch': 58, 'time_epoch': 2.83185, 'loss': 0.15576468, 'lr': 0, 'params': 195018, 'time_iter': 0.06025, 'accuracy': 0.97581, 'f1': 0.97635, 'auc': 0.99789}\n",
      "test: {'epoch': 58, 'time_epoch': 2.82178, 'loss': 0.19502874, 'lr': 0, 'params': 195018, 'time_iter': 0.06004, 'accuracy': 0.96779, 'f1': 0.9672, 'auc': 0.99763}\n",
      "> Epoch 58: took 50.5s (avg 48.9s) | Best so far: epoch 28\ttrain_loss: 0.0168 train_accuracy: 0.9946\tval_loss: 0.1130 val_accuracy: 0.9785\ttest_loss: 0.1599 test_accuracy: 0.9651\n",
      "train: {'epoch': 59, 'time_epoch': 42.50659, 'eta': 868.83761, 'eta_hours': 0.24134, 'loss': 0.00045636, 'lr': 0.00018129, 'params': 195018, 'time_iter': 0.11396, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 59, 'time_epoch': 2.72914, 'loss': 0.1222468, 'lr': 0, 'params': 195018, 'time_iter': 0.05807, 'accuracy': 0.97984, 'f1': 0.97997, 'auc': 0.99897}\n",
      "test: {'epoch': 59, 'time_epoch': 2.86966, 'loss': 0.19320658, 'lr': 0, 'params': 195018, 'time_iter': 0.06106, 'accuracy': 0.97047, 'f1': 0.97019, 'auc': 0.99868}\n",
      "> Epoch 59: took 48.2s (avg 48.9s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 60, 'time_epoch': 44.2353, 'eta': 825.64286, 'eta_hours': 0.22935, 'loss': 0.00202647, 'lr': 0.00016543, 'params': 195018, 'time_iter': 0.11859, 'accuracy': 0.99933, 'f1': 0.99933, 'auc': 1.0}\n",
      "val: {'epoch': 60, 'time_epoch': 2.64571, 'loss': 0.17210645, 'lr': 0, 'params': 195018, 'time_iter': 0.05629, 'accuracy': 0.97177, 'f1': 0.97244, 'auc': 0.99761}\n",
      "test: {'epoch': 60, 'time_epoch': 2.47663, 'loss': 0.21678532, 'lr': 0, 'params': 195018, 'time_iter': 0.05269, 'accuracy': 0.96913, 'f1': 0.96851, 'auc': 0.9968}\n",
      "> Epoch 60: took 49.4s (avg 48.9s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 61, 'time_epoch': 42.64361, 'eta': 781.95245, 'eta_hours': 0.21721, 'loss': 0.00026459, 'lr': 0.00015017, 'params': 195018, 'time_iter': 0.11433, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 61, 'time_epoch': 2.80419, 'loss': 0.14147275, 'lr': 0, 'params': 195018, 'time_iter': 0.05966, 'accuracy': 0.97446, 'f1': 0.97488, 'auc': 0.99877}\n",
      "test: {'epoch': 61, 'time_epoch': 3.09494, 'loss': 0.18301551, 'lr': 0, 'params': 195018, 'time_iter': 0.06585, 'accuracy': 0.97315, 'f1': 0.97281, 'auc': 0.99856}\n",
      "> Epoch 61: took 48.6s (avg 48.9s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 62, 'time_epoch': 44.72882, 'eta': 738.85793, 'eta_hours': 0.20524, 'loss': 0.00108883, 'lr': 0.00013552, 'params': 195018, 'time_iter': 0.11992, 'accuracy': 0.99966, 'f1': 0.99965, 'auc': 1.0}\n",
      "val: {'epoch': 62, 'time_epoch': 2.83603, 'loss': 0.14179655, 'lr': 0, 'params': 195018, 'time_iter': 0.06034, 'accuracy': 0.97715, 'f1': 0.97765, 'auc': 0.99835}\n",
      "test: {'epoch': 62, 'time_epoch': 2.86426, 'loss': 0.17935351, 'lr': 0, 'params': 195018, 'time_iter': 0.06094, 'accuracy': 0.96242, 'f1': 0.96271, 'auc': 0.99795}\n",
      "> Epoch 62: took 50.5s (avg 49.0s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 63, 'time_epoch': 44.3263, 'eta': 695.61172, 'eta_hours': 0.19323, 'loss': 0.00156224, 'lr': 0.0001215, 'params': 195018, 'time_iter': 0.11884, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 63, 'time_epoch': 2.85914, 'loss': 0.15032341, 'lr': 0, 'params': 195018, 'time_iter': 0.06083, 'accuracy': 0.97581, 'f1': 0.97612, 'auc': 0.99816}\n",
      "test: {'epoch': 63, 'time_epoch': 2.6348, 'loss': 0.17603105, 'lr': 0, 'params': 195018, 'time_iter': 0.05606, 'accuracy': 0.96644, 'f1': 0.96624, 'auc': 0.99839}\n",
      "> Epoch 63: took 49.9s (avg 49.0s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 64, 'time_epoch': 45.03048, 'eta': 652.49477, 'eta_hours': 0.18125, 'loss': 0.00021623, 'lr': 0.00010815, 'params': 195018, 'time_iter': 0.12073, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 64, 'time_epoch': 2.73838, 'loss': 0.13751891, 'lr': 0, 'params': 195018, 'time_iter': 0.05826, 'accuracy': 0.97849, 'f1': 0.9789, 'auc': 0.99826}\n",
      "test: {'epoch': 64, 'time_epoch': 2.68023, 'loss': 0.17390082, 'lr': 0, 'params': 195018, 'time_iter': 0.05703, 'accuracy': 0.97047, 'f1': 0.97049, 'auc': 0.99739}\n",
      "> Epoch 64: took 50.5s (avg 49.0s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 65, 'time_epoch': 46.65064, 'eta': 609.66351, 'eta_hours': 0.16935, 'loss': 0.00148719, 'lr': 9.549e-05, 'params': 195018, 'time_iter': 0.12507, 'accuracy': 0.99966, 'f1': 0.99967, 'auc': 1.0}\n",
      "val: {'epoch': 65, 'time_epoch': 2.8901, 'loss': 0.14293309, 'lr': 0, 'params': 195018, 'time_iter': 0.06149, 'accuracy': 0.97581, 'f1': 0.97625, 'auc': 0.99817}\n",
      "test: {'epoch': 65, 'time_epoch': 2.89553, 'loss': 0.1767587, 'lr': 0, 'params': 195018, 'time_iter': 0.06161, 'accuracy': 0.96779, 'f1': 0.96793, 'auc': 0.99757}\n",
      "> Epoch 65: took 52.5s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 66, 'time_epoch': 46.21615, 'eta': 566.63394, 'eta_hours': 0.1574, 'loss': 0.00078317, 'lr': 8.354e-05, 'params': 195018, 'time_iter': 0.1239, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 66, 'time_epoch': 2.95904, 'loss': 0.13940436, 'lr': 0, 'params': 195018, 'time_iter': 0.06296, 'accuracy': 0.97715, 'f1': 0.9776, 'auc': 0.99803}\n",
      "test: {'epoch': 66, 'time_epoch': 2.68239, 'loss': 0.17860237, 'lr': 0, 'params': 195018, 'time_iter': 0.05707, 'accuracy': 0.97181, 'f1': 0.97192, 'auc': 0.99734}\n",
      "> Epoch 66: took 51.9s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 67, 'time_epoch': 44.0791, 'eta': 523.13351, 'eta_hours': 0.14531, 'loss': 0.00019284, 'lr': 7.232e-05, 'params': 195018, 'time_iter': 0.11817, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 67, 'time_epoch': 2.84969, 'loss': 0.13411243, 'lr': 0, 'params': 195018, 'time_iter': 0.06063, 'accuracy': 0.97849, 'f1': 0.97888, 'auc': 0.9983}\n",
      "test: {'epoch': 67, 'time_epoch': 2.76819, 'loss': 0.17664277, 'lr': 0, 'params': 195018, 'time_iter': 0.0589, 'accuracy': 0.97181, 'f1': 0.97179, 'auc': 0.99754}\n",
      "> Epoch 67: took 49.8s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 68, 'time_epoch': 42.09832, 'eta': 479.30054, 'eta_hours': 0.13314, 'loss': 0.00017602, 'lr': 6.185e-05, 'params': 195018, 'time_iter': 0.11286, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 68, 'time_epoch': 2.707, 'loss': 0.15120483, 'lr': 0, 'params': 195018, 'time_iter': 0.0576, 'accuracy': 0.97581, 'f1': 0.97632, 'auc': 0.99788}\n",
      "test: {'epoch': 68, 'time_epoch': 2.6332, 'loss': 0.17630311, 'lr': 0, 'params': 195018, 'time_iter': 0.05603, 'accuracy': 0.97315, 'f1': 0.97305, 'auc': 0.99773}\n",
      "> Epoch 68: took 47.5s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 69, 'time_epoch': 42.23993, 'eta': 435.53736, 'eta_hours': 0.12098, 'loss': 0.00141437, 'lr': 5.214e-05, 'params': 195018, 'time_iter': 0.11324, 'accuracy': 0.99983, 'f1': 0.99984, 'auc': 1.0}\n",
      "val: {'epoch': 69, 'time_epoch': 2.70175, 'loss': 0.13988129, 'lr': 0, 'params': 195018, 'time_iter': 0.05748, 'accuracy': 0.97849, 'f1': 0.97897, 'auc': 0.99828}\n",
      "test: {'epoch': 69, 'time_epoch': 2.81186, 'loss': 0.17709066, 'lr': 0, 'params': 195018, 'time_iter': 0.05983, 'accuracy': 0.97181, 'f1': 0.97165, 'auc': 0.99757}\n",
      "> Epoch 69: took 47.8s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 70, 'time_epoch': 43.0391, 'eta': 391.91839, 'eta_hours': 0.10887, 'loss': 0.00018594, 'lr': 4.323e-05, 'params': 195018, 'time_iter': 0.11539, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 70, 'time_epoch': 2.74785, 'loss': 0.14166461, 'lr': 0, 'params': 195018, 'time_iter': 0.05846, 'accuracy': 0.97849, 'f1': 0.97899, 'auc': 0.99893}\n",
      "test: {'epoch': 70, 'time_epoch': 2.73682, 'loss': 0.17426575, 'lr': 0, 'params': 195018, 'time_iter': 0.05823, 'accuracy': 0.97315, 'f1': 0.97295, 'auc': 0.99801}\n",
      "> Epoch 70: took 48.6s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 71, 'time_epoch': 44.76364, 'eta': 348.50714, 'eta_hours': 0.09681, 'loss': 0.00016277, 'lr': 3.511e-05, 'params': 195018, 'time_iter': 0.12001, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 71, 'time_epoch': 2.92022, 'loss': 0.14385802, 'lr': 0, 'params': 195018, 'time_iter': 0.06213, 'accuracy': 0.97849, 'f1': 0.97896, 'auc': 0.99868}\n",
      "test: {'epoch': 71, 'time_epoch': 2.91144, 'loss': 0.17579437, 'lr': 0, 'params': 195018, 'time_iter': 0.06195, 'accuracy': 0.97315, 'f1': 0.97284, 'auc': 0.99782}\n",
      "> Epoch 71: took 50.7s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 72, 'time_epoch': 45.56053, 'eta': 305.13525, 'eta_hours': 0.08476, 'loss': 0.00015307, 'lr': 2.781e-05, 'params': 195018, 'time_iter': 0.12215, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 72, 'time_epoch': 2.60581, 'loss': 0.14709103, 'lr': 0, 'params': 195018, 'time_iter': 0.05544, 'accuracy': 0.97984, 'f1': 0.98026, 'auc': 0.9984}\n",
      "test: {'epoch': 72, 'time_epoch': 2.66019, 'loss': 0.17168452, 'lr': 0, 'params': 195018, 'time_iter': 0.0566, 'accuracy': 0.97315, 'f1': 0.97295, 'auc': 0.99769}\n",
      "> Epoch 72: took 50.9s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 73, 'time_epoch': 44.58722, 'eta': 261.6253, 'eta_hours': 0.07267, 'loss': 0.00016045, 'lr': 2.134e-05, 'params': 195018, 'time_iter': 0.11954, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 73, 'time_epoch': 2.56356, 'loss': 0.14668299, 'lr': 0, 'params': 195018, 'time_iter': 0.05454, 'accuracy': 0.97849, 'f1': 0.97896, 'auc': 0.99864}\n",
      "test: {'epoch': 73, 'time_epoch': 2.63413, 'loss': 0.17031054, 'lr': 0, 'params': 195018, 'time_iter': 0.05605, 'accuracy': 0.9745, 'f1': 0.97425, 'auc': 0.99802}\n",
      "> Epoch 73: took 49.9s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 74, 'time_epoch': 43.53646, 'eta': 218.01656, 'eta_hours': 0.06056, 'loss': 0.00015563, 'lr': 1.571e-05, 'params': 195018, 'time_iter': 0.11672, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 74, 'time_epoch': 2.62806, 'loss': 0.1488561, 'lr': 0, 'params': 195018, 'time_iter': 0.05592, 'accuracy': 0.97849, 'f1': 0.97899, 'auc': 0.99865}\n",
      "test: {'epoch': 74, 'time_epoch': 2.80867, 'loss': 0.17872223, 'lr': 0, 'params': 195018, 'time_iter': 0.05976, 'accuracy': 0.97181, 'f1': 0.97146, 'auc': 0.99785}\n",
      "> Epoch 74: took 49.1s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 75, 'time_epoch': 43.15607, 'eta': 174.38971, 'eta_hours': 0.04844, 'loss': 0.00015249, 'lr': 1.093e-05, 'params': 195018, 'time_iter': 0.1157, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 75, 'time_epoch': 2.83953, 'loss': 0.13952703, 'lr': 0, 'params': 195018, 'time_iter': 0.06042, 'accuracy': 0.97984, 'f1': 0.98027, 'auc': 0.99887}\n",
      "test: {'epoch': 75, 'time_epoch': 2.76898, 'loss': 0.17477935, 'lr': 0, 'params': 195018, 'time_iter': 0.05891, 'accuracy': 0.97315, 'f1': 0.97295, 'auc': 0.99816}\n",
      "> Epoch 75: took 48.8s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 76, 'time_epoch': 42.89856, 'eta': 130.76505, 'eta_hours': 0.03632, 'loss': 0.00015185, 'lr': 7e-06, 'params': 195018, 'time_iter': 0.11501, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 76, 'time_epoch': 2.80747, 'loss': 0.16074771, 'lr': 0, 'params': 195018, 'time_iter': 0.05973, 'accuracy': 0.97849, 'f1': 0.97899, 'auc': 0.99814}\n",
      "test: {'epoch': 76, 'time_epoch': 2.69539, 'loss': 0.1817355, 'lr': 0, 'params': 195018, 'time_iter': 0.05735, 'accuracy': 0.97315, 'f1': 0.97255, 'auc': 0.99767}\n",
      "> Epoch 76: took 48.5s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 77, 'time_epoch': 43.7062, 'eta': 87.17973, 'eta_hours': 0.02422, 'loss': 0.00015572, 'lr': 3.94e-06, 'params': 195018, 'time_iter': 0.11717, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 77, 'time_epoch': 2.76784, 'loss': 0.14472865, 'lr': 0, 'params': 195018, 'time_iter': 0.05889, 'accuracy': 0.97984, 'f1': 0.98026, 'auc': 0.99874}\n",
      "test: {'epoch': 77, 'time_epoch': 2.70823, 'loss': 0.17361052, 'lr': 0, 'params': 195018, 'time_iter': 0.05762, 'accuracy': 0.97315, 'f1': 0.97295, 'auc': 0.99802}\n",
      "> Epoch 77: took 49.2s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 78, 'time_epoch': 43.8281, 'eta': 43.59288, 'eta_hours': 0.01211, 'loss': 0.002557, 'lr': 1.75e-06, 'params': 195018, 'time_iter': 0.1175, 'accuracy': 0.99966, 'f1': 0.99966, 'auc': 1.0}\n",
      "val: {'epoch': 78, 'time_epoch': 2.73358, 'loss': 0.13612262, 'lr': 0, 'params': 195018, 'time_iter': 0.05816, 'accuracy': 0.97849, 'f1': 0.97896, 'auc': 0.99876}\n",
      "test: {'epoch': 78, 'time_epoch': 2.84941, 'loss': 0.17205709, 'lr': 0, 'params': 195018, 'time_iter': 0.06063, 'accuracy': 0.97181, 'f1': 0.97155, 'auc': 0.9981}\n",
      "> Epoch 78: took 49.5s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "train: {'epoch': 79, 'time_epoch': 45.44221, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.00014672, 'lr': 4.4e-07, 'params': 195018, 'time_iter': 0.12183, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "val: {'epoch': 79, 'time_epoch': 3.09708, 'loss': 0.1397737, 'lr': 0, 'params': 195018, 'time_iter': 0.0659, 'accuracy': 0.97984, 'f1': 0.98029, 'auc': 0.99876}\n",
      "test: {'epoch': 79, 'time_epoch': 3.21274, 'loss': 0.17741552, 'lr': 0, 'params': 195018, 'time_iter': 0.06836, 'accuracy': 0.97315, 'f1': 0.97265, 'auc': 0.99827}\n",
      "> Epoch 79: took 51.8s (avg 49.1s) | Best so far: epoch 59\ttrain_loss: 0.0005 train_accuracy: 1.0000\tval_loss: 0.1222 val_accuracy: 0.9798\ttest_loss: 0.1932 test_accuracy: 0.9705\n",
      "Avg time per epoch: 49.14s\n",
      "Total train loop time: 1.09h\n",
      "Task done, results saved in results\\neural-Act\\0\n",
      "59\n",
      "{'epoch': 59, 'time_epoch': 2.86966, 'loss': 0.19320658, 'lr': 0, 'params': 195018, 'time_iter': 0.06106, 'accuracy': 0.97047, 'f1': 0.97019, 'auc': 0.99868}\n",
      "{'epoch': 59, 'time_epoch': 42.50659, 'eta': 868.83761, 'eta_hours': 0.24134, 'loss': 0.00045636, 'lr': 0.00018129, 'params': 195018, 'time_iter': 0.11396, 'accuracy': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "{'epoch': 59, 'time_epoch': 2.72914, 'loss': 0.1222468, 'lr': 0, 'params': 195018, 'time_iter': 0.05807, 'accuracy': 0.97984, 'f1': 0.97997, 'auc': 0.99897}\n",
      "Results aggregated across runs saved in results\\neural-Act\\agg\n",
      "[*] All done: 2024-03-03 04:21:15.764568\n"
     ]
    }
   ],
   "source": [
    "#CustomGatedGCN+Exphormer dropout 0.3 attn dropout 0.5\n",
    "%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186098d4-04b4-46c4-8fe4-835c8f33daa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-03-05 03:12:39.557013\n",
      "[*] Loaded dataset 'HCPActivity' from 'PyG-NeuroGraphDataset':\n",
      "  Data(x=[2977200, 400], edge_index=[2, 52318216], y=[7443])\n",
      "  undirected: True\n",
      "  num graphs: 7443\n",
      "  avg num_nodes/graph: 400\n",
      "  num node features: 400\n",
      "  num edge features: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\jmlr9\\.conda\\envs\\neuro\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  num classes: 7\n",
      "Precomputing Positional Encoding statistics: ['EquivStableLapPE'] for all graphs...\n",
      "  ...estimated to be undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7443/7443 [15:39<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:15:46.50\n",
      "Adding expander edges (round 0) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7443/7443 [00:57<00:00, 129.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 00:00:59.66\n",
      "--------------------Begining splitting\n",
      "--------------------Finish splitting\n",
      "GraphGymModule(\n",
      "  (model): MultiModel(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): Concat2NodeEncoder(\n",
      "        (encoder1): LinearNodeEncoder(\n",
      "          (encoder): Linear(in_features=400, out_features=64, bias=True)\n",
      "        )\n",
      "        (encoder2): EquivStableLapPENodeEncoder(\n",
      "          (linear_encoder_eigenvec): Linear(in_features=8, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_encoder): LinearEdgeEncoder(\n",
      "        (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
      "      )\n",
      "      (exp_edge_fixer): ExpanderEdgeFixer(\n",
      "        (exp_edge_attr): Embedding(1, 64)\n",
      "        (virt_node_emb): Embedding(1, 64)\n",
      "        (virt_edge_out_emb): Embedding(1, 64)\n",
      "        (virt_edge_in_emb): Embedding(1, 64)\n",
      "      )\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=2\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=2\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=2\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=2\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): MultiLayer(\n",
      "        summary: dim_h=64, local_gnn_type=['CustomGatedGCN', 'Exphormer'], heads=2\n",
      "        (models): ModuleList(\n",
      "          (0): LocalModel(\n",
      "            (local_model): GatedGCNLayer()\n",
      "            (norm1_local): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_local): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): GlobalModel(\n",
      "            (self_attn): ExphormerAttention(\n",
      "              (Q): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (K): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (E): Linear(in_features=64, out_features=64, bias=False)\n",
      "              (V): Linear(in_features=64, out_features=64, bias=False)\n",
      "            )\n",
      "            (norm1_attn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (dropout_attn): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (ff_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (ff_dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (ff_dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): GeneralMultiLayer(\n",
      "            (Layer_0): GeneralLayer(\n",
      "              (layer): Linear(\n",
      "                (model): Linear(64, 64, bias=True)\n",
      "              )\n",
      "              (post_layer): Sequential(\n",
      "                (0): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Linear(\n",
      "            (model): Linear(64, 7, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: True\n",
      "  edge_encoder_bn: False\n",
      "  edge_encoder_name: LinearEdge\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG-NeuroGraphDataset\n",
      "  infer_link_label: None\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: HCPActivity\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: LinearNode+EquivStableLapPE\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: random\n",
      "  task: graph\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 64\n",
      "  dropout: 0.1\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: generalconv\n",
      "  layers_mp: 2\n",
      "  layers_post_mp: 2\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "graphormer:\n",
      "  attention_dropout: 0.0\n",
      "  dropout: 0.0\n",
      "  embed_dim: 80\n",
      "  input_dropout: 0.0\n",
      "  mlp_dropout: 0.0\n",
      "  num_heads: 4\n",
      "  num_layers: 6\n",
      "  use_graph_token: True\n",
      "gt:\n",
      "  activation: relu\n",
      "  attn_dropout: 0.1\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_edge: 64\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.1\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: CustomGatedGCN+Exphormer\n",
      "  layers: 5\n",
      "  n_heads: 2\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "  secondary_edges: full_graph\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: accuracy\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: MultiModel\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: True\n",
      "  clip_grad_norm_value: 1.0\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 70\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cosine_with_warmup\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 1e-05\n",
      "out_dir: results\\neural-Act\n",
      "posenc_ERE:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ERN:\n",
      "  accuracy: 0.1\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  er_dim: none\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: none\n",
      "    max_freqs: 8\n",
      "  enable: True\n",
      "  raw_norm_type: none\n",
      "posenc_GraphormerBias:\n",
      "  dim_pe: 0\n",
      "  enable: False\n",
      "  node_degrees_only: False\n",
      "  num_in_degrees: None\n",
      "  num_out_degrees: None\n",
      "  num_spatial_types: None\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "prep:\n",
      "  add_edge_index: True\n",
      "  add_reverse_edges: True\n",
      "  add_self_loops: False\n",
      "  dist_cutoff: 510\n",
      "  dist_enable: False\n",
      "  exp: True\n",
      "  exp_algorithm: Random-d\n",
      "  exp_count: 1\n",
      "  exp_deg: 5\n",
      "  exp_max_num_iters: 100\n",
      "  layer_edge_indices_dir: None\n",
      "  num_virt_node: 1\n",
      "  train_percent: 0.6\n",
      "  use_exp_edges: True\n",
      "pretrained:\n",
      "  dir: \n",
      "  freeze_main: False\n",
      "  reset_prediction_head: True\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results\\neural-Act\\0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 400\n",
      "  dim_out: 7\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: True\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 16\n",
      "  ckpt_best: False\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: gtransformers\n",
      "  name: \n",
      "  project: neural\n",
      "  use: False\n",
      "Num parameters: 304204\n",
      "Start from epoch 0\n",
      "train: {'epoch': 0, 'time_epoch': 63.18487, 'eta': 4359.75624, 'eta_hours': 1.21104, 'loss': 1.94719871, 'lr': 0.0, 'params': 304204, 'time_iter': 0.1694, 'accuracy': 0.14931, 'f1': 0.07362, 'auc': 0.52073}\n",
      "...computing epoch stats took: 0.19s\n",
      "val: {'epoch': 0, 'time_epoch': 3.52931, 'loss': 1.95215172, 'lr': 0, 'params': 304204, 'time_iter': 0.07509, 'accuracy': 0.13172, 'f1': 0.05858, 'auc': 0.51593}\n",
      "...computing epoch stats took: 0.06s\n",
      "test: {'epoch': 0, 'time_epoch': 3.79642, 'loss': 1.95601626, 'lr': 0, 'params': 304204, 'time_iter': 0.08077, 'accuracy': 0.12886, 'f1': 0.05904, 'auc': 0.53325}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 0: took 70.8s (avg 70.8s) | Best so far: epoch 0\ttrain_loss: 1.9472 train_accuracy: 0.1493\tval_loss: 1.9522 val_accuracy: 0.1317\ttest_loss: 1.9560 test_accuracy: 0.1289\n",
      "train: {'epoch': 1, 'time_epoch': 61.36072, 'eta': 4234.55007, 'eta_hours': 1.17626, 'loss': 1.68697382, 'lr': 0.0002, 'params': 304204, 'time_iter': 0.16451, 'accuracy': 0.61992, 'f1': 0.59781, 'auc': 0.90793}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 1, 'time_epoch': 3.80407, 'loss': 1.5089153, 'lr': 0, 'params': 304204, 'time_iter': 0.08094, 'accuracy': 0.78629, 'f1': 0.78509, 'auc': 0.97328}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 1, 'time_epoch': 3.49402, 'loss': 1.50504893, 'lr': 0, 'params': 304204, 'time_iter': 0.07434, 'accuracy': 0.82148, 'f1': 0.8165, 'auc': 0.97611}\n",
      "...computing epoch stats took: 0.01s\n",
      "> Epoch 1: took 68.7s (avg 69.8s) | Best so far: epoch 1\ttrain_loss: 1.6870 train_accuracy: 0.6199\tval_loss: 1.5089 val_accuracy: 0.7863\ttest_loss: 1.5050 test_accuracy: 0.8215\n",
      "train: {'epoch': 2, 'time_epoch': 62.44348, 'eta': 4176.08916, 'eta_hours': 1.16002, 'loss': 1.29337024, 'lr': 0.0004, 'params': 304204, 'time_iter': 0.16741, 'accuracy': 0.85791, 'f1': 0.8546, 'auc': 0.97443}\n",
      "...computing epoch stats took: 0.02s\n",
      "val: {'epoch': 2, 'time_epoch': 3.62208, 'loss': 1.10354582, 'lr': 0, 'params': 304204, 'time_iter': 0.07707, 'accuracy': 0.89785, 'f1': 0.90282, 'auc': 0.9847}\n",
      "...computing epoch stats took: 0.01s\n",
      "test: {'epoch': 2, 'time_epoch': 4.31486, 'loss': 1.10165815, 'lr': 0, 'params': 304204, 'time_iter': 0.09181, 'accuracy': 0.89933, 'f1': 0.90236, 'auc': 0.98808}\n",
      "...computing epoch stats took: 0.03s\n",
      "> Epoch 2: took 70.4s (avg 70.0s) | Best so far: epoch 2\ttrain_loss: 1.2934 train_accuracy: 0.8579\tval_loss: 1.1035 val_accuracy: 0.8979\ttest_loss: 1.1017 test_accuracy: 0.8993\n",
      "train: {'epoch': 3, 'time_epoch': 63.00834, 'eta': 4124.95713, 'eta_hours': 1.14582, 'loss': 0.89021472, 'lr': 0.0006, 'params': 304204, 'time_iter': 0.16892, 'accuracy': 0.913, 'f1': 0.91227, 'auc': 0.98575}\n",
      "val: {'epoch': 3, 'time_epoch': 3.58115, 'loss': 0.73020252, 'lr': 0, 'params': 304204, 'time_iter': 0.07619, 'accuracy': 0.91129, 'f1': 0.9136, 'auc': 0.98947}\n",
      "test: {'epoch': 3, 'time_epoch': 3.5998, 'loss': 0.71914103, 'lr': 0, 'params': 304204, 'time_iter': 0.07659, 'accuracy': 0.92349, 'f1': 0.92398, 'auc': 0.9892}\n",
      "> Epoch 3: took 70.3s (avg 70.1s) | Best so far: epoch 3\ttrain_loss: 0.8902 train_accuracy: 0.9130\tval_loss: 0.7302 val_accuracy: 0.9113\ttest_loss: 0.7191 test_accuracy: 0.9235\n",
      "train: {'epoch': 4, 'time_epoch': 61.85454, 'eta': 4054.07519, 'eta_hours': 1.12613, 'loss': 0.58754663, 'lr': 0.0008, 'params': 304204, 'time_iter': 0.16583, 'accuracy': 0.9256, 'f1': 0.92527, 'auc': 0.99028}\n",
      "val: {'epoch': 4, 'time_epoch': 3.6256, 'loss': 0.4859247, 'lr': 0, 'params': 304204, 'time_iter': 0.07714, 'accuracy': 0.9328, 'f1': 0.93382, 'auc': 0.99136}\n",
      "test: {'epoch': 4, 'time_epoch': 3.65736, 'loss': 0.45886561, 'lr': 0, 'params': 304204, 'time_iter': 0.07782, 'accuracy': 0.9396, 'f1': 0.93889, 'auc': 0.99311}\n",
      "> Epoch 4: took 69.2s (avg 69.9s) | Best so far: epoch 4\ttrain_loss: 0.5875 train_accuracy: 0.9256\tval_loss: 0.4859 val_accuracy: 0.9328\ttest_loss: 0.4589 test_accuracy: 0.9396\n",
      "train: {'epoch': 5, 'time_epoch': 65.42421, 'eta': 4024.27889, 'eta_hours': 1.11786, 'loss': 0.40077297, 'lr': 0.001, 'params': 304204, 'time_iter': 0.1754, 'accuracy': 0.93467, 'f1': 0.93436, 'auc': 0.99138}\n",
      "val: {'epoch': 5, 'time_epoch': 3.77852, 'loss': 0.51556533, 'lr': 0, 'params': 304204, 'time_iter': 0.08039, 'accuracy': 0.86694, 'f1': 0.87034, 'auc': 0.98085}\n",
      "test: {'epoch': 5, 'time_epoch': 3.57874, 'loss': 0.52733314, 'lr': 0, 'params': 304204, 'time_iter': 0.07614, 'accuracy': 0.8604, 'f1': 0.86149, 'auc': 0.98272}\n",
      "> Epoch 5: took 72.8s (avg 70.4s) | Best so far: epoch 4\ttrain_loss: 0.5875 train_accuracy: 0.9256\tval_loss: 0.4859 val_accuracy: 0.9328\ttest_loss: 0.4589 test_accuracy: 0.9396\n",
      "train: {'epoch': 6, 'time_epoch': 63.63845, 'eta': 3968.23135, 'eta_hours': 1.10229, 'loss': 0.28012298, 'lr': 0.00099942, 'params': 304204, 'time_iter': 0.17061, 'accuracy': 0.95045, 'f1': 0.95029, 'auc': 0.99378}\n",
      "val: {'epoch': 6, 'time_epoch': 3.85608, 'loss': 0.48514005, 'lr': 0, 'params': 304204, 'time_iter': 0.08204, 'accuracy': 0.87366, 'f1': 0.87664, 'auc': 0.98784}\n",
      "test: {'epoch': 6, 'time_epoch': 3.57402, 'loss': 0.58730083, 'lr': 0, 'params': 304204, 'time_iter': 0.07604, 'accuracy': 0.82282, 'f1': 0.83251, 'auc': 0.98624}\n",
      "> Epoch 6: took 71.1s (avg 70.5s) | Best so far: epoch 4\ttrain_loss: 0.5875 train_accuracy: 0.9256\tval_loss: 0.4859 val_accuracy: 0.9328\ttest_loss: 0.4589 test_accuracy: 0.9396\n",
      "train: {'epoch': 7, 'time_epoch': 63.67007, 'eta': 3910.53112, 'eta_hours': 1.08626, 'loss': 0.21887253, 'lr': 0.00099767, 'params': 304204, 'time_iter': 0.1707, 'accuracy': 0.95348, 'f1': 0.95347, 'auc': 0.99606}\n",
      "val: {'epoch': 7, 'time_epoch': 3.47964, 'loss': 0.20765078, 'lr': 0, 'params': 304204, 'time_iter': 0.07403, 'accuracy': 0.95833, 'f1': 0.95924, 'auc': 0.99541}\n",
      "test: {'epoch': 7, 'time_epoch': 3.52597, 'loss': 0.1821404, 'lr': 0, 'params': 304204, 'time_iter': 0.07502, 'accuracy': 0.96376, 'f1': 0.96386, 'auc': 0.99707}\n",
      "> Epoch 7: took 70.7s (avg 70.5s) | Best so far: epoch 7\ttrain_loss: 0.2189 train_accuracy: 0.9535\tval_loss: 0.2077 val_accuracy: 0.9583\ttest_loss: 0.1821 test_accuracy: 0.9638\n",
      "train: {'epoch': 8, 'time_epoch': 62.87506, 'eta': 3846.11592, 'eta_hours': 1.06837, 'loss': 0.16677868, 'lr': 0.00099475, 'params': 304204, 'time_iter': 0.16857, 'accuracy': 0.96322, 'f1': 0.96312, 'auc': 0.9975}\n",
      "val: {'epoch': 8, 'time_epoch': 4.17354, 'loss': 0.16189869, 'lr': 0, 'params': 304204, 'time_iter': 0.0888, 'accuracy': 0.96371, 'f1': 0.96447, 'auc': 0.9986}\n",
      "test: {'epoch': 8, 'time_epoch': 3.56859, 'loss': 0.17063797, 'lr': 0, 'params': 304204, 'time_iter': 0.07593, 'accuracy': 0.96242, 'f1': 0.96119, 'auc': 0.99745}\n",
      "> Epoch 8: took 70.7s (avg 70.5s) | Best so far: epoch 8\ttrain_loss: 0.1668 train_accuracy: 0.9632\tval_loss: 0.1619 val_accuracy: 0.9637\ttest_loss: 0.1706 test_accuracy: 0.9624\n",
      "train: {'epoch': 9, 'time_epoch': 64.18351, 'eta': 3789.85942, 'eta_hours': 1.05274, 'loss': 0.13564606, 'lr': 0.00099069, 'params': 304204, 'time_iter': 0.17207, 'accuracy': 0.97111, 'f1': 0.97114, 'auc': 0.99808}\n",
      "val: {'epoch': 9, 'time_epoch': 3.51699, 'loss': 0.1537605, 'lr': 0, 'params': 304204, 'time_iter': 0.07483, 'accuracy': 0.96371, 'f1': 0.96415, 'auc': 0.99717}\n",
      "test: {'epoch': 9, 'time_epoch': 3.70687, 'loss': 0.20837273, 'lr': 0, 'params': 304204, 'time_iter': 0.07887, 'accuracy': 0.94631, 'f1': 0.94523, 'auc': 0.99588}\n",
      "> Epoch 9: took 71.5s (avg 70.6s) | Best so far: epoch 8\ttrain_loss: 0.1668 train_accuracy: 0.9632\tval_loss: 0.1619 val_accuracy: 0.9637\ttest_loss: 0.1706 test_accuracy: 0.9624\n",
      "train: {'epoch': 10, 'time_epoch': 63.52518, 'eta': 3728.63057, 'eta_hours': 1.03573, 'loss': 0.10519556, 'lr': 0.00098547, 'params': 304204, 'time_iter': 0.17031, 'accuracy': 0.978, 'f1': 0.97797, 'auc': 0.9983}\n",
      "val: {'epoch': 10, 'time_epoch': 3.66862, 'loss': 0.1752361, 'lr': 0, 'params': 304204, 'time_iter': 0.07806, 'accuracy': 0.95833, 'f1': 0.95904, 'auc': 0.99853}\n",
      "test: {'epoch': 10, 'time_epoch': 3.55124, 'loss': 0.18713547, 'lr': 0, 'params': 304204, 'time_iter': 0.07556, 'accuracy': 0.95302, 'f1': 0.95318, 'auc': 0.99737}\n",
      "> Epoch 10: took 70.8s (avg 70.6s) | Best so far: epoch 8\ttrain_loss: 0.1668 train_accuracy: 0.9632\tval_loss: 0.1619 val_accuracy: 0.9637\ttest_loss: 0.1706 test_accuracy: 0.9624\n",
      "train: {'epoch': 11, 'time_epoch': 61.68841, 'eta': 3658.1413, 'eta_hours': 1.01615, 'loss': 0.08593017, 'lr': 0.00097912, 'params': 304204, 'time_iter': 0.16538, 'accuracy': 0.98018, 'f1': 0.98018, 'auc': 0.99923}\n",
      "val: {'epoch': 11, 'time_epoch': 3.46568, 'loss': 0.20869504, 'lr': 0, 'params': 304204, 'time_iter': 0.07374, 'accuracy': 0.9422, 'f1': 0.9433, 'auc': 0.99643}\n",
      "test: {'epoch': 11, 'time_epoch': 3.57693, 'loss': 0.1332805, 'lr': 0, 'params': 304204, 'time_iter': 0.0761, 'accuracy': 0.9651, 'f1': 0.96489, 'auc': 0.99687}\n",
      "> Epoch 11: took 68.8s (avg 70.5s) | Best so far: epoch 8\ttrain_loss: 0.1668 train_accuracy: 0.9632\tval_loss: 0.1619 val_accuracy: 0.9637\ttest_loss: 0.1706 test_accuracy: 0.9624\n",
      "train: {'epoch': 12, 'time_epoch': 62.4086, 'eta': 3592.16377, 'eta_hours': 0.99782, 'loss': 0.07511866, 'lr': 0.00097166, 'params': 304204, 'time_iter': 0.16732, 'accuracy': 0.98287, 'f1': 0.98282, 'auc': 0.99924}\n",
      "val: {'epoch': 12, 'time_epoch': 3.4431, 'loss': 0.14360774, 'lr': 0, 'params': 304204, 'time_iter': 0.07326, 'accuracy': 0.95699, 'f1': 0.9574, 'auc': 0.99853}\n",
      "test: {'epoch': 12, 'time_epoch': 3.53542, 'loss': 0.16984079, 'lr': 0, 'params': 304204, 'time_iter': 0.07522, 'accuracy': 0.96376, 'f1': 0.96304, 'auc': 0.99493}\n",
      "> Epoch 12: took 69.4s (avg 70.4s) | Best so far: epoch 8\ttrain_loss: 0.1668 train_accuracy: 0.9632\tval_loss: 0.1619 val_accuracy: 0.9637\ttest_loss: 0.1706 test_accuracy: 0.9624\n",
      "train: {'epoch': 13, 'time_epoch': 64.00214, 'eta': 3533.07023, 'eta_hours': 0.98141, 'loss': 0.07195454, 'lr': 0.00096309, 'params': 304204, 'time_iter': 0.17159, 'accuracy': 0.98203, 'f1': 0.98203, 'auc': 0.99931}\n",
      "val: {'epoch': 13, 'time_epoch': 3.91532, 'loss': 0.12682442, 'lr': 0, 'params': 304204, 'time_iter': 0.0833, 'accuracy': 0.97043, 'f1': 0.97122, 'auc': 0.99719}\n",
      "test: {'epoch': 13, 'time_epoch': 3.64788, 'loss': 0.16467648, 'lr': 0, 'params': 304204, 'time_iter': 0.07761, 'accuracy': 0.95705, 'f1': 0.95733, 'auc': 0.99803}\n",
      "> Epoch 13: took 71.6s (avg 70.5s) | Best so far: epoch 13\ttrain_loss: 0.0720 train_accuracy: 0.9820\tval_loss: 0.1268 val_accuracy: 0.9704\ttest_loss: 0.1647 test_accuracy: 0.9570\n",
      "train: {'epoch': 14, 'time_epoch': 64.4613, 'eta': 3475.00583, 'eta_hours': 0.96528, 'loss': 0.05548851, 'lr': 0.00095344, 'params': 304204, 'time_iter': 0.17282, 'accuracy': 0.98656, 'f1': 0.98665, 'auc': 0.99958}\n",
      "val: {'epoch': 14, 'time_epoch': 4.17038, 'loss': 0.15191939, 'lr': 0, 'params': 304204, 'time_iter': 0.08873, 'accuracy': 0.96505, 'f1': 0.96596, 'auc': 0.99827}\n",
      "test: {'epoch': 14, 'time_epoch': 4.30449, 'loss': 0.16882261, 'lr': 0, 'params': 304204, 'time_iter': 0.09158, 'accuracy': 0.95973, 'f1': 0.96012, 'auc': 0.99823}\n",
      "> Epoch 14: took 73.0s (avg 70.7s) | Best so far: epoch 13\ttrain_loss: 0.0720 train_accuracy: 0.9820\tval_loss: 0.1268 val_accuracy: 0.9704\ttest_loss: 0.1647 test_accuracy: 0.9570\n",
      "train: {'epoch': 15, 'time_epoch': 63.43959, 'eta': 3412.69352, 'eta_hours': 0.94797, 'loss': 0.05779359, 'lr': 0.00094273, 'params': 304204, 'time_iter': 0.17008, 'accuracy': 0.98623, 'f1': 0.98625, 'auc': 0.99958}\n",
      "val: {'epoch': 15, 'time_epoch': 3.57625, 'loss': 0.15611279, 'lr': 0, 'params': 304204, 'time_iter': 0.07609, 'accuracy': 0.96102, 'f1': 0.96126, 'auc': 0.99773}\n",
      "test: {'epoch': 15, 'time_epoch': 4.07917, 'loss': 0.16063574, 'lr': 0, 'params': 304204, 'time_iter': 0.08679, 'accuracy': 0.96242, 'f1': 0.96112, 'auc': 0.99825}\n",
      "> Epoch 15: took 71.2s (avg 70.7s) | Best so far: epoch 13\ttrain_loss: 0.0720 train_accuracy: 0.9820\tval_loss: 0.1268 val_accuracy: 0.9704\ttest_loss: 0.1647 test_accuracy: 0.9570\n",
      "train: {'epoch': 16, 'time_epoch': 64.78842, 'eta': 3354.45376, 'eta_hours': 0.93179, 'loss': 0.05507538, 'lr': 0.00093098, 'params': 304204, 'time_iter': 0.1737, 'accuracy': 0.98488, 'f1': 0.9849, 'auc': 0.99974}\n",
      "val: {'epoch': 16, 'time_epoch': 4.04542, 'loss': 0.21178443, 'lr': 0, 'params': 304204, 'time_iter': 0.08607, 'accuracy': 0.94758, 'f1': 0.94905, 'auc': 0.99677}\n",
      "test: {'epoch': 16, 'time_epoch': 3.84552, 'loss': 0.20914073, 'lr': 0, 'params': 304204, 'time_iter': 0.08182, 'accuracy': 0.94094, 'f1': 0.93779, 'auc': 0.99832}\n",
      "> Epoch 16: took 72.8s (avg 70.8s) | Best so far: epoch 13\ttrain_loss: 0.0720 train_accuracy: 0.9820\tval_loss: 0.1268 val_accuracy: 0.9704\ttest_loss: 0.1647 test_accuracy: 0.9570\n",
      "train: {'epoch': 17, 'time_epoch': 63.81599, 'eta': 3292.67714, 'eta_hours': 0.91463, 'loss': 0.04244029, 'lr': 0.00091824, 'params': 304204, 'time_iter': 0.17109, 'accuracy': 0.98975, 'f1': 0.98975, 'auc': 0.99956}\n",
      "val: {'epoch': 17, 'time_epoch': 3.69976, 'loss': 0.18745376, 'lr': 0, 'params': 304204, 'time_iter': 0.07872, 'accuracy': 0.95833, 'f1': 0.95947, 'auc': 0.99696}\n",
      "test: {'epoch': 17, 'time_epoch': 3.53372, 'loss': 0.12778962, 'lr': 0, 'params': 304204, 'time_iter': 0.07519, 'accuracy': 0.97315, 'f1': 0.97398, 'auc': 0.99671}\n",
      "> Epoch 17: took 71.1s (avg 70.8s) | Best so far: epoch 13\ttrain_loss: 0.0720 train_accuracy: 0.9820\tval_loss: 0.1268 val_accuracy: 0.9704\ttest_loss: 0.1647 test_accuracy: 0.9570\n",
      "train: {'epoch': 18, 'time_epoch': 63.95341, 'eta': 3231.05471, 'eta_hours': 0.89752, 'loss': 0.02899786, 'lr': 0.00090451, 'params': 304204, 'time_iter': 0.17146, 'accuracy': 0.99261, 'f1': 0.99257, 'auc': 0.9998}\n",
      "val: {'epoch': 18, 'time_epoch': 3.7143, 'loss': 0.09465431, 'lr': 0, 'params': 304204, 'time_iter': 0.07903, 'accuracy': 0.97849, 'f1': 0.97896, 'auc': 0.99833}\n",
      "test: {'epoch': 18, 'time_epoch': 4.12185, 'loss': 0.151561, 'lr': 0, 'params': 304204, 'time_iter': 0.0877, 'accuracy': 0.96376, 'f1': 0.96351, 'auc': 0.99822}\n",
      "> Epoch 18: took 71.9s (avg 70.9s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 19, 'time_epoch': 66.45934, 'eta': 3175.46402, 'eta_hours': 0.88207, 'loss': 0.03622908, 'lr': 0.00088984, 'params': 304204, 'time_iter': 0.17818, 'accuracy': 0.99177, 'f1': 0.99174, 'auc': 0.99979}\n",
      "val: {'epoch': 19, 'time_epoch': 4.44725, 'loss': 0.15294847, 'lr': 0, 'params': 304204, 'time_iter': 0.09462, 'accuracy': 0.96371, 'f1': 0.96466, 'auc': 0.99863}\n",
      "test: {'epoch': 19, 'time_epoch': 4.48453, 'loss': 0.14218673, 'lr': 0, 'params': 304204, 'time_iter': 0.09542, 'accuracy': 0.97181, 'f1': 0.9717, 'auc': 0.99884}\n",
      "> Epoch 19: took 75.5s (avg 71.1s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 20, 'time_epoch': 67.22794, 'eta': 3120.63162, 'eta_hours': 0.86684, 'loss': 0.03699994, 'lr': 0.00087426, 'params': 304204, 'time_iter': 0.18024, 'accuracy': 0.99026, 'f1': 0.99021, 'auc': 0.99978}\n",
      "val: {'epoch': 20, 'time_epoch': 4.29236, 'loss': 0.10316331, 'lr': 0, 'params': 304204, 'time_iter': 0.09133, 'accuracy': 0.97581, 'f1': 0.97629, 'auc': 0.99896}\n",
      "test: {'epoch': 20, 'time_epoch': 4.69158, 'loss': 0.14868492, 'lr': 0, 'params': 304204, 'time_iter': 0.09982, 'accuracy': 0.96644, 'f1': 0.96737, 'auc': 0.99615}\n",
      "> Epoch 20: took 76.3s (avg 71.4s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 21, 'time_epoch': 70.39173, 'eta': 3071.57515, 'eta_hours': 0.85322, 'loss': 0.03586637, 'lr': 0.0008578, 'params': 304204, 'time_iter': 0.18872, 'accuracy': 0.99009, 'f1': 0.99009, 'auc': 0.99976}\n",
      "val: {'epoch': 21, 'time_epoch': 4.38497, 'loss': 0.13569346, 'lr': 0, 'params': 304204, 'time_iter': 0.0933, 'accuracy': 0.96505, 'f1': 0.96534, 'auc': 0.99873}\n",
      "test: {'epoch': 21, 'time_epoch': 4.48701, 'loss': 0.12264487, 'lr': 0, 'params': 304204, 'time_iter': 0.09547, 'accuracy': 0.97047, 'f1': 0.97051, 'auc': 0.99736}\n",
      "> Epoch 21: took 79.4s (avg 71.7s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 22, 'time_epoch': 70.95153, 'eta': 3021.8074, 'eta_hours': 0.83939, 'loss': 0.03124715, 'lr': 0.00084051, 'params': 304204, 'time_iter': 0.19022, 'accuracy': 0.99194, 'f1': 0.99191, 'auc': 0.99984}\n",
      "val: {'epoch': 22, 'time_epoch': 4.42886, 'loss': 0.16136622, 'lr': 0, 'params': 304204, 'time_iter': 0.09423, 'accuracy': 0.96102, 'f1': 0.96164, 'auc': 0.99734}\n",
      "test: {'epoch': 22, 'time_epoch': 4.30521, 'loss': 0.12790082, 'lr': 0, 'params': 304204, 'time_iter': 0.0916, 'accuracy': 0.96779, 'f1': 0.96728, 'auc': 0.99916}\n",
      "> Epoch 22: took 79.8s (avg 72.1s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 23, 'time_epoch': 70.53166, 'eta': 2969.46957, 'eta_hours': 0.82485, 'loss': 0.02256086, 'lr': 0.00082242, 'params': 304204, 'time_iter': 0.18909, 'accuracy': 0.99446, 'f1': 0.99447, 'auc': 0.99974}\n",
      "val: {'epoch': 23, 'time_epoch': 4.59889, 'loss': 0.15177401, 'lr': 0, 'params': 304204, 'time_iter': 0.09785, 'accuracy': 0.96774, 'f1': 0.96786, 'auc': 0.99655}\n",
      "test: {'epoch': 23, 'time_epoch': 4.37839, 'loss': 0.15029725, 'lr': 0, 'params': 304204, 'time_iter': 0.09316, 'accuracy': 0.97047, 'f1': 0.97037, 'auc': 0.99672}\n",
      "> Epoch 23: took 79.6s (avg 72.4s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 24, 'time_epoch': 71.98626, 'eta': 2918.29451, 'eta_hours': 0.81064, 'loss': 0.01325164, 'lr': 0.00080358, 'params': 304204, 'time_iter': 0.19299, 'accuracy': 0.99631, 'f1': 0.99631, 'auc': 0.99984}\n",
      "val: {'epoch': 24, 'time_epoch': 4.68004, 'loss': 0.17922855, 'lr': 0, 'params': 304204, 'time_iter': 0.09958, 'accuracy': 0.96237, 'f1': 0.96319, 'auc': 0.99694}\n",
      "test: {'epoch': 24, 'time_epoch': 4.33916, 'loss': 0.18518802, 'lr': 0, 'params': 304204, 'time_iter': 0.09232, 'accuracy': 0.96644, 'f1': 0.96562, 'auc': 0.99828}\n",
      "> Epoch 24: took 81.1s (avg 72.7s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 25, 'time_epoch': 73.06967, 'eta': 2867.35206, 'eta_hours': 0.79649, 'loss': 0.01565211, 'lr': 0.00078403, 'params': 304204, 'time_iter': 0.1959, 'accuracy': 0.99563, 'f1': 0.99563, 'auc': 0.99999}\n",
      "val: {'epoch': 25, 'time_epoch': 4.69636, 'loss': 0.24438428, 'lr': 0, 'params': 304204, 'time_iter': 0.09992, 'accuracy': 0.95296, 'f1': 0.9533, 'auc': 0.99714}\n",
      "test: {'epoch': 25, 'time_epoch': 4.61531, 'loss': 0.23571309, 'lr': 0, 'params': 304204, 'time_iter': 0.0982, 'accuracy': 0.94631, 'f1': 0.94684, 'auc': 0.99848}\n",
      "> Epoch 25: took 82.5s (avg 73.1s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 26, 'time_epoch': 72.64789, 'eta': 2814.09883, 'eta_hours': 0.78169, 'loss': 0.02492757, 'lr': 0.00076382, 'params': 304204, 'time_iter': 0.19477, 'accuracy': 0.99379, 'f1': 0.99376, 'auc': 0.99991}\n",
      "val: {'epoch': 26, 'time_epoch': 4.44601, 'loss': 0.13112597, 'lr': 0, 'params': 304204, 'time_iter': 0.0946, 'accuracy': 0.96774, 'f1': 0.96851, 'auc': 0.9992}\n",
      "test: {'epoch': 26, 'time_epoch': 4.49175, 'loss': 0.1396207, 'lr': 0, 'params': 304204, 'time_iter': 0.09557, 'accuracy': 0.96913, 'f1': 0.96918, 'auc': 0.99928}\n",
      "> Epoch 26: took 81.7s (avg 73.4s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 27, 'time_epoch': 71.56862, 'eta': 2757.84135, 'eta_hours': 0.76607, 'loss': 0.01637843, 'lr': 0.00074299, 'params': 304204, 'time_iter': 0.19187, 'accuracy': 0.99496, 'f1': 0.99497, 'auc': 0.99989}\n",
      "val: {'epoch': 27, 'time_epoch': 4.47324, 'loss': 0.16203315, 'lr': 0, 'params': 304204, 'time_iter': 0.09518, 'accuracy': 0.96909, 'f1': 0.97018, 'auc': 0.99838}\n",
      "test: {'epoch': 27, 'time_epoch': 4.2802, 'loss': 0.12314192, 'lr': 0, 'params': 304204, 'time_iter': 0.09107, 'accuracy': 0.97315, 'f1': 0.9733, 'auc': 0.99854}\n",
      "> Epoch 27: took 80.4s (avg 73.7s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 28, 'time_epoch': 71.15297, 'eta': 2699.9403, 'eta_hours': 0.74998, 'loss': 0.01901148, 'lr': 0.0007216, 'params': 304204, 'time_iter': 0.19076, 'accuracy': 0.99429, 'f1': 0.99427, 'auc': 0.99996}\n",
      "val: {'epoch': 28, 'time_epoch': 4.50867, 'loss': 0.20675192, 'lr': 0, 'params': 304204, 'time_iter': 0.09593, 'accuracy': 0.96102, 'f1': 0.96168, 'auc': 0.99584}\n",
      "test: {'epoch': 28, 'time_epoch': 4.36331, 'loss': 0.14549995, 'lr': 0, 'params': 304204, 'time_iter': 0.09284, 'accuracy': 0.96644, 'f1': 0.96712, 'auc': 0.99832}\n",
      "> Epoch 28: took 80.1s (avg 73.9s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 29, 'time_epoch': 70.75012, 'eta': 2640.61866, 'eta_hours': 0.73351, 'loss': 0.02206784, 'lr': 0.00069968, 'params': 304204, 'time_iter': 0.18968, 'accuracy': 0.99328, 'f1': 0.99327, 'auc': 0.99996}\n",
      "val: {'epoch': 29, 'time_epoch': 4.32194, 'loss': 0.15129582, 'lr': 0, 'params': 304204, 'time_iter': 0.09196, 'accuracy': 0.96774, 'f1': 0.96873, 'auc': 0.99931}\n",
      "test: {'epoch': 29, 'time_epoch': 4.52775, 'loss': 0.17083273, 'lr': 0, 'params': 304204, 'time_iter': 0.09634, 'accuracy': 0.96779, 'f1': 0.96857, 'auc': 0.99878}\n",
      "> Epoch 29: took 79.7s (avg 74.1s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 30, 'time_epoch': 71.63667, 'eta': 2581.67502, 'eta_hours': 0.71713, 'loss': 0.01337176, 'lr': 0.0006773, 'params': 304204, 'time_iter': 0.19206, 'accuracy': 0.99614, 'f1': 0.99611, 'auc': 0.99994}\n",
      "val: {'epoch': 30, 'time_epoch': 4.3825, 'loss': 0.16544022, 'lr': 0, 'params': 304204, 'time_iter': 0.09324, 'accuracy': 0.96774, 'f1': 0.96871, 'auc': 0.99739}\n",
      "test: {'epoch': 30, 'time_epoch': 4.61629, 'loss': 0.15943512, 'lr': 0, 'params': 304204, 'time_iter': 0.09822, 'accuracy': 0.9651, 'f1': 0.96422, 'auc': 0.99822}\n",
      "> Epoch 30: took 80.8s (avg 74.3s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 31, 'time_epoch': 72.50767, 'eta': 2522.97239, 'eta_hours': 0.70083, 'loss': 0.01520937, 'lr': 0.00065451, 'params': 304204, 'time_iter': 0.19439, 'accuracy': 0.99479, 'f1': 0.9948, 'auc': 0.99998}\n",
      "val: {'epoch': 31, 'time_epoch': 4.5079, 'loss': 0.10138415, 'lr': 0, 'params': 304204, 'time_iter': 0.09591, 'accuracy': 0.97581, 'f1': 0.97657, 'auc': 0.9991}\n",
      "test: {'epoch': 31, 'time_epoch': 4.55728, 'loss': 0.13452585, 'lr': 0, 'params': 304204, 'time_iter': 0.09696, 'accuracy': 0.97315, 'f1': 0.97354, 'auc': 0.99918}\n",
      "> Epoch 31: took 81.7s (avg 74.5s) | Best so far: epoch 18\ttrain_loss: 0.0290 train_accuracy: 0.9926\tval_loss: 0.0947 val_accuracy: 0.9785\ttest_loss: 0.1516 test_accuracy: 0.9638\n",
      "train: {'epoch': 32, 'time_epoch': 68.69836, 'eta': 2459.16204, 'eta_hours': 0.6831, 'loss': 0.00842457, 'lr': 0.00063135, 'params': 304204, 'time_iter': 0.18418, 'accuracy': 0.99782, 'f1': 0.99782, 'auc': 0.99999}\n",
      "val: {'epoch': 32, 'time_epoch': 3.4989, 'loss': 0.09687196, 'lr': 0, 'params': 304204, 'time_iter': 0.07444, 'accuracy': 0.98118, 'f1': 0.9815, 'auc': 0.99949}\n",
      "test: {'epoch': 32, 'time_epoch': 3.57651, 'loss': 0.13309768, 'lr': 0, 'params': 304204, 'time_iter': 0.0761, 'accuracy': 0.97047, 'f1': 0.97037, 'auc': 0.99932}\n",
      "> Epoch 32: took 75.8s (avg 74.6s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n",
      "train: {'epoch': 33, 'time_epoch': 61.08163, 'eta': 2386.99939, 'eta_hours': 0.66306, 'loss': 0.00289665, 'lr': 0.00060789, 'params': 304204, 'time_iter': 0.16376, 'accuracy': 0.99866, 'f1': 0.99865, 'auc': 1.0}\n",
      "val: {'epoch': 33, 'time_epoch': 3.6182, 'loss': 0.13169239, 'lr': 0, 'params': 304204, 'time_iter': 0.07698, 'accuracy': 0.97312, 'f1': 0.97357, 'auc': 0.99821}\n",
      "test: {'epoch': 33, 'time_epoch': 3.57686, 'loss': 0.16715407, 'lr': 0, 'params': 304204, 'time_iter': 0.0761, 'accuracy': 0.96644, 'f1': 0.96588, 'auc': 0.99903}\n",
      "> Epoch 33: took 68.3s (avg 74.4s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n",
      "train: {'epoch': 34, 'time_epoch': 61.39134, 'eta': 2315.77965, 'eta_hours': 0.64327, 'loss': 0.00334746, 'lr': 0.00058418, 'params': 304204, 'time_iter': 0.16459, 'accuracy': 0.99882, 'f1': 0.99881, 'auc': 1.0}\n",
      "val: {'epoch': 34, 'time_epoch': 3.58578, 'loss': 0.13428208, 'lr': 0, 'params': 304204, 'time_iter': 0.07629, 'accuracy': 0.96909, 'f1': 0.96964, 'auc': 0.99898}\n",
      "test: {'epoch': 34, 'time_epoch': 3.65421, 'loss': 0.21130071, 'lr': 0, 'params': 304204, 'time_iter': 0.07775, 'accuracy': 0.96242, 'f1': 0.96149, 'auc': 0.99862}\n",
      "> Epoch 34: took 68.7s (avg 74.2s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n",
      "train: {'epoch': 35, 'time_epoch': 71.17749, 'eta': 2254.34841, 'eta_hours': 0.62621, 'loss': 0.016791, 'lr': 0.00056027, 'params': 304204, 'time_iter': 0.19082, 'accuracy': 0.99614, 'f1': 0.99612, 'auc': 0.99997}\n",
      "val: {'epoch': 35, 'time_epoch': 4.36504, 'loss': 0.15797233, 'lr': 0, 'params': 304204, 'time_iter': 0.09287, 'accuracy': 0.96909, 'f1': 0.96958, 'auc': 0.99817}\n",
      "test: {'epoch': 35, 'time_epoch': 4.64555, 'loss': 0.15107922, 'lr': 0, 'params': 304204, 'time_iter': 0.09884, 'accuracy': 0.97315, 'f1': 0.97321, 'auc': 0.99679}\n",
      "> Epoch 35: took 80.3s (avg 74.4s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n",
      "train: {'epoch': 36, 'time_epoch': 71.22172, 'eta': 2192.4298, 'eta_hours': 0.60901, 'loss': 0.00673774, 'lr': 0.00053622, 'params': 304204, 'time_iter': 0.19094, 'accuracy': 0.99849, 'f1': 0.99847, 'auc': 0.99998}\n",
      "val: {'epoch': 36, 'time_epoch': 4.29129, 'loss': 0.1341312, 'lr': 0, 'params': 304204, 'time_iter': 0.0913, 'accuracy': 0.97581, 'f1': 0.97636, 'auc': 0.99937}\n",
      "test: {'epoch': 36, 'time_epoch': 4.57245, 'loss': 0.16374025, 'lr': 0, 'params': 304204, 'time_iter': 0.09729, 'accuracy': 0.97181, 'f1': 0.97195, 'auc': 0.99755}\n",
      "> Epoch 36: took 80.2s (avg 74.6s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n",
      "train: {'epoch': 37, 'time_epoch': 64.56027, 'eta': 2124.4119, 'eta_hours': 0.59011, 'loss': 0.00961456, 'lr': 0.00051208, 'params': 304204, 'time_iter': 0.17308, 'accuracy': 0.99748, 'f1': 0.99748, 'auc': 0.99999}\n",
      "val: {'epoch': 37, 'time_epoch': 3.53769, 'loss': 0.11847868, 'lr': 0, 'params': 304204, 'time_iter': 0.07527, 'accuracy': 0.97312, 'f1': 0.97371, 'auc': 0.99915}\n",
      "test: {'epoch': 37, 'time_epoch': 3.62929, 'loss': 0.17967711, 'lr': 0, 'params': 304204, 'time_iter': 0.07722, 'accuracy': 0.96644, 'f1': 0.96677, 'auc': 0.99913}\n",
      "> Epoch 37: took 71.8s (avg 74.5s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n",
      "train: {'epoch': 38, 'time_epoch': 64.97158, 'eta': 2056.89826, 'eta_hours': 0.57136, 'loss': 0.00622753, 'lr': 0.00048792, 'params': 304204, 'time_iter': 0.17419, 'accuracy': 0.99849, 'f1': 0.9985, 'auc': 0.99999}\n",
      "val: {'epoch': 38, 'time_epoch': 4.55252, 'loss': 0.10604623, 'lr': 0, 'params': 304204, 'time_iter': 0.09686, 'accuracy': 0.97984, 'f1': 0.98032, 'auc': 0.99944}\n",
      "test: {'epoch': 38, 'time_epoch': 4.72747, 'loss': 0.19432186, 'lr': 0, 'params': 304204, 'time_iter': 0.10058, 'accuracy': 0.96913, 'f1': 0.9689, 'auc': 0.99872}\n",
      "> Epoch 38: took 74.4s (avg 74.5s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n",
      "train: {'epoch': 39, 'time_epoch': 65.15367, 'eta': 1989.64829, 'eta_hours': 0.55268, 'loss': 0.00768471, 'lr': 0.00046378, 'params': 304204, 'time_iter': 0.17467, 'accuracy': 0.99849, 'f1': 0.99848, 'auc': 0.99996}\n",
      "val: {'epoch': 39, 'time_epoch': 3.50504, 'loss': 0.10865782, 'lr': 0, 'params': 304204, 'time_iter': 0.07458, 'accuracy': 0.97715, 'f1': 0.97768, 'auc': 0.99948}\n",
      "test: {'epoch': 39, 'time_epoch': 3.54901, 'loss': 0.13747512, 'lr': 0, 'params': 304204, 'time_iter': 0.07551, 'accuracy': 0.9745, 'f1': 0.97459, 'auc': 0.99907}\n",
      "> Epoch 39: took 72.3s (avg 74.4s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n",
      "train: {'epoch': 40, 'time_epoch': 63.03266, 'eta': 1921.00034, 'eta_hours': 0.53361, 'loss': 0.00494514, 'lr': 0.00043973, 'params': 304204, 'time_iter': 0.16899, 'accuracy': 0.99866, 'f1': 0.99869, 'auc': 1.0}\n",
      "val: {'epoch': 40, 'time_epoch': 4.41448, 'loss': 0.11748712, 'lr': 0, 'params': 304204, 'time_iter': 0.09393, 'accuracy': 0.97581, 'f1': 0.97658, 'auc': 0.99954}\n",
      "test: {'epoch': 40, 'time_epoch': 4.26868, 'loss': 0.15185238, 'lr': 0, 'params': 304204, 'time_iter': 0.09082, 'accuracy': 0.97315, 'f1': 0.97239, 'auc': 0.99851}\n",
      "> Epoch 40: took 71.8s (avg 74.4s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n",
      "train: {'epoch': 41, 'time_epoch': 70.18346, 'eta': 1857.387, 'eta_hours': 0.51594, 'loss': 0.00591141, 'lr': 0.00041582, 'params': 304204, 'time_iter': 0.18816, 'accuracy': 0.99899, 'f1': 0.99898, 'auc': 0.99996}\n",
      "val: {'epoch': 41, 'time_epoch': 4.2738, 'loss': 0.12611296, 'lr': 0, 'params': 304204, 'time_iter': 0.09093, 'accuracy': 0.97715, 'f1': 0.9777, 'auc': 0.99948}\n",
      "test: {'epoch': 41, 'time_epoch': 4.4044, 'loss': 0.18923156, 'lr': 0, 'params': 304204, 'time_iter': 0.09371, 'accuracy': 0.96242, 'f1': 0.96159, 'auc': 0.99865}\n",
      "> Epoch 41: took 79.0s (avg 74.5s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n",
      "train: {'epoch': 42, 'time_epoch': 65.41163, 'eta': 1790.47181, 'eta_hours': 0.49735, 'loss': 0.00603633, 'lr': 0.00039211, 'params': 304204, 'time_iter': 0.17537, 'accuracy': 0.99866, 'f1': 0.99865, 'auc': 1.0}\n",
      "val: {'epoch': 42, 'time_epoch': 3.56874, 'loss': 0.11886751, 'lr': 0, 'params': 304204, 'time_iter': 0.07593, 'accuracy': 0.97849, 'f1': 0.9789, 'auc': 0.99934}\n",
      "test: {'epoch': 42, 'time_epoch': 3.62739, 'loss': 0.17199775, 'lr': 0, 'params': 304204, 'time_iter': 0.07718, 'accuracy': 0.97181, 'f1': 0.9705, 'auc': 0.99716}\n",
      "> Epoch 42: took 72.7s (avg 74.4s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n",
      "train: {'epoch': 43, 'time_epoch': 63.58474, 'eta': 1722.54542, 'eta_hours': 0.47848, 'loss': 0.00633676, 'lr': 0.00036865, 'params': 304204, 'time_iter': 0.17047, 'accuracy': 0.99832, 'f1': 0.9983, 'auc': 0.99998}\n",
      "val: {'epoch': 43, 'time_epoch': 4.37766, 'loss': 0.08906142, 'lr': 0, 'params': 304204, 'time_iter': 0.09314, 'accuracy': 0.98118, 'f1': 0.9816, 'auc': 0.99955}\n",
      "test: {'epoch': 43, 'time_epoch': 4.3833, 'loss': 0.16057637, 'lr': 0, 'params': 304204, 'time_iter': 0.09326, 'accuracy': 0.96779, 'f1': 0.96696, 'auc': 0.9988}\n",
      "> Epoch 43: took 72.4s (avg 74.4s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n",
      "train: {'epoch': 44, 'time_epoch': 73.78823, 'eta': 1660.48061, 'eta_hours': 0.46124, 'loss': 0.00127886, 'lr': 0.00034549, 'params': 304204, 'time_iter': 0.19782, 'accuracy': 0.99983, 'f1': 0.99983, 'auc': 1.0}\n",
      "val: {'epoch': 44, 'time_epoch': 4.85954, 'loss': 0.11743939, 'lr': 0, 'params': 304204, 'time_iter': 0.10339, 'accuracy': 0.97581, 'f1': 0.97625, 'auc': 0.99953}\n",
      "test: {'epoch': 44, 'time_epoch': 4.55402, 'loss': 0.1641873, 'lr': 0, 'params': 304204, 'time_iter': 0.09689, 'accuracy': 0.97047, 'f1': 0.97001, 'auc': 0.99883}\n",
      "> Epoch 44: took 83.3s (avg 74.6s) | Best so far: epoch 32\ttrain_loss: 0.0084 train_accuracy: 0.9978\tval_loss: 0.0969 val_accuracy: 0.9812\ttest_loss: 0.1331 test_accuracy: 0.9705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Age using Exphormer 5 layers and 2 att heads 0.1 att dropout 0.1 dropout\n",
    "%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210e452-3423-47af-9795-365388201940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age using Exphormer 5 layers and 4 att heads 0.1 att dropout 0.1 dropout\n",
    "#%run main.py --cfg configs/Exphormer/neural-Act.yaml  wandb.use False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3bb2e8-6e40-4642-9792-603cc45a334c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8cdaf4-f78c-47fa-b988-9006b19dc1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d7ca31-0b99-4a04-883e-744549d138b2",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "faccc9a9-e4c8-43a4-a982-110cc4665fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "def parse_log(log):\n",
    "    '''This function takes a txt with the logs for an experiment and parse it to \n",
    "    obtain the keys and values for each epoch and phase (train, val, test)'''\n",
    "    parsed_logs = []\n",
    "    for line in log.split('\\n'):\n",
    "        if line.startswith('train:') or line.startswith('val:') or line.startswith('test:'):\n",
    "            # Split the line at the first colon\n",
    "            parts = line.split(': ', 1)\n",
    "            if len(parts) == 2:\n",
    "                try:\n",
    "                    # Attempt to parse the data as JSON\n",
    "                    data = json.loads(parts[1].replace(\"'\", '\"'))\n",
    "                    phase = parts[0]  # Extract the phase from the line\n",
    "                    data['phase'] = phase  # Add the phase to the dictionary\n",
    "                    parsed_logs.append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Error parsing line:\", line)\n",
    "    return parsed_logs\n",
    "\n",
    "\n",
    "# Log data\n",
    "def tb_log_data(parsed_data, log_dire, phase):\n",
    "    '''This function takes parsed data and creates tensorboard logs'''\n",
    "    \n",
    "    summary_writer = tf.summary.create_file_writer(log_dire)\n",
    "    with summary_writer.as_default():\n",
    "        for data in parsed_data:\n",
    "            if data['phase'] == phase:\n",
    "                epoch = data['epoch']\n",
    "                for key, value in data.items():\n",
    "                    if key != 'epoch' and key != 'phase':\n",
    "                        #tag = f\"{phase}/{key}\" #use if you want train, val, test in different plots\n",
    "                        tag = f\"{key}\" #use if you want train, val, test in the same plot\n",
    "                        tf.summary.scalar(tag, value, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f332ede5-b18d-4b7c-b1bf-3cef5c02396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tensorboard_logs(log_file_path, output_path):\n",
    "    '''this generates the log files for loading tensorboard from txt files\n",
    "    It assumes the txt contains the logs for train, val, and test, and creates \n",
    "    one folder for each to plot the three series using tensorboard'''\n",
    "\n",
    "    # Read log data from file\n",
    "    with open(log_file_path, \"r\") as f:\n",
    "        log_data = f.read()\n",
    "\n",
    "    # Parse log data\n",
    "    parsed_data = parse_log(log_data)\n",
    "    \n",
    "    #create output paths\n",
    "    train_log_dir = output_path+ \"train/\"  #results/other/exphormer/act/drop05/train/\"\n",
    "    val_log_dir = output_path+ \"val/\"\n",
    "    test_log_dir = output_path+ \"test/\"\n",
    "\n",
    "    #create logs\n",
    "    tb_log_data(parsed_data=parsed_data,log_dire=train_log_dir, phase='train')\n",
    "    tb_log_data(parsed_data=parsed_data,log_dire=val_log_dir, phase='val')\n",
    "    tb_log_data(parsed_data=parsed_data,log_dire=test_log_dir, phase='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bdab2d-cafc-4966-a4a4-8162e9683cd2",
   "metadata": {},
   "source": [
    "### Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2f579f5-c961-46b7-879c-fbab59d8d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exphormer\n",
    "output_path=\"results/other/exphormer/act/l3ah4do1attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/act/l3ah4do1attdo3/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/act/l3ah4do3attdo3/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/act/l3ah4do5attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/act/l3ah4do6attdo3/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/act/l5ah4do1attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b592fd6e-9ded-4543-bfef-887ec5d278da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GCN\n",
    "output_path=\"results/other/CGCN_Exphormer/act/l3ah4do1attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/CGCN_Exphormer/act/l3ah4do1attdo5/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/CGCN_Exphormer/act/l3ah4do3attdo3/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/CGCN_Exphormer/act/l3ah4do3attdo5/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23782296-bbe6-44fe-8a08-c2fb67e22c34",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a43ebd0-5020-4ba2-a510-e60506ad0cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exphormer\n",
    "output_path=\"results/other/exphormer/gender/l2ah4do1attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/gender/l2ah4do1attdo3/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/gender/l2ah4do1attdo5/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/gender/l2ah4do3attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/gender/l2ah4do3attdo3/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/gender/l3ah4do1attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "039289d5-c899-4163-81fb-8a66d166e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GCN\n",
    "output_path=\"results/other/CGCN_Exphormer/gender/l2ah4do1attdo3/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/CGCN_Exphormer/gender/l3ah4do1attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ced4aea-cb61-4914-9f49-4e641d09cbeb",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "932bd6bd-1bc8-4f75-bb38-86d86cee4ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path=\"results/other/exphormer/age/l2ah2do1attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/age/l2ah2do1attdo3/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/age/l2ah4do1attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/age/l2ah4do3attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/age/l3ah4do1attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/age/l3ah4do3attdo1/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)\n",
    "\n",
    "output_path=\"results/other/exphormer/age/l3ah4do3attdo3/\"\n",
    "log_file_path=output_path+\"log.txt\"\n",
    "gen_tensorboard_logs(log_file_path=log_file_path, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9d028-ef26-41b6-9d19-cad982f2fcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfecbac3-7120-4cf1-824d-c846cba92043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}